{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from Utils.nlp import get_word_to_index\n",
    "from Utils.neural_net import TrainLoopText, TextDataset\n",
    "from Utils.models import LSTMmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Data/multimodal.csv\")\n",
    "data['Caption'] = data['Caption'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, shuffle=True, stratify=data['LABEL'], random_state=1)\n",
    "train, val = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['LABEL'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.array(train['Caption'])\n",
    "test_text = np.array(test['Caption'])\n",
    "val_text = np.array(val['Caption'])\n",
    "\n",
    "train_label = np.array(train['LABEL'])\n",
    "test_label = np.array(test['LABEL'])\n",
    "val_label = np.array(val['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = get_word_to_index(\"../.vector_cache/glove.twitter.27B.25d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TextDataset(train_text, train_label, word_to_index)\n",
    "test_set = TextDataset(test_text, test_label, word_to_index)\n",
    "val_set = TextDataset(val_text, val_label, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, 32)\n",
    "test_loader = DataLoader(test_set, 32)\n",
    "val_loader = DataLoader(val_set, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Text only model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b9b214ed10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "text_modelv1 = LSTMmodel(4, 25, 256, bidirectionality=True)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.NAdam(text_modelv1.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def TrainLoopText(\n",
    "    model,\n",
    "    optimizer:torch.optim.Optimizer,\n",
    "    criterion:torch.nn.Module,\n",
    "    train_dataloader:torch.utils.data.DataLoader,\n",
    "    val_dataloader:torch.utils.data.DataLoader,\n",
    "    scheduler:torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    num_epochs:int=20,\n",
    "    early_stopping_rounds:int=5,\n",
    "    return_best_model:bool=True,\n",
    "    device:str='cpu'\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    total_train_loss = []\n",
    "    total_val_loss = []\n",
    "    best_model_weights = model.state_dict()\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        print(\"\\nEpoch {}\\n----------\".format(epoch))\n",
    "        train_loss = 0\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            text_indices = batch['text_indices'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(text_indices)\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Loss for batch {} = {}\".format(i, loss))\n",
    "\n",
    "        print(\"\\nTraining Loss for epoch {} = {}\\n\".format(epoch, train_loss))\n",
    "        total_train_loss.append(train_loss/len(train_dataloader.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        with torch.inference_mode():\n",
    "            val_true_labels = []\n",
    "            train_true_labels = []\n",
    "            val_pred_labels = []\n",
    "            train_pred_labels = []\n",
    "            for batch in val_dataloader:\n",
    "                text_indices = batch['text_indices'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                outputs = model(text_indices)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validation_loss += loss\n",
    "\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "                val_true_labels.extend(labels.cpu().numpy())\n",
    "                val_pred_labels.extend(outputs.cpu().numpy())\n",
    "\n",
    "            for batch in train_dataloader:\n",
    "                text_indices = batch['text_indices'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                outputs = model(text_indices)\n",
    "\n",
    "                outputs = torch.argmax(outputs, dim=1)\n",
    "                train_true_labels.extend(labels.cpu().numpy())\n",
    "                train_pred_labels.extend(outputs.cpu().numpy())\n",
    "\n",
    "            if validation_loss < best_val_loss:\n",
    "                best_val_loss = validation_loss\n",
    "                epochs_without_improvement = 0\n",
    "                best_model_weights = model.state_dict()\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "\n",
    "            val_true_labels = np.array(val_true_labels)\n",
    "            train_true_labels = np.array(train_true_labels)\n",
    "            val_pred_labels = np.array(val_pred_labels)\n",
    "            train_pred_labels = np.array(train_pred_labels)\n",
    "\n",
    "            train_accuracy = accuracy_score(train_true_labels, train_pred_labels)\n",
    "            val_accuracy = accuracy_score(val_true_labels, val_pred_labels)\n",
    "\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            print(f\"Current Validation Loss = {validation_loss}\")\n",
    "            print(f\"Best Validation Loss = {best_val_loss}\")\n",
    "            print(f\"Epochs without Improvement = {epochs_without_improvement}\")\n",
    "\n",
    "            print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "            print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "        \n",
    "        total_val_loss.append(validation_loss/len(val_dataloader.dataset))\n",
    "        scheduler.step(validation_loss)\n",
    "        \n",
    "        if epochs_without_improvement == early_stopping_rounds:\n",
    "            break\n",
    "\n",
    "    if return_best_model == True:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "    total_train_loss = [item.cpu().detach().numpy() for item in total_train_loss]\n",
    "    total_val_loss = [item.cpu().detach().numpy() for item in total_val_loss]\n",
    "\n",
    "    total_train_loss = np.array(total_train_loss)\n",
    "    total_val_loss = np.array(total_val_loss)\n",
    "\n",
    "    train_accuracies = np.array(train_accuracies)\n",
    "    val_accuracies = np.array(val_accuracies)\n",
    "\n",
    "    x_train = np.arange(len(total_train_loss))\n",
    "    x_val = np.arange(len(total_val_loss))\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(14,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    sns.lineplot(x=x_train, y=total_train_loss, label='Training Loss')\n",
    "    sns.lineplot(x=x_val, y=total_val_loss, label='Validation Loss')\n",
    "    plt.title(\"Loss over {} Epochs\".format(len(total_train_loss)))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xticks(np.arange(len(total_train_loss)))\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    sns.lineplot(x=x_train, y=train_accuracies, label='Training Accuracy')\n",
    "    sns.lineplot(x=x_val, y=val_accuracies, label='Validation Accuracy')\n",
    "    plt.title(\"Accuracy over {} Epochs\".format(len(total_train_loss)))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(np.arange(len(total_train_loss)))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fff8a24566f4444ad2a9dbf842e66c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "----------\n",
      "Loss for batch 0 = 1.097667932510376\n",
      "Loss for batch 1 = 1.1018106937408447\n",
      "Loss for batch 2 = 1.0960149765014648\n",
      "Loss for batch 3 = 1.081615924835205\n",
      "Loss for batch 4 = 1.099334955215454\n",
      "Loss for batch 5 = 1.1081565618515015\n",
      "Loss for batch 6 = 1.1096361875534058\n",
      "Loss for batch 7 = 1.0892208814620972\n",
      "Loss for batch 8 = 1.0873992443084717\n",
      "Loss for batch 9 = 1.0670220851898193\n",
      "Loss for batch 10 = 1.1529885530471802\n",
      "Loss for batch 11 = 1.102056860923767\n",
      "Loss for batch 12 = 1.103671669960022\n",
      "Loss for batch 13 = 1.1090586185455322\n",
      "Loss for batch 14 = 1.0916748046875\n",
      "Loss for batch 15 = 1.0763286352157593\n",
      "Loss for batch 16 = 1.092576026916504\n",
      "Loss for batch 17 = 1.0981913805007935\n",
      "Loss for batch 18 = 1.0846587419509888\n",
      "Loss for batch 19 = 1.077620506286621\n",
      "Loss for batch 20 = 1.067098617553711\n",
      "Loss for batch 21 = 1.0829699039459229\n",
      "Loss for batch 22 = 1.0949883460998535\n",
      "Loss for batch 23 = 1.1004576683044434\n",
      "Loss for batch 24 = 1.1425501108169556\n",
      "Loss for batch 25 = 1.1116575002670288\n",
      "Loss for batch 26 = 1.098962426185608\n",
      "Loss for batch 27 = 1.0784037113189697\n",
      "Loss for batch 28 = 1.1039127111434937\n",
      "Loss for batch 29 = 1.1057263612747192\n",
      "Loss for batch 30 = 1.1084238290786743\n",
      "Loss for batch 31 = 1.1271822452545166\n",
      "Loss for batch 32 = 1.0863637924194336\n",
      "Loss for batch 33 = 1.0983859300613403\n",
      "Loss for batch 34 = 1.0974900722503662\n",
      "Loss for batch 35 = 1.103562831878662\n",
      "Loss for batch 36 = 1.1046524047851562\n",
      "Loss for batch 37 = 1.0936193466186523\n",
      "Loss for batch 38 = 1.0861178636550903\n",
      "Loss for batch 39 = 1.0963209867477417\n",
      "Loss for batch 40 = 1.083753228187561\n",
      "Loss for batch 41 = 1.0783274173736572\n",
      "Loss for batch 42 = 1.107782244682312\n",
      "Loss for batch 43 = 1.0847883224487305\n",
      "Loss for batch 44 = 1.085848331451416\n",
      "Loss for batch 45 = 1.0959019660949707\n",
      "Loss for batch 46 = 1.1006799936294556\n",
      "Loss for batch 47 = 1.082662582397461\n",
      "Loss for batch 48 = 1.105594515800476\n",
      "Loss for batch 49 = 1.1010520458221436\n",
      "Loss for batch 50 = 1.0867011547088623\n",
      "Loss for batch 51 = 1.0805596113204956\n",
      "Loss for batch 52 = 1.2239940166473389\n",
      "Loss for batch 53 = 1.0875210762023926\n",
      "Loss for batch 54 = 1.1030241250991821\n",
      "Loss for batch 55 = 1.1036229133605957\n",
      "Loss for batch 56 = 1.081459641456604\n",
      "Loss for batch 57 = 1.0848050117492676\n",
      "Loss for batch 58 = 1.036740779876709\n",
      "Loss for batch 59 = 1.2377790212631226\n",
      "Loss for batch 60 = 1.0918015241622925\n",
      "Loss for batch 61 = 1.0864821672439575\n",
      "Loss for batch 62 = 1.081357479095459\n",
      "Loss for batch 63 = 1.0933865308761597\n",
      "Loss for batch 64 = 1.0652273893356323\n",
      "Loss for batch 65 = 1.079340934753418\n",
      "Loss for batch 66 = 1.1373406648635864\n",
      "Loss for batch 67 = 1.0523489713668823\n",
      "Loss for batch 68 = 1.1067417860031128\n",
      "Loss for batch 69 = 1.1032264232635498\n",
      "Loss for batch 70 = 1.1123361587524414\n",
      "Loss for batch 71 = 1.0815259218215942\n",
      "Loss for batch 72 = 1.0634806156158447\n",
      "Loss for batch 73 = 1.1191065311431885\n",
      "Loss for batch 74 = 1.0746887922286987\n",
      "Loss for batch 75 = 1.0872611999511719\n",
      "Loss for batch 76 = 1.0455825328826904\n",
      "Loss for batch 77 = 1.0585293769836426\n",
      "Loss for batch 78 = 1.0526336431503296\n",
      "Loss for batch 79 = 1.0199670791625977\n",
      "Loss for batch 80 = 1.2263599634170532\n",
      "Loss for batch 81 = 1.099479079246521\n",
      "Loss for batch 82 = 1.101181149482727\n",
      "Loss for batch 83 = 1.10386061668396\n",
      "Loss for batch 84 = 1.096655011177063\n",
      "Loss for batch 85 = 1.1048208475112915\n",
      "Loss for batch 86 = 1.0832716226577759\n",
      "Loss for batch 87 = 1.0908384323120117\n",
      "Loss for batch 88 = 1.052541732788086\n",
      "Loss for batch 89 = 1.0894173383712769\n",
      "Loss for batch 90 = 1.0839523077011108\n",
      "Loss for batch 91 = 1.127415418624878\n",
      "Loss for batch 92 = 1.0565732717514038\n",
      "Loss for batch 93 = 1.0894209146499634\n",
      "Loss for batch 94 = 1.1116559505462646\n",
      "Loss for batch 95 = 1.1027675867080688\n",
      "Loss for batch 96 = 1.1066207885742188\n",
      "Loss for batch 97 = 1.0887027978897095\n",
      "\n",
      "Training Loss for epoch 0 = 107.39604949951172\n",
      "\n",
      "Current Validation Loss = 27.142555236816406\n",
      "Best Validation Loss = 27.142555236816406\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.72%\n",
      "Validation Accuracy: 40.82%\n",
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss for batch 0 = 1.0558552742004395\n",
      "Loss for batch 1 = 1.0635666847229004\n",
      "Loss for batch 2 = 1.0924360752105713\n",
      "Loss for batch 3 = 1.0338630676269531\n",
      "Loss for batch 4 = 1.0582717657089233\n",
      "Loss for batch 5 = 1.0496829748153687\n",
      "Loss for batch 6 = 1.0755367279052734\n",
      "Loss for batch 7 = 1.0645920038223267\n",
      "Loss for batch 8 = 1.0839970111846924\n",
      "Loss for batch 9 = 1.0014954805374146\n",
      "Loss for batch 10 = 1.2099900245666504\n",
      "Loss for batch 11 = 1.1059479713439941\n",
      "Loss for batch 12 = 1.0608702898025513\n",
      "Loss for batch 13 = 1.0860235691070557\n",
      "Loss for batch 14 = 1.0296239852905273\n",
      "Loss for batch 15 = 1.1305391788482666\n",
      "Loss for batch 16 = 1.0345913171768188\n",
      "Loss for batch 17 = 0.9780058860778809\n",
      "Loss for batch 18 = 0.995625913143158\n",
      "Loss for batch 19 = 1.1379269361495972\n",
      "Loss for batch 20 = 1.0116490125656128\n",
      "Loss for batch 21 = 1.083117961883545\n",
      "Loss for batch 22 = 1.0125157833099365\n",
      "Loss for batch 23 = 1.0055568218231201\n",
      "Loss for batch 24 = 1.0311702489852905\n",
      "Loss for batch 25 = 1.0551490783691406\n",
      "Loss for batch 26 = 1.103951334953308\n",
      "Loss for batch 27 = 1.014758586883545\n",
      "Loss for batch 28 = 1.1110055446624756\n",
      "Loss for batch 29 = 1.1413882970809937\n",
      "Loss for batch 30 = 1.0624088048934937\n",
      "Loss for batch 31 = 1.0950790643692017\n",
      "Loss for batch 32 = 1.0891555547714233\n",
      "Loss for batch 33 = 1.098731517791748\n",
      "Loss for batch 34 = 0.9963947534561157\n",
      "Loss for batch 35 = 1.0897455215454102\n",
      "Loss for batch 36 = 1.093065619468689\n",
      "Loss for batch 37 = 1.1036289930343628\n",
      "Loss for batch 38 = 1.0705859661102295\n",
      "Loss for batch 39 = 1.0785938501358032\n",
      "Loss for batch 40 = 1.065754771232605\n",
      "Loss for batch 41 = 1.0715258121490479\n",
      "Loss for batch 42 = 1.0965403318405151\n",
      "Loss for batch 43 = 1.0485258102416992\n",
      "Loss for batch 44 = 1.072744369506836\n",
      "Loss for batch 45 = 1.0608447790145874\n",
      "Loss for batch 46 = 1.0768579244613647\n",
      "Loss for batch 47 = 1.06196928024292\n",
      "Loss for batch 48 = 1.1163933277130127\n",
      "Loss for batch 49 = 1.0278338193893433\n",
      "Loss for batch 50 = 0.9963200092315674\n",
      "Loss for batch 51 = 1.0345615148544312\n",
      "Loss for batch 52 = 1.1213926076889038\n",
      "Loss for batch 53 = 1.0789192914962769\n",
      "Loss for batch 54 = 1.1112412214279175\n",
      "Loss for batch 55 = 1.1239941120147705\n",
      "Loss for batch 56 = 1.0509169101715088\n",
      "Loss for batch 57 = 1.0817443132400513\n",
      "Loss for batch 58 = 0.9583709836006165\n",
      "Loss for batch 59 = 1.0907636880874634\n",
      "Loss for batch 60 = 1.1099597215652466\n",
      "Loss for batch 61 = 1.040046215057373\n",
      "Loss for batch 62 = 1.0089046955108643\n",
      "Loss for batch 63 = 1.0468180179595947\n",
      "Loss for batch 64 = 1.0002790689468384\n",
      "Loss for batch 65 = 1.0683680772781372\n",
      "Loss for batch 66 = 1.1892812252044678\n",
      "Loss for batch 67 = 1.0646158456802368\n",
      "Loss for batch 68 = 1.099953293800354\n",
      "Loss for batch 69 = 1.0611882209777832\n",
      "Loss for batch 70 = 1.1533769369125366\n",
      "Loss for batch 71 = 1.0626211166381836\n",
      "Loss for batch 72 = 1.03883957862854\n",
      "Loss for batch 73 = 1.1208502054214478\n",
      "Loss for batch 74 = 1.0600895881652832\n",
      "Loss for batch 75 = 1.0731143951416016\n",
      "Loss for batch 76 = 1.0214080810546875\n",
      "Loss for batch 77 = 1.0626349449157715\n",
      "Loss for batch 78 = 1.0178359746932983\n",
      "Loss for batch 79 = 1.0022928714752197\n",
      "Loss for batch 80 = 1.0947339534759521\n",
      "Loss for batch 81 = 1.1071873903274536\n",
      "Loss for batch 82 = 1.0910520553588867\n",
      "Loss for batch 83 = 1.0875298976898193\n",
      "Loss for batch 84 = 1.105332612991333\n",
      "Loss for batch 85 = 1.069173812866211\n",
      "Loss for batch 86 = 1.0566132068634033\n",
      "Loss for batch 87 = 1.0397812128067017\n",
      "Loss for batch 88 = 0.9621669054031372\n",
      "Loss for batch 89 = 1.113121509552002\n",
      "Loss for batch 90 = 1.090291976928711\n",
      "Loss for batch 91 = 1.175585150718689\n",
      "Loss for batch 92 = 1.01318359375\n",
      "Loss for batch 93 = 1.1180288791656494\n",
      "Loss for batch 94 = 1.1079258918762207\n",
      "Loss for batch 95 = 1.0435528755187988\n",
      "Loss for batch 96 = 1.0865941047668457\n",
      "Loss for batch 97 = 1.0528043508529663\n",
      "\n",
      "Training Loss for epoch 1 = 104.76043701171875\n",
      "\n",
      "Current Validation Loss = 26.59988784790039\n",
      "Best Validation Loss = 26.59988784790039\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 47.02%\n",
      "Validation Accuracy: 43.90%\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss for batch 0 = 1.0005683898925781\n",
      "Loss for batch 1 = 1.0366294384002686\n",
      "Loss for batch 2 = 1.09340500831604\n",
      "Loss for batch 3 = 0.9347154498100281\n",
      "Loss for batch 4 = 1.0162205696105957\n",
      "Loss for batch 5 = 0.9999364614486694\n",
      "Loss for batch 6 = 1.0537221431732178\n",
      "Loss for batch 7 = 1.1949522495269775\n",
      "Loss for batch 8 = 1.0820865631103516\n",
      "Loss for batch 9 = 0.9608360528945923\n",
      "Loss for batch 10 = 1.1912420988082886\n",
      "Loss for batch 11 = 1.088826060295105\n",
      "Loss for batch 12 = 1.053087592124939\n",
      "Loss for batch 13 = 1.1321784257888794\n",
      "Loss for batch 14 = 1.012627124786377\n",
      "Loss for batch 15 = 1.0767138004302979\n",
      "Loss for batch 16 = 1.023025393486023\n",
      "Loss for batch 17 = 0.9675915241241455\n",
      "Loss for batch 18 = 0.9476830363273621\n",
      "Loss for batch 19 = 1.1314244270324707\n",
      "Loss for batch 20 = 1.0081130266189575\n",
      "Loss for batch 21 = 1.0349094867706299\n",
      "Loss for batch 22 = 1.0303962230682373\n",
      "Loss for batch 23 = 0.9855570197105408\n",
      "Loss for batch 24 = 1.0446946620941162\n",
      "Loss for batch 25 = 1.0380699634552002\n",
      "Loss for batch 26 = 1.0796760320663452\n",
      "Loss for batch 27 = 1.0079096555709839\n",
      "Loss for batch 28 = 1.1219226121902466\n",
      "Loss for batch 29 = 1.0872392654418945\n",
      "Loss for batch 30 = 1.0150071382522583\n",
      "Loss for batch 31 = 1.1013118028640747\n",
      "Loss for batch 32 = 1.0636569261550903\n",
      "Loss for batch 33 = 1.1376137733459473\n",
      "Loss for batch 34 = 0.9704240560531616\n",
      "Loss for batch 35 = 1.0965815782546997\n",
      "Loss for batch 36 = 1.08095121383667\n",
      "Loss for batch 37 = 1.0499986410140991\n",
      "Loss for batch 38 = 1.0879992246627808\n",
      "Loss for batch 39 = 1.0781468152999878\n",
      "Loss for batch 40 = 1.0442055463790894\n",
      "Loss for batch 41 = 1.0254071950912476\n",
      "Loss for batch 42 = 1.1219580173492432\n",
      "Loss for batch 43 = 1.0288490056991577\n",
      "Loss for batch 44 = 1.0612142086029053\n",
      "Loss for batch 45 = 1.0452536344528198\n",
      "Loss for batch 46 = 1.0658937692642212\n",
      "Loss for batch 47 = 1.0191481113433838\n",
      "Loss for batch 48 = 1.0180386304855347\n",
      "Loss for batch 49 = 1.0012494325637817\n",
      "Loss for batch 50 = 0.9629491567611694\n",
      "Loss for batch 51 = 1.0038682222366333\n",
      "Loss for batch 52 = 1.1589410305023193\n",
      "Loss for batch 53 = 1.0765043497085571\n",
      "Loss for batch 54 = 1.0882154703140259\n",
      "Loss for batch 55 = 1.078838586807251\n",
      "Loss for batch 56 = 1.10706627368927\n",
      "Loss for batch 57 = 1.033069133758545\n",
      "Loss for batch 58 = 0.9893948435783386\n",
      "Loss for batch 59 = 1.1292227506637573\n",
      "Loss for batch 60 = 1.1029236316680908\n",
      "Loss for batch 61 = 1.0117449760437012\n",
      "Loss for batch 62 = 0.9810751676559448\n",
      "Loss for batch 63 = 1.077867031097412\n",
      "Loss for batch 64 = 0.972190797328949\n",
      "Loss for batch 65 = 1.0581085681915283\n",
      "Loss for batch 66 = 1.12385094165802\n",
      "Loss for batch 67 = 1.0033806562423706\n",
      "Loss for batch 68 = 1.0432668924331665\n",
      "Loss for batch 69 = 1.0875571966171265\n",
      "Loss for batch 70 = 1.1730643510818481\n",
      "Loss for batch 71 = 1.0149822235107422\n",
      "Loss for batch 72 = 0.9737692475318909\n",
      "Loss for batch 73 = 1.098131775856018\n",
      "Loss for batch 74 = 0.999343991279602\n",
      "Loss for batch 75 = 0.9744280576705933\n",
      "Loss for batch 76 = 0.9618389010429382\n",
      "Loss for batch 77 = 0.9454476833343506\n",
      "Loss for batch 78 = 1.0128591060638428\n",
      "Loss for batch 79 = 1.0101714134216309\n",
      "Loss for batch 80 = 1.0655311346054077\n",
      "Loss for batch 81 = 1.088509202003479\n",
      "Loss for batch 82 = 1.1111655235290527\n",
      "Loss for batch 83 = 1.0470556020736694\n",
      "Loss for batch 84 = 1.080057144165039\n",
      "Loss for batch 85 = 0.9990566968917847\n",
      "Loss for batch 86 = 1.0162216424942017\n",
      "Loss for batch 87 = 1.0244641304016113\n",
      "Loss for batch 88 = 0.9042541980743408\n",
      "Loss for batch 89 = 1.0255167484283447\n",
      "Loss for batch 90 = 1.0151249170303345\n",
      "Loss for batch 91 = 1.1941447257995605\n",
      "Loss for batch 92 = 1.0611025094985962\n",
      "Loss for batch 93 = 1.0644326210021973\n",
      "Loss for batch 94 = 1.085129737854004\n",
      "Loss for batch 95 = 1.1228505373001099\n",
      "Loss for batch 96 = 1.0898152589797974\n",
      "Loss for batch 97 = 1.0458563566207886\n",
      "\n",
      "Training Loss for epoch 2 = 102.84320068359375\n",
      "\n",
      "Current Validation Loss = 27.21053695678711\n",
      "Best Validation Loss = 26.59988784790039\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 42.75%\n",
      "Validation Accuracy: 39.41%\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss for batch 0 = 1.0524132251739502\n",
      "Loss for batch 1 = 1.0450655221939087\n",
      "Loss for batch 2 = 1.055139422416687\n",
      "Loss for batch 3 = 0.9611144661903381\n",
      "Loss for batch 4 = 1.053215742111206\n",
      "Loss for batch 5 = 1.000472068786621\n",
      "Loss for batch 6 = 1.0203492641448975\n",
      "Loss for batch 7 = 1.0878299474716187\n",
      "Loss for batch 8 = 1.0486117601394653\n",
      "Loss for batch 9 = 0.960286021232605\n",
      "Loss for batch 10 = 1.1728166341781616\n",
      "Loss for batch 11 = 1.1859601736068726\n",
      "Loss for batch 12 = 1.0222201347351074\n",
      "Loss for batch 13 = 1.1020253896713257\n",
      "Loss for batch 14 = 1.0094407796859741\n",
      "Loss for batch 15 = 1.0866791009902954\n",
      "Loss for batch 16 = 1.0006285905838013\n",
      "Loss for batch 17 = 0.9397779703140259\n",
      "Loss for batch 18 = 0.9518405199050903\n",
      "Loss for batch 19 = 1.0720089673995972\n",
      "Loss for batch 20 = 0.9358431696891785\n",
      "Loss for batch 21 = 1.0532630681991577\n",
      "Loss for batch 22 = 0.9785284996032715\n",
      "Loss for batch 23 = 0.9449474215507507\n",
      "Loss for batch 24 = 0.967904269695282\n",
      "Loss for batch 25 = 1.0248669385910034\n",
      "Loss for batch 26 = 1.047844409942627\n",
      "Loss for batch 27 = 0.9748890399932861\n",
      "Loss for batch 28 = 1.0745186805725098\n",
      "Loss for batch 29 = 1.1229121685028076\n",
      "Loss for batch 30 = 0.9898155927658081\n",
      "Loss for batch 31 = 1.1033369302749634\n",
      "Loss for batch 32 = 1.047289252281189\n",
      "Loss for batch 33 = 1.102048397064209\n",
      "Loss for batch 34 = 0.9706079959869385\n",
      "Loss for batch 35 = 1.0410289764404297\n",
      "Loss for batch 36 = 1.0700719356536865\n",
      "Loss for batch 37 = 1.034818410873413\n",
      "Loss for batch 38 = 1.125011682510376\n",
      "Loss for batch 39 = 1.067525863647461\n",
      "Loss for batch 40 = 1.017746090888977\n",
      "Loss for batch 41 = 1.0166161060333252\n",
      "Loss for batch 42 = 1.0345262289047241\n",
      "Loss for batch 43 = 0.9977500438690186\n",
      "Loss for batch 44 = 0.9626973271369934\n",
      "Loss for batch 45 = 0.9759378433227539\n",
      "Loss for batch 46 = 1.0506261587142944\n",
      "Loss for batch 47 = 0.9682259559631348\n",
      "Loss for batch 48 = 0.8873118162155151\n",
      "Loss for batch 49 = 0.984285295009613\n",
      "Loss for batch 50 = 0.967204749584198\n",
      "Loss for batch 51 = 0.9877619743347168\n",
      "Loss for batch 52 = 1.0868500471115112\n",
      "Loss for batch 53 = 0.9898355603218079\n",
      "Loss for batch 54 = 1.0962070226669312\n",
      "Loss for batch 55 = 0.9772705435752869\n",
      "Loss for batch 56 = 1.006040096282959\n",
      "Loss for batch 57 = 0.8916970491409302\n",
      "Loss for batch 58 = 0.9728374481201172\n",
      "Loss for batch 59 = 1.1304278373718262\n",
      "Loss for batch 60 = 1.0769122838974\n",
      "Loss for batch 61 = 0.9652073979377747\n",
      "Loss for batch 62 = 0.9753104448318481\n",
      "Loss for batch 63 = 1.080696702003479\n",
      "Loss for batch 64 = 0.9544171690940857\n",
      "Loss for batch 65 = 1.0378168821334839\n",
      "Loss for batch 66 = 1.0853102207183838\n",
      "Loss for batch 67 = 0.9215375781059265\n",
      "Loss for batch 68 = 1.003959059715271\n",
      "Loss for batch 69 = 1.0461921691894531\n",
      "Loss for batch 70 = 1.149208664894104\n",
      "Loss for batch 71 = 0.9535108208656311\n",
      "Loss for batch 72 = 0.9001386761665344\n",
      "Loss for batch 73 = 1.0514990091323853\n",
      "Loss for batch 74 = 0.8666946291923523\n",
      "Loss for batch 75 = 0.9449276328086853\n",
      "Loss for batch 76 = 0.9035125374794006\n",
      "Loss for batch 77 = 0.8879314064979553\n",
      "Loss for batch 78 = 0.8522857427597046\n",
      "Loss for batch 79 = 0.9477406740188599\n",
      "Loss for batch 80 = 0.8988409042358398\n",
      "Loss for batch 81 = 1.2384471893310547\n",
      "Loss for batch 82 = 1.1160609722137451\n",
      "Loss for batch 83 = 1.030397653579712\n",
      "Loss for batch 84 = 1.0231170654296875\n",
      "Loss for batch 85 = 0.9254752993583679\n",
      "Loss for batch 86 = 0.9799094200134277\n",
      "Loss for batch 87 = 1.0198040008544922\n",
      "Loss for batch 88 = 0.877804696559906\n",
      "Loss for batch 89 = 0.9765888452529907\n",
      "Loss for batch 90 = 0.9112082123756409\n",
      "Loss for batch 91 = 0.9832113981246948\n",
      "Loss for batch 92 = 0.8486651182174683\n",
      "Loss for batch 93 = 1.1071276664733887\n",
      "Loss for batch 94 = 0.9802316427230835\n",
      "Loss for batch 95 = 0.9195046424865723\n",
      "Loss for batch 96 = 0.9456772208213806\n",
      "Loss for batch 97 = 1.1272202730178833\n",
      "\n",
      "Training Loss for epoch 3 = 99.02091217041016\n",
      "\n",
      "Current Validation Loss = 25.04753875732422\n",
      "Best Validation Loss = 25.04753875732422\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 55.33%\n",
      "Validation Accuracy: 53.40%\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss for batch 0 = 0.9403306841850281\n",
      "Loss for batch 1 = 0.9586611390113831\n",
      "Loss for batch 2 = 0.9846490025520325\n",
      "Loss for batch 3 = 0.7865880727767944\n",
      "Loss for batch 4 = 0.8780485987663269\n",
      "Loss for batch 5 = 0.8946871161460876\n",
      "Loss for batch 6 = 0.9695022702217102\n",
      "Loss for batch 7 = 1.138974666595459\n",
      "Loss for batch 8 = 0.9427168965339661\n",
      "Loss for batch 9 = 0.8963544368743896\n",
      "Loss for batch 10 = 1.0084145069122314\n",
      "Loss for batch 11 = 0.8077167272567749\n",
      "Loss for batch 12 = 0.8580995798110962\n",
      "Loss for batch 13 = 1.1290972232818604\n",
      "Loss for batch 14 = 0.8887121081352234\n",
      "Loss for batch 15 = 1.096928358078003\n",
      "Loss for batch 16 = 0.9540147185325623\n",
      "Loss for batch 17 = 1.0496166944503784\n",
      "Loss for batch 18 = 0.9287298917770386\n",
      "Loss for batch 19 = 0.9936279654502869\n",
      "Loss for batch 20 = 0.8250605463981628\n",
      "Loss for batch 21 = 0.8905691504478455\n",
      "Loss for batch 22 = 0.8613267540931702\n",
      "Loss for batch 23 = 0.9255372881889343\n",
      "Loss for batch 24 = 0.8208073973655701\n",
      "Loss for batch 25 = 0.9049239754676819\n",
      "Loss for batch 26 = 0.928805410861969\n",
      "Loss for batch 27 = 0.9808670282363892\n",
      "Loss for batch 28 = 1.0943262577056885\n",
      "Loss for batch 29 = 0.984624981880188\n",
      "Loss for batch 30 = 0.968610405921936\n",
      "Loss for batch 31 = 1.030189871788025\n",
      "Loss for batch 32 = 0.9247774481773376\n",
      "Loss for batch 33 = 1.0842511653900146\n",
      "Loss for batch 34 = 0.9193753600120544\n",
      "Loss for batch 35 = 0.9617937207221985\n",
      "Loss for batch 36 = 0.9878820180892944\n",
      "Loss for batch 37 = 1.0049622058868408\n",
      "Loss for batch 38 = 1.125473141670227\n",
      "Loss for batch 39 = 1.0200061798095703\n",
      "Loss for batch 40 = 0.9870501756668091\n",
      "Loss for batch 41 = 1.0401296615600586\n",
      "Loss for batch 42 = 0.8948126435279846\n",
      "Loss for batch 43 = 0.8918249607086182\n",
      "Loss for batch 44 = 0.8530197739601135\n",
      "Loss for batch 45 = 0.8785021901130676\n",
      "Loss for batch 46 = 1.0282987356185913\n",
      "Loss for batch 47 = 0.8903006315231323\n",
      "Loss for batch 48 = 0.8031662702560425\n",
      "Loss for batch 49 = 0.9123095273971558\n",
      "Loss for batch 50 = 0.932851254940033\n",
      "Loss for batch 51 = 0.8989701271057129\n",
      "Loss for batch 52 = 1.0097228288650513\n",
      "Loss for batch 53 = 0.97584468126297\n",
      "Loss for batch 54 = 1.0344276428222656\n",
      "Loss for batch 55 = 1.0242708921432495\n",
      "Loss for batch 56 = 0.9387909173965454\n",
      "Loss for batch 57 = 0.8497614860534668\n",
      "Loss for batch 58 = 0.8433048129081726\n",
      "Loss for batch 59 = 1.0631552934646606\n",
      "Loss for batch 60 = 1.0254160165786743\n",
      "Loss for batch 61 = 0.9097527861595154\n",
      "Loss for batch 62 = 0.9198946952819824\n",
      "Loss for batch 63 = 0.9973297119140625\n",
      "Loss for batch 64 = 0.8196913003921509\n",
      "Loss for batch 65 = 0.959257960319519\n",
      "Loss for batch 66 = 0.9968528151512146\n",
      "Loss for batch 67 = 0.934472382068634\n",
      "Loss for batch 68 = 0.8845889568328857\n",
      "Loss for batch 69 = 1.0828142166137695\n",
      "Loss for batch 70 = 1.050229787826538\n",
      "Loss for batch 71 = 0.9044662117958069\n",
      "Loss for batch 72 = 0.9279448390007019\n",
      "Loss for batch 73 = 1.0067534446716309\n",
      "Loss for batch 74 = 0.8149937987327576\n",
      "Loss for batch 75 = 0.8121058940887451\n",
      "Loss for batch 76 = 0.8496490120887756\n",
      "Loss for batch 77 = 0.8247565627098083\n",
      "Loss for batch 78 = 0.7489272356033325\n",
      "Loss for batch 79 = 0.8857519626617432\n",
      "Loss for batch 80 = 0.9257556796073914\n",
      "Loss for batch 81 = 1.2442659139633179\n",
      "Loss for batch 82 = 1.107789158821106\n",
      "Loss for batch 83 = 1.015072226524353\n",
      "Loss for batch 84 = 0.8807412981987\n",
      "Loss for batch 85 = 0.846733808517456\n",
      "Loss for batch 86 = 0.8876593112945557\n",
      "Loss for batch 87 = 0.9512526988983154\n",
      "Loss for batch 88 = 0.8401063680648804\n",
      "Loss for batch 89 = 0.8965466618537903\n",
      "Loss for batch 90 = 0.9086464047431946\n",
      "Loss for batch 91 = 0.9440295696258545\n",
      "Loss for batch 92 = 0.7985002994537354\n",
      "Loss for batch 93 = 1.0236170291900635\n",
      "Loss for batch 94 = 0.9170942902565002\n",
      "Loss for batch 95 = 0.8345145583152771\n",
      "Loss for batch 96 = 0.9114765524864197\n",
      "Loss for batch 97 = 0.9808867573738098\n",
      "\n",
      "Training Loss for epoch 4 = 92.3704833984375\n",
      "\n",
      "Current Validation Loss = 23.571178436279297\n",
      "Best Validation Loss = 23.571178436279297\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 58.60%\n",
      "Validation Accuracy: 57.00%\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss for batch 0 = 0.92047119140625\n",
      "Loss for batch 1 = 0.8794469833374023\n",
      "Loss for batch 2 = 0.9489849805831909\n",
      "Loss for batch 3 = 0.6852518320083618\n",
      "Loss for batch 4 = 0.8230089545249939\n",
      "Loss for batch 5 = 0.8292579054832458\n",
      "Loss for batch 6 = 0.8461171984672546\n",
      "Loss for batch 7 = 1.0792511701583862\n",
      "Loss for batch 8 = 0.9247965812683105\n",
      "Loss for batch 9 = 0.8317341208457947\n",
      "Loss for batch 10 = 0.9467134475708008\n",
      "Loss for batch 11 = 0.7632216811180115\n",
      "Loss for batch 12 = 0.7665433883666992\n",
      "Loss for batch 13 = 0.9390162825584412\n",
      "Loss for batch 14 = 0.7674126029014587\n",
      "Loss for batch 15 = 1.0574567317962646\n",
      "Loss for batch 16 = 0.8592476844787598\n",
      "Loss for batch 17 = 0.9581154584884644\n",
      "Loss for batch 18 = 0.8542521595954895\n",
      "Loss for batch 19 = 0.964586615562439\n",
      "Loss for batch 20 = 0.838770866394043\n",
      "Loss for batch 21 = 0.9312142729759216\n",
      "Loss for batch 22 = 0.8335593342781067\n",
      "Loss for batch 23 = 0.8808020353317261\n",
      "Loss for batch 24 = 0.7853721976280212\n",
      "Loss for batch 25 = 0.8916034698486328\n",
      "Loss for batch 26 = 0.8744630813598633\n",
      "Loss for batch 27 = 0.8566160202026367\n",
      "Loss for batch 28 = 0.972318172454834\n",
      "Loss for batch 29 = 0.9582710266113281\n",
      "Loss for batch 30 = 0.9435098171234131\n",
      "Loss for batch 31 = 0.9732420444488525\n",
      "Loss for batch 32 = 0.8340036869049072\n",
      "Loss for batch 33 = 0.9680403470993042\n",
      "Loss for batch 34 = 0.8252084255218506\n",
      "Loss for batch 35 = 0.9198035597801208\n",
      "Loss for batch 36 = 1.0431936979293823\n",
      "Loss for batch 37 = 1.0275977849960327\n",
      "Loss for batch 38 = 1.0447559356689453\n",
      "Loss for batch 39 = 0.9638447761535645\n",
      "Loss for batch 40 = 0.8903947472572327\n",
      "Loss for batch 41 = 1.039065957069397\n",
      "Loss for batch 42 = 0.8891216516494751\n",
      "Loss for batch 43 = 0.889879584312439\n",
      "Loss for batch 44 = 0.8322617411613464\n",
      "Loss for batch 45 = 0.826537549495697\n",
      "Loss for batch 46 = 0.9677864909172058\n",
      "Loss for batch 47 = 0.9029363393783569\n",
      "Loss for batch 48 = 0.8516435027122498\n",
      "Loss for batch 49 = 0.8591547012329102\n",
      "Loss for batch 50 = 1.020551323890686\n",
      "Loss for batch 51 = 0.8282982110977173\n",
      "Loss for batch 52 = 0.939862072467804\n",
      "Loss for batch 53 = 0.8308348059654236\n",
      "Loss for batch 54 = 1.1021829843521118\n",
      "Loss for batch 55 = 0.8793584704399109\n",
      "Loss for batch 56 = 0.7946333289146423\n",
      "Loss for batch 57 = 0.7784051895141602\n",
      "Loss for batch 58 = 0.8429126143455505\n",
      "Loss for batch 59 = 1.1376194953918457\n",
      "Loss for batch 60 = 0.9942750334739685\n",
      "Loss for batch 61 = 0.9212984442710876\n",
      "Loss for batch 62 = 0.9172839522361755\n",
      "Loss for batch 63 = 0.9668715000152588\n",
      "Loss for batch 64 = 0.7545608878135681\n",
      "Loss for batch 65 = 0.9348102807998657\n",
      "Loss for batch 66 = 0.9534285664558411\n",
      "Loss for batch 67 = 0.9444867372512817\n",
      "Loss for batch 68 = 0.8453184962272644\n",
      "Loss for batch 69 = 0.9687886834144592\n",
      "Loss for batch 70 = 0.9858188629150391\n",
      "Loss for batch 71 = 0.8269778490066528\n",
      "Loss for batch 72 = 0.8925658464431763\n",
      "Loss for batch 73 = 0.901424765586853\n",
      "Loss for batch 74 = 0.6835256814956665\n",
      "Loss for batch 75 = 0.7124416828155518\n",
      "Loss for batch 76 = 0.8464435935020447\n",
      "Loss for batch 77 = 0.7648377418518066\n",
      "Loss for batch 78 = 0.6855378150939941\n",
      "Loss for batch 79 = 0.7840703725814819\n",
      "Loss for batch 80 = 0.8041399717330933\n",
      "Loss for batch 81 = 1.181754231452942\n",
      "Loss for batch 82 = 1.0842629671096802\n",
      "Loss for batch 83 = 1.021897554397583\n",
      "Loss for batch 84 = 0.8487302660942078\n",
      "Loss for batch 85 = 0.8326476216316223\n",
      "Loss for batch 86 = 0.8161429762840271\n",
      "Loss for batch 87 = 0.9716638922691345\n",
      "Loss for batch 88 = 0.6951044797897339\n",
      "Loss for batch 89 = 0.8743152022361755\n",
      "Loss for batch 90 = 0.9188210368156433\n",
      "Loss for batch 91 = 0.8646355271339417\n",
      "Loss for batch 92 = 0.7635588049888611\n",
      "Loss for batch 93 = 0.9957894682884216\n",
      "Loss for batch 94 = 0.8455767035484314\n",
      "Loss for batch 95 = 0.8084079623222351\n",
      "Loss for batch 96 = 0.956648588180542\n",
      "Loss for batch 97 = 0.8875221610069275\n",
      "\n",
      "Training Loss for epoch 5 = 87.57090759277344\n",
      "\n",
      "Current Validation Loss = 23.053470611572266\n",
      "Best Validation Loss = 23.053470611572266\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 62.61%\n",
      "Validation Accuracy: 59.18%\n",
      "\n",
      "Epoch 6\n",
      "----------\n",
      "Loss for batch 0 = 0.7171840667724609\n",
      "Loss for batch 1 = 0.8249222040176392\n",
      "Loss for batch 2 = 0.9039512276649475\n",
      "Loss for batch 3 = 0.6843553185462952\n",
      "Loss for batch 4 = 0.882689893245697\n",
      "Loss for batch 5 = 0.8620657324790955\n",
      "Loss for batch 6 = 0.8348708748817444\n",
      "Loss for batch 7 = 1.0215277671813965\n",
      "Loss for batch 8 = 0.8474357724189758\n",
      "Loss for batch 9 = 0.7404757738113403\n",
      "Loss for batch 10 = 0.8987131714820862\n",
      "Loss for batch 11 = 0.6102359890937805\n",
      "Loss for batch 12 = 0.7248613834381104\n",
      "Loss for batch 13 = 1.0366843938827515\n",
      "Loss for batch 14 = 0.7977319359779358\n",
      "Loss for batch 15 = 0.9393640160560608\n",
      "Loss for batch 16 = 0.7762921452522278\n",
      "Loss for batch 17 = 0.9888444542884827\n",
      "Loss for batch 18 = 0.8518754839897156\n",
      "Loss for batch 19 = 0.8721268773078918\n",
      "Loss for batch 20 = 0.7463781237602234\n",
      "Loss for batch 21 = 0.97342449426651\n",
      "Loss for batch 22 = 0.8157804608345032\n",
      "Loss for batch 23 = 0.8077478408813477\n",
      "Loss for batch 24 = 0.9240151047706604\n",
      "Loss for batch 25 = 0.8226170539855957\n",
      "Loss for batch 26 = 0.8485633730888367\n",
      "Loss for batch 27 = 0.81783527135849\n",
      "Loss for batch 28 = 0.9165918231010437\n",
      "Loss for batch 29 = 0.8178300261497498\n",
      "Loss for batch 30 = 0.8144839406013489\n",
      "Loss for batch 31 = 0.9936942458152771\n",
      "Loss for batch 32 = 0.817986011505127\n",
      "Loss for batch 33 = 0.8516400456428528\n",
      "Loss for batch 34 = 0.7361155152320862\n",
      "Loss for batch 35 = 0.8667609691619873\n",
      "Loss for batch 36 = 0.9672040343284607\n",
      "Loss for batch 37 = 1.0452892780303955\n",
      "Loss for batch 38 = 1.0940091609954834\n",
      "Loss for batch 39 = 0.9092429876327515\n",
      "Loss for batch 40 = 0.8508468866348267\n",
      "Loss for batch 41 = 0.9701454043388367\n",
      "Loss for batch 42 = 0.8568408489227295\n",
      "Loss for batch 43 = 0.9010723233222961\n",
      "Loss for batch 44 = 0.7806931138038635\n",
      "Loss for batch 45 = 0.7841300964355469\n",
      "Loss for batch 46 = 0.9129813313484192\n",
      "Loss for batch 47 = 0.9518853425979614\n",
      "Loss for batch 48 = 0.6929627656936646\n",
      "Loss for batch 49 = 0.9152303338050842\n",
      "Loss for batch 50 = 1.058950424194336\n",
      "Loss for batch 51 = 0.768948495388031\n",
      "Loss for batch 52 = 0.9157701730728149\n",
      "Loss for batch 53 = 0.7615301609039307\n",
      "Loss for batch 54 = 1.1057116985321045\n",
      "Loss for batch 55 = 0.7923542261123657\n",
      "Loss for batch 56 = 0.793605387210846\n",
      "Loss for batch 57 = 0.7587394714355469\n",
      "Loss for batch 58 = 0.6868154406547546\n",
      "Loss for batch 59 = 1.1226428747177124\n",
      "Loss for batch 60 = 0.9303353428840637\n",
      "Loss for batch 61 = 0.9358759522438049\n",
      "Loss for batch 62 = 0.8748349547386169\n",
      "Loss for batch 63 = 0.9019743800163269\n",
      "Loss for batch 64 = 0.6419947147369385\n",
      "Loss for batch 65 = 0.9053676128387451\n",
      "Loss for batch 66 = 0.8730675578117371\n",
      "Loss for batch 67 = 0.940313458442688\n",
      "Loss for batch 68 = 0.8233048915863037\n",
      "Loss for batch 69 = 0.8889533877372742\n",
      "Loss for batch 70 = 1.0649996995925903\n",
      "Loss for batch 71 = 0.806452214717865\n",
      "Loss for batch 72 = 0.8288108110427856\n",
      "Loss for batch 73 = 0.9162351489067078\n",
      "Loss for batch 74 = 0.6556183099746704\n",
      "Loss for batch 75 = 0.6963327527046204\n",
      "Loss for batch 76 = 0.8070434331893921\n",
      "Loss for batch 77 = 0.7486220002174377\n",
      "Loss for batch 78 = 0.6900467276573181\n",
      "Loss for batch 79 = 0.7312783598899841\n",
      "Loss for batch 80 = 0.8437867164611816\n",
      "Loss for batch 81 = 1.0049939155578613\n",
      "Loss for batch 82 = 1.0755826234817505\n",
      "Loss for batch 83 = 0.9606825709342957\n",
      "Loss for batch 84 = 0.7960348725318909\n",
      "Loss for batch 85 = 0.7514007687568665\n",
      "Loss for batch 86 = 0.8199825286865234\n",
      "Loss for batch 87 = 0.8976249694824219\n",
      "Loss for batch 88 = 0.674785315990448\n",
      "Loss for batch 89 = 0.8498356342315674\n",
      "Loss for batch 90 = 0.8776557445526123\n",
      "Loss for batch 91 = 0.8855132460594177\n",
      "Loss for batch 92 = 0.6611388325691223\n",
      "Loss for batch 93 = 0.9204214811325073\n",
      "Loss for batch 94 = 0.774732768535614\n",
      "Loss for batch 95 = 0.780913233757019\n",
      "Loss for batch 96 = 0.8542612195014954\n",
      "Loss for batch 97 = 0.8357002139091492\n",
      "\n",
      "Training Loss for epoch 6 = 83.71180725097656\n",
      "\n",
      "Current Validation Loss = 22.326601028442383\n",
      "Best Validation Loss = 22.326601028442383\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 66.53%\n",
      "Validation Accuracy: 58.79%\n",
      "\n",
      "Epoch 7\n",
      "----------\n",
      "Loss for batch 0 = 0.7287612557411194\n",
      "Loss for batch 1 = 0.7548971772193909\n",
      "Loss for batch 2 = 0.8098634481430054\n",
      "Loss for batch 3 = 0.6818544864654541\n",
      "Loss for batch 4 = 0.8173395991325378\n",
      "Loss for batch 5 = 0.7495540976524353\n",
      "Loss for batch 6 = 0.8308634161949158\n",
      "Loss for batch 7 = 0.8660000562667847\n",
      "Loss for batch 8 = 0.805735170841217\n",
      "Loss for batch 9 = 0.6539232134819031\n",
      "Loss for batch 10 = 0.9070004820823669\n",
      "Loss for batch 11 = 0.6483286619186401\n",
      "Loss for batch 12 = 0.7636326551437378\n",
      "Loss for batch 13 = 0.9247459173202515\n",
      "Loss for batch 14 = 0.6857238411903381\n",
      "Loss for batch 15 = 0.8463325500488281\n",
      "Loss for batch 16 = 0.7564111351966858\n",
      "Loss for batch 17 = 0.9656583070755005\n",
      "Loss for batch 18 = 0.7607434391975403\n",
      "Loss for batch 19 = 0.7599292397499084\n",
      "Loss for batch 20 = 0.7020374536514282\n",
      "Loss for batch 21 = 0.9296439290046692\n",
      "Loss for batch 22 = 0.7502039074897766\n",
      "Loss for batch 23 = 0.7060266733169556\n",
      "Loss for batch 24 = 0.8089931607246399\n",
      "Loss for batch 25 = 0.7805389761924744\n",
      "Loss for batch 26 = 0.833312451839447\n",
      "Loss for batch 27 = 0.7567019462585449\n",
      "Loss for batch 28 = 0.8342223167419434\n",
      "Loss for batch 29 = 0.7639601230621338\n",
      "Loss for batch 30 = 0.7568327784538269\n",
      "Loss for batch 31 = 0.9891342520713806\n",
      "Loss for batch 32 = 0.7166843414306641\n",
      "Loss for batch 33 = 0.7860676646232605\n",
      "Loss for batch 34 = 0.7488622665405273\n",
      "Loss for batch 35 = 0.8000250458717346\n",
      "Loss for batch 36 = 0.8247395753860474\n",
      "Loss for batch 37 = 1.0310195684432983\n",
      "Loss for batch 38 = 0.9332559704780579\n",
      "Loss for batch 39 = 0.8972285985946655\n",
      "Loss for batch 40 = 0.8616019487380981\n",
      "Loss for batch 41 = 0.8939647674560547\n",
      "Loss for batch 42 = 0.84767746925354\n",
      "Loss for batch 43 = 0.8174771070480347\n",
      "Loss for batch 44 = 0.7892717719078064\n",
      "Loss for batch 45 = 0.7543152570724487\n",
      "Loss for batch 46 = 0.9348258972167969\n",
      "Loss for batch 47 = 0.8832234144210815\n",
      "Loss for batch 48 = 0.7640554308891296\n",
      "Loss for batch 49 = 0.8408852219581604\n",
      "Loss for batch 50 = 0.99522465467453\n",
      "Loss for batch 51 = 0.7091978788375854\n",
      "Loss for batch 52 = 0.7433353066444397\n",
      "Loss for batch 53 = 0.6292280554771423\n",
      "Loss for batch 54 = 0.9008617401123047\n",
      "Loss for batch 55 = 0.9084281921386719\n",
      "Loss for batch 56 = 0.781546950340271\n",
      "Loss for batch 57 = 0.6769641041755676\n",
      "Loss for batch 58 = 0.6830824613571167\n",
      "Loss for batch 59 = 1.0196099281311035\n",
      "Loss for batch 60 = 0.8814559578895569\n",
      "Loss for batch 61 = 0.9046677947044373\n",
      "Loss for batch 62 = 0.8279871940612793\n",
      "Loss for batch 63 = 0.8679484724998474\n",
      "Loss for batch 64 = 0.5386244654655457\n",
      "Loss for batch 65 = 0.8463392853736877\n",
      "Loss for batch 66 = 0.8285425305366516\n",
      "Loss for batch 67 = 0.9090381860733032\n",
      "Loss for batch 68 = 0.7863581776618958\n",
      "Loss for batch 69 = 0.884016752243042\n",
      "Loss for batch 70 = 1.0091495513916016\n",
      "Loss for batch 71 = 0.7042739391326904\n",
      "Loss for batch 72 = 0.8123492002487183\n",
      "Loss for batch 73 = 0.8240930438041687\n",
      "Loss for batch 74 = 0.6572569012641907\n",
      "Loss for batch 75 = 0.6678420901298523\n",
      "Loss for batch 76 = 0.6708197593688965\n",
      "Loss for batch 77 = 0.6536834836006165\n",
      "Loss for batch 78 = 0.5782289505004883\n",
      "Loss for batch 79 = 0.7581357955932617\n",
      "Loss for batch 80 = 0.7790234088897705\n",
      "Loss for batch 81 = 0.9365613460540771\n",
      "Loss for batch 82 = 1.0669090747833252\n",
      "Loss for batch 83 = 0.9354798793792725\n",
      "Loss for batch 84 = 0.7696763277053833\n",
      "Loss for batch 85 = 0.6940562725067139\n",
      "Loss for batch 86 = 0.7059062719345093\n",
      "Loss for batch 87 = 0.9239954948425293\n",
      "Loss for batch 88 = 0.6621135473251343\n",
      "Loss for batch 89 = 0.8488351106643677\n",
      "Loss for batch 90 = 0.8758137226104736\n",
      "Loss for batch 91 = 0.8903618454933167\n",
      "Loss for batch 92 = 0.6467075943946838\n",
      "Loss for batch 93 = 0.9101718664169312\n",
      "Loss for batch 94 = 0.7447888851165771\n",
      "Loss for batch 95 = 0.735623836517334\n",
      "Loss for batch 96 = 0.7874733209609985\n",
      "Loss for batch 97 = 0.8844874501228333\n",
      "\n",
      "Training Loss for epoch 7 = 78.9103775024414\n",
      "\n",
      "Current Validation Loss = 22.40690040588379\n",
      "Best Validation Loss = 22.326601028442383\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 60.88%\n",
      "Validation Accuracy: 57.12%\n",
      "\n",
      "Epoch 8\n",
      "----------\n",
      "Loss for batch 0 = 0.6921299695968628\n",
      "Loss for batch 1 = 0.7245599031448364\n",
      "Loss for batch 2 = 0.777073085308075\n",
      "Loss for batch 3 = 0.7391660809516907\n",
      "Loss for batch 4 = 0.7704358696937561\n",
      "Loss for batch 5 = 0.7283554673194885\n",
      "Loss for batch 6 = 0.7623518109321594\n",
      "Loss for batch 7 = 0.8535951972007751\n",
      "Loss for batch 8 = 0.8087270855903625\n",
      "Loss for batch 9 = 0.6495394110679626\n",
      "Loss for batch 10 = 0.8388437032699585\n",
      "Loss for batch 11 = 0.5769063234329224\n",
      "Loss for batch 12 = 0.7686586380004883\n",
      "Loss for batch 13 = 0.8607521653175354\n",
      "Loss for batch 14 = 0.6659534573554993\n",
      "Loss for batch 15 = 0.8081532716751099\n",
      "Loss for batch 16 = 0.6874696612358093\n",
      "Loss for batch 17 = 0.8914797306060791\n",
      "Loss for batch 18 = 0.7104077339172363\n",
      "Loss for batch 19 = 0.6726803779602051\n",
      "Loss for batch 20 = 0.6629637479782104\n",
      "Loss for batch 21 = 0.8847199082374573\n",
      "Loss for batch 22 = 0.6667699813842773\n",
      "Loss for batch 23 = 0.6303281188011169\n",
      "Loss for batch 24 = 0.7908792495727539\n",
      "Loss for batch 25 = 0.7380554676055908\n",
      "Loss for batch 26 = 0.8301435112953186\n",
      "Loss for batch 27 = 0.7438226342201233\n",
      "Loss for batch 28 = 0.7845286726951599\n",
      "Loss for batch 29 = 0.7495168447494507\n",
      "Loss for batch 30 = 0.7129921913146973\n",
      "Loss for batch 31 = 0.9413260221481323\n",
      "Loss for batch 32 = 0.6577168107032776\n",
      "Loss for batch 33 = 0.7253153324127197\n",
      "Loss for batch 34 = 0.7496824264526367\n",
      "Loss for batch 35 = 0.7755393385887146\n",
      "Loss for batch 36 = 0.7979816794395447\n",
      "Loss for batch 37 = 1.0008105039596558\n",
      "Loss for batch 38 = 0.8810179829597473\n",
      "Loss for batch 39 = 0.8544909954071045\n",
      "Loss for batch 40 = 0.8666802644729614\n",
      "Loss for batch 41 = 0.8760184049606323\n",
      "Loss for batch 42 = 0.8304916620254517\n",
      "Loss for batch 43 = 0.7759439945220947\n",
      "Loss for batch 44 = 0.7862744331359863\n",
      "Loss for batch 45 = 0.752251923084259\n",
      "Loss for batch 46 = 0.8624942302703857\n",
      "Loss for batch 47 = 0.8879045248031616\n",
      "Loss for batch 48 = 0.7430264353752136\n",
      "Loss for batch 49 = 0.8066478967666626\n",
      "Loss for batch 50 = 1.027645230293274\n",
      "Loss for batch 51 = 0.701839804649353\n",
      "Loss for batch 52 = 0.7100618481636047\n",
      "Loss for batch 53 = 0.6068030595779419\n",
      "Loss for batch 54 = 0.8552016615867615\n",
      "Loss for batch 55 = 0.7510632872581482\n",
      "Loss for batch 56 = 0.7428550124168396\n",
      "Loss for batch 57 = 0.6821814179420471\n",
      "Loss for batch 58 = 0.6943745017051697\n",
      "Loss for batch 59 = 0.9580855369567871\n",
      "Loss for batch 60 = 0.8712548613548279\n",
      "Loss for batch 61 = 0.9518085718154907\n",
      "Loss for batch 62 = 0.8098515272140503\n",
      "Loss for batch 63 = 0.8235137462615967\n",
      "Loss for batch 64 = 0.5800751447677612\n",
      "Loss for batch 65 = 0.8138018846511841\n",
      "Loss for batch 66 = 0.8980538845062256\n",
      "Loss for batch 67 = 0.9133664965629578\n",
      "Loss for batch 68 = 0.7641252279281616\n",
      "Loss for batch 69 = 0.8051047325134277\n",
      "Loss for batch 70 = 0.9551869034767151\n",
      "Loss for batch 71 = 0.690903902053833\n",
      "Loss for batch 72 = 0.8266145586967468\n",
      "Loss for batch 73 = 0.7604402899742126\n",
      "Loss for batch 74 = 0.5751873850822449\n",
      "Loss for batch 75 = 0.6502891182899475\n",
      "Loss for batch 76 = 0.6677525043487549\n",
      "Loss for batch 77 = 0.6578112244606018\n",
      "Loss for batch 78 = 0.5589830279350281\n",
      "Loss for batch 79 = 0.7364124655723572\n",
      "Loss for batch 80 = 0.7736591100692749\n",
      "Loss for batch 81 = 0.8621153235435486\n",
      "Loss for batch 82 = 1.0574231147766113\n",
      "Loss for batch 83 = 0.8639330267906189\n",
      "Loss for batch 84 = 0.7238583564758301\n",
      "Loss for batch 85 = 0.6223782300949097\n",
      "Loss for batch 86 = 0.6295493841171265\n",
      "Loss for batch 87 = 0.8287373781204224\n",
      "Loss for batch 88 = 0.5588110685348511\n",
      "Loss for batch 89 = 0.7653120160102844\n",
      "Loss for batch 90 = 0.861609697341919\n",
      "Loss for batch 91 = 0.8034506440162659\n",
      "Loss for batch 92 = 0.7982791066169739\n",
      "Loss for batch 93 = 0.8893646001815796\n",
      "Loss for batch 94 = 0.6962869167327881\n",
      "Loss for batch 95 = 0.6588743925094604\n",
      "Loss for batch 96 = 0.8246250748634338\n",
      "Loss for batch 97 = 0.7663499712944031\n",
      "\n",
      "Training Loss for epoch 8 = 75.77881622314453\n",
      "\n",
      "Current Validation Loss = 22.383054733276367\n",
      "Best Validation Loss = 22.326601028442383\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 67.49%\n",
      "Validation Accuracy: 59.05%\n",
      "\n",
      "Epoch 9\n",
      "----------\n",
      "Loss for batch 0 = 0.7244524359703064\n",
      "Loss for batch 1 = 0.6755551099777222\n",
      "Loss for batch 2 = 0.759509265422821\n",
      "Loss for batch 3 = 0.6861947178840637\n",
      "Loss for batch 4 = 0.7790836095809937\n",
      "Loss for batch 5 = 0.7386397123336792\n",
      "Loss for batch 6 = 0.7353134751319885\n",
      "Loss for batch 7 = 0.7906208634376526\n",
      "Loss for batch 8 = 0.7822756767272949\n",
      "Loss for batch 9 = 0.5563913583755493\n",
      "Loss for batch 10 = 0.8440247774124146\n",
      "Loss for batch 11 = 0.5429096817970276\n",
      "Loss for batch 12 = 0.7556009292602539\n",
      "Loss for batch 13 = 0.7555510401725769\n",
      "Loss for batch 14 = 0.677914023399353\n",
      "Loss for batch 15 = 0.8138262033462524\n",
      "Loss for batch 16 = 0.6211454272270203\n",
      "Loss for batch 17 = 0.7549951672554016\n",
      "Loss for batch 18 = 0.733970046043396\n",
      "Loss for batch 19 = 0.6349791884422302\n",
      "Loss for batch 20 = 0.6392550468444824\n",
      "Loss for batch 21 = 0.8719038963317871\n",
      "Loss for batch 22 = 0.6378483176231384\n",
      "Loss for batch 23 = 0.6182912588119507\n",
      "Loss for batch 24 = 0.7906972765922546\n",
      "Loss for batch 25 = 0.7304580807685852\n",
      "Loss for batch 26 = 0.8154646158218384\n",
      "Loss for batch 27 = 0.6981346607208252\n",
      "Loss for batch 28 = 0.7595218420028687\n",
      "Loss for batch 29 = 0.718475341796875\n",
      "Loss for batch 30 = 0.6677570939064026\n",
      "Loss for batch 31 = 0.9243626594543457\n",
      "Loss for batch 32 = 0.6455695033073425\n",
      "Loss for batch 33 = 0.6937263607978821\n",
      "Loss for batch 34 = 0.7510961294174194\n",
      "Loss for batch 35 = 0.7759912014007568\n",
      "Loss for batch 36 = 0.7653578519821167\n",
      "Loss for batch 37 = 0.969931960105896\n",
      "Loss for batch 38 = 0.8989772200584412\n",
      "Loss for batch 39 = 0.6891467571258545\n",
      "Loss for batch 40 = 1.0671613216400146\n",
      "Loss for batch 41 = 0.8607192039489746\n",
      "Loss for batch 42 = 0.8213310837745667\n",
      "Loss for batch 43 = 0.7197780609130859\n",
      "Loss for batch 44 = 0.7309144735336304\n",
      "Loss for batch 45 = 0.730659008026123\n",
      "Loss for batch 46 = 0.7848609685897827\n",
      "Loss for batch 47 = 0.8601208329200745\n",
      "Loss for batch 48 = 0.7325376272201538\n",
      "Loss for batch 49 = 0.7510752081871033\n",
      "Loss for batch 50 = 0.9533228278160095\n",
      "Loss for batch 51 = 0.6636634469032288\n",
      "Loss for batch 52 = 0.682723343372345\n",
      "Loss for batch 53 = 0.5670827031135559\n",
      "Loss for batch 54 = 0.863564133644104\n",
      "Loss for batch 55 = 0.7701535224914551\n",
      "Loss for batch 56 = 0.7369616627693176\n",
      "Loss for batch 57 = 0.630083441734314\n",
      "Loss for batch 58 = 0.6332376599311829\n",
      "Loss for batch 59 = 0.9594009518623352\n",
      "Loss for batch 60 = 0.8124070167541504\n",
      "Loss for batch 61 = 0.9286107420921326\n",
      "Loss for batch 62 = 0.7610998153686523\n",
      "Loss for batch 63 = 0.8095512390136719\n",
      "Loss for batch 64 = 0.5084308981895447\n",
      "Loss for batch 65 = 0.7583746910095215\n",
      "Loss for batch 66 = 0.9366657137870789\n",
      "Loss for batch 67 = 0.8984288573265076\n",
      "Loss for batch 68 = 0.799489438533783\n",
      "Loss for batch 69 = 0.7471957802772522\n",
      "Loss for batch 70 = 0.9292863607406616\n",
      "Loss for batch 71 = 0.6535274386405945\n",
      "Loss for batch 72 = 0.8062350153923035\n",
      "Loss for batch 73 = 0.7102914452552795\n",
      "Loss for batch 74 = 0.5375325083732605\n",
      "Loss for batch 75 = 0.5984218716621399\n",
      "Loss for batch 76 = 0.6280069351196289\n",
      "Loss for batch 77 = 0.6360986828804016\n",
      "Loss for batch 78 = 0.522387683391571\n",
      "Loss for batch 79 = 0.7039534449577332\n",
      "Loss for batch 80 = 0.8512846827507019\n",
      "Loss for batch 81 = 0.8879052996635437\n",
      "Loss for batch 82 = 1.0309991836547852\n",
      "Loss for batch 83 = 0.8556565046310425\n",
      "Loss for batch 84 = 0.6608128547668457\n",
      "Loss for batch 85 = 0.6027162075042725\n",
      "Loss for batch 86 = 0.5605412721633911\n",
      "Loss for batch 87 = 0.765099287033081\n",
      "Loss for batch 88 = 0.52925044298172\n",
      "Loss for batch 89 = 0.742919921875\n",
      "Loss for batch 90 = 0.8538651466369629\n",
      "Loss for batch 91 = 0.7870634198188782\n",
      "Loss for batch 92 = 0.773413896560669\n",
      "Loss for batch 93 = 0.89509516954422\n",
      "Loss for batch 94 = 0.7049120664596558\n",
      "Loss for batch 95 = 0.6329910159111023\n",
      "Loss for batch 96 = 0.8500797748565674\n",
      "Loss for batch 97 = 0.7887782454490662\n",
      "\n",
      "Training Loss for epoch 9 = 73.40364837646484\n",
      "\n",
      "Current Validation Loss = 21.966571807861328\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 69.90%\n",
      "Validation Accuracy: 61.36%\n",
      "\n",
      "Epoch 10\n",
      "----------\n",
      "Loss for batch 0 = 0.651492714881897\n",
      "Loss for batch 1 = 0.6487536430358887\n",
      "Loss for batch 2 = 0.7282936573028564\n",
      "Loss for batch 3 = 0.6638256311416626\n",
      "Loss for batch 4 = 0.7841266393661499\n",
      "Loss for batch 5 = 0.7167572975158691\n",
      "Loss for batch 6 = 0.7359541058540344\n",
      "Loss for batch 7 = 0.8124868273735046\n",
      "Loss for batch 8 = 0.6813666224479675\n",
      "Loss for batch 9 = 0.5635817050933838\n",
      "Loss for batch 10 = 0.8618238568305969\n",
      "Loss for batch 11 = 0.5235835313796997\n",
      "Loss for batch 12 = 0.6675489544868469\n",
      "Loss for batch 13 = 0.718082070350647\n",
      "Loss for batch 14 = 0.6442142724990845\n",
      "Loss for batch 15 = 0.827191948890686\n",
      "Loss for batch 16 = 0.6417465806007385\n",
      "Loss for batch 17 = 0.6930172443389893\n",
      "Loss for batch 18 = 0.6699268817901611\n",
      "Loss for batch 19 = 0.6316826939582825\n",
      "Loss for batch 20 = 0.6057291030883789\n",
      "Loss for batch 21 = 0.8198641538619995\n",
      "Loss for batch 22 = 0.6283538341522217\n",
      "Loss for batch 23 = 0.5765271186828613\n",
      "Loss for batch 24 = 0.7062333226203918\n",
      "Loss for batch 25 = 0.6598621606826782\n",
      "Loss for batch 26 = 0.7901484370231628\n",
      "Loss for batch 27 = 0.7280710935592651\n",
      "Loss for batch 28 = 0.7303050756454468\n",
      "Loss for batch 29 = 0.7178106307983398\n",
      "Loss for batch 30 = 0.6609868407249451\n",
      "Loss for batch 31 = 0.8541738986968994\n",
      "Loss for batch 32 = 0.5933421850204468\n",
      "Loss for batch 33 = 0.688297688961029\n",
      "Loss for batch 34 = 0.7469311952590942\n",
      "Loss for batch 35 = 0.7411472201347351\n",
      "Loss for batch 36 = 0.6830044388771057\n",
      "Loss for batch 37 = 1.0007575750350952\n",
      "Loss for batch 38 = 0.8343499302864075\n",
      "Loss for batch 39 = 0.6287286877632141\n",
      "Loss for batch 40 = 0.9561692476272583\n",
      "Loss for batch 41 = 0.8511486649513245\n",
      "Loss for batch 42 = 0.7735042572021484\n",
      "Loss for batch 43 = 0.6808491945266724\n",
      "Loss for batch 44 = 0.6712234020233154\n",
      "Loss for batch 45 = 0.7240444421768188\n",
      "Loss for batch 46 = 0.7916238903999329\n",
      "Loss for batch 47 = 0.8355710506439209\n",
      "Loss for batch 48 = 0.6302769184112549\n",
      "Loss for batch 49 = 0.7246650457382202\n",
      "Loss for batch 50 = 0.9367398619651794\n",
      "Loss for batch 51 = 0.6320126056671143\n",
      "Loss for batch 52 = 0.6159487962722778\n",
      "Loss for batch 53 = 0.5142040252685547\n",
      "Loss for batch 54 = 0.8226333856582642\n",
      "Loss for batch 55 = 0.6168829202651978\n",
      "Loss for batch 56 = 0.7986717224121094\n",
      "Loss for batch 57 = 0.5632089972496033\n",
      "Loss for batch 58 = 0.5923978686332703\n",
      "Loss for batch 59 = 0.9794594645500183\n",
      "Loss for batch 60 = 0.7553234696388245\n",
      "Loss for batch 61 = 0.9170680642127991\n",
      "Loss for batch 62 = 0.7515432834625244\n",
      "Loss for batch 63 = 0.7728904485702515\n",
      "Loss for batch 64 = 0.5345660448074341\n",
      "Loss for batch 65 = 0.7355642914772034\n",
      "Loss for batch 66 = 0.7766990661621094\n",
      "Loss for batch 67 = 0.8591108918190002\n",
      "Loss for batch 68 = 0.7117360234260559\n",
      "Loss for batch 69 = 0.7359506487846375\n",
      "Loss for batch 70 = 0.8835830688476562\n",
      "Loss for batch 71 = 0.6323887705802917\n",
      "Loss for batch 72 = 0.7312159538269043\n",
      "Loss for batch 73 = 0.6981538534164429\n",
      "Loss for batch 74 = 0.5489513874053955\n",
      "Loss for batch 75 = 0.5924261808395386\n",
      "Loss for batch 76 = 0.6005129218101501\n",
      "Loss for batch 77 = 0.5803633332252502\n",
      "Loss for batch 78 = 0.527309775352478\n",
      "Loss for batch 79 = 0.6459640860557556\n",
      "Loss for batch 80 = 0.839769184589386\n",
      "Loss for batch 81 = 0.8279250860214233\n",
      "Loss for batch 82 = 0.9356191754341125\n",
      "Loss for batch 83 = 0.8352302312850952\n",
      "Loss for batch 84 = 0.614372968673706\n",
      "Loss for batch 85 = 0.609370768070221\n",
      "Loss for batch 86 = 0.5484594106674194\n",
      "Loss for batch 87 = 0.7650448679924011\n",
      "Loss for batch 88 = 0.4775004982948303\n",
      "Loss for batch 89 = 0.7002296447753906\n",
      "Loss for batch 90 = 0.830234706401825\n",
      "Loss for batch 91 = 0.7968748807907104\n",
      "Loss for batch 92 = 0.6922561526298523\n",
      "Loss for batch 93 = 0.8775313496589661\n",
      "Loss for batch 94 = 0.7066963315010071\n",
      "Loss for batch 95 = 0.6184185743331909\n",
      "Loss for batch 96 = 0.7537400126457214\n",
      "Loss for batch 97 = 0.8123483657836914\n",
      "\n",
      "Training Loss for epoch 10 = 70.20426177978516\n",
      "\n",
      "Current Validation Loss = 24.085710525512695\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 66.05%\n",
      "Validation Accuracy: 58.02%\n",
      "\n",
      "Epoch 11\n",
      "----------\n",
      "Loss for batch 0 = 0.7572935223579407\n",
      "Loss for batch 1 = 0.622188150882721\n",
      "Loss for batch 2 = 0.7401663661003113\n",
      "Loss for batch 3 = 0.6692717671394348\n",
      "Loss for batch 4 = 0.7604796886444092\n",
      "Loss for batch 5 = 0.6436840295791626\n",
      "Loss for batch 6 = 0.7290229201316833\n",
      "Loss for batch 7 = 0.7597196698188782\n",
      "Loss for batch 8 = 0.7198981642723083\n",
      "Loss for batch 9 = 0.5488591194152832\n",
      "Loss for batch 10 = 0.881179690361023\n",
      "Loss for batch 11 = 0.44973641633987427\n",
      "Loss for batch 12 = 0.7095649838447571\n",
      "Loss for batch 13 = 0.7792927026748657\n",
      "Loss for batch 14 = 0.6283591985702515\n",
      "Loss for batch 15 = 0.759113609790802\n",
      "Loss for batch 16 = 0.5754336714744568\n",
      "Loss for batch 17 = 0.5949693918228149\n",
      "Loss for batch 18 = 0.6098579168319702\n",
      "Loss for batch 19 = 0.5995961427688599\n",
      "Loss for batch 20 = 0.5409082174301147\n",
      "Loss for batch 21 = 0.8317281007766724\n",
      "Loss for batch 22 = 0.61417555809021\n",
      "Loss for batch 23 = 0.5774628520011902\n",
      "Loss for batch 24 = 0.6885998249053955\n",
      "Loss for batch 25 = 0.6038870811462402\n",
      "Loss for batch 26 = 0.6881690621376038\n",
      "Loss for batch 27 = 0.694053590297699\n",
      "Loss for batch 28 = 0.675455629825592\n",
      "Loss for batch 29 = 0.6226271390914917\n",
      "Loss for batch 30 = 0.5844160914421082\n",
      "Loss for batch 31 = 0.7420645952224731\n",
      "Loss for batch 32 = 0.6228196620941162\n",
      "Loss for batch 33 = 0.6344732046127319\n",
      "Loss for batch 34 = 0.6908828020095825\n",
      "Loss for batch 35 = 0.6294882297515869\n",
      "Loss for batch 36 = 0.7440462112426758\n",
      "Loss for batch 37 = 0.943713366985321\n",
      "Loss for batch 38 = 0.8697376251220703\n",
      "Loss for batch 39 = 0.6322822570800781\n",
      "Loss for batch 40 = 0.8319904804229736\n",
      "Loss for batch 41 = 0.8394059538841248\n",
      "Loss for batch 42 = 0.6979511976242065\n",
      "Loss for batch 43 = 0.6607074737548828\n",
      "Loss for batch 44 = 0.5813746452331543\n",
      "Loss for batch 45 = 0.6586674451828003\n",
      "Loss for batch 46 = 0.806474506855011\n",
      "Loss for batch 47 = 0.8319704532623291\n",
      "Loss for batch 48 = 0.6486570239067078\n",
      "Loss for batch 49 = 0.6624512076377869\n",
      "Loss for batch 50 = 0.8648252487182617\n",
      "Loss for batch 51 = 0.6268481016159058\n",
      "Loss for batch 52 = 0.5967602133750916\n",
      "Loss for batch 53 = 0.48561227321624756\n",
      "Loss for batch 54 = 0.7352412939071655\n",
      "Loss for batch 55 = 0.6879490613937378\n",
      "Loss for batch 56 = 0.7580604553222656\n",
      "Loss for batch 57 = 0.5559999942779541\n",
      "Loss for batch 58 = 0.5633503198623657\n",
      "Loss for batch 59 = 0.938258707523346\n",
      "Loss for batch 60 = 0.7349923253059387\n",
      "Loss for batch 61 = 0.8692852258682251\n",
      "Loss for batch 62 = 0.8225728869438171\n",
      "Loss for batch 63 = 0.715152382850647\n",
      "Loss for batch 64 = 0.4287802577018738\n",
      "Loss for batch 65 = 0.6998821496963501\n",
      "Loss for batch 66 = 0.7591381669044495\n",
      "Loss for batch 67 = 0.7989888787269592\n",
      "Loss for batch 68 = 0.6935989856719971\n",
      "Loss for batch 69 = 0.7441644668579102\n",
      "Loss for batch 70 = 0.8787004947662354\n",
      "Loss for batch 71 = 0.6169721484184265\n",
      "Loss for batch 72 = 0.694322407245636\n",
      "Loss for batch 73 = 0.6897950768470764\n",
      "Loss for batch 74 = 0.5411059856414795\n",
      "Loss for batch 75 = 0.5701336860656738\n",
      "Loss for batch 76 = 0.5854421854019165\n",
      "Loss for batch 77 = 0.5790684819221497\n",
      "Loss for batch 78 = 0.583393394947052\n",
      "Loss for batch 79 = 0.6762540340423584\n",
      "Loss for batch 80 = 0.7058631181716919\n",
      "Loss for batch 81 = 0.8448339700698853\n",
      "Loss for batch 82 = 0.9484491348266602\n",
      "Loss for batch 83 = 0.8609501719474792\n",
      "Loss for batch 84 = 0.6104962825775146\n",
      "Loss for batch 85 = 0.5917602181434631\n",
      "Loss for batch 86 = 0.45715755224227905\n",
      "Loss for batch 87 = 0.6559991240501404\n",
      "Loss for batch 88 = 0.49019598960876465\n",
      "Loss for batch 89 = 0.7666417360305786\n",
      "Loss for batch 90 = 0.8364253044128418\n",
      "Loss for batch 91 = 0.8257291913032532\n",
      "Loss for batch 92 = 0.6335822343826294\n",
      "Loss for batch 93 = 0.8251655101776123\n",
      "Loss for batch 94 = 0.6794050335884094\n",
      "Loss for batch 95 = 0.6356807351112366\n",
      "Loss for batch 96 = 0.7594940662384033\n",
      "Loss for batch 97 = 0.7642736434936523\n",
      "\n",
      "Training Loss for epoch 11 = 67.77508544921875\n",
      "\n",
      "Current Validation Loss = 22.603761672973633\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 72.14%\n",
      "Validation Accuracy: 61.23%\n",
      "\n",
      "Epoch 12\n",
      "----------\n",
      "Loss for batch 0 = 0.5905950665473938\n",
      "Loss for batch 1 = 0.6322213411331177\n",
      "Loss for batch 2 = 0.6868671774864197\n",
      "Loss for batch 3 = 0.6792818307876587\n",
      "Loss for batch 4 = 0.7253174781799316\n",
      "Loss for batch 5 = 0.6531213521957397\n",
      "Loss for batch 6 = 0.7259273529052734\n",
      "Loss for batch 7 = 0.7411137819290161\n",
      "Loss for batch 8 = 0.7403597235679626\n",
      "Loss for batch 9 = 0.5499477386474609\n",
      "Loss for batch 10 = 0.8279989957809448\n",
      "Loss for batch 11 = 0.47818535566329956\n",
      "Loss for batch 12 = 0.6202934384346008\n",
      "Loss for batch 13 = 0.6923983097076416\n",
      "Loss for batch 14 = 0.6109326481819153\n",
      "Loss for batch 15 = 0.7097829580307007\n",
      "Loss for batch 16 = 0.5338096618652344\n",
      "Loss for batch 17 = 0.540357232093811\n",
      "Loss for batch 18 = 0.6542859673500061\n",
      "Loss for batch 19 = 0.5551419854164124\n",
      "Loss for batch 20 = 0.4991704523563385\n",
      "Loss for batch 21 = 0.7865040302276611\n",
      "Loss for batch 22 = 0.5785215497016907\n",
      "Loss for batch 23 = 0.5378799438476562\n",
      "Loss for batch 24 = 0.6179506182670593\n",
      "Loss for batch 25 = 0.5221834182739258\n",
      "Loss for batch 26 = 0.6942432522773743\n",
      "Loss for batch 27 = 0.6852366924285889\n",
      "Loss for batch 28 = 0.7120727300643921\n",
      "Loss for batch 29 = 0.6463378667831421\n",
      "Loss for batch 30 = 0.5665348768234253\n",
      "Loss for batch 31 = 0.6294774413108826\n",
      "Loss for batch 32 = 0.5920023322105408\n",
      "Loss for batch 33 = 0.613412618637085\n",
      "Loss for batch 34 = 0.6609590649604797\n",
      "Loss for batch 35 = 0.5743873119354248\n",
      "Loss for batch 36 = 0.7054245471954346\n",
      "Loss for batch 37 = 0.8787552118301392\n",
      "Loss for batch 38 = 0.7666807770729065\n",
      "Loss for batch 39 = 0.542685866355896\n",
      "Loss for batch 40 = 0.9401994943618774\n",
      "Loss for batch 41 = 0.772538423538208\n",
      "Loss for batch 42 = 0.7047919034957886\n",
      "Loss for batch 43 = 0.6642743349075317\n",
      "Loss for batch 44 = 0.5139727592468262\n",
      "Loss for batch 45 = 0.6214854121208191\n",
      "Loss for batch 46 = 0.7737442851066589\n",
      "Loss for batch 47 = 0.8058713674545288\n",
      "Loss for batch 48 = 0.5978716015815735\n",
      "Loss for batch 49 = 0.6118448972702026\n",
      "Loss for batch 50 = 0.8451296091079712\n",
      "Loss for batch 51 = 0.5985002517700195\n",
      "Loss for batch 52 = 0.5639532804489136\n",
      "Loss for batch 53 = 0.4661790132522583\n",
      "Loss for batch 54 = 0.7037604451179504\n",
      "Loss for batch 55 = 0.6459885239601135\n",
      "Loss for batch 56 = 0.7667466402053833\n",
      "Loss for batch 57 = 0.5025746822357178\n",
      "Loss for batch 58 = 0.5462989807128906\n",
      "Loss for batch 59 = 0.9014168977737427\n",
      "Loss for batch 60 = 0.7196822166442871\n",
      "Loss for batch 61 = 0.9188361167907715\n",
      "Loss for batch 62 = 0.7221015691757202\n",
      "Loss for batch 63 = 0.7296079993247986\n",
      "Loss for batch 64 = 0.466515451669693\n",
      "Loss for batch 65 = 0.7000729441642761\n",
      "Loss for batch 66 = 0.847597599029541\n",
      "Loss for batch 67 = 0.8618463277816772\n",
      "Loss for batch 68 = 0.7590746879577637\n",
      "Loss for batch 69 = 0.6246348023414612\n",
      "Loss for batch 70 = 0.8478844165802002\n",
      "Loss for batch 71 = 0.5734381675720215\n",
      "Loss for batch 72 = 0.6046373844146729\n",
      "Loss for batch 73 = 0.6287918090820312\n",
      "Loss for batch 74 = 0.5038294196128845\n",
      "Loss for batch 75 = 0.5967460870742798\n",
      "Loss for batch 76 = 0.5383908748626709\n",
      "Loss for batch 77 = 0.6061180830001831\n",
      "Loss for batch 78 = 0.4919888377189636\n",
      "Loss for batch 79 = 0.5932309031486511\n",
      "Loss for batch 80 = 0.6875163316726685\n",
      "Loss for batch 81 = 0.8371665477752686\n",
      "Loss for batch 82 = 0.8491001129150391\n",
      "Loss for batch 83 = 0.7783694267272949\n",
      "Loss for batch 84 = 0.5394748449325562\n",
      "Loss for batch 85 = 0.5291704535484314\n",
      "Loss for batch 86 = 0.39232346415519714\n",
      "Loss for batch 87 = 0.5976828336715698\n",
      "Loss for batch 88 = 0.49499401450157166\n",
      "Loss for batch 89 = 0.6647582650184631\n",
      "Loss for batch 90 = 0.8004038333892822\n",
      "Loss for batch 91 = 0.755088746547699\n",
      "Loss for batch 92 = 0.6890580654144287\n",
      "Loss for batch 93 = 0.8326907753944397\n",
      "Loss for batch 94 = 0.6132875680923462\n",
      "Loss for batch 95 = 0.510417640209198\n",
      "Loss for batch 96 = 0.8012678623199463\n",
      "Loss for batch 97 = 0.8367311358451843\n",
      "\n",
      "Training Loss for epoch 12 = 64.85002136230469\n",
      "\n",
      "Current Validation Loss = 22.450254440307617\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 73.68%\n",
      "Validation Accuracy: 61.23%\n",
      "\n",
      "Epoch 13\n",
      "----------\n",
      "Loss for batch 0 = 0.5269749760627747\n",
      "Loss for batch 1 = 0.5954762101173401\n",
      "Loss for batch 2 = 0.6043460369110107\n",
      "Loss for batch 3 = 0.6484748125076294\n",
      "Loss for batch 4 = 0.710590660572052\n",
      "Loss for batch 5 = 0.6289348602294922\n",
      "Loss for batch 6 = 0.7416552305221558\n",
      "Loss for batch 7 = 0.7462470531463623\n",
      "Loss for batch 8 = 0.766312301158905\n",
      "Loss for batch 9 = 0.5164077281951904\n",
      "Loss for batch 10 = 0.8039279580116272\n",
      "Loss for batch 11 = 0.4775019884109497\n",
      "Loss for batch 12 = 0.6321505308151245\n",
      "Loss for batch 13 = 0.6802324056625366\n",
      "Loss for batch 14 = 0.5793473720550537\n",
      "Loss for batch 15 = 0.6506068110466003\n",
      "Loss for batch 16 = 0.4843654930591583\n",
      "Loss for batch 17 = 0.5735121965408325\n",
      "Loss for batch 18 = 0.6188555955886841\n",
      "Loss for batch 19 = 0.5043679475784302\n",
      "Loss for batch 20 = 0.48677441477775574\n",
      "Loss for batch 21 = 0.6996637582778931\n",
      "Loss for batch 22 = 0.553204357624054\n",
      "Loss for batch 23 = 0.4873664975166321\n",
      "Loss for batch 24 = 0.5371727347373962\n",
      "Loss for batch 25 = 0.5771404504776001\n",
      "Loss for batch 26 = 0.7087517380714417\n",
      "Loss for batch 27 = 0.6087055206298828\n",
      "Loss for batch 28 = 0.6336349248886108\n",
      "Loss for batch 29 = 0.552471935749054\n",
      "Loss for batch 30 = 0.5900038480758667\n",
      "Loss for batch 31 = 0.5960544347763062\n",
      "Loss for batch 32 = 0.5786938667297363\n",
      "Loss for batch 33 = 0.575780987739563\n",
      "Loss for batch 34 = 0.6374629139900208\n",
      "Loss for batch 35 = 0.578462541103363\n",
      "Loss for batch 36 = 0.6980088353157043\n",
      "Loss for batch 37 = 0.8710244297981262\n",
      "Loss for batch 38 = 0.7356470227241516\n",
      "Loss for batch 39 = 0.5867636203765869\n",
      "Loss for batch 40 = 0.8820112347602844\n",
      "Loss for batch 41 = 0.7546351552009583\n",
      "Loss for batch 42 = 0.665391206741333\n",
      "Loss for batch 43 = 0.6465452313423157\n",
      "Loss for batch 44 = 0.47479695081710815\n",
      "Loss for batch 45 = 0.6181790232658386\n",
      "Loss for batch 46 = 0.7259514927864075\n",
      "Loss for batch 47 = 0.7627948522567749\n",
      "Loss for batch 48 = 0.580669641494751\n",
      "Loss for batch 49 = 0.5471226572990417\n",
      "Loss for batch 50 = 0.8143468499183655\n",
      "Loss for batch 51 = 0.529441237449646\n",
      "Loss for batch 52 = 0.5102541446685791\n",
      "Loss for batch 53 = 0.4575328230857849\n",
      "Loss for batch 54 = 0.7196435928344727\n",
      "Loss for batch 55 = 0.6436679363250732\n",
      "Loss for batch 56 = 0.6467980742454529\n",
      "Loss for batch 57 = 0.5643582940101624\n",
      "Loss for batch 58 = 0.5541238188743591\n",
      "Loss for batch 59 = 0.8738073110580444\n",
      "Loss for batch 60 = 0.6755262017250061\n",
      "Loss for batch 61 = 0.8738479614257812\n",
      "Loss for batch 62 = 0.6967360973358154\n",
      "Loss for batch 63 = 0.6727893948554993\n",
      "Loss for batch 64 = 0.38745614886283875\n",
      "Loss for batch 65 = 0.6803387403488159\n",
      "Loss for batch 66 = 0.7317568063735962\n",
      "Loss for batch 67 = 0.7866239547729492\n",
      "Loss for batch 68 = 0.6555601954460144\n",
      "Loss for batch 69 = 0.6334180235862732\n",
      "Loss for batch 70 = 0.8436262011528015\n",
      "Loss for batch 71 = 0.5168318748474121\n",
      "Loss for batch 72 = 0.5628541111946106\n",
      "Loss for batch 73 = 0.6720945835113525\n",
      "Loss for batch 74 = 0.46195006370544434\n",
      "Loss for batch 75 = 0.5881946086883545\n",
      "Loss for batch 76 = 0.5200167298316956\n",
      "Loss for batch 77 = 0.5888401865959167\n",
      "Loss for batch 78 = 0.5192383527755737\n",
      "Loss for batch 79 = 0.537604808807373\n",
      "Loss for batch 80 = 0.6374636888504028\n",
      "Loss for batch 81 = 0.8263816237449646\n",
      "Loss for batch 82 = 0.6692884564399719\n",
      "Loss for batch 83 = 0.7752775549888611\n",
      "Loss for batch 84 = 0.5426499843597412\n",
      "Loss for batch 85 = 0.487331360578537\n",
      "Loss for batch 86 = 0.347895085811615\n",
      "Loss for batch 87 = 0.5589630007743835\n",
      "Loss for batch 88 = 0.4285016655921936\n",
      "Loss for batch 89 = 0.658402681350708\n",
      "Loss for batch 90 = 0.8117084503173828\n",
      "Loss for batch 91 = 0.7982050180435181\n",
      "Loss for batch 92 = 0.6385104060173035\n",
      "Loss for batch 93 = 0.8082477450370789\n",
      "Loss for batch 94 = 0.6222412586212158\n",
      "Loss for batch 95 = 0.5234940052032471\n",
      "Loss for batch 96 = 0.7419705986976624\n",
      "Loss for batch 97 = 0.8150668144226074\n",
      "\n",
      "Training Loss for epoch 13 = 62.05204772949219\n",
      "\n",
      "Current Validation Loss = 22.875030517578125\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 4\n",
      "Train Accuracy: 74.42%\n",
      "Validation Accuracy: 61.62%\n",
      "\n",
      "Epoch 14\n",
      "----------\n",
      "Loss for batch 0 = 0.5033742785453796\n",
      "Loss for batch 1 = 0.5794208645820618\n",
      "Loss for batch 2 = 0.5986006259918213\n",
      "Loss for batch 3 = 0.6256244778633118\n",
      "Loss for batch 4 = 0.677294135093689\n",
      "Loss for batch 5 = 0.5526198148727417\n",
      "Loss for batch 6 = 0.7415736317634583\n",
      "Loss for batch 7 = 0.6909055113792419\n",
      "Loss for batch 8 = 0.6951925158500671\n",
      "Loss for batch 9 = 0.49215197563171387\n",
      "Loss for batch 10 = 0.8269046545028687\n",
      "Loss for batch 11 = 0.4252052307128906\n",
      "Loss for batch 12 = 0.6142738461494446\n",
      "Loss for batch 13 = 0.6787776350975037\n",
      "Loss for batch 14 = 0.5961560606956482\n",
      "Loss for batch 15 = 0.6047606468200684\n",
      "Loss for batch 16 = 0.502443253993988\n",
      "Loss for batch 17 = 0.5332797765731812\n",
      "Loss for batch 18 = 0.5816881656646729\n",
      "Loss for batch 19 = 0.4927249252796173\n",
      "Loss for batch 20 = 0.4583350419998169\n",
      "Loss for batch 21 = 0.7055035829544067\n",
      "Loss for batch 22 = 0.5368070602416992\n",
      "Loss for batch 23 = 0.47508475184440613\n",
      "Loss for batch 24 = 0.4488219916820526\n",
      "Loss for batch 25 = 0.4673047661781311\n",
      "Loss for batch 26 = 0.683171272277832\n",
      "Loss for batch 27 = 0.6032276153564453\n",
      "Loss for batch 28 = 0.5751040577888489\n",
      "Loss for batch 29 = 0.5935659408569336\n",
      "Loss for batch 30 = 0.5623137950897217\n",
      "Loss for batch 31 = 0.5185054540634155\n",
      "Loss for batch 32 = 0.5785349011421204\n",
      "Loss for batch 33 = 0.545871913433075\n",
      "Loss for batch 34 = 0.6896775960922241\n",
      "Loss for batch 35 = 0.650933563709259\n",
      "Loss for batch 36 = 0.7230279445648193\n",
      "Loss for batch 37 = 0.8444244265556335\n",
      "Loss for batch 38 = 0.6687220335006714\n",
      "Loss for batch 39 = 0.4906538724899292\n",
      "Loss for batch 40 = 0.7801582217216492\n",
      "Loss for batch 41 = 0.7534794807434082\n",
      "Loss for batch 42 = 0.6614654660224915\n",
      "Loss for batch 43 = 0.6640148162841797\n",
      "Loss for batch 44 = 0.5175855159759521\n",
      "Loss for batch 45 = 0.5944864749908447\n",
      "Loss for batch 46 = 0.6945642232894897\n",
      "Loss for batch 47 = 0.7458104491233826\n",
      "Loss for batch 48 = 0.5392385721206665\n",
      "Loss for batch 49 = 0.5880392789840698\n",
      "Loss for batch 50 = 0.8128470778465271\n",
      "Loss for batch 51 = 0.5343430638313293\n",
      "Loss for batch 52 = 0.5117360353469849\n",
      "Loss for batch 53 = 0.45137155055999756\n",
      "Loss for batch 54 = 0.665813684463501\n",
      "Loss for batch 55 = 0.6346588730812073\n",
      "Loss for batch 56 = 0.6761174201965332\n",
      "Loss for batch 57 = 0.4707053005695343\n",
      "Loss for batch 58 = 0.5072731971740723\n",
      "Loss for batch 59 = 0.8428107500076294\n",
      "Loss for batch 60 = 0.6198144555091858\n",
      "Loss for batch 61 = 0.8109394311904907\n",
      "Loss for batch 62 = 0.6904207468032837\n",
      "Loss for batch 63 = 0.6906413435935974\n",
      "Loss for batch 64 = 0.39419713616371155\n",
      "Loss for batch 65 = 0.6202057003974915\n",
      "Loss for batch 66 = 0.6889796853065491\n",
      "Loss for batch 67 = 0.8313371539115906\n",
      "Loss for batch 68 = 0.6407120823860168\n",
      "Loss for batch 69 = 0.6030939221382141\n",
      "Loss for batch 70 = 0.7733136415481567\n",
      "Loss for batch 71 = 0.5166008472442627\n",
      "Loss for batch 72 = 0.5610272288322449\n",
      "Loss for batch 73 = 0.5287564396858215\n",
      "Loss for batch 74 = 0.43982812762260437\n",
      "Loss for batch 75 = 0.5390893816947937\n",
      "Loss for batch 76 = 0.5219871997833252\n",
      "Loss for batch 77 = 0.5530918836593628\n",
      "Loss for batch 78 = 0.42171287536621094\n",
      "Loss for batch 79 = 0.4669148623943329\n",
      "Loss for batch 80 = 0.6247658133506775\n",
      "Loss for batch 81 = 0.7512462139129639\n",
      "Loss for batch 82 = 0.604196310043335\n",
      "Loss for batch 83 = 0.7453474998474121\n",
      "Loss for batch 84 = 0.47832363843917847\n",
      "Loss for batch 85 = 0.43573129177093506\n",
      "Loss for batch 86 = 0.29496023058891296\n",
      "Loss for batch 87 = 0.48933038115501404\n",
      "Loss for batch 88 = 0.3753539025783539\n",
      "Loss for batch 89 = 0.64794921875\n",
      "Loss for batch 90 = 0.7971868515014648\n",
      "Loss for batch 91 = 0.6925572752952576\n",
      "Loss for batch 92 = 0.6852515935897827\n",
      "Loss for batch 93 = 0.782283365726471\n",
      "Loss for batch 94 = 0.6057417392730713\n",
      "Loss for batch 95 = 0.5029865503311157\n",
      "Loss for batch 96 = 0.7607404589653015\n",
      "Loss for batch 97 = 0.7889290452003479\n",
      "\n",
      "Training Loss for epoch 14 = 59.45463943481445\n",
      "\n",
      "Current Validation Loss = 23.150089263916016\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 5\n",
      "Train Accuracy: 73.91%\n",
      "Validation Accuracy: 62.52%\n",
      "\n",
      "Epoch 15\n",
      "----------\n",
      "Loss for batch 0 = 0.5021910071372986\n",
      "Loss for batch 1 = 0.6146992444992065\n",
      "Loss for batch 2 = 0.6605955362319946\n",
      "Loss for batch 3 = 0.6176872849464417\n",
      "Loss for batch 4 = 0.7018561959266663\n",
      "Loss for batch 5 = 0.5437713861465454\n",
      "Loss for batch 6 = 0.7091026902198792\n",
      "Loss for batch 7 = 0.6716713905334473\n",
      "Loss for batch 8 = 0.7080917358398438\n",
      "Loss for batch 9 = 0.45789003372192383\n",
      "Loss for batch 10 = 0.8371132016181946\n",
      "Loss for batch 11 = 0.42089876532554626\n",
      "Loss for batch 12 = 0.5984945893287659\n",
      "Loss for batch 13 = 0.6644023656845093\n",
      "Loss for batch 14 = 0.5710732936859131\n",
      "Loss for batch 15 = 0.5239819884300232\n",
      "Loss for batch 16 = 0.4462806284427643\n",
      "Loss for batch 17 = 0.4433337450027466\n",
      "Loss for batch 18 = 0.5579659342765808\n",
      "Loss for batch 19 = 0.5224742889404297\n",
      "Loss for batch 20 = 0.4471254050731659\n",
      "Loss for batch 21 = 0.6531738638877869\n",
      "Loss for batch 22 = 0.5275486707687378\n",
      "Loss for batch 23 = 0.44861501455307007\n",
      "Loss for batch 24 = 0.4283047318458557\n",
      "Loss for batch 25 = 0.47130435705184937\n",
      "Loss for batch 26 = 0.6763862371444702\n",
      "Loss for batch 27 = 0.5447531342506409\n",
      "Loss for batch 28 = 0.5938355326652527\n",
      "Loss for batch 29 = 0.8827682137489319\n",
      "Loss for batch 30 = 0.6714308857917786\n",
      "Loss for batch 31 = 0.5459579825401306\n",
      "Loss for batch 32 = 0.5531846284866333\n",
      "Loss for batch 33 = 0.5917540192604065\n",
      "Loss for batch 34 = 0.7024206519126892\n",
      "Loss for batch 35 = 0.6249149441719055\n",
      "Loss for batch 36 = 1.0037670135498047\n",
      "Loss for batch 37 = 0.7784814238548279\n",
      "Loss for batch 38 = 0.7097695469856262\n",
      "Loss for batch 39 = 0.49150949716567993\n",
      "Loss for batch 40 = 0.7356916069984436\n",
      "Loss for batch 41 = 0.8419764637947083\n",
      "Loss for batch 42 = 0.5614202618598938\n",
      "Loss for batch 43 = 0.5996735095977783\n",
      "Loss for batch 44 = 0.402334600687027\n",
      "Loss for batch 45 = 0.5569545030593872\n",
      "Loss for batch 46 = 0.6642557382583618\n",
      "Loss for batch 47 = 0.7163555026054382\n",
      "Loss for batch 48 = 0.588909387588501\n",
      "Loss for batch 49 = 0.5655289888381958\n",
      "Loss for batch 50 = 0.7749758958816528\n",
      "Loss for batch 51 = 0.49134960770606995\n",
      "Loss for batch 52 = 0.5411102175712585\n",
      "Loss for batch 53 = 0.39392727613449097\n",
      "Loss for batch 54 = 0.6872116327285767\n",
      "Loss for batch 55 = 0.6097353100776672\n",
      "Loss for batch 56 = 0.6058022379875183\n",
      "Loss for batch 57 = 0.5614489912986755\n",
      "Loss for batch 58 = 0.5291103720664978\n",
      "Loss for batch 59 = 0.8227058053016663\n",
      "Loss for batch 60 = 0.642393171787262\n",
      "Loss for batch 61 = 0.8461843132972717\n",
      "Loss for batch 62 = 0.7311314940452576\n",
      "Loss for batch 63 = 0.6451486349105835\n",
      "Loss for batch 64 = 0.342498779296875\n",
      "Loss for batch 65 = 0.6046802401542664\n",
      "Loss for batch 66 = 0.6691553592681885\n",
      "Loss for batch 67 = 0.7142744064331055\n",
      "Loss for batch 68 = 0.6615002751350403\n",
      "Loss for batch 69 = 0.564241886138916\n",
      "Loss for batch 70 = 0.7577522397041321\n",
      "Loss for batch 71 = 0.49943116307258606\n",
      "Loss for batch 72 = 0.5229542851448059\n",
      "Loss for batch 73 = 0.5209758877754211\n",
      "Loss for batch 74 = 0.413766473531723\n",
      "Loss for batch 75 = 0.5294267535209656\n",
      "Loss for batch 76 = 0.5574073791503906\n",
      "Loss for batch 77 = 0.528203547000885\n",
      "Loss for batch 78 = 0.4210803806781769\n",
      "Loss for batch 79 = 0.4612756371498108\n",
      "Loss for batch 80 = 0.5715422630310059\n",
      "Loss for batch 81 = 0.7044862508773804\n",
      "Loss for batch 82 = 0.5479779243469238\n",
      "Loss for batch 83 = 0.7519271969795227\n",
      "Loss for batch 84 = 0.42371490597724915\n",
      "Loss for batch 85 = 0.49244165420532227\n",
      "Loss for batch 86 = 0.355733186006546\n",
      "Loss for batch 87 = 0.5692861080169678\n",
      "Loss for batch 88 = 0.3860907256603241\n",
      "Loss for batch 89 = 0.6531643271446228\n",
      "Loss for batch 90 = 0.7495549321174622\n",
      "Loss for batch 91 = 0.6788401007652283\n",
      "Loss for batch 92 = 0.646040141582489\n",
      "Loss for batch 93 = 0.7368519902229309\n",
      "Loss for batch 94 = 0.6632717847824097\n",
      "Loss for batch 95 = 0.4429957866668701\n",
      "Loss for batch 96 = 0.6913065314292908\n",
      "Loss for batch 97 = 0.7337352633476257\n",
      "\n",
      "Training Loss for epoch 15 = 58.80349349975586\n",
      "\n",
      "Current Validation Loss = 24.879131317138672\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 6\n",
      "Train Accuracy: 75.19%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 16\n",
      "----------\n",
      "Loss for batch 0 = 0.38862815499305725\n",
      "Loss for batch 1 = 0.552886426448822\n",
      "Loss for batch 2 = 0.6176963448524475\n",
      "Loss for batch 3 = 0.6419200301170349\n",
      "Loss for batch 4 = 0.6187143921852112\n",
      "Loss for batch 5 = 0.4877084493637085\n",
      "Loss for batch 6 = 0.7105965614318848\n",
      "Loss for batch 7 = 0.6680726408958435\n",
      "Loss for batch 8 = 0.7126041650772095\n",
      "Loss for batch 9 = 0.461121141910553\n",
      "Loss for batch 10 = 0.7477326393127441\n",
      "Loss for batch 11 = 0.368639200925827\n",
      "Loss for batch 12 = 0.608000636100769\n",
      "Loss for batch 13 = 0.7101467847824097\n",
      "Loss for batch 14 = 0.4927177131175995\n",
      "Loss for batch 15 = 0.6068433523178101\n",
      "Loss for batch 16 = 0.4411752223968506\n",
      "Loss for batch 17 = 0.47168752551078796\n",
      "Loss for batch 18 = 0.5302521586418152\n",
      "Loss for batch 19 = 0.4737784266471863\n",
      "Loss for batch 20 = 0.4226073622703552\n",
      "Loss for batch 21 = 0.6547873020172119\n",
      "Loss for batch 22 = 0.4567135274410248\n",
      "Loss for batch 23 = 0.4242202341556549\n",
      "Loss for batch 24 = 0.4481651782989502\n",
      "Loss for batch 25 = 0.422875314950943\n",
      "Loss for batch 26 = 0.650550365447998\n",
      "Loss for batch 27 = 0.5367032289505005\n",
      "Loss for batch 28 = 0.5255206227302551\n",
      "Loss for batch 29 = 0.6938493251800537\n",
      "Loss for batch 30 = 0.5625872015953064\n",
      "Loss for batch 31 = 0.5103662014007568\n",
      "Loss for batch 32 = 0.5930787920951843\n",
      "Loss for batch 33 = 0.5682955980300903\n",
      "Loss for batch 34 = 0.6912422776222229\n",
      "Loss for batch 35 = 0.4913709759712219\n",
      "Loss for batch 36 = 0.6116179823875427\n",
      "Loss for batch 37 = 0.7266456484794617\n",
      "Loss for batch 38 = 0.6039648056030273\n",
      "Loss for batch 39 = 0.43408095836639404\n",
      "Loss for batch 40 = 0.9201871156692505\n",
      "Loss for batch 41 = 0.716545581817627\n",
      "Loss for batch 42 = 0.6254301071166992\n",
      "Loss for batch 43 = 0.6452232599258423\n",
      "Loss for batch 44 = 0.42939138412475586\n",
      "Loss for batch 45 = 0.609230637550354\n",
      "Loss for batch 46 = 0.6435967683792114\n",
      "Loss for batch 47 = 0.6716284155845642\n",
      "Loss for batch 48 = 0.5074736475944519\n",
      "Loss for batch 49 = 0.5597928166389465\n",
      "Loss for batch 50 = 0.7651748657226562\n",
      "Loss for batch 51 = 0.44410768151283264\n",
      "Loss for batch 52 = 0.4525843858718872\n",
      "Loss for batch 53 = 0.3502576947212219\n",
      "Loss for batch 54 = 0.7048853635787964\n",
      "Loss for batch 55 = 0.6574701070785522\n",
      "Loss for batch 56 = 0.6049944162368774\n",
      "Loss for batch 57 = 0.5328845977783203\n",
      "Loss for batch 58 = 0.5209436416625977\n",
      "Loss for batch 59 = 0.9058844447135925\n",
      "Loss for batch 60 = 0.5760277509689331\n",
      "Loss for batch 61 = 0.7849071621894836\n",
      "Loss for batch 62 = 0.7151581645011902\n",
      "Loss for batch 63 = 0.6820869445800781\n",
      "Loss for batch 64 = 0.34988945722579956\n",
      "Loss for batch 65 = 0.5954344272613525\n",
      "Loss for batch 66 = 0.7273234128952026\n",
      "Loss for batch 67 = 0.7700982689857483\n",
      "Loss for batch 68 = 0.6631083488464355\n",
      "Loss for batch 69 = 0.54078608751297\n",
      "Loss for batch 70 = 0.7655639052391052\n",
      "Loss for batch 71 = 0.5275434851646423\n",
      "Loss for batch 72 = 0.48718997836112976\n",
      "Loss for batch 73 = 0.49597254395484924\n",
      "Loss for batch 74 = 0.4805145859718323\n",
      "Loss for batch 75 = 0.5255643129348755\n",
      "Loss for batch 76 = 0.5454030632972717\n",
      "Loss for batch 77 = 0.49904805421829224\n",
      "Loss for batch 78 = 0.3736017942428589\n",
      "Loss for batch 79 = 0.4147639572620392\n",
      "Loss for batch 80 = 0.5238229632377625\n",
      "Loss for batch 81 = 0.6572791337966919\n",
      "Loss for batch 82 = 0.4896255135536194\n",
      "Loss for batch 83 = 0.682077169418335\n",
      "Loss for batch 84 = 0.5004173517227173\n",
      "Loss for batch 85 = 0.39895766973495483\n",
      "Loss for batch 86 = 0.35283344984054565\n",
      "Loss for batch 87 = 0.5390135049819946\n",
      "Loss for batch 88 = 0.37194007635116577\n",
      "Loss for batch 89 = 0.6139487624168396\n",
      "Loss for batch 90 = 0.6919916272163391\n",
      "Loss for batch 91 = 0.9040842056274414\n",
      "Loss for batch 92 = 0.6352399587631226\n",
      "Loss for batch 93 = 0.7745328545570374\n",
      "Loss for batch 94 = 0.6609058976173401\n",
      "Loss for batch 95 = 0.43096432089805603\n",
      "Loss for batch 96 = 0.6587014198303223\n",
      "Loss for batch 97 = 0.7831763625144958\n",
      "\n",
      "Training Loss for epoch 16 = 56.79734420776367\n",
      "\n",
      "Current Validation Loss = 24.15027618408203\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 7\n",
      "Train Accuracy: 73.59%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 17\n",
      "----------\n",
      "Loss for batch 0 = 0.4956144094467163\n",
      "Loss for batch 1 = 0.6750742197036743\n",
      "Loss for batch 2 = 0.5859308242797852\n",
      "Loss for batch 3 = 0.5914269685745239\n",
      "Loss for batch 4 = 0.5860424637794495\n",
      "Loss for batch 5 = 0.5009540319442749\n",
      "Loss for batch 6 = 0.7164244651794434\n",
      "Loss for batch 7 = 0.6215501427650452\n",
      "Loss for batch 8 = 0.6483317613601685\n",
      "Loss for batch 9 = 0.39264342188835144\n",
      "Loss for batch 10 = 0.7795368432998657\n",
      "Loss for batch 11 = 0.4438280761241913\n",
      "Loss for batch 12 = 0.5962267518043518\n",
      "Loss for batch 13 = 0.6365306377410889\n",
      "Loss for batch 14 = 0.5266779661178589\n",
      "Loss for batch 15 = 0.5941960215568542\n",
      "Loss for batch 16 = 0.4829428493976593\n",
      "Loss for batch 17 = 0.43003615736961365\n",
      "Loss for batch 18 = 0.4398185610771179\n",
      "Loss for batch 19 = 0.4281812012195587\n",
      "Loss for batch 20 = 0.40185031294822693\n",
      "Loss for batch 21 = 0.6120119094848633\n",
      "Loss for batch 22 = 0.39219292998313904\n",
      "Loss for batch 23 = 0.40798264741897583\n",
      "Loss for batch 24 = 0.3765849769115448\n",
      "Loss for batch 25 = 0.4633827805519104\n",
      "Loss for batch 26 = 0.7333282828330994\n",
      "Loss for batch 27 = 0.5322830080986023\n",
      "Loss for batch 28 = 0.5508384704589844\n",
      "Loss for batch 29 = 0.5148265361785889\n",
      "Loss for batch 30 = 0.5913662314414978\n",
      "Loss for batch 31 = 0.48941895365715027\n",
      "Loss for batch 32 = 0.5640829205513\n",
      "Loss for batch 33 = 0.49226999282836914\n",
      "Loss for batch 34 = 0.6613997220993042\n",
      "Loss for batch 35 = 0.717326819896698\n",
      "Loss for batch 36 = 0.6386255621910095\n",
      "Loss for batch 37 = 0.7414916753768921\n",
      "Loss for batch 38 = 0.6523466110229492\n",
      "Loss for batch 39 = 0.4533612132072449\n",
      "Loss for batch 40 = 0.7188249230384827\n",
      "Loss for batch 41 = 0.7563468813896179\n",
      "Loss for batch 42 = 0.652579128742218\n",
      "Loss for batch 43 = 0.6583026647567749\n",
      "Loss for batch 44 = 0.4258507192134857\n",
      "Loss for batch 45 = 0.5029343366622925\n",
      "Loss for batch 46 = 0.7430104613304138\n",
      "Loss for batch 47 = 0.6703271269798279\n",
      "Loss for batch 48 = 0.5255739092826843\n",
      "Loss for batch 49 = 0.521003782749176\n",
      "Loss for batch 50 = 0.7966207265853882\n",
      "Loss for batch 51 = 0.4240771234035492\n",
      "Loss for batch 52 = 0.49910515546798706\n",
      "Loss for batch 53 = 0.5086305141448975\n",
      "Loss for batch 54 = 0.6156829595565796\n",
      "Loss for batch 55 = 0.6132342219352722\n",
      "Loss for batch 56 = 0.6409081220626831\n",
      "Loss for batch 57 = 0.4729836881160736\n",
      "Loss for batch 58 = 0.45620474219322205\n",
      "Loss for batch 59 = 0.816343367099762\n",
      "Loss for batch 60 = 0.6081517338752747\n",
      "Loss for batch 61 = 0.7630949020385742\n",
      "Loss for batch 62 = 0.687272846698761\n",
      "Loss for batch 63 = 0.6224434971809387\n",
      "Loss for batch 64 = 0.26767590641975403\n",
      "Loss for batch 65 = 0.5958458781242371\n",
      "Loss for batch 66 = 0.6738691329956055\n",
      "Loss for batch 67 = 0.712750256061554\n",
      "Loss for batch 68 = 0.6745429039001465\n",
      "Loss for batch 69 = 0.487838476896286\n",
      "Loss for batch 70 = 0.7327696681022644\n",
      "Loss for batch 71 = 0.4858141243457794\n",
      "Loss for batch 72 = 0.5573894381523132\n",
      "Loss for batch 73 = 0.47817519307136536\n",
      "Loss for batch 74 = 0.4178899824619293\n",
      "Loss for batch 75 = 0.4932546615600586\n",
      "Loss for batch 76 = 0.4946354627609253\n",
      "Loss for batch 77 = 0.49869808554649353\n",
      "Loss for batch 78 = 0.45242834091186523\n",
      "Loss for batch 79 = 0.40813642740249634\n",
      "Loss for batch 80 = 0.5538195967674255\n",
      "Loss for batch 81 = 0.6776809096336365\n",
      "Loss for batch 82 = 0.5442253351211548\n",
      "Loss for batch 83 = 0.7454828023910522\n",
      "Loss for batch 84 = 0.4750261604785919\n",
      "Loss for batch 85 = 0.40584155917167664\n",
      "Loss for batch 86 = 0.30208444595336914\n",
      "Loss for batch 87 = 0.5698693990707397\n",
      "Loss for batch 88 = 0.4047861695289612\n",
      "Loss for batch 89 = 0.568161129951477\n",
      "Loss for batch 90 = 0.7845736742019653\n",
      "Loss for batch 91 = 0.7531177997589111\n",
      "Loss for batch 92 = 0.5511815547943115\n",
      "Loss for batch 93 = 0.7048108577728271\n",
      "Loss for batch 94 = 0.6316002011299133\n",
      "Loss for batch 95 = 0.38830992579460144\n",
      "Loss for batch 96 = 0.6216079592704773\n",
      "Loss for batch 97 = 0.7613863945007324\n",
      "\n",
      "Training Loss for epoch 17 = 55.73371887207031\n",
      "\n",
      "Current Validation Loss = 24.328874588012695\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 8\n",
      "Train Accuracy: 76.83%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 18\n",
      "----------\n",
      "Loss for batch 0 = 0.40679919719696045\n",
      "Loss for batch 1 = 0.6153925061225891\n",
      "Loss for batch 2 = 0.5234658718109131\n",
      "Loss for batch 3 = 0.5744287371635437\n",
      "Loss for batch 4 = 0.6552850604057312\n",
      "Loss for batch 5 = 0.4797392189502716\n",
      "Loss for batch 6 = 0.665529727935791\n",
      "Loss for batch 7 = 0.5918962359428406\n",
      "Loss for batch 8 = 0.6170827150344849\n",
      "Loss for batch 9 = 0.3472763001918793\n",
      "Loss for batch 10 = 0.7635923624038696\n",
      "Loss for batch 11 = 0.3774547576904297\n",
      "Loss for batch 12 = 0.5975532531738281\n",
      "Loss for batch 13 = 0.598628044128418\n",
      "Loss for batch 14 = 0.5001289248466492\n",
      "Loss for batch 15 = 0.5210420489311218\n",
      "Loss for batch 16 = 0.4381909966468811\n",
      "Loss for batch 17 = 0.36618465185165405\n",
      "Loss for batch 18 = 0.4671902358531952\n",
      "Loss for batch 19 = 0.3745410442352295\n",
      "Loss for batch 20 = 0.31019580364227295\n",
      "Loss for batch 21 = 0.5978242754936218\n",
      "Loss for batch 22 = 0.44678086042404175\n",
      "Loss for batch 23 = 0.41965532302856445\n",
      "Loss for batch 24 = 0.5143404006958008\n",
      "Loss for batch 25 = 0.3667413890361786\n",
      "Loss for batch 26 = 0.6956462264060974\n",
      "Loss for batch 27 = 0.520429253578186\n",
      "Loss for batch 28 = 0.44520753622055054\n",
      "Loss for batch 29 = 0.5096780061721802\n",
      "Loss for batch 30 = 0.48765885829925537\n",
      "Loss for batch 31 = 0.40033984184265137\n",
      "Loss for batch 32 = 0.4951378107070923\n",
      "Loss for batch 33 = 0.5023577213287354\n",
      "Loss for batch 34 = 0.6495553851127625\n",
      "Loss for batch 35 = 0.6719247698783875\n",
      "Loss for batch 36 = 0.6612180471420288\n",
      "Loss for batch 37 = 0.7099546194076538\n",
      "Loss for batch 38 = 0.6084335446357727\n",
      "Loss for batch 39 = 0.38009563088417053\n",
      "Loss for batch 40 = 0.7650516629219055\n",
      "Loss for batch 41 = 0.7399088144302368\n",
      "Loss for batch 42 = 0.6223673820495605\n",
      "Loss for batch 43 = 0.6104350686073303\n",
      "Loss for batch 44 = 0.41827327013015747\n",
      "Loss for batch 45 = 0.4670412540435791\n",
      "Loss for batch 46 = 0.7468122243881226\n",
      "Loss for batch 47 = 0.6587580442428589\n",
      "Loss for batch 48 = 0.5038155913352966\n",
      "Loss for batch 49 = 0.5067895650863647\n",
      "Loss for batch 50 = 0.820692777633667\n",
      "Loss for batch 51 = 0.4208986163139343\n",
      "Loss for batch 52 = 0.43920713663101196\n",
      "Loss for batch 53 = 0.4241960048675537\n",
      "Loss for batch 54 = 0.5857837200164795\n",
      "Loss for batch 55 = 0.4969073235988617\n",
      "Loss for batch 56 = 0.6288866400718689\n",
      "Loss for batch 57 = 0.4408875107765198\n",
      "Loss for batch 58 = 0.4699992835521698\n",
      "Loss for batch 59 = 0.8157747387886047\n",
      "Loss for batch 60 = 0.593007504940033\n",
      "Loss for batch 61 = 0.7714428901672363\n",
      "Loss for batch 62 = 0.7130833268165588\n",
      "Loss for batch 63 = 0.667253315448761\n",
      "Loss for batch 64 = 0.2634391188621521\n",
      "Loss for batch 65 = 0.6424275636672974\n",
      "Loss for batch 66 = 0.62527996301651\n",
      "Loss for batch 67 = 0.7717356085777283\n",
      "Loss for batch 68 = 0.6343455910682678\n",
      "Loss for batch 69 = 0.40519171953201294\n",
      "Loss for batch 70 = 0.7573744058609009\n",
      "Loss for batch 71 = 0.47060665488243103\n",
      "Loss for batch 72 = 0.473098486661911\n",
      "Loss for batch 73 = 0.46227288246154785\n",
      "Loss for batch 74 = 0.4165429174900055\n",
      "Loss for batch 75 = 0.4797101616859436\n",
      "Loss for batch 76 = 0.4313814342021942\n",
      "Loss for batch 77 = 0.4661746919155121\n",
      "Loss for batch 78 = 0.5685485005378723\n",
      "Loss for batch 79 = 0.4372444748878479\n",
      "Loss for batch 80 = 0.47633254528045654\n",
      "Loss for batch 81 = 0.6750467419624329\n",
      "Loss for batch 82 = 0.4877346158027649\n",
      "Loss for batch 83 = 0.6178113222122192\n",
      "Loss for batch 84 = 0.4366379380226135\n",
      "Loss for batch 85 = 0.457051157951355\n",
      "Loss for batch 86 = 0.26315170526504517\n",
      "Loss for batch 87 = 0.5477214455604553\n",
      "Loss for batch 88 = 0.4080255627632141\n",
      "Loss for batch 89 = 0.5540682673454285\n",
      "Loss for batch 90 = 0.7941378355026245\n",
      "Loss for batch 91 = 0.6882001757621765\n",
      "Loss for batch 92 = 0.5729494094848633\n",
      "Loss for batch 93 = 0.6933498382568359\n",
      "Loss for batch 94 = 0.5603371262550354\n",
      "Loss for batch 95 = 0.4619963765144348\n",
      "Loss for batch 96 = 0.6551496386528015\n",
      "Loss for batch 97 = 0.7066963315010071\n",
      "\n",
      "Training Loss for epoch 18 = 53.56362533569336\n",
      "\n",
      "Current Validation Loss = 25.113874435424805\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 9\n",
      "Train Accuracy: 76.60%\n",
      "Validation Accuracy: 59.56%\n",
      "\n",
      "Epoch 19\n",
      "----------\n",
      "Loss for batch 0 = 0.3771750032901764\n",
      "Loss for batch 1 = 0.5803998112678528\n",
      "Loss for batch 2 = 0.6035956144332886\n",
      "Loss for batch 3 = 0.6131831407546997\n",
      "Loss for batch 4 = 0.6173415780067444\n",
      "Loss for batch 5 = 0.5020735263824463\n",
      "Loss for batch 6 = 0.5939900875091553\n",
      "Loss for batch 7 = 0.641700029373169\n",
      "Loss for batch 8 = 0.5921773314476013\n",
      "Loss for batch 9 = 0.3785442113876343\n",
      "Loss for batch 10 = 0.5770472288131714\n",
      "Loss for batch 11 = 0.4182814061641693\n",
      "Loss for batch 12 = 0.5749536752700806\n",
      "Loss for batch 13 = 0.5392831563949585\n",
      "Loss for batch 14 = 0.4759194552898407\n",
      "Loss for batch 15 = 0.4434692859649658\n",
      "Loss for batch 16 = 0.4207538962364197\n",
      "Loss for batch 17 = 0.43255990743637085\n",
      "Loss for batch 18 = 0.42336174845695496\n",
      "Loss for batch 19 = 0.37585213780403137\n",
      "Loss for batch 20 = 0.3389350175857544\n",
      "Loss for batch 21 = 0.6090738773345947\n",
      "Loss for batch 22 = 0.4064015746116638\n",
      "Loss for batch 23 = 0.3839905560016632\n",
      "Loss for batch 24 = 0.39702099561691284\n",
      "Loss for batch 25 = 0.4693465828895569\n",
      "Loss for batch 26 = 0.6111928820610046\n",
      "Loss for batch 27 = 0.5053033232688904\n",
      "Loss for batch 28 = 0.5191420912742615\n",
      "Loss for batch 29 = 0.549623966217041\n",
      "Loss for batch 30 = 0.48791298270225525\n",
      "Loss for batch 31 = 0.46439266204833984\n",
      "Loss for batch 32 = 0.5602998733520508\n",
      "Loss for batch 33 = 0.48612117767333984\n",
      "Loss for batch 34 = 0.6480402946472168\n",
      "Loss for batch 35 = 0.4687410295009613\n",
      "Loss for batch 36 = 0.5925765037536621\n",
      "Loss for batch 37 = 0.6327840089797974\n",
      "Loss for batch 38 = 0.7114640474319458\n",
      "Loss for batch 39 = 0.34440773725509644\n",
      "Loss for batch 40 = 0.7207918167114258\n",
      "Loss for batch 41 = 0.6784422993659973\n",
      "Loss for batch 42 = 0.5872454047203064\n",
      "Loss for batch 43 = 0.5704392194747925\n",
      "Loss for batch 44 = 0.31509849429130554\n",
      "Loss for batch 45 = 0.43705928325653076\n",
      "Loss for batch 46 = 0.6488043665885925\n",
      "Loss for batch 47 = 0.5748016238212585\n",
      "Loss for batch 48 = 0.44729629158973694\n",
      "Loss for batch 49 = 0.4550895094871521\n",
      "Loss for batch 50 = 0.7802475690841675\n",
      "Loss for batch 51 = 0.3591236174106598\n",
      "Loss for batch 52 = 0.36505186557769775\n",
      "Loss for batch 53 = 0.31170639395713806\n",
      "Loss for batch 54 = 0.6582140326499939\n",
      "Loss for batch 55 = 0.5535356998443604\n",
      "Loss for batch 56 = 0.6334373950958252\n",
      "Loss for batch 57 = 0.3806215226650238\n",
      "Loss for batch 58 = 0.3978058993816376\n",
      "Loss for batch 59 = 0.7664104700088501\n",
      "Loss for batch 60 = 0.49453890323638916\n",
      "Loss for batch 61 = 0.7622880339622498\n",
      "Loss for batch 62 = 0.6161754131317139\n",
      "Loss for batch 63 = 0.5379078388214111\n",
      "Loss for batch 64 = 0.26457685232162476\n",
      "Loss for batch 65 = 0.5391711592674255\n",
      "Loss for batch 66 = 0.5830033421516418\n",
      "Loss for batch 67 = 0.716975212097168\n",
      "Loss for batch 68 = 0.6077256798744202\n",
      "Loss for batch 69 = 0.3688271939754486\n",
      "Loss for batch 70 = 0.6620166301727295\n",
      "Loss for batch 71 = 0.4496045410633087\n",
      "Loss for batch 72 = 0.47572001814842224\n",
      "Loss for batch 73 = 0.41863489151000977\n",
      "Loss for batch 74 = 0.3672645688056946\n",
      "Loss for batch 75 = 0.4645022749900818\n",
      "Loss for batch 76 = 0.41599610447883606\n",
      "Loss for batch 77 = 0.4058510363101959\n",
      "Loss for batch 78 = 0.3685205280780792\n",
      "Loss for batch 79 = 0.3167038559913635\n",
      "Loss for batch 80 = 0.40236109495162964\n",
      "Loss for batch 81 = 0.6001445651054382\n",
      "Loss for batch 82 = 0.5168330669403076\n",
      "Loss for batch 83 = 0.5720336437225342\n",
      "Loss for batch 84 = 0.39370468258857727\n",
      "Loss for batch 85 = 0.3265756070613861\n",
      "Loss for batch 86 = 0.2627708613872528\n",
      "Loss for batch 87 = 0.46041572093963623\n",
      "Loss for batch 88 = 0.34716713428497314\n",
      "Loss for batch 89 = 0.5171929001808167\n",
      "Loss for batch 90 = 0.7626630663871765\n",
      "Loss for batch 91 = 0.5875884294509888\n",
      "Loss for batch 92 = 0.6137243509292603\n",
      "Loss for batch 93 = 0.6052492260932922\n",
      "Loss for batch 94 = 0.5055028796195984\n",
      "Loss for batch 95 = 0.3429844081401825\n",
      "Loss for batch 96 = 0.5858588814735413\n",
      "Loss for batch 97 = 0.6581262946128845\n",
      "\n",
      "Training Loss for epoch 19 = 49.90655517578125\n",
      "\n",
      "Current Validation Loss = 28.264978408813477\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 10\n",
      "Train Accuracy: 76.70%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 20\n",
      "----------\n",
      "Loss for batch 0 = 0.47758638858795166\n",
      "Loss for batch 1 = 0.5453336238861084\n",
      "Loss for batch 2 = 0.4414762258529663\n",
      "Loss for batch 3 = 0.5874659419059753\n",
      "Loss for batch 4 = 0.6280304789543152\n",
      "Loss for batch 5 = 0.5003085136413574\n",
      "Loss for batch 6 = 0.6236335635185242\n",
      "Loss for batch 7 = 0.6253145933151245\n",
      "Loss for batch 8 = 0.5464918613433838\n",
      "Loss for batch 9 = 0.31832411885261536\n",
      "Loss for batch 10 = 0.5774688720703125\n",
      "Loss for batch 11 = 0.3308756947517395\n",
      "Loss for batch 12 = 0.5194351077079773\n",
      "Loss for batch 13 = 0.5432859063148499\n",
      "Loss for batch 14 = 0.45768341422080994\n",
      "Loss for batch 15 = 0.4218009412288666\n",
      "Loss for batch 16 = 0.3811376690864563\n",
      "Loss for batch 17 = 0.3326474130153656\n",
      "Loss for batch 18 = 0.3782272934913635\n",
      "Loss for batch 19 = 0.3087877035140991\n",
      "Loss for batch 20 = 0.3063617944717407\n",
      "Loss for batch 21 = 0.6377899050712585\n",
      "Loss for batch 22 = 0.37453457713127136\n",
      "Loss for batch 23 = 0.36555495858192444\n",
      "Loss for batch 24 = 0.3557392656803131\n",
      "Loss for batch 25 = 0.3867053687572479\n",
      "Loss for batch 26 = 0.5920692086219788\n",
      "Loss for batch 27 = 0.4883902966976166\n",
      "Loss for batch 28 = 0.47018957138061523\n",
      "Loss for batch 29 = 0.4418103098869324\n",
      "Loss for batch 30 = 0.48630988597869873\n",
      "Loss for batch 31 = 0.3961503505706787\n",
      "Loss for batch 32 = 0.5385242700576782\n",
      "Loss for batch 33 = 0.44684159755706787\n",
      "Loss for batch 34 = 0.6637145280838013\n",
      "Loss for batch 35 = 0.4233739376068115\n",
      "Loss for batch 36 = 0.5409154891967773\n",
      "Loss for batch 37 = 0.6064283847808838\n",
      "Loss for batch 38 = 0.6745935082435608\n",
      "Loss for batch 39 = 0.3068387806415558\n",
      "Loss for batch 40 = 0.6916486024856567\n",
      "Loss for batch 41 = 0.65046626329422\n",
      "Loss for batch 42 = 0.576268196105957\n",
      "Loss for batch 43 = 0.5422989726066589\n",
      "Loss for batch 44 = 0.2910831868648529\n",
      "Loss for batch 45 = 0.39892590045928955\n",
      "Loss for batch 46 = 0.6281667351722717\n",
      "Loss for batch 47 = 0.5212986469268799\n",
      "Loss for batch 48 = 0.4396081864833832\n",
      "Loss for batch 49 = 0.44052422046661377\n",
      "Loss for batch 50 = 0.7910187840461731\n",
      "Loss for batch 51 = 0.3349109888076782\n",
      "Loss for batch 52 = 0.33318084478378296\n",
      "Loss for batch 53 = 0.26886260509490967\n",
      "Loss for batch 54 = 0.6456882357597351\n",
      "Loss for batch 55 = 0.5522201657295227\n",
      "Loss for batch 56 = 0.6130441427230835\n",
      "Loss for batch 57 = 0.3724071681499481\n",
      "Loss for batch 58 = 0.3849306106567383\n",
      "Loss for batch 59 = 0.7516509890556335\n",
      "Loss for batch 60 = 0.4287819266319275\n",
      "Loss for batch 61 = 0.7548088431358337\n",
      "Loss for batch 62 = 0.5870792269706726\n",
      "Loss for batch 63 = 0.4881910979747772\n",
      "Loss for batch 64 = 0.24433669447898865\n",
      "Loss for batch 65 = 0.5327885150909424\n",
      "Loss for batch 66 = 0.5585266351699829\n",
      "Loss for batch 67 = 0.6754393577575684\n",
      "Loss for batch 68 = 0.608674943447113\n",
      "Loss for batch 69 = 0.3451741337776184\n",
      "Loss for batch 70 = 0.6314608454704285\n",
      "Loss for batch 71 = 0.43827879428863525\n",
      "Loss for batch 72 = 0.4376590847969055\n",
      "Loss for batch 73 = 0.3877002000808716\n",
      "Loss for batch 74 = 0.3490811586380005\n",
      "Loss for batch 75 = 0.4493776261806488\n",
      "Loss for batch 76 = 0.4280947744846344\n",
      "Loss for batch 77 = 0.374182790517807\n",
      "Loss for batch 78 = 0.35596510767936707\n",
      "Loss for batch 79 = 0.29637411236763\n",
      "Loss for batch 80 = 0.3771578371524811\n",
      "Loss for batch 81 = 0.575320839881897\n",
      "Loss for batch 82 = 0.5027786493301392\n",
      "Loss for batch 83 = 0.5353691577911377\n",
      "Loss for batch 84 = 0.36842724680900574\n",
      "Loss for batch 85 = 0.2843370735645294\n",
      "Loss for batch 86 = 0.2711873948574066\n",
      "Loss for batch 87 = 0.4635160267353058\n",
      "Loss for batch 88 = 0.33736321330070496\n",
      "Loss for batch 89 = 0.47489041090011597\n",
      "Loss for batch 90 = 0.7359316349029541\n",
      "Loss for batch 91 = 0.5710291266441345\n",
      "Loss for batch 92 = 0.5616442561149597\n",
      "Loss for batch 93 = 0.5796913504600525\n",
      "Loss for batch 94 = 0.514190137386322\n",
      "Loss for batch 95 = 0.31808605790138245\n",
      "Loss for batch 96 = 0.5558938980102539\n",
      "Loss for batch 97 = 0.6246366500854492\n",
      "\n",
      "Training Loss for epoch 20 = 47.29978942871094\n",
      "\n",
      "Current Validation Loss = 28.366409301757812\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 11\n",
      "Train Accuracy: 79.69%\n",
      "Validation Accuracy: 59.56%\n",
      "\n",
      "Epoch 21\n",
      "----------\n",
      "Loss for batch 0 = 0.2768424153327942\n",
      "Loss for batch 1 = 0.5489447712898254\n",
      "Loss for batch 2 = 0.38986068964004517\n",
      "Loss for batch 3 = 0.5570116639137268\n",
      "Loss for batch 4 = 0.6333388686180115\n",
      "Loss for batch 5 = 0.46919068694114685\n",
      "Loss for batch 6 = 0.6060339212417603\n",
      "Loss for batch 7 = 0.5857916474342346\n",
      "Loss for batch 8 = 0.49637818336486816\n",
      "Loss for batch 9 = 0.3040972650051117\n",
      "Loss for batch 10 = 0.542675256729126\n",
      "Loss for batch 11 = 0.3194543123245239\n",
      "Loss for batch 12 = 0.5437708497047424\n",
      "Loss for batch 13 = 0.5125634670257568\n",
      "Loss for batch 14 = 0.4558343291282654\n",
      "Loss for batch 15 = 0.4025893211364746\n",
      "Loss for batch 16 = 0.34784090518951416\n",
      "Loss for batch 17 = 0.2860378623008728\n",
      "Loss for batch 18 = 0.3562241494655609\n",
      "Loss for batch 19 = 0.32447609305381775\n",
      "Loss for batch 20 = 0.31036514043807983\n",
      "Loss for batch 21 = 0.6627917885780334\n",
      "Loss for batch 22 = 0.363709032535553\n",
      "Loss for batch 23 = 0.36823028326034546\n",
      "Loss for batch 24 = 0.38315439224243164\n",
      "Loss for batch 25 = 0.3470970094203949\n",
      "Loss for batch 26 = 0.5748743414878845\n",
      "Loss for batch 27 = 0.4806373417377472\n",
      "Loss for batch 28 = 0.4472466707229614\n",
      "Loss for batch 29 = 0.42289116978645325\n",
      "Loss for batch 30 = 0.46806469559669495\n",
      "Loss for batch 31 = 0.36846521496772766\n",
      "Loss for batch 32 = 0.5461012125015259\n",
      "Loss for batch 33 = 0.4338851869106293\n",
      "Loss for batch 34 = 0.641166090965271\n",
      "Loss for batch 35 = 0.36799362301826477\n",
      "Loss for batch 36 = 0.5288649797439575\n",
      "Loss for batch 37 = 0.6025573015213013\n",
      "Loss for batch 38 = 0.638945996761322\n",
      "Loss for batch 39 = 0.33528685569763184\n",
      "Loss for batch 40 = 0.6643940806388855\n",
      "Loss for batch 41 = 0.6205505132675171\n",
      "Loss for batch 42 = 0.5581082701683044\n",
      "Loss for batch 43 = 0.5302609801292419\n",
      "Loss for batch 44 = 0.3167514204978943\n",
      "Loss for batch 45 = 0.38525283336639404\n",
      "Loss for batch 46 = 0.6006929278373718\n",
      "Loss for batch 47 = 0.46640050411224365\n",
      "Loss for batch 48 = 0.43729451298713684\n",
      "Loss for batch 49 = 0.4176478981971741\n",
      "Loss for batch 50 = 0.8398320078849792\n",
      "Loss for batch 51 = 0.31537386775016785\n",
      "Loss for batch 52 = 0.3184264302253723\n",
      "Loss for batch 53 = 0.29449570178985596\n",
      "Loss for batch 54 = 0.6497160196304321\n",
      "Loss for batch 55 = 0.539788007736206\n",
      "Loss for batch 56 = 0.6191973090171814\n",
      "Loss for batch 57 = 0.3640153408050537\n",
      "Loss for batch 58 = 0.3792054057121277\n",
      "Loss for batch 59 = 0.750027596950531\n",
      "Loss for batch 60 = 0.4301047921180725\n",
      "Loss for batch 61 = 0.7516192197799683\n",
      "Loss for batch 62 = 0.5721717476844788\n",
      "Loss for batch 63 = 0.4721493721008301\n",
      "Loss for batch 64 = 0.24045561254024506\n",
      "Loss for batch 65 = 0.5093322396278381\n",
      "Loss for batch 66 = 0.5457756519317627\n",
      "Loss for batch 67 = 0.6064802408218384\n",
      "Loss for batch 68 = 0.5917609930038452\n",
      "Loss for batch 69 = 0.3351127803325653\n",
      "Loss for batch 70 = 0.6350166201591492\n",
      "Loss for batch 71 = 0.4350041449069977\n",
      "Loss for batch 72 = 0.43084827065467834\n",
      "Loss for batch 73 = 0.38387173414230347\n",
      "Loss for batch 74 = 0.3476300835609436\n",
      "Loss for batch 75 = 0.5195629596710205\n",
      "Loss for batch 76 = 0.39405617117881775\n",
      "Loss for batch 77 = 0.3598969280719757\n",
      "Loss for batch 78 = 0.34125223755836487\n",
      "Loss for batch 79 = 0.331678181886673\n",
      "Loss for batch 80 = 0.3674522638320923\n",
      "Loss for batch 81 = 0.5762390494346619\n",
      "Loss for batch 82 = 0.492014616727829\n",
      "Loss for batch 83 = 0.4852306544780731\n",
      "Loss for batch 84 = 0.362080842256546\n",
      "Loss for batch 85 = 0.2652982473373413\n",
      "Loss for batch 86 = 0.2368047833442688\n",
      "Loss for batch 87 = 0.4565233588218689\n",
      "Loss for batch 88 = 0.32987362146377563\n",
      "Loss for batch 89 = 0.4713100492954254\n",
      "Loss for batch 90 = 0.6912351846694946\n",
      "Loss for batch 91 = 0.5429717302322388\n",
      "Loss for batch 92 = 0.5560123920440674\n",
      "Loss for batch 93 = 0.5300069451332092\n",
      "Loss for batch 94 = 0.5278978943824768\n",
      "Loss for batch 95 = 0.30514320731163025\n",
      "Loss for batch 96 = 0.5692138075828552\n",
      "Loss for batch 97 = 0.620229959487915\n",
      "\n",
      "Training Loss for epoch 21 = 45.93803024291992\n",
      "\n",
      "Current Validation Loss = 29.019256591796875\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 12\n",
      "Train Accuracy: 79.72%\n",
      "Validation Accuracy: 59.56%\n",
      "\n",
      "Epoch 22\n",
      "----------\n",
      "Loss for batch 0 = 0.3164992928504944\n",
      "Loss for batch 1 = 0.5608214139938354\n",
      "Loss for batch 2 = 0.3924286663532257\n",
      "Loss for batch 3 = 0.5757531523704529\n",
      "Loss for batch 4 = 0.5963606238365173\n",
      "Loss for batch 5 = 0.4264327585697174\n",
      "Loss for batch 6 = 0.6045235991477966\n",
      "Loss for batch 7 = 0.6138864755630493\n",
      "Loss for batch 8 = 0.5274471640586853\n",
      "Loss for batch 9 = 0.29728832840919495\n",
      "Loss for batch 10 = 0.5110844969749451\n",
      "Loss for batch 11 = 0.25254255533218384\n",
      "Loss for batch 12 = 0.46790555119514465\n",
      "Loss for batch 13 = 0.5060572624206543\n",
      "Loss for batch 14 = 0.43435004353523254\n",
      "Loss for batch 15 = 0.38417744636535645\n",
      "Loss for batch 16 = 0.3715910017490387\n",
      "Loss for batch 17 = 0.2685019075870514\n",
      "Loss for batch 18 = 0.33026251196861267\n",
      "Loss for batch 19 = 0.2988436222076416\n",
      "Loss for batch 20 = 0.28176599740982056\n",
      "Loss for batch 21 = 0.5595380663871765\n",
      "Loss for batch 22 = 0.35911011695861816\n",
      "Loss for batch 23 = 0.3496244251728058\n",
      "Loss for batch 24 = 0.3420361876487732\n",
      "Loss for batch 25 = 0.32858213782310486\n",
      "Loss for batch 26 = 0.5596616864204407\n",
      "Loss for batch 27 = 0.4709807336330414\n",
      "Loss for batch 28 = 0.43572819232940674\n",
      "Loss for batch 29 = 0.42086637020111084\n",
      "Loss for batch 30 = 0.44993939995765686\n",
      "Loss for batch 31 = 0.36374354362487793\n",
      "Loss for batch 32 = 0.565014660358429\n",
      "Loss for batch 33 = 0.4401453733444214\n",
      "Loss for batch 34 = 0.6196652054786682\n",
      "Loss for batch 35 = 0.33266115188598633\n",
      "Loss for batch 36 = 0.50462806224823\n",
      "Loss for batch 37 = 0.574463963508606\n",
      "Loss for batch 38 = 0.6121241450309753\n",
      "Loss for batch 39 = 0.25835341215133667\n",
      "Loss for batch 40 = 0.6268813610076904\n",
      "Loss for batch 41 = 0.6295245289802551\n",
      "Loss for batch 42 = 0.5420076251029968\n",
      "Loss for batch 43 = 0.5379278659820557\n",
      "Loss for batch 44 = 0.3382422924041748\n",
      "Loss for batch 45 = 0.37764638662338257\n",
      "Loss for batch 46 = 0.5856688022613525\n",
      "Loss for batch 47 = 0.45488038659095764\n",
      "Loss for batch 48 = 0.4233085513114929\n",
      "Loss for batch 49 = 0.435285359621048\n",
      "Loss for batch 50 = 0.7948265075683594\n",
      "Loss for batch 51 = 0.30519235134124756\n",
      "Loss for batch 52 = 0.29660844802856445\n",
      "Loss for batch 53 = 0.27868330478668213\n",
      "Loss for batch 54 = 0.6466631293296814\n",
      "Loss for batch 55 = 0.5256654024124146\n",
      "Loss for batch 56 = 0.5763016939163208\n",
      "Loss for batch 57 = 0.357401043176651\n",
      "Loss for batch 58 = 0.369724303483963\n",
      "Loss for batch 59 = 0.746290922164917\n",
      "Loss for batch 60 = 0.4870888292789459\n",
      "Loss for batch 61 = 0.7284386157989502\n",
      "Loss for batch 62 = 0.5652858018875122\n",
      "Loss for batch 63 = 0.46384960412979126\n",
      "Loss for batch 64 = 0.18411719799041748\n",
      "Loss for batch 65 = 0.5152444839477539\n",
      "Loss for batch 66 = 0.5201696157455444\n",
      "Loss for batch 67 = 0.5814187526702881\n",
      "Loss for batch 68 = 0.6088399887084961\n",
      "Loss for batch 69 = 0.32781824469566345\n",
      "Loss for batch 70 = 0.6173467636108398\n",
      "Loss for batch 71 = 0.4262491762638092\n",
      "Loss for batch 72 = 0.4110587239265442\n",
      "Loss for batch 73 = 0.3686794638633728\n",
      "Loss for batch 74 = 0.342953622341156\n",
      "Loss for batch 75 = 0.4217767119407654\n",
      "Loss for batch 76 = 0.4252783954143524\n",
      "Loss for batch 77 = 0.3579097390174866\n",
      "Loss for batch 78 = 0.3259170949459076\n",
      "Loss for batch 79 = 0.2603583037853241\n",
      "Loss for batch 80 = 0.36022889614105225\n",
      "Loss for batch 81 = 0.5388785600662231\n",
      "Loss for batch 82 = 0.4102376401424408\n",
      "Loss for batch 83 = 0.4689781367778778\n",
      "Loss for batch 84 = 0.3525279760360718\n",
      "Loss for batch 85 = 0.24154189229011536\n",
      "Loss for batch 86 = 0.2482651174068451\n",
      "Loss for batch 87 = 0.46468329429626465\n",
      "Loss for batch 88 = 0.3155989646911621\n",
      "Loss for batch 89 = 0.4394586682319641\n",
      "Loss for batch 90 = 0.6795220375061035\n",
      "Loss for batch 91 = 0.5256545543670654\n",
      "Loss for batch 92 = 0.5496383309364319\n",
      "Loss for batch 93 = 0.5164433121681213\n",
      "Loss for batch 94 = 0.5220270752906799\n",
      "Loss for batch 95 = 0.3001416325569153\n",
      "Loss for batch 96 = 0.5108988881111145\n",
      "Loss for batch 97 = 0.6087448000907898\n",
      "\n",
      "Training Loss for epoch 22 = 44.407386779785156\n",
      "\n",
      "Current Validation Loss = 29.11310577392578\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 13\n",
      "Train Accuracy: 81.39%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 23\n",
      "----------\n",
      "Loss for batch 0 = 0.24642860889434814\n",
      "Loss for batch 1 = 0.5509604215621948\n",
      "Loss for batch 2 = 0.3848073184490204\n",
      "Loss for batch 3 = 0.5686135292053223\n",
      "Loss for batch 4 = 0.5416737198829651\n",
      "Loss for batch 5 = 0.40977346897125244\n",
      "Loss for batch 6 = 0.5452244281768799\n",
      "Loss for batch 7 = 0.5602609515190125\n",
      "Loss for batch 8 = 0.48347240686416626\n",
      "Loss for batch 9 = 0.2571597099304199\n",
      "Loss for batch 10 = 0.5077275037765503\n",
      "Loss for batch 11 = 0.2831694483757019\n",
      "Loss for batch 12 = 0.4534340798854828\n",
      "Loss for batch 13 = 0.4867369532585144\n",
      "Loss for batch 14 = 0.43052297830581665\n",
      "Loss for batch 15 = 0.36151376366615295\n",
      "Loss for batch 16 = 0.34623488783836365\n",
      "Loss for batch 17 = 0.26527902483940125\n",
      "Loss for batch 18 = 0.30250370502471924\n",
      "Loss for batch 19 = 0.2952382564544678\n",
      "Loss for batch 20 = 0.29929119348526\n",
      "Loss for batch 21 = 0.5190162658691406\n",
      "Loss for batch 22 = 0.35935285687446594\n",
      "Loss for batch 23 = 0.34404945373535156\n",
      "Loss for batch 24 = 0.3396933078765869\n",
      "Loss for batch 25 = 0.3102132976055145\n",
      "Loss for batch 26 = 0.5502213835716248\n",
      "Loss for batch 27 = 0.47836923599243164\n",
      "Loss for batch 28 = 0.4435420334339142\n",
      "Loss for batch 29 = 0.333532452583313\n",
      "Loss for batch 30 = 0.44838860630989075\n",
      "Loss for batch 31 = 0.3360581696033478\n",
      "Loss for batch 32 = 0.5629194974899292\n",
      "Loss for batch 33 = 0.4380790889263153\n",
      "Loss for batch 34 = 0.5693705081939697\n",
      "Loss for batch 35 = 0.32827168703079224\n",
      "Loss for batch 36 = 0.48596423864364624\n",
      "Loss for batch 37 = 0.579113781452179\n",
      "Loss for batch 38 = 0.595736026763916\n",
      "Loss for batch 39 = 0.25097933411598206\n",
      "Loss for batch 40 = 0.5677272081375122\n",
      "Loss for batch 41 = 0.619776725769043\n",
      "Loss for batch 42 = 0.5231976509094238\n",
      "Loss for batch 43 = 0.5711679458618164\n",
      "Loss for batch 44 = 0.4015130400657654\n",
      "Loss for batch 45 = 0.3740028738975525\n",
      "Loss for batch 46 = 0.5741369724273682\n",
      "Loss for batch 47 = 0.43003422021865845\n",
      "Loss for batch 48 = 0.4165470600128174\n",
      "Loss for batch 49 = 0.3613421320915222\n",
      "Loss for batch 50 = 0.7936328649520874\n",
      "Loss for batch 51 = 0.30454128980636597\n",
      "Loss for batch 52 = 0.32102081179618835\n",
      "Loss for batch 53 = 0.25121596455574036\n",
      "Loss for batch 54 = 0.6113317608833313\n",
      "Loss for batch 55 = 0.535183310508728\n",
      "Loss for batch 56 = 0.577987015247345\n",
      "Loss for batch 57 = 0.35367551445961\n",
      "Loss for batch 58 = 0.35506483912467957\n",
      "Loss for batch 59 = 0.7096433043479919\n",
      "Loss for batch 60 = 0.35771164298057556\n",
      "Loss for batch 61 = 0.7359546422958374\n",
      "Loss for batch 62 = 0.6435006856918335\n",
      "Loss for batch 63 = 0.4572976529598236\n",
      "Loss for batch 64 = 0.18258315324783325\n",
      "Loss for batch 65 = 0.48859962821006775\n",
      "Loss for batch 66 = 0.529448390007019\n",
      "Loss for batch 67 = 0.6489030718803406\n",
      "Loss for batch 68 = 0.6088601350784302\n",
      "Loss for batch 69 = 0.3155912756919861\n",
      "Loss for batch 70 = 0.6395764350891113\n",
      "Loss for batch 71 = 0.41803404688835144\n",
      "Loss for batch 72 = 0.3512880206108093\n",
      "Loss for batch 73 = 0.37755778431892395\n",
      "Loss for batch 74 = 0.29075223207473755\n",
      "Loss for batch 75 = 0.4258618652820587\n",
      "Loss for batch 76 = 0.37872084975242615\n",
      "Loss for batch 77 = 0.37695997953414917\n",
      "Loss for batch 78 = 0.32164064049720764\n",
      "Loss for batch 79 = 0.2577764391899109\n",
      "Loss for batch 80 = 0.37229567766189575\n",
      "Loss for batch 81 = 0.5382021069526672\n",
      "Loss for batch 82 = 0.40962129831314087\n",
      "Loss for batch 83 = 0.45334506034851074\n",
      "Loss for batch 84 = 0.36087143421173096\n",
      "Loss for batch 85 = 0.23882004618644714\n",
      "Loss for batch 86 = 0.23217147588729858\n",
      "Loss for batch 87 = 0.45763346552848816\n",
      "Loss for batch 88 = 0.31165531277656555\n",
      "Loss for batch 89 = 0.4310467541217804\n",
      "Loss for batch 90 = 0.6612488031387329\n",
      "Loss for batch 91 = 0.6908692717552185\n",
      "Loss for batch 92 = 0.5442199110984802\n",
      "Loss for batch 93 = 0.5667345523834229\n",
      "Loss for batch 94 = 0.5211794376373291\n",
      "Loss for batch 95 = 0.29648861289024353\n",
      "Loss for batch 96 = 0.5140790343284607\n",
      "Loss for batch 97 = 0.5731813311576843\n",
      "\n",
      "Training Loss for epoch 23 = 43.48591613769531\n",
      "\n",
      "Current Validation Loss = 29.377338409423828\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 14\n",
      "Train Accuracy: 81.26%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 24\n",
      "----------\n",
      "Loss for batch 0 = 0.2591214179992676\n",
      "Loss for batch 1 = 0.54819655418396\n",
      "Loss for batch 2 = 0.39500150084495544\n",
      "Loss for batch 3 = 0.5839999914169312\n",
      "Loss for batch 4 = 0.5545498728752136\n",
      "Loss for batch 5 = 0.4057672619819641\n",
      "Loss for batch 6 = 0.5166639089584351\n",
      "Loss for batch 7 = 0.5734850168228149\n",
      "Loss for batch 8 = 0.49838173389434814\n",
      "Loss for batch 9 = 0.2676068842411041\n",
      "Loss for batch 10 = 0.4873492121696472\n",
      "Loss for batch 11 = 0.22782042622566223\n",
      "Loss for batch 12 = 0.4649914801120758\n",
      "Loss for batch 13 = 0.49302834272384644\n",
      "Loss for batch 14 = 0.38196688890457153\n",
      "Loss for batch 15 = 0.36974668502807617\n",
      "Loss for batch 16 = 0.3500869870185852\n",
      "Loss for batch 17 = 0.27234694361686707\n",
      "Loss for batch 18 = 0.32903167605400085\n",
      "Loss for batch 19 = 0.2776903808116913\n",
      "Loss for batch 20 = 0.2834473252296448\n",
      "Loss for batch 21 = 0.47815343737602234\n",
      "Loss for batch 22 = 0.3582391142845154\n",
      "Loss for batch 23 = 0.3472270369529724\n",
      "Loss for batch 24 = 0.32998406887054443\n",
      "Loss for batch 25 = 0.2671358287334442\n",
      "Loss for batch 26 = 0.5368483066558838\n",
      "Loss for batch 27 = 0.47049590945243835\n",
      "Loss for batch 28 = 0.5015302300453186\n",
      "Loss for batch 29 = 0.308127760887146\n",
      "Loss for batch 30 = 0.46628010272979736\n",
      "Loss for batch 31 = 0.34758609533309937\n",
      "Loss for batch 32 = 0.5496004819869995\n",
      "Loss for batch 33 = 0.4129418730735779\n",
      "Loss for batch 34 = 0.5839086771011353\n",
      "Loss for batch 35 = 0.3250996470451355\n",
      "Loss for batch 36 = 0.4856193959712982\n",
      "Loss for batch 37 = 0.5987483859062195\n",
      "Loss for batch 38 = 0.5573068857192993\n",
      "Loss for batch 39 = 0.239173024892807\n",
      "Loss for batch 40 = 0.5955413579940796\n",
      "Loss for batch 41 = 0.5792466998100281\n",
      "Loss for batch 42 = 0.5214307308197021\n",
      "Loss for batch 43 = 0.5027540922164917\n",
      "Loss for batch 44 = 0.27228066325187683\n",
      "Loss for batch 45 = 0.339358389377594\n",
      "Loss for batch 46 = 0.558584988117218\n",
      "Loss for batch 47 = 0.4281836748123169\n",
      "Loss for batch 48 = 0.40876123309135437\n",
      "Loss for batch 49 = 0.34291183948516846\n",
      "Loss for batch 50 = 0.7869637608528137\n",
      "Loss for batch 51 = 0.2855290472507477\n",
      "Loss for batch 52 = 0.2588886022567749\n",
      "Loss for batch 53 = 0.2885761559009552\n",
      "Loss for batch 54 = 0.5686294436454773\n",
      "Loss for batch 55 = 0.5197108387947083\n",
      "Loss for batch 56 = 0.5515750050544739\n",
      "Loss for batch 57 = 0.352541983127594\n",
      "Loss for batch 58 = 0.343308687210083\n",
      "Loss for batch 59 = 0.7230267524719238\n",
      "Loss for batch 60 = 0.3200199007987976\n",
      "Loss for batch 61 = 0.7318810820579529\n",
      "Loss for batch 62 = 0.5582978129386902\n",
      "Loss for batch 63 = 0.4745985269546509\n",
      "Loss for batch 64 = 0.1978616714477539\n",
      "Loss for batch 65 = 0.47982844710350037\n",
      "Loss for batch 66 = 0.5067834854125977\n",
      "Loss for batch 67 = 0.560993492603302\n",
      "Loss for batch 68 = 0.5862096548080444\n",
      "Loss for batch 69 = 0.3101753890514374\n",
      "Loss for batch 70 = 0.6009761095046997\n",
      "Loss for batch 71 = 0.42636537551879883\n",
      "Loss for batch 72 = 0.403670072555542\n",
      "Loss for batch 73 = 0.36097636818885803\n",
      "Loss for batch 74 = 0.27564671635627747\n",
      "Loss for batch 75 = 0.38627687096595764\n",
      "Loss for batch 76 = 0.38767215609550476\n",
      "Loss for batch 77 = 0.344909131526947\n",
      "Loss for batch 78 = 0.29131922125816345\n",
      "Loss for batch 79 = 0.22902435064315796\n",
      "Loss for batch 80 = 0.3571862280368805\n",
      "Loss for batch 81 = 0.5241767764091492\n",
      "Loss for batch 82 = 0.37993624806404114\n",
      "Loss for batch 83 = 0.41613221168518066\n",
      "Loss for batch 84 = 0.33987870812416077\n",
      "Loss for batch 85 = 0.22312219440937042\n",
      "Loss for batch 86 = 0.2213464081287384\n",
      "Loss for batch 87 = 0.44223982095718384\n",
      "Loss for batch 88 = 0.3070892095565796\n",
      "Loss for batch 89 = 0.4230068624019623\n",
      "Loss for batch 90 = 0.658350944519043\n",
      "Loss for batch 91 = 0.46864673495292664\n",
      "Loss for batch 92 = 0.5165406465530396\n",
      "Loss for batch 93 = 0.5237353444099426\n",
      "Loss for batch 94 = 0.5008605718612671\n",
      "Loss for batch 95 = 0.3044866621494293\n",
      "Loss for batch 96 = 0.5099713802337646\n",
      "Loss for batch 97 = 0.5501189231872559\n",
      "\n",
      "Training Loss for epoch 24 = 42.03240966796875\n",
      "\n",
      "Current Validation Loss = 31.350175857543945\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 15\n",
      "Train Accuracy: 81.00%\n",
      "Validation Accuracy: 60.21%\n",
      "\n",
      "Epoch 25\n",
      "----------\n",
      "Loss for batch 0 = 0.2539158761501312\n",
      "Loss for batch 1 = 0.5531913042068481\n",
      "Loss for batch 2 = 0.3859837055206299\n",
      "Loss for batch 3 = 0.6077589988708496\n",
      "Loss for batch 4 = 0.5270140171051025\n",
      "Loss for batch 5 = 0.3586529493331909\n",
      "Loss for batch 6 = 0.51118403673172\n",
      "Loss for batch 7 = 0.5739156007766724\n",
      "Loss for batch 8 = 0.41297104954719543\n",
      "Loss for batch 9 = 0.27400466799736023\n",
      "Loss for batch 10 = 0.48776373267173767\n",
      "Loss for batch 11 = 0.3164718449115753\n",
      "Loss for batch 12 = 0.5208230018615723\n",
      "Loss for batch 13 = 0.46751782298088074\n",
      "Loss for batch 14 = 0.46697747707366943\n",
      "Loss for batch 15 = 0.3623237907886505\n",
      "Loss for batch 16 = 0.37093451619148254\n",
      "Loss for batch 17 = 0.2518150508403778\n",
      "Loss for batch 18 = 0.27526214718818665\n",
      "Loss for batch 19 = 0.2642152011394501\n",
      "Loss for batch 20 = 0.29918208718299866\n",
      "Loss for batch 21 = 0.48162195086479187\n",
      "Loss for batch 22 = 0.3645106256008148\n",
      "Loss for batch 23 = 0.3635677993297577\n",
      "Loss for batch 24 = 0.32127049565315247\n",
      "Loss for batch 25 = 0.24298705160617828\n",
      "Loss for batch 26 = 0.5198009610176086\n",
      "Loss for batch 27 = 0.46483051776885986\n",
      "Loss for batch 28 = 0.3989548683166504\n",
      "Loss for batch 29 = 0.26207610964775085\n",
      "Loss for batch 30 = 0.4110817313194275\n",
      "Loss for batch 31 = 0.3263772130012512\n",
      "Loss for batch 32 = 0.5428463220596313\n",
      "Loss for batch 33 = 0.3801595866680145\n",
      "Loss for batch 34 = 0.5527343153953552\n",
      "Loss for batch 35 = 0.31703677773475647\n",
      "Loss for batch 36 = 0.49153339862823486\n",
      "Loss for batch 37 = 0.5817577242851257\n",
      "Loss for batch 38 = 0.5641034245491028\n",
      "Loss for batch 39 = 0.2396370768547058\n",
      "Loss for batch 40 = 0.5368232727050781\n",
      "Loss for batch 41 = 0.6456707119941711\n",
      "Loss for batch 42 = 0.5195950269699097\n",
      "Loss for batch 43 = 0.5109612345695496\n",
      "Loss for batch 44 = 0.25499674677848816\n",
      "Loss for batch 45 = 0.3304498791694641\n",
      "Loss for batch 46 = 0.5992082357406616\n",
      "Loss for batch 47 = 0.48441094160079956\n",
      "Loss for batch 48 = 0.40435290336608887\n",
      "Loss for batch 49 = 0.38112470507621765\n",
      "Loss for batch 50 = 0.788537859916687\n",
      "Loss for batch 51 = 0.27243414521217346\n",
      "Loss for batch 52 = 0.2514781057834625\n",
      "Loss for batch 53 = 0.2659766972064972\n",
      "Loss for batch 54 = 0.5310015678405762\n",
      "Loss for batch 55 = 0.5185964107513428\n",
      "Loss for batch 56 = 0.5475906729698181\n",
      "Loss for batch 57 = 0.35916274785995483\n",
      "Loss for batch 58 = 0.3671175241470337\n",
      "Loss for batch 59 = 0.6614214777946472\n",
      "Loss for batch 60 = 0.3792491853237152\n",
      "Loss for batch 61 = 0.7483359575271606\n",
      "Loss for batch 62 = 0.5136537551879883\n",
      "Loss for batch 63 = 0.43750515580177307\n",
      "Loss for batch 64 = 0.17301113903522491\n",
      "Loss for batch 65 = 0.39422667026519775\n",
      "Loss for batch 66 = 0.4525269865989685\n",
      "Loss for batch 67 = 0.5685580968856812\n",
      "Loss for batch 68 = 0.574565052986145\n",
      "Loss for batch 69 = 0.30692169070243835\n",
      "Loss for batch 70 = 0.6410195231437683\n",
      "Loss for batch 71 = 0.40134742856025696\n",
      "Loss for batch 72 = 0.37346118688583374\n",
      "Loss for batch 73 = 0.3684356212615967\n",
      "Loss for batch 74 = 0.25876355171203613\n",
      "Loss for batch 75 = 0.39776110649108887\n",
      "Loss for batch 76 = 0.35578709840774536\n",
      "Loss for batch 77 = 0.32023659348487854\n",
      "Loss for batch 78 = 0.3119989335536957\n",
      "Loss for batch 79 = 0.2250085175037384\n",
      "Loss for batch 80 = 0.3513637185096741\n",
      "Loss for batch 81 = 0.5765689611434937\n",
      "Loss for batch 82 = 0.3736044764518738\n",
      "Loss for batch 83 = 0.42989593744277954\n",
      "Loss for batch 84 = 0.3434779644012451\n",
      "Loss for batch 85 = 0.21906161308288574\n",
      "Loss for batch 86 = 0.19375869631767273\n",
      "Loss for batch 87 = 0.3893999755382538\n",
      "Loss for batch 88 = 0.3332366347312927\n",
      "Loss for batch 89 = 0.39864686131477356\n",
      "Loss for batch 90 = 0.6145725846290588\n",
      "Loss for batch 91 = 0.4731512665748596\n",
      "Loss for batch 92 = 0.539467453956604\n",
      "Loss for batch 93 = 0.4780794382095337\n",
      "Loss for batch 94 = 0.5169453620910645\n",
      "Loss for batch 95 = 0.27051255106925964\n",
      "Loss for batch 96 = 0.4864187240600586\n",
      "Loss for batch 97 = 0.5111664533615112\n",
      "\n",
      "Training Loss for epoch 25 = 41.301387786865234\n",
      "\n",
      "Current Validation Loss = 31.17198944091797\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 16\n",
      "Train Accuracy: 82.86%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 26\n",
      "----------\n",
      "Loss for batch 0 = 0.23555009067058563\n",
      "Loss for batch 1 = 0.5426143407821655\n",
      "Loss for batch 2 = 0.3720017373561859\n",
      "Loss for batch 3 = 0.5907121300697327\n",
      "Loss for batch 4 = 0.5039145946502686\n",
      "Loss for batch 5 = 0.3458016514778137\n",
      "Loss for batch 6 = 0.46870091557502747\n",
      "Loss for batch 7 = 0.5303092002868652\n",
      "Loss for batch 8 = 0.4023588299751282\n",
      "Loss for batch 9 = 0.24286602437496185\n",
      "Loss for batch 10 = 0.47161945700645447\n",
      "Loss for batch 11 = 0.22006230056285858\n",
      "Loss for batch 12 = 0.443268358707428\n",
      "Loss for batch 13 = 0.48397713899612427\n",
      "Loss for batch 14 = 0.33085259795188904\n",
      "Loss for batch 15 = 0.35907405614852905\n",
      "Loss for batch 16 = 0.30519190430641174\n",
      "Loss for batch 17 = 0.2452469766139984\n",
      "Loss for batch 18 = 0.2714957296848297\n",
      "Loss for batch 19 = 0.2518121004104614\n",
      "Loss for batch 20 = 0.274975448846817\n",
      "Loss for batch 21 = 0.47649067640304565\n",
      "Loss for batch 22 = 0.35231348872184753\n",
      "Loss for batch 23 = 0.33557528257369995\n",
      "Loss for batch 24 = 0.3224005699157715\n",
      "Loss for batch 25 = 0.23593579232692719\n",
      "Loss for batch 26 = 0.5170550346374512\n",
      "Loss for batch 27 = 0.4540654718875885\n",
      "Loss for batch 28 = 0.3892272710800171\n",
      "Loss for batch 29 = 0.23593521118164062\n",
      "Loss for batch 30 = 0.4027518332004547\n",
      "Loss for batch 31 = 0.33498769998550415\n",
      "Loss for batch 32 = 0.5620299577713013\n",
      "Loss for batch 33 = 0.36248543858528137\n",
      "Loss for batch 34 = 0.5546596646308899\n",
      "Loss for batch 35 = 0.3326689600944519\n",
      "Loss for batch 36 = 0.5035521388053894\n",
      "Loss for batch 37 = 0.5358008146286011\n",
      "Loss for batch 38 = 0.5269962549209595\n",
      "Loss for batch 39 = 0.23003728687763214\n",
      "Loss for batch 40 = 0.53976970911026\n",
      "Loss for batch 41 = 0.6084816455841064\n",
      "Loss for batch 42 = 0.5046467185020447\n",
      "Loss for batch 43 = 0.5095523595809937\n",
      "Loss for batch 44 = 0.23215165734291077\n",
      "Loss for batch 45 = 0.3213452994823456\n",
      "Loss for batch 46 = 0.5310394167900085\n",
      "Loss for batch 47 = 0.49500367045402527\n",
      "Loss for batch 48 = 0.4145781397819519\n",
      "Loss for batch 49 = 0.3959698975086212\n",
      "Loss for batch 50 = 0.7749842405319214\n",
      "Loss for batch 51 = 0.27437788248062134\n",
      "Loss for batch 52 = 0.24258005619049072\n",
      "Loss for batch 53 = 0.27535298466682434\n",
      "Loss for batch 54 = 0.5040077567100525\n",
      "Loss for batch 55 = 0.5311572551727295\n",
      "Loss for batch 56 = 0.5276110172271729\n",
      "Loss for batch 57 = 0.34884822368621826\n",
      "Loss for batch 58 = 0.35345762968063354\n",
      "Loss for batch 59 = 0.6884691715240479\n",
      "Loss for batch 60 = 0.33609938621520996\n",
      "Loss for batch 61 = 0.7369487285614014\n",
      "Loss for batch 62 = 0.5037040114402771\n",
      "Loss for batch 63 = 0.4119495749473572\n",
      "Loss for batch 64 = 0.2263266146183014\n",
      "Loss for batch 65 = 0.3328169584274292\n",
      "Loss for batch 66 = 0.5127182602882385\n",
      "Loss for batch 67 = 0.5626506805419922\n",
      "Loss for batch 68 = 0.5337508320808411\n",
      "Loss for batch 69 = 0.38325121998786926\n",
      "Loss for batch 70 = 0.6996522545814514\n",
      "Loss for batch 71 = 0.4340282380580902\n",
      "Loss for batch 72 = 0.4340168535709381\n",
      "Loss for batch 73 = 0.3686029314994812\n",
      "Loss for batch 74 = 0.29743513464927673\n",
      "Loss for batch 75 = 0.3639862537384033\n",
      "Loss for batch 76 = 0.3396637439727783\n",
      "Loss for batch 77 = 0.3363245129585266\n",
      "Loss for batch 78 = 0.31331321597099304\n",
      "Loss for batch 79 = 0.26649725437164307\n",
      "Loss for batch 80 = 0.3301956057548523\n",
      "Loss for batch 81 = 0.5478550791740417\n",
      "Loss for batch 82 = 0.3955409824848175\n",
      "Loss for batch 83 = 0.42987552285194397\n",
      "Loss for batch 84 = 0.3559650480747223\n",
      "Loss for batch 85 = 0.2170519381761551\n",
      "Loss for batch 86 = 0.1686682105064392\n",
      "Loss for batch 87 = 0.39279744029045105\n",
      "Loss for batch 88 = 0.338606059551239\n",
      "Loss for batch 89 = 0.4099166691303253\n",
      "Loss for batch 90 = 0.5969725847244263\n",
      "Loss for batch 91 = 0.42887023091316223\n",
      "Loss for batch 92 = 0.4987310469150543\n",
      "Loss for batch 93 = 0.4737612009048462\n",
      "Loss for batch 94 = 0.48975619673728943\n",
      "Loss for batch 95 = 0.27395832538604736\n",
      "Loss for batch 96 = 0.5574135780334473\n",
      "Loss for batch 97 = 0.4515134394168854\n",
      "\n",
      "Training Loss for epoch 26 = 40.3819465637207\n",
      "\n",
      "Current Validation Loss = 31.852947235107422\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 17\n",
      "Train Accuracy: 81.61%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 27\n",
      "----------\n",
      "Loss for batch 0 = 0.23180896043777466\n",
      "Loss for batch 1 = 0.5590358972549438\n",
      "Loss for batch 2 = 0.36150455474853516\n",
      "Loss for batch 3 = 0.6115939617156982\n",
      "Loss for batch 4 = 0.4934881925582886\n",
      "Loss for batch 5 = 0.4033268690109253\n",
      "Loss for batch 6 = 0.527951717376709\n",
      "Loss for batch 7 = 0.5581086874008179\n",
      "Loss for batch 8 = 0.5117598176002502\n",
      "Loss for batch 9 = 0.28962332010269165\n",
      "Loss for batch 10 = 0.4400845766067505\n",
      "Loss for batch 11 = 0.18905329704284668\n",
      "Loss for batch 12 = 0.42822250723838806\n",
      "Loss for batch 13 = 0.4732738435268402\n",
      "Loss for batch 14 = 0.3728812038898468\n",
      "Loss for batch 15 = 0.34823551774024963\n",
      "Loss for batch 16 = 0.3512268364429474\n",
      "Loss for batch 17 = 0.24690796434879303\n",
      "Loss for batch 18 = 0.37896108627319336\n",
      "Loss for batch 19 = 0.25166791677474976\n",
      "Loss for batch 20 = 0.2849603593349457\n",
      "Loss for batch 21 = 0.454174667596817\n",
      "Loss for batch 22 = 0.3613917827606201\n",
      "Loss for batch 23 = 0.34649142622947693\n",
      "Loss for batch 24 = 0.3347337245941162\n",
      "Loss for batch 25 = 0.2495047152042389\n",
      "Loss for batch 26 = 0.5698311924934387\n",
      "Loss for batch 27 = 0.47160470485687256\n",
      "Loss for batch 28 = 0.4239064157009125\n",
      "Loss for batch 29 = 0.26928380131721497\n",
      "Loss for batch 30 = 0.4547576606273651\n",
      "Loss for batch 31 = 0.3589184582233429\n",
      "Loss for batch 32 = 0.5263717770576477\n",
      "Loss for batch 33 = 0.4052008092403412\n",
      "Loss for batch 34 = 0.5759983658790588\n",
      "Loss for batch 35 = 0.3184911608695984\n",
      "Loss for batch 36 = 0.4628988206386566\n",
      "Loss for batch 37 = 0.5869293212890625\n",
      "Loss for batch 38 = 0.5134128332138062\n",
      "Loss for batch 39 = 0.2274503856897354\n",
      "Loss for batch 40 = 0.5939031839370728\n",
      "Loss for batch 41 = 0.5808442234992981\n",
      "Loss for batch 42 = 0.5110049247741699\n",
      "Loss for batch 43 = 0.5065528154373169\n",
      "Loss for batch 44 = 0.30002063512802124\n",
      "Loss for batch 45 = 0.3217247426509857\n",
      "Loss for batch 46 = 0.5415948629379272\n",
      "Loss for batch 47 = 0.41468551754951477\n",
      "Loss for batch 48 = 0.40664389729499817\n",
      "Loss for batch 49 = 0.30850422382354736\n",
      "Loss for batch 50 = 0.7744227647781372\n",
      "Loss for batch 51 = 0.26960042119026184\n",
      "Loss for batch 52 = 0.2499067485332489\n",
      "Loss for batch 53 = 0.24279530346393585\n",
      "Loss for batch 54 = 0.49271368980407715\n",
      "Loss for batch 55 = 0.5456276535987854\n",
      "Loss for batch 56 = 0.4951954483985901\n",
      "Loss for batch 57 = 0.3489919602870941\n",
      "Loss for batch 58 = 0.3682689964771271\n",
      "Loss for batch 59 = 0.6820006370544434\n",
      "Loss for batch 60 = 0.28601834177970886\n",
      "Loss for batch 61 = 0.7167143225669861\n",
      "Loss for batch 62 = 0.5453659892082214\n",
      "Loss for batch 63 = 0.39456018805503845\n",
      "Loss for batch 64 = 0.1856875717639923\n",
      "Loss for batch 65 = 0.35822075605392456\n",
      "Loss for batch 66 = 0.4644545614719391\n",
      "Loss for batch 67 = 0.5575522780418396\n",
      "Loss for batch 68 = 0.5038942098617554\n",
      "Loss for batch 69 = 0.29268112778663635\n",
      "Loss for batch 70 = 0.6434009075164795\n",
      "Loss for batch 71 = 0.42901521921157837\n",
      "Loss for batch 72 = 0.36953005194664\n",
      "Loss for batch 73 = 0.35184353590011597\n",
      "Loss for batch 74 = 0.2835048735141754\n",
      "Loss for batch 75 = 0.36742639541625977\n",
      "Loss for batch 76 = 0.31189024448394775\n",
      "Loss for batch 77 = 0.3041658103466034\n",
      "Loss for batch 78 = 0.2867438495159149\n",
      "Loss for batch 79 = 0.2159210592508316\n",
      "Loss for batch 80 = 0.3494403064250946\n",
      "Loss for batch 81 = 0.5100448727607727\n",
      "Loss for batch 82 = 0.37316974997520447\n",
      "Loss for batch 83 = 0.4197103977203369\n",
      "Loss for batch 84 = 0.3369846045970917\n",
      "Loss for batch 85 = 0.22093163430690765\n",
      "Loss for batch 86 = 0.19548434019088745\n",
      "Loss for batch 87 = 0.36100703477859497\n",
      "Loss for batch 88 = 0.3158404231071472\n",
      "Loss for batch 89 = 0.3963300585746765\n",
      "Loss for batch 90 = 0.5444797277450562\n",
      "Loss for batch 91 = 0.4463343620300293\n",
      "Loss for batch 92 = 0.4593380093574524\n",
      "Loss for batch 93 = 0.5019928812980652\n",
      "Loss for batch 94 = 0.4986129403114319\n",
      "Loss for batch 95 = 0.23456573486328125\n",
      "Loss for batch 96 = 0.5081552863121033\n",
      "Loss for batch 97 = 0.4641954004764557\n",
      "\n",
      "Training Loss for epoch 27 = 40.185245513916016\n",
      "\n",
      "Current Validation Loss = 32.04701614379883\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 18\n",
      "Train Accuracy: 84.11%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 28\n",
      "----------\n",
      "Loss for batch 0 = 0.3024325668811798\n",
      "Loss for batch 1 = 0.5221453905105591\n",
      "Loss for batch 2 = 0.32975226640701294\n",
      "Loss for batch 3 = 0.5710305571556091\n",
      "Loss for batch 4 = 0.4894637167453766\n",
      "Loss for batch 5 = 0.3367280662059784\n",
      "Loss for batch 6 = 0.4655216932296753\n",
      "Loss for batch 7 = 0.5694718956947327\n",
      "Loss for batch 8 = 0.3717953562736511\n",
      "Loss for batch 9 = 0.2549678385257721\n",
      "Loss for batch 10 = 0.4509369730949402\n",
      "Loss for batch 11 = 0.19471625983715057\n",
      "Loss for batch 12 = 0.45138880610466003\n",
      "Loss for batch 13 = 0.4708588719367981\n",
      "Loss for batch 14 = 0.368712842464447\n",
      "Loss for batch 15 = 0.3575173318386078\n",
      "Loss for batch 16 = 0.33914509415626526\n",
      "Loss for batch 17 = 0.23659618198871613\n",
      "Loss for batch 18 = 0.28573939204216003\n",
      "Loss for batch 19 = 0.24050553143024445\n",
      "Loss for batch 20 = 0.3070995807647705\n",
      "Loss for batch 21 = 0.4730115532875061\n",
      "Loss for batch 22 = 0.3598952889442444\n",
      "Loss for batch 23 = 0.33304181694984436\n",
      "Loss for batch 24 = 0.31068506836891174\n",
      "Loss for batch 25 = 0.23693028092384338\n",
      "Loss for batch 26 = 0.5077351331710815\n",
      "Loss for batch 27 = 0.46903884410858154\n",
      "Loss for batch 28 = 0.38527506589889526\n",
      "Loss for batch 29 = 0.21249224245548248\n",
      "Loss for batch 30 = 0.38667669892311096\n",
      "Loss for batch 31 = 0.3554878234863281\n",
      "Loss for batch 32 = 0.5409848690032959\n",
      "Loss for batch 33 = 0.41279610991477966\n",
      "Loss for batch 34 = 0.5269297957420349\n",
      "Loss for batch 35 = 0.3230384588241577\n",
      "Loss for batch 36 = 0.48287808895111084\n",
      "Loss for batch 37 = 0.5451411008834839\n",
      "Loss for batch 38 = 0.5101386904716492\n",
      "Loss for batch 39 = 0.2620545029640198\n",
      "Loss for batch 40 = 0.5814077258110046\n",
      "Loss for batch 41 = 0.5756088495254517\n",
      "Loss for batch 42 = 0.5076779127120972\n",
      "Loss for batch 43 = 0.5106465816497803\n",
      "Loss for batch 44 = 0.3079592287540436\n",
      "Loss for batch 45 = 0.3524993658065796\n",
      "Loss for batch 46 = 0.5527477860450745\n",
      "Loss for batch 47 = 0.38583096861839294\n",
      "Loss for batch 48 = 0.4196755886077881\n",
      "Loss for batch 49 = 0.3567557632923126\n",
      "Loss for batch 50 = 0.7332198619842529\n",
      "Loss for batch 51 = 0.25213366746902466\n",
      "Loss for batch 52 = 0.2616312503814697\n",
      "Loss for batch 53 = 0.24914662539958954\n",
      "Loss for batch 54 = 0.46199631690979004\n",
      "Loss for batch 55 = 0.47768551111221313\n",
      "Loss for batch 56 = 0.5006815791130066\n",
      "Loss for batch 57 = 0.34690919518470764\n",
      "Loss for batch 58 = 0.37209656834602356\n",
      "Loss for batch 59 = 0.632491946220398\n",
      "Loss for batch 60 = 0.2844175398349762\n",
      "Loss for batch 61 = 0.7067044973373413\n",
      "Loss for batch 62 = 0.5208009481430054\n",
      "Loss for batch 63 = 0.38572561740875244\n",
      "Loss for batch 64 = 0.142911896109581\n",
      "Loss for batch 65 = 0.29624998569488525\n",
      "Loss for batch 66 = 0.4506566822528839\n",
      "Loss for batch 67 = 0.5645540356636047\n",
      "Loss for batch 68 = 0.5038238167762756\n",
      "Loss for batch 69 = 0.29341819882392883\n",
      "Loss for batch 70 = 0.6236608028411865\n",
      "Loss for batch 71 = 0.41479256749153137\n",
      "Loss for batch 72 = 0.33142006397247314\n",
      "Loss for batch 73 = 0.3499003052711487\n",
      "Loss for batch 74 = 0.2592250108718872\n",
      "Loss for batch 75 = 0.30748164653778076\n",
      "Loss for batch 76 = 0.27651843428611755\n",
      "Loss for batch 77 = 0.28240516781806946\n",
      "Loss for batch 78 = 0.28168433904647827\n",
      "Loss for batch 79 = 0.22011014819145203\n",
      "Loss for batch 80 = 0.33111393451690674\n",
      "Loss for batch 81 = 0.4722880721092224\n",
      "Loss for batch 82 = 0.3622291088104248\n",
      "Loss for batch 83 = 0.37978196144104004\n",
      "Loss for batch 84 = 0.32879164814949036\n",
      "Loss for batch 85 = 0.21785028278827667\n",
      "Loss for batch 86 = 0.18505339324474335\n",
      "Loss for batch 87 = 0.4398670196533203\n",
      "Loss for batch 88 = 0.30532050132751465\n",
      "Loss for batch 89 = 0.383477121591568\n",
      "Loss for batch 90 = 0.5649023652076721\n",
      "Loss for batch 91 = 0.4349750578403473\n",
      "Loss for batch 92 = 0.3664790987968445\n",
      "Loss for batch 93 = 0.4998132586479187\n",
      "Loss for batch 94 = 0.4610651731491089\n",
      "Loss for batch 95 = 0.22409050166606903\n",
      "Loss for batch 96 = 0.5488120913505554\n",
      "Loss for batch 97 = 0.38789793848991394\n",
      "\n",
      "Training Loss for epoch 28 = 38.77983474731445\n",
      "\n",
      "Current Validation Loss = 32.66968536376953\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 19\n",
      "Train Accuracy: 84.79%\n",
      "Validation Accuracy: 60.21%\n",
      "\n",
      "Epoch 29\n",
      "----------\n",
      "Loss for batch 0 = 0.23319698870182037\n",
      "Loss for batch 1 = 0.48376068472862244\n",
      "Loss for batch 2 = 0.3282410204410553\n",
      "Loss for batch 3 = 0.5281260013580322\n",
      "Loss for batch 4 = 0.4978328347206116\n",
      "Loss for batch 5 = 0.33416470885276794\n",
      "Loss for batch 6 = 0.4485582709312439\n",
      "Loss for batch 7 = 0.5745586156845093\n",
      "Loss for batch 8 = 0.363598495721817\n",
      "Loss for batch 9 = 0.2369176149368286\n",
      "Loss for batch 10 = 0.46610215306282043\n",
      "Loss for batch 11 = 0.18490780889987946\n",
      "Loss for batch 12 = 0.457465261220932\n",
      "Loss for batch 13 = 0.46766984462738037\n",
      "Loss for batch 14 = 0.35225367546081543\n",
      "Loss for batch 15 = 0.3572826683521271\n",
      "Loss for batch 16 = 0.3377389907836914\n",
      "Loss for batch 17 = 0.22632481157779694\n",
      "Loss for batch 18 = 0.26118892431259155\n",
      "Loss for batch 19 = 0.22165875136852264\n",
      "Loss for batch 20 = 0.28294000029563904\n",
      "Loss for batch 21 = 0.4645078480243683\n",
      "Loss for batch 22 = 0.35572558641433716\n",
      "Loss for batch 23 = 0.33396661281585693\n",
      "Loss for batch 24 = 0.300556480884552\n",
      "Loss for batch 25 = 0.22379961609840393\n",
      "Loss for batch 26 = 0.5145350694656372\n",
      "Loss for batch 27 = 0.46720629930496216\n",
      "Loss for batch 28 = 0.37290117144584656\n",
      "Loss for batch 29 = 0.21546924114227295\n",
      "Loss for batch 30 = 0.38493332266807556\n",
      "Loss for batch 31 = 0.32073086500167847\n",
      "Loss for batch 32 = 0.5238552093505859\n",
      "Loss for batch 33 = 0.3997824192047119\n",
      "Loss for batch 34 = 0.522098183631897\n",
      "Loss for batch 35 = 0.31936031579971313\n",
      "Loss for batch 36 = 0.4738737940788269\n",
      "Loss for batch 37 = 0.5449674129486084\n",
      "Loss for batch 38 = 0.4761725068092346\n",
      "Loss for batch 39 = 0.24612483382225037\n",
      "Loss for batch 40 = 0.5579482913017273\n",
      "Loss for batch 41 = 0.5646696090698242\n",
      "Loss for batch 42 = 0.4993707835674286\n",
      "Loss for batch 43 = 0.5192192792892456\n",
      "Loss for batch 44 = 0.3156840205192566\n",
      "Loss for batch 45 = 0.3416286110877991\n",
      "Loss for batch 46 = 0.5327409505844116\n",
      "Loss for batch 47 = 0.37843647599220276\n",
      "Loss for batch 48 = 0.42153820395469666\n",
      "Loss for batch 49 = 0.2717711329460144\n",
      "Loss for batch 50 = 0.7176145315170288\n",
      "Loss for batch 51 = 0.2419128715991974\n",
      "Loss for batch 52 = 0.24760623276233673\n",
      "Loss for batch 53 = 0.2052316516637802\n",
      "Loss for batch 54 = 0.43985116481781006\n",
      "Loss for batch 55 = 0.4634782671928406\n",
      "Loss for batch 56 = 0.46866002678871155\n",
      "Loss for batch 57 = 0.34614673256874084\n",
      "Loss for batch 58 = 0.35878369212150574\n",
      "Loss for batch 59 = 0.6342262029647827\n",
      "Loss for batch 60 = 0.25049301981925964\n",
      "Loss for batch 61 = 0.7040976285934448\n",
      "Loss for batch 62 = 0.4934048056602478\n",
      "Loss for batch 63 = 0.38050413131713867\n",
      "Loss for batch 64 = 0.1588020920753479\n",
      "Loss for batch 65 = 0.29602494835853577\n",
      "Loss for batch 66 = 0.4288620948791504\n",
      "Loss for batch 67 = 0.5725269913673401\n",
      "Loss for batch 68 = 0.5149785876274109\n",
      "Loss for batch 69 = 0.2924889624118805\n",
      "Loss for batch 70 = 0.6209169030189514\n",
      "Loss for batch 71 = 0.41050806641578674\n",
      "Loss for batch 72 = 0.332318514585495\n",
      "Loss for batch 73 = 0.36141684651374817\n",
      "Loss for batch 74 = 0.23177677392959595\n",
      "Loss for batch 75 = 0.3011954724788666\n",
      "Loss for batch 76 = 0.27240824699401855\n",
      "Loss for batch 77 = 0.273305207490921\n",
      "Loss for batch 78 = 0.2853168845176697\n",
      "Loss for batch 79 = 0.22500883042812347\n",
      "Loss for batch 80 = 0.3134598135948181\n",
      "Loss for batch 81 = 0.4653816223144531\n",
      "Loss for batch 82 = 0.3537692725658417\n",
      "Loss for batch 83 = 0.37920457124710083\n",
      "Loss for batch 84 = 0.32525819540023804\n",
      "Loss for batch 85 = 0.21659424901008606\n",
      "Loss for batch 86 = 0.20006269216537476\n",
      "Loss for batch 87 = 0.3755602240562439\n",
      "Loss for batch 88 = 0.3125387132167816\n",
      "Loss for batch 89 = 0.39956390857696533\n",
      "Loss for batch 90 = 0.566150963306427\n",
      "Loss for batch 91 = 0.4188719689846039\n",
      "Loss for batch 92 = 0.36318239569664\n",
      "Loss for batch 93 = 0.48765137791633606\n",
      "Loss for batch 94 = 0.4586958885192871\n",
      "Loss for batch 95 = 0.22449932992458344\n",
      "Loss for batch 96 = 0.5443125367164612\n",
      "Loss for batch 97 = 0.3826485574245453\n",
      "\n",
      "Training Loss for epoch 29 = 37.825321197509766\n",
      "\n",
      "Current Validation Loss = 33.19626998901367\n",
      "Best Validation Loss = 21.966571807861328\n",
      "Epochs without Improvement = 20\n",
      "Train Accuracy: 85.14%\n",
      "Validation Accuracy: 60.21%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainLoopText(text_modelv1, optimizer, loss_fn, train_loader, val_loader, scheduler, 100, 20, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.68%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv1(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_modelv1.state_dict(), 'LSTMv1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "text_modelv2 = LSTMmodel(3, 25, 512, bidirectionality=True)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.NAdam(text_modelv2.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017d5fb05f1d4711a88d124f39da0ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "----------\n",
      "Loss for batch 0 = 1.1009656190872192\n",
      "Loss for batch 1 = 1.105316162109375\n",
      "Loss for batch 2 = 1.099278211593628\n",
      "Loss for batch 3 = 1.0781726837158203\n",
      "Loss for batch 4 = 1.1139616966247559\n",
      "Loss for batch 5 = 1.1061747074127197\n",
      "Loss for batch 6 = 1.1124461889266968\n",
      "Loss for batch 7 = 1.0931756496429443\n",
      "Loss for batch 8 = 1.0874216556549072\n",
      "Loss for batch 9 = 1.0679340362548828\n",
      "Loss for batch 10 = 1.1731222867965698\n",
      "Loss for batch 11 = 1.101493239402771\n",
      "Loss for batch 12 = 1.1018526554107666\n",
      "Loss for batch 13 = 1.1055727005004883\n",
      "Loss for batch 14 = 1.0938283205032349\n",
      "Loss for batch 15 = 1.084906816482544\n",
      "Loss for batch 16 = 1.0932576656341553\n",
      "Loss for batch 17 = 1.0975786447525024\n",
      "Loss for batch 18 = 1.0871587991714478\n",
      "Loss for batch 19 = 1.0808978080749512\n",
      "Loss for batch 20 = 1.0676358938217163\n",
      "Loss for batch 21 = 1.0835015773773193\n",
      "Loss for batch 22 = 1.0937045812606812\n",
      "Loss for batch 23 = 1.1027730703353882\n",
      "Loss for batch 24 = 1.135549545288086\n",
      "Loss for batch 25 = 1.0974907875061035\n",
      "Loss for batch 26 = 1.1782352924346924\n",
      "Loss for batch 27 = 1.0841392278671265\n",
      "Loss for batch 28 = 1.0907986164093018\n",
      "Loss for batch 29 = 1.1045012474060059\n",
      "Loss for batch 30 = 1.1066272258758545\n",
      "Loss for batch 31 = 1.1207878589630127\n",
      "Loss for batch 32 = 1.0874940156936646\n",
      "Loss for batch 33 = 1.1004300117492676\n",
      "Loss for batch 34 = 1.0988315343856812\n",
      "Loss for batch 35 = 1.1028705835342407\n",
      "Loss for batch 36 = 1.103168249130249\n",
      "Loss for batch 37 = 1.0950236320495605\n",
      "Loss for batch 38 = 1.0889198780059814\n",
      "Loss for batch 39 = 1.0960441827774048\n",
      "Loss for batch 40 = 1.0867805480957031\n",
      "Loss for batch 41 = 1.0819668769836426\n",
      "Loss for batch 42 = 1.1054935455322266\n",
      "Loss for batch 43 = 1.0857394933700562\n",
      "Loss for batch 44 = 1.0872565507888794\n",
      "Loss for batch 45 = 1.0966144800186157\n",
      "Loss for batch 46 = 1.1027116775512695\n",
      "Loss for batch 47 = 1.0869510173797607\n",
      "Loss for batch 48 = 1.0994430780410767\n",
      "Loss for batch 49 = 1.1162383556365967\n",
      "Loss for batch 50 = 1.0893628597259521\n",
      "Loss for batch 51 = 1.1003142595291138\n",
      "Loss for batch 52 = 1.0940172672271729\n",
      "Loss for batch 53 = 1.0934351682662964\n",
      "Loss for batch 54 = 1.0980256795883179\n",
      "Loss for batch 55 = 1.0964598655700684\n",
      "Loss for batch 56 = 1.0840247869491577\n",
      "Loss for batch 57 = 1.1593927145004272\n",
      "Loss for batch 58 = 1.062077283859253\n",
      "Loss for batch 59 = 1.151914119720459\n",
      "Loss for batch 60 = 1.0865106582641602\n",
      "Loss for batch 61 = 1.0799872875213623\n",
      "Loss for batch 62 = 1.0998786687850952\n",
      "Loss for batch 63 = 1.122309684753418\n",
      "Loss for batch 64 = 1.098013162612915\n",
      "Loss for batch 65 = 1.0852572917938232\n",
      "Loss for batch 66 = 1.0849483013153076\n",
      "Loss for batch 67 = 1.0403341054916382\n",
      "Loss for batch 68 = 1.0882585048675537\n",
      "Loss for batch 69 = 1.133165955543518\n",
      "Loss for batch 70 = 1.1156549453735352\n",
      "Loss for batch 71 = 1.1032036542892456\n",
      "Loss for batch 72 = 1.0899657011032104\n",
      "Loss for batch 73 = 1.0963101387023926\n",
      "Loss for batch 74 = 1.0789862871170044\n",
      "Loss for batch 75 = 1.0989893674850464\n",
      "Loss for batch 76 = 1.083025574684143\n",
      "Loss for batch 77 = 1.0755999088287354\n",
      "Loss for batch 78 = 1.0965290069580078\n",
      "Loss for batch 79 = 1.0639840364456177\n",
      "Loss for batch 80 = 1.2080800533294678\n",
      "Loss for batch 81 = 1.1018794775009155\n",
      "Loss for batch 82 = 1.103348970413208\n",
      "Loss for batch 83 = 1.1075732707977295\n",
      "Loss for batch 84 = 1.095715880393982\n",
      "Loss for batch 85 = 1.0980398654937744\n",
      "Loss for batch 86 = 1.0984424352645874\n",
      "Loss for batch 87 = 1.09527587890625\n",
      "Loss for batch 88 = 1.0861103534698486\n",
      "Loss for batch 89 = 1.0874557495117188\n",
      "Loss for batch 90 = 1.0965300798416138\n",
      "Loss for batch 91 = 1.1229084730148315\n",
      "Loss for batch 92 = 1.0866252183914185\n",
      "Loss for batch 93 = 1.094338059425354\n",
      "Loss for batch 94 = 1.094157099723816\n",
      "Loss for batch 95 = 1.1031339168548584\n",
      "Loss for batch 96 = 1.1085600852966309\n",
      "Loss for batch 97 = 1.1162066459655762\n",
      "\n",
      "Training Loss for epoch 0 = 107.72654724121094\n",
      "\n",
      "Current Validation Loss = 27.371061325073242\n",
      "Best Validation Loss = 27.371061325073242\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.97%\n",
      "Validation Accuracy: 40.69%\n",
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss for batch 0 = 1.0924181938171387\n",
      "Loss for batch 1 = 1.0944936275482178\n",
      "Loss for batch 2 = 1.0931243896484375\n",
      "Loss for batch 3 = 1.0836308002471924\n",
      "Loss for batch 4 = 1.093290090560913\n",
      "Loss for batch 5 = 1.0911836624145508\n",
      "Loss for batch 6 = 1.1051069498062134\n",
      "Loss for batch 7 = 1.0969617366790771\n",
      "Loss for batch 8 = 1.0878371000289917\n",
      "Loss for batch 9 = 1.0658338069915771\n",
      "Loss for batch 10 = 1.1489191055297852\n",
      "Loss for batch 11 = 1.0997179746627808\n",
      "Loss for batch 12 = 1.0879820585250854\n",
      "Loss for batch 13 = 1.1047054529190063\n",
      "Loss for batch 14 = 1.085610032081604\n",
      "Loss for batch 15 = 1.0991476774215698\n",
      "Loss for batch 16 = 1.0872561931610107\n",
      "Loss for batch 17 = 1.082428216934204\n",
      "Loss for batch 18 = 1.0773828029632568\n",
      "Loss for batch 19 = 1.0663427114486694\n",
      "Loss for batch 20 = 1.0467684268951416\n",
      "Loss for batch 21 = 1.094704031944275\n",
      "Loss for batch 22 = 1.0814152956008911\n",
      "Loss for batch 23 = 1.0741572380065918\n",
      "Loss for batch 24 = 1.0969483852386475\n",
      "Loss for batch 25 = 1.0322530269622803\n",
      "Loss for batch 26 = 1.147660493850708\n",
      "Loss for batch 27 = 1.0444788932800293\n",
      "Loss for batch 28 = 1.0937080383300781\n",
      "Loss for batch 29 = 1.1447426080703735\n",
      "Loss for batch 30 = 1.1075384616851807\n",
      "Loss for batch 31 = 1.1183174848556519\n",
      "Loss for batch 32 = 1.0782735347747803\n",
      "Loss for batch 33 = 1.0943342447280884\n",
      "Loss for batch 34 = 1.0842783451080322\n",
      "Loss for batch 35 = 1.0909556150436401\n",
      "Loss for batch 36 = 1.0971176624298096\n",
      "Loss for batch 37 = 1.1025718450546265\n",
      "Loss for batch 38 = 1.0795812606811523\n",
      "Loss for batch 39 = 1.0780376195907593\n",
      "Loss for batch 40 = 1.0683135986328125\n",
      "Loss for batch 41 = 1.067151427268982\n",
      "Loss for batch 42 = 1.110629916191101\n",
      "Loss for batch 43 = 1.0823403596878052\n",
      "Loss for batch 44 = 1.0710351467132568\n",
      "Loss for batch 45 = 1.0837773084640503\n",
      "Loss for batch 46 = 1.0871309041976929\n",
      "Loss for batch 47 = 1.0577250719070435\n",
      "Loss for batch 48 = 1.125032663345337\n",
      "Loss for batch 49 = 1.061599612236023\n",
      "Loss for batch 50 = 1.04399836063385\n",
      "Loss for batch 51 = 1.0597796440124512\n",
      "Loss for batch 52 = 1.1351449489593506\n",
      "Loss for batch 53 = 1.0703359842300415\n",
      "Loss for batch 54 = 1.1486599445343018\n",
      "Loss for batch 55 = 1.1010338068008423\n",
      "Loss for batch 56 = 1.079393744468689\n",
      "Loss for batch 57 = 1.079896330833435\n",
      "Loss for batch 58 = 1.0262141227722168\n",
      "Loss for batch 59 = 1.0896111726760864\n",
      "Loss for batch 60 = 1.1073939800262451\n",
      "Loss for batch 61 = 1.0598537921905518\n",
      "Loss for batch 62 = 1.0655279159545898\n",
      "Loss for batch 63 = 1.0730555057525635\n",
      "Loss for batch 64 = 1.0300134420394897\n",
      "Loss for batch 65 = 1.0708673000335693\n",
      "Loss for batch 66 = 1.1718971729278564\n",
      "Loss for batch 67 = 1.0275311470031738\n",
      "Loss for batch 68 = 1.1200777292251587\n",
      "Loss for batch 69 = 1.1240904331207275\n",
      "Loss for batch 70 = 1.1177337169647217\n",
      "Loss for batch 71 = 1.0790963172912598\n",
      "Loss for batch 72 = 1.0616728067398071\n",
      "Loss for batch 73 = 1.1254334449768066\n",
      "Loss for batch 74 = 1.0783406496047974\n",
      "Loss for batch 75 = 1.0807143449783325\n",
      "Loss for batch 76 = 1.0496715307235718\n",
      "Loss for batch 77 = 1.0594186782836914\n",
      "Loss for batch 78 = 1.0620394945144653\n",
      "Loss for batch 79 = 1.030945897102356\n",
      "Loss for batch 80 = 1.1127389669418335\n",
      "Loss for batch 81 = 1.1048327684402466\n",
      "Loss for batch 82 = 1.1087474822998047\n",
      "Loss for batch 83 = 1.0989923477172852\n",
      "Loss for batch 84 = 1.1108571290969849\n",
      "Loss for batch 85 = 1.100028395652771\n",
      "Loss for batch 86 = 1.079966425895691\n",
      "Loss for batch 87 = 1.09454345703125\n",
      "Loss for batch 88 = 1.020700216293335\n",
      "Loss for batch 89 = 1.0919817686080933\n",
      "Loss for batch 90 = 1.0732605457305908\n",
      "Loss for batch 91 = 1.147464632987976\n",
      "Loss for batch 92 = 1.0423321723937988\n",
      "Loss for batch 93 = 1.084883451461792\n",
      "Loss for batch 94 = 1.112447738647461\n",
      "Loss for batch 95 = 1.0993130207061768\n",
      "Loss for batch 96 = 1.1042025089263916\n",
      "Loss for batch 97 = 1.067710041999817\n",
      "\n",
      "Training Loss for epoch 1 = 106.53041076660156\n",
      "\n",
      "Current Validation Loss = 27.008129119873047\n",
      "Best Validation Loss = 27.008129119873047\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.11%\n",
      "Validation Accuracy: 40.95%\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss for batch 0 = 1.0301586389541626\n",
      "Loss for batch 1 = 1.0568629503250122\n",
      "Loss for batch 2 = 1.0927544832229614\n",
      "Loss for batch 3 = 1.0043373107910156\n",
      "Loss for batch 4 = 1.0589138269424438\n",
      "Loss for batch 5 = 1.04265296459198\n",
      "Loss for batch 6 = 1.0561339855194092\n",
      "Loss for batch 7 = 1.069464921951294\n",
      "Loss for batch 8 = 1.0853726863861084\n",
      "Loss for batch 9 = 0.9902610778808594\n",
      "Loss for batch 10 = 1.221077799797058\n",
      "Loss for batch 11 = 1.1063646078109741\n",
      "Loss for batch 12 = 1.0452790260314941\n",
      "Loss for batch 13 = 1.0956155061721802\n",
      "Loss for batch 14 = 1.0345721244812012\n",
      "Loss for batch 15 = 1.118523120880127\n",
      "Loss for batch 16 = 1.0233123302459717\n",
      "Loss for batch 17 = 0.9612873792648315\n",
      "Loss for batch 18 = 0.999718427658081\n",
      "Loss for batch 19 = 1.1216195821762085\n",
      "Loss for batch 20 = 0.9913229942321777\n",
      "Loss for batch 21 = 1.1109777688980103\n",
      "Loss for batch 22 = 1.0069321393966675\n",
      "Loss for batch 23 = 0.987144947052002\n",
      "Loss for batch 24 = 1.0112226009368896\n",
      "Loss for batch 25 = 1.0204824209213257\n",
      "Loss for batch 26 = 1.1050208806991577\n",
      "Loss for batch 27 = 0.9612564444541931\n",
      "Loss for batch 28 = 1.164849877357483\n",
      "Loss for batch 29 = 1.1447069644927979\n",
      "Loss for batch 30 = 1.0568652153015137\n",
      "Loss for batch 31 = 1.0962241888046265\n",
      "Loss for batch 32 = 1.0970150232315063\n",
      "Loss for batch 33 = 1.0643470287322998\n",
      "Loss for batch 34 = 0.9695273041725159\n",
      "Loss for batch 35 = 1.091587781906128\n",
      "Loss for batch 36 = 1.0747361183166504\n",
      "Loss for batch 37 = 1.1008483171463013\n",
      "Loss for batch 38 = 1.0745600461959839\n",
      "Loss for batch 39 = 1.085267186164856\n",
      "Loss for batch 40 = 1.0465742349624634\n",
      "Loss for batch 41 = 1.0581567287445068\n",
      "Loss for batch 42 = 1.1093428134918213\n",
      "Loss for batch 43 = 1.061042070388794\n",
      "Loss for batch 44 = 1.071837067604065\n",
      "Loss for batch 45 = 1.0577245950698853\n",
      "Loss for batch 46 = 1.0785490274429321\n",
      "Loss for batch 47 = 1.0537863969802856\n",
      "Loss for batch 48 = 1.0927246809005737\n",
      "Loss for batch 49 = 1.0159635543823242\n",
      "Loss for batch 50 = 0.976967453956604\n",
      "Loss for batch 51 = 1.0407326221466064\n",
      "Loss for batch 52 = 1.1264556646347046\n",
      "Loss for batch 53 = 1.075332522392273\n",
      "Loss for batch 54 = 1.1232693195343018\n",
      "Loss for batch 55 = 1.1073015928268433\n",
      "Loss for batch 56 = 1.0481854677200317\n",
      "Loss for batch 57 = 1.0629677772521973\n",
      "Loss for batch 58 = 0.940241277217865\n",
      "Loss for batch 59 = 1.0986989736557007\n",
      "Loss for batch 60 = 1.0968279838562012\n",
      "Loss for batch 61 = 1.038673996925354\n",
      "Loss for batch 62 = 1.0195668935775757\n",
      "Loss for batch 63 = 1.0742942094802856\n",
      "Loss for batch 64 = 0.9862491488456726\n",
      "Loss for batch 65 = 1.0605548620224\n",
      "Loss for batch 66 = 1.1564218997955322\n",
      "Loss for batch 67 = 1.0410182476043701\n",
      "Loss for batch 68 = 1.0665496587753296\n",
      "Loss for batch 69 = 1.1144849061965942\n",
      "Loss for batch 70 = 1.1599863767623901\n",
      "Loss for batch 71 = 1.0565909147262573\n",
      "Loss for batch 72 = 1.0385013818740845\n",
      "Loss for batch 73 = 1.1149977445602417\n",
      "Loss for batch 74 = 1.044683814048767\n",
      "Loss for batch 75 = 1.0422266721725464\n",
      "Loss for batch 76 = 1.006982684135437\n",
      "Loss for batch 77 = 1.0350629091262817\n",
      "Loss for batch 78 = 1.163374423980713\n",
      "Loss for batch 79 = 1.1759306192398071\n",
      "Loss for batch 80 = 1.1046901941299438\n",
      "Loss for batch 81 = 1.1079765558242798\n",
      "Loss for batch 82 = 1.0939366817474365\n",
      "Loss for batch 83 = 1.0933274030685425\n",
      "Loss for batch 84 = 1.0804774761199951\n",
      "Loss for batch 85 = 1.089105486869812\n",
      "Loss for batch 86 = 1.0386688709259033\n",
      "Loss for batch 87 = 1.0829764604568481\n",
      "Loss for batch 88 = 0.9864954352378845\n",
      "Loss for batch 89 = 1.0781363248825073\n",
      "Loss for batch 90 = 1.0791919231414795\n",
      "Loss for batch 91 = 1.1311596632003784\n",
      "Loss for batch 92 = 1.0001989603042603\n",
      "Loss for batch 93 = 1.066046118736267\n",
      "Loss for batch 94 = 1.1232569217681885\n",
      "Loss for batch 95 = 1.1053228378295898\n",
      "Loss for batch 96 = 1.0939503908157349\n",
      "Loss for batch 97 = 1.0456764698028564\n",
      "\n",
      "Training Loss for epoch 2 = 104.56861114501953\n",
      "\n",
      "Current Validation Loss = 26.757709503173828\n",
      "Best Validation Loss = 26.757709503173828\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 46.21%\n",
      "Validation Accuracy: 43.52%\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss for batch 0 = 1.019026756286621\n",
      "Loss for batch 1 = 1.0341870784759521\n",
      "Loss for batch 2 = 1.0375133752822876\n",
      "Loss for batch 3 = 0.8971306085586548\n",
      "Loss for batch 4 = 1.008790373802185\n",
      "Loss for batch 5 = 0.9957868456840515\n",
      "Loss for batch 6 = 1.0410128831863403\n",
      "Loss for batch 7 = 1.0660992860794067\n",
      "Loss for batch 8 = 1.0256505012512207\n",
      "Loss for batch 9 = 1.0458346605300903\n",
      "Loss for batch 10 = 1.2510428428649902\n",
      "Loss for batch 11 = 1.0006183385849\n",
      "Loss for batch 12 = 1.0237936973571777\n",
      "Loss for batch 13 = 1.11642587184906\n",
      "Loss for batch 14 = 1.0038495063781738\n",
      "Loss for batch 15 = 1.0737786293029785\n",
      "Loss for batch 16 = 1.0521847009658813\n",
      "Loss for batch 17 = 1.0052677392959595\n",
      "Loss for batch 18 = 1.0062556266784668\n",
      "Loss for batch 19 = 1.0577483177185059\n",
      "Loss for batch 20 = 0.9644455313682556\n",
      "Loss for batch 21 = 0.9603977799415588\n",
      "Loss for batch 22 = 1.0936006307601929\n",
      "Loss for batch 23 = 1.0363874435424805\n",
      "Loss for batch 24 = 1.0379313230514526\n",
      "Loss for batch 25 = 1.0789158344268799\n",
      "Loss for batch 26 = 0.9841921925544739\n",
      "Loss for batch 27 = 0.9242047071456909\n",
      "Loss for batch 28 = 1.1361188888549805\n",
      "Loss for batch 29 = 1.1202179193496704\n",
      "Loss for batch 30 = 1.031129240989685\n",
      "Loss for batch 31 = 1.1163990497589111\n",
      "Loss for batch 32 = 1.036977767944336\n",
      "Loss for batch 33 = 1.0371997356414795\n",
      "Loss for batch 34 = 0.9529106616973877\n",
      "Loss for batch 35 = 1.06968355178833\n",
      "Loss for batch 36 = 1.0863018035888672\n",
      "Loss for batch 37 = 1.0656856298446655\n",
      "Loss for batch 38 = 1.0901989936828613\n",
      "Loss for batch 39 = 1.0630853176116943\n",
      "Loss for batch 40 = 1.0138099193572998\n",
      "Loss for batch 41 = 0.9854670166969299\n",
      "Loss for batch 42 = 1.0896193981170654\n",
      "Loss for batch 43 = 1.046020269393921\n",
      "Loss for batch 44 = 1.027161955833435\n",
      "Loss for batch 45 = 1.0287896394729614\n",
      "Loss for batch 46 = 1.047655463218689\n",
      "Loss for batch 47 = 0.9786792993545532\n",
      "Loss for batch 48 = 0.9227101802825928\n",
      "Loss for batch 49 = 1.0560296773910522\n",
      "Loss for batch 50 = 0.9620859026908875\n",
      "Loss for batch 51 = 1.0302265882492065\n",
      "Loss for batch 52 = 1.3796523809432983\n",
      "Loss for batch 53 = 1.127550721168518\n",
      "Loss for batch 54 = 1.1163376569747925\n",
      "Loss for batch 55 = 1.0951323509216309\n",
      "Loss for batch 56 = 1.041538953781128\n",
      "Loss for batch 57 = 1.0421403646469116\n",
      "Loss for batch 58 = 0.9400758743286133\n",
      "Loss for batch 59 = 1.1174075603485107\n",
      "Loss for batch 60 = 1.1019810438156128\n",
      "Loss for batch 61 = 1.0422838926315308\n",
      "Loss for batch 62 = 0.9912135004997253\n",
      "Loss for batch 63 = 1.0627598762512207\n",
      "Loss for batch 64 = 0.9933056831359863\n",
      "Loss for batch 65 = 1.044426679611206\n",
      "Loss for batch 66 = 1.1447137594223022\n",
      "Loss for batch 67 = 1.074720025062561\n",
      "Loss for batch 68 = 1.0336036682128906\n",
      "Loss for batch 69 = 1.0686275959014893\n",
      "Loss for batch 70 = 1.1627346277236938\n",
      "Loss for batch 71 = 1.0577759742736816\n",
      "Loss for batch 72 = 1.007219910621643\n",
      "Loss for batch 73 = 1.094144582748413\n",
      "Loss for batch 74 = 1.0164694786071777\n",
      "Loss for batch 75 = 1.0429067611694336\n",
      "Loss for batch 76 = 1.0373814105987549\n",
      "Loss for batch 77 = 1.046360969543457\n",
      "Loss for batch 78 = 0.953423261642456\n",
      "Loss for batch 79 = 0.9950389266014099\n",
      "Loss for batch 80 = 0.9852163791656494\n",
      "Loss for batch 81 = 1.0984432697296143\n",
      "Loss for batch 82 = 1.100914716720581\n",
      "Loss for batch 83 = 1.1039549112319946\n",
      "Loss for batch 84 = 1.0288441181182861\n",
      "Loss for batch 85 = 0.9752565026283264\n",
      "Loss for batch 86 = 1.0609487295150757\n",
      "Loss for batch 87 = 1.0546623468399048\n",
      "Loss for batch 88 = 0.9571422338485718\n",
      "Loss for batch 89 = 1.031959056854248\n",
      "Loss for batch 90 = 0.9701208472251892\n",
      "Loss for batch 91 = 1.053746223449707\n",
      "Loss for batch 92 = 0.9216201901435852\n",
      "Loss for batch 93 = 1.039765477180481\n",
      "Loss for batch 94 = 1.0061454772949219\n",
      "Loss for batch 95 = 1.0184524059295654\n",
      "Loss for batch 96 = 1.0358985662460327\n",
      "Loss for batch 97 = 1.014051914215088\n",
      "\n",
      "Training Loss for epoch 3 = 102.12432861328125\n",
      "\n",
      "Current Validation Loss = 25.77005958557129\n",
      "Best Validation Loss = 25.77005958557129\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 52.15%\n",
      "Validation Accuracy: 48.40%\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss for batch 0 = 0.9680404663085938\n",
      "Loss for batch 1 = 1.0343821048736572\n",
      "Loss for batch 2 = 1.010922908782959\n",
      "Loss for batch 3 = 0.7743483185768127\n",
      "Loss for batch 4 = 0.9291144013404846\n",
      "Loss for batch 5 = 0.9265389442443848\n",
      "Loss for batch 6 = 1.3453301191329956\n",
      "Loss for batch 7 = 1.0861881971359253\n",
      "Loss for batch 8 = 0.9993667602539062\n",
      "Loss for batch 9 = 1.0217351913452148\n",
      "Loss for batch 10 = 1.1464110612869263\n",
      "Loss for batch 11 = 1.000521183013916\n",
      "Loss for batch 12 = 0.9952515959739685\n",
      "Loss for batch 13 = 1.0636073350906372\n",
      "Loss for batch 14 = 0.8851331472396851\n",
      "Loss for batch 15 = 1.1181848049163818\n",
      "Loss for batch 16 = 0.9876250624656677\n",
      "Loss for batch 17 = 0.9964504241943359\n",
      "Loss for batch 18 = 0.906452476978302\n",
      "Loss for batch 19 = 1.0012202262878418\n",
      "Loss for batch 20 = 0.8851235508918762\n",
      "Loss for batch 21 = 0.9285417795181274\n",
      "Loss for batch 22 = 0.9743530750274658\n",
      "Loss for batch 23 = 0.9435769319534302\n",
      "Loss for batch 24 = 0.9793610572814941\n",
      "Loss for batch 25 = 0.9765673875808716\n",
      "Loss for batch 26 = 0.9665101766586304\n",
      "Loss for batch 27 = 0.9844473600387573\n",
      "Loss for batch 28 = 1.1278012990951538\n",
      "Loss for batch 29 = 1.0300103425979614\n",
      "Loss for batch 30 = 0.9905279874801636\n",
      "Loss for batch 31 = 1.0821456909179688\n",
      "Loss for batch 32 = 1.088165521621704\n",
      "Loss for batch 33 = 0.9755666255950928\n",
      "Loss for batch 34 = 0.9435122013092041\n",
      "Loss for batch 35 = 1.0918599367141724\n",
      "Loss for batch 36 = 1.0576838254928589\n",
      "Loss for batch 37 = 1.0429329872131348\n",
      "Loss for batch 38 = 1.117077350616455\n",
      "Loss for batch 39 = 1.052357792854309\n",
      "Loss for batch 40 = 0.9731606245040894\n",
      "Loss for batch 41 = 1.0558432340621948\n",
      "Loss for batch 42 = 1.0472850799560547\n",
      "Loss for batch 43 = 0.9747666716575623\n",
      "Loss for batch 44 = 1.0057096481323242\n",
      "Loss for batch 45 = 0.9756530523300171\n",
      "Loss for batch 46 = 1.0503042936325073\n",
      "Loss for batch 47 = 0.9298738241195679\n",
      "Loss for batch 48 = 0.9326291680335999\n",
      "Loss for batch 49 = 0.959922730922699\n",
      "Loss for batch 50 = 0.9473113417625427\n",
      "Loss for batch 51 = 0.9794121980667114\n",
      "Loss for batch 52 = 1.1905875205993652\n",
      "Loss for batch 53 = 1.0179517269134521\n",
      "Loss for batch 54 = 1.0366976261138916\n",
      "Loss for batch 55 = 1.0730035305023193\n",
      "Loss for batch 56 = 1.113924264907837\n",
      "Loss for batch 57 = 0.9208250045776367\n",
      "Loss for batch 58 = 1.020892858505249\n",
      "Loss for batch 59 = 1.0564625263214111\n",
      "Loss for batch 60 = 1.0500855445861816\n",
      "Loss for batch 61 = 0.9570969939231873\n",
      "Loss for batch 62 = 1.0079762935638428\n",
      "Loss for batch 63 = 1.0161784887313843\n",
      "Loss for batch 64 = 0.8805362582206726\n",
      "Loss for batch 65 = 1.0388820171356201\n",
      "Loss for batch 66 = 1.1517150402069092\n",
      "Loss for batch 67 = 0.9438045024871826\n",
      "Loss for batch 68 = 1.0178886651992798\n",
      "Loss for batch 69 = 1.085331916809082\n",
      "Loss for batch 70 = 1.0753788948059082\n",
      "Loss for batch 71 = 1.015291690826416\n",
      "Loss for batch 72 = 0.9467748999595642\n",
      "Loss for batch 73 = 1.0684560537338257\n",
      "Loss for batch 74 = 0.9887290596961975\n",
      "Loss for batch 75 = 1.0013347864151\n",
      "Loss for batch 76 = 0.9927043914794922\n",
      "Loss for batch 77 = 1.001111388206482\n",
      "Loss for batch 78 = 0.9346368312835693\n",
      "Loss for batch 79 = 0.9827975034713745\n",
      "Loss for batch 80 = 1.106000542640686\n",
      "Loss for batch 81 = 1.116580843925476\n",
      "Loss for batch 82 = 1.0624394416809082\n",
      "Loss for batch 83 = 1.081671953201294\n",
      "Loss for batch 84 = 1.0131102800369263\n",
      "Loss for batch 85 = 0.9711242914199829\n",
      "Loss for batch 86 = 0.9915316104888916\n",
      "Loss for batch 87 = 0.9869992136955261\n",
      "Loss for batch 88 = 0.9381497502326965\n",
      "Loss for batch 89 = 0.9859266877174377\n",
      "Loss for batch 90 = 0.9706642031669617\n",
      "Loss for batch 91 = 1.0362273454666138\n",
      "Loss for batch 92 = 0.8564214110374451\n",
      "Loss for batch 93 = 1.04677152633667\n",
      "Loss for batch 94 = 1.0624858140945435\n",
      "Loss for batch 95 = 0.9119864702224731\n",
      "Loss for batch 96 = 0.9943248629570007\n",
      "Loss for batch 97 = 0.9866297841072083\n",
      "\n",
      "Training Loss for epoch 4 = 98.97293090820312\n",
      "\n",
      "Current Validation Loss = 26.26491928100586\n",
      "Best Validation Loss = 25.77005958557129\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 54.46%\n",
      "Validation Accuracy: 52.76%\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss for batch 0 = 0.998452365398407\n",
      "Loss for batch 1 = 0.93006432056427\n",
      "Loss for batch 2 = 1.045772910118103\n",
      "Loss for batch 3 = 0.7208434343338013\n",
      "Loss for batch 4 = 0.9541742205619812\n",
      "Loss for batch 5 = 0.8610959053039551\n",
      "Loss for batch 6 = 0.981967568397522\n",
      "Loss for batch 7 = 1.2357308864593506\n",
      "Loss for batch 8 = 0.9615996479988098\n",
      "Loss for batch 9 = 0.9202985167503357\n",
      "Loss for batch 10 = 1.0935579538345337\n",
      "Loss for batch 11 = 1.0926470756530762\n",
      "Loss for batch 12 = 0.9236177206039429\n",
      "Loss for batch 13 = 1.0536081790924072\n",
      "Loss for batch 14 = 0.8624489307403564\n",
      "Loss for batch 15 = 1.1529406309127808\n",
      "Loss for batch 16 = 1.0753954648971558\n",
      "Loss for batch 17 = 0.999810516834259\n",
      "Loss for batch 18 = 0.997061550617218\n",
      "Loss for batch 19 = 1.080145001411438\n",
      "Loss for batch 20 = 0.9361979961395264\n",
      "Loss for batch 21 = 1.0740954875946045\n",
      "Loss for batch 22 = 1.0054123401641846\n",
      "Loss for batch 23 = 0.9587856531143188\n",
      "Loss for batch 24 = 1.0116251707077026\n",
      "Loss for batch 25 = 0.9929360747337341\n",
      "Loss for batch 26 = 1.1178191900253296\n",
      "Loss for batch 27 = 0.9897964596748352\n",
      "Loss for batch 28 = 1.0373799800872803\n",
      "Loss for batch 29 = 1.1535735130310059\n",
      "Loss for batch 30 = 1.046284556388855\n",
      "Loss for batch 31 = 1.0847851037979126\n",
      "Loss for batch 32 = 1.1282862424850464\n",
      "Loss for batch 33 = 0.9977628588676453\n",
      "Loss for batch 34 = 0.9604172110557556\n",
      "Loss for batch 35 = 1.1128666400909424\n",
      "Loss for batch 36 = 1.0379736423492432\n",
      "Loss for batch 37 = 1.0577894449234009\n",
      "Loss for batch 38 = 1.0908030271530151\n",
      "Loss for batch 39 = 1.0701528787612915\n",
      "Loss for batch 40 = 1.0186325311660767\n",
      "Loss for batch 41 = 0.9892096519470215\n",
      "Loss for batch 42 = 1.0072782039642334\n",
      "Loss for batch 43 = 1.0145381689071655\n",
      "Loss for batch 44 = 0.9942345023155212\n",
      "Loss for batch 45 = 0.988844633102417\n",
      "Loss for batch 46 = 1.069995641708374\n",
      "Loss for batch 47 = 0.9856107831001282\n",
      "Loss for batch 48 = 0.9827914834022522\n",
      "Loss for batch 49 = 0.9892761707305908\n",
      "Loss for batch 50 = 0.9379565715789795\n",
      "Loss for batch 51 = 1.0221223831176758\n",
      "Loss for batch 52 = 1.0404579639434814\n",
      "Loss for batch 53 = 0.9854480028152466\n",
      "Loss for batch 54 = 1.050214171409607\n",
      "Loss for batch 55 = 1.005740761756897\n",
      "Loss for batch 56 = 0.9695528745651245\n",
      "Loss for batch 57 = 0.8483017086982727\n",
      "Loss for batch 58 = 0.7919170260429382\n",
      "Loss for batch 59 = 1.1564496755599976\n",
      "Loss for batch 60 = 1.1907685995101929\n",
      "Loss for batch 61 = 1.0172683000564575\n",
      "Loss for batch 62 = 0.9723786115646362\n",
      "Loss for batch 63 = 1.1153696775436401\n",
      "Loss for batch 64 = 0.9121086597442627\n",
      "Loss for batch 65 = 1.152984619140625\n",
      "Loss for batch 66 = 1.0362423658370972\n",
      "Loss for batch 67 = 0.87151700258255\n",
      "Loss for batch 68 = 1.0528130531311035\n",
      "Loss for batch 69 = 1.116483449935913\n",
      "Loss for batch 70 = 1.110313892364502\n",
      "Loss for batch 71 = 0.9760392904281616\n",
      "Loss for batch 72 = 0.9638617634773254\n",
      "Loss for batch 73 = 1.0184441804885864\n",
      "Loss for batch 74 = 0.9234551191329956\n",
      "Loss for batch 75 = 0.9323078393936157\n",
      "Loss for batch 76 = 0.9486572742462158\n",
      "Loss for batch 77 = 0.9424179196357727\n",
      "Loss for batch 78 = 0.9681404829025269\n",
      "Loss for batch 79 = 1.0060956478118896\n",
      "Loss for batch 80 = 0.8910269737243652\n",
      "Loss for batch 81 = 1.064040184020996\n",
      "Loss for batch 82 = 1.0566198825836182\n",
      "Loss for batch 83 = 1.0956332683563232\n",
      "Loss for batch 84 = 0.9458803534507751\n",
      "Loss for batch 85 = 0.9258631467819214\n",
      "Loss for batch 86 = 0.9684669971466064\n",
      "Loss for batch 87 = 0.9960557818412781\n",
      "Loss for batch 88 = 0.9123513102531433\n",
      "Loss for batch 89 = 0.9903977513313293\n",
      "Loss for batch 90 = 0.9247584342956543\n",
      "Loss for batch 91 = 0.9301148056983948\n",
      "Loss for batch 92 = 1.003675103187561\n",
      "Loss for batch 93 = 1.0332738161087036\n",
      "Loss for batch 94 = 0.9921616315841675\n",
      "Loss for batch 95 = 0.9183844923973083\n",
      "Loss for batch 96 = 0.9846176505088806\n",
      "Loss for batch 97 = 1.0744746923446655\n",
      "\n",
      "Training Loss for epoch 5 = 98.58999633789062\n",
      "\n",
      "Current Validation Loss = 25.639141082763672\n",
      "Best Validation Loss = 25.639141082763672\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 57.96%\n",
      "Validation Accuracy: 54.69%\n",
      "\n",
      "Epoch 6\n",
      "----------\n",
      "Loss for batch 0 = 0.9175193309783936\n",
      "Loss for batch 1 = 0.9332008361816406\n",
      "Loss for batch 2 = 0.9810672998428345\n",
      "Loss for batch 3 = 0.7997995615005493\n",
      "Loss for batch 4 = 0.921948254108429\n",
      "Loss for batch 5 = 0.855897068977356\n",
      "Loss for batch 6 = 0.9206355810165405\n",
      "Loss for batch 7 = 1.1172153949737549\n",
      "Loss for batch 8 = 0.9049488306045532\n",
      "Loss for batch 9 = 0.8812485337257385\n",
      "Loss for batch 10 = 0.9748497605323792\n",
      "Loss for batch 11 = 0.8047726154327393\n",
      "Loss for batch 12 = 0.8671503067016602\n",
      "Loss for batch 13 = 1.0372384786605835\n",
      "Loss for batch 14 = 0.7453908920288086\n",
      "Loss for batch 15 = 1.104949712753296\n",
      "Loss for batch 16 = 0.9617895483970642\n",
      "Loss for batch 17 = 0.9971393942832947\n",
      "Loss for batch 18 = 0.849794328212738\n",
      "Loss for batch 19 = 0.9379192590713501\n",
      "Loss for batch 20 = 0.805586576461792\n",
      "Loss for batch 21 = 0.9549924731254578\n",
      "Loss for batch 22 = 0.9702816009521484\n",
      "Loss for batch 23 = 0.9101585149765015\n",
      "Loss for batch 24 = 0.9052073955535889\n",
      "Loss for batch 25 = 0.9193254709243774\n",
      "Loss for batch 26 = 0.9563284516334534\n",
      "Loss for batch 27 = 0.8766804933547974\n",
      "Loss for batch 28 = 0.9633195400238037\n",
      "Loss for batch 29 = 0.9470678567886353\n",
      "Loss for batch 30 = 0.9450803995132446\n",
      "Loss for batch 31 = 1.070792555809021\n",
      "Loss for batch 32 = 0.9025954008102417\n",
      "Loss for batch 33 = 1.0531402826309204\n",
      "Loss for batch 34 = 0.9424756169319153\n",
      "Loss for batch 35 = 0.9918268322944641\n",
      "Loss for batch 36 = 0.9292022585868835\n",
      "Loss for batch 37 = 1.0227421522140503\n",
      "Loss for batch 38 = 1.0521377325057983\n",
      "Loss for batch 39 = 0.9749572277069092\n",
      "Loss for batch 40 = 0.9283866882324219\n",
      "Loss for batch 41 = 0.9820607900619507\n",
      "Loss for batch 42 = 0.8901625275611877\n",
      "Loss for batch 43 = 0.8423953652381897\n",
      "Loss for batch 44 = 0.8327472805976868\n",
      "Loss for batch 45 = 0.888674259185791\n",
      "Loss for batch 46 = 1.0242478847503662\n",
      "Loss for batch 47 = 0.8914818167686462\n",
      "Loss for batch 48 = 0.7824251651763916\n",
      "Loss for batch 49 = 0.8548193573951721\n",
      "Loss for batch 50 = 0.9186750650405884\n",
      "Loss for batch 51 = 0.9213367104530334\n",
      "Loss for batch 52 = 0.9810543656349182\n",
      "Loss for batch 53 = 0.976353108882904\n",
      "Loss for batch 54 = 1.0619977712631226\n",
      "Loss for batch 55 = 0.932708203792572\n",
      "Loss for batch 56 = 0.8854777216911316\n",
      "Loss for batch 57 = 0.8104650378227234\n",
      "Loss for batch 58 = 0.7717605233192444\n",
      "Loss for batch 59 = 1.1424005031585693\n",
      "Loss for batch 60 = 1.0318580865859985\n",
      "Loss for batch 61 = 0.8848507404327393\n",
      "Loss for batch 62 = 0.9794787168502808\n",
      "Loss for batch 63 = 1.1769120693206787\n",
      "Loss for batch 64 = 0.8234003782272339\n",
      "Loss for batch 65 = 0.9700618386268616\n",
      "Loss for batch 66 = 1.0145189762115479\n",
      "Loss for batch 67 = 0.9367385506629944\n",
      "Loss for batch 68 = 0.9130415320396423\n",
      "Loss for batch 69 = 0.9291815161705017\n",
      "Loss for batch 70 = 1.0672369003295898\n",
      "Loss for batch 71 = 0.851211428642273\n",
      "Loss for batch 72 = 0.8542760610580444\n",
      "Loss for batch 73 = 0.9164825677871704\n",
      "Loss for batch 74 = 0.8700765371322632\n",
      "Loss for batch 75 = 0.92403244972229\n",
      "Loss for batch 76 = 0.9653564691543579\n",
      "Loss for batch 77 = 0.9113245010375977\n",
      "Loss for batch 78 = 0.8637298345565796\n",
      "Loss for batch 79 = 0.889869213104248\n",
      "Loss for batch 80 = 0.812069296836853\n",
      "Loss for batch 81 = 1.0834078788757324\n",
      "Loss for batch 82 = 1.0713704824447632\n",
      "Loss for batch 83 = 1.0395737886428833\n",
      "Loss for batch 84 = 0.8591875433921814\n",
      "Loss for batch 85 = 0.811521053314209\n",
      "Loss for batch 86 = 0.9172699451446533\n",
      "Loss for batch 87 = 0.885607123374939\n",
      "Loss for batch 88 = 0.8653287887573242\n",
      "Loss for batch 89 = 0.9182273149490356\n",
      "Loss for batch 90 = 0.9556959867477417\n",
      "Loss for batch 91 = 0.9188542366027832\n",
      "Loss for batch 92 = 0.8636407852172852\n",
      "Loss for batch 93 = 1.0553336143493652\n",
      "Loss for batch 94 = 0.9297095537185669\n",
      "Loss for batch 95 = 0.8799697160720825\n",
      "Loss for batch 96 = 0.969684898853302\n",
      "Loss for batch 97 = 1.1219905614852905\n",
      "\n",
      "Training Loss for epoch 6 = 91.66008758544922\n",
      "\n",
      "Current Validation Loss = 24.436635971069336\n",
      "Best Validation Loss = 24.436635971069336\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 58.09%\n",
      "Validation Accuracy: 53.79%\n",
      "\n",
      "Epoch 7\n",
      "----------\n",
      "Loss for batch 0 = 0.8593176603317261\n",
      "Loss for batch 1 = 0.88161700963974\n",
      "Loss for batch 2 = 0.9726217985153198\n",
      "Loss for batch 3 = 0.7892037034034729\n",
      "Loss for batch 4 = 0.9020158052444458\n",
      "Loss for batch 5 = 0.8715248703956604\n",
      "Loss for batch 6 = 0.8873344659805298\n",
      "Loss for batch 7 = 1.0582859516143799\n",
      "Loss for batch 8 = 0.9793605804443359\n",
      "Loss for batch 9 = 0.8663966059684753\n",
      "Loss for batch 10 = 0.9205692410469055\n",
      "Loss for batch 11 = 0.7678117752075195\n",
      "Loss for batch 12 = 0.8197409510612488\n",
      "Loss for batch 13 = 1.112992525100708\n",
      "Loss for batch 14 = 0.7349761724472046\n",
      "Loss for batch 15 = 1.0521161556243896\n",
      "Loss for batch 16 = 0.8509277105331421\n",
      "Loss for batch 17 = 1.0170907974243164\n",
      "Loss for batch 18 = 0.8731141686439514\n",
      "Loss for batch 19 = 0.8622259497642517\n",
      "Loss for batch 20 = 0.7789202928543091\n",
      "Loss for batch 21 = 0.8360385298728943\n",
      "Loss for batch 22 = 0.8737875819206238\n",
      "Loss for batch 23 = 0.8226147294044495\n",
      "Loss for batch 24 = 0.8368142247200012\n",
      "Loss for batch 25 = 0.8725244402885437\n",
      "Loss for batch 26 = 0.9507805705070496\n",
      "Loss for batch 27 = 0.8716723322868347\n",
      "Loss for batch 28 = 0.9304904937744141\n",
      "Loss for batch 29 = 0.9458227753639221\n",
      "Loss for batch 30 = 0.9878605604171753\n",
      "Loss for batch 31 = 0.9838455319404602\n",
      "Loss for batch 32 = 0.8885595202445984\n",
      "Loss for batch 33 = 0.9905977249145508\n",
      "Loss for batch 34 = 0.9091223478317261\n",
      "Loss for batch 35 = 0.9826412796974182\n",
      "Loss for batch 36 = 1.0355099439620972\n",
      "Loss for batch 37 = 1.00882887840271\n",
      "Loss for batch 38 = 1.0693213939666748\n",
      "Loss for batch 39 = 0.8913902044296265\n",
      "Loss for batch 40 = 0.9043583869934082\n",
      "Loss for batch 41 = 0.9127739667892456\n",
      "Loss for batch 42 = 0.7913119792938232\n",
      "Loss for batch 43 = 0.8377009630203247\n",
      "Loss for batch 44 = 0.8564918041229248\n",
      "Loss for batch 45 = 0.8213720321655273\n",
      "Loss for batch 46 = 0.9962359666824341\n",
      "Loss for batch 47 = 0.8471494913101196\n",
      "Loss for batch 48 = 0.7809953689575195\n",
      "Loss for batch 49 = 0.9190399646759033\n",
      "Loss for batch 50 = 0.9126935005187988\n",
      "Loss for batch 51 = 0.919983446598053\n",
      "Loss for batch 52 = 0.8569433093070984\n",
      "Loss for batch 53 = 0.841607391834259\n",
      "Loss for batch 54 = 0.9344726204872131\n",
      "Loss for batch 55 = 1.0289585590362549\n",
      "Loss for batch 56 = 0.9701142907142639\n",
      "Loss for batch 57 = 0.7908127903938293\n",
      "Loss for batch 58 = 0.7360893487930298\n",
      "Loss for batch 59 = 1.1341805458068848\n",
      "Loss for batch 60 = 1.0873125791549683\n",
      "Loss for batch 61 = 0.927090585231781\n",
      "Loss for batch 62 = 0.8776182532310486\n",
      "Loss for batch 63 = 1.0209901332855225\n",
      "Loss for batch 64 = 0.7503945827484131\n",
      "Loss for batch 65 = 0.8906909823417664\n",
      "Loss for batch 66 = 0.9852123856544495\n",
      "Loss for batch 67 = 0.8957132697105408\n",
      "Loss for batch 68 = 0.895723283290863\n",
      "Loss for batch 69 = 0.9998976588249207\n",
      "Loss for batch 70 = 1.0579206943511963\n",
      "Loss for batch 71 = 0.8355942368507385\n",
      "Loss for batch 72 = 0.8862616419792175\n",
      "Loss for batch 73 = 0.956687331199646\n",
      "Loss for batch 74 = 0.7834351062774658\n",
      "Loss for batch 75 = 0.9007031321525574\n",
      "Loss for batch 76 = 0.8789417743682861\n",
      "Loss for batch 77 = 0.8269498944282532\n",
      "Loss for batch 78 = 0.8142786622047424\n",
      "Loss for batch 79 = 0.8666152358055115\n",
      "Loss for batch 80 = 0.8369949460029602\n",
      "Loss for batch 81 = 1.0061532258987427\n",
      "Loss for batch 82 = 0.9831641316413879\n",
      "Loss for batch 83 = 1.0167262554168701\n",
      "Loss for batch 84 = 0.8568252921104431\n",
      "Loss for batch 85 = 0.8867901563644409\n",
      "Loss for batch 86 = 0.892084002494812\n",
      "Loss for batch 87 = 0.8766094446182251\n",
      "Loss for batch 88 = 0.8563109636306763\n",
      "Loss for batch 89 = 0.9336215853691101\n",
      "Loss for batch 90 = 0.917096734046936\n",
      "Loss for batch 91 = 0.8577274680137634\n",
      "Loss for batch 92 = 0.72830730676651\n",
      "Loss for batch 93 = 1.0339934825897217\n",
      "Loss for batch 94 = 0.8441974520683289\n",
      "Loss for batch 95 = 0.83724445104599\n",
      "Loss for batch 96 = 0.9504084587097168\n",
      "Loss for batch 97 = 0.9222880005836487\n",
      "\n",
      "Training Loss for epoch 7 = 88.71424102783203\n",
      "\n",
      "Current Validation Loss = 23.764564514160156\n",
      "Best Validation Loss = 23.764564514160156\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 60.85%\n",
      "Validation Accuracy: 56.61%\n",
      "\n",
      "Epoch 8\n",
      "----------\n",
      "Loss for batch 0 = 0.8497244119644165\n",
      "Loss for batch 1 = 0.8068253993988037\n",
      "Loss for batch 2 = 0.8493381142616272\n",
      "Loss for batch 3 = 0.7183569669723511\n",
      "Loss for batch 4 = 0.8393681049346924\n",
      "Loss for batch 5 = 0.7992041707038879\n",
      "Loss for batch 6 = 0.7831002473831177\n",
      "Loss for batch 7 = 1.034516453742981\n",
      "Loss for batch 8 = 0.8329430222511292\n",
      "Loss for batch 9 = 0.7032356858253479\n",
      "Loss for batch 10 = 0.8632652163505554\n",
      "Loss for batch 11 = 0.7100092172622681\n",
      "Loss for batch 12 = 0.7747369408607483\n",
      "Loss for batch 13 = 1.0320020914077759\n",
      "Loss for batch 14 = 0.7364642024040222\n",
      "Loss for batch 15 = 1.0414360761642456\n",
      "Loss for batch 16 = 0.8679434061050415\n",
      "Loss for batch 17 = 0.9587559103965759\n",
      "Loss for batch 18 = 0.7897232174873352\n",
      "Loss for batch 19 = 0.807216227054596\n",
      "Loss for batch 20 = 0.7635700106620789\n",
      "Loss for batch 21 = 0.8732320070266724\n",
      "Loss for batch 22 = 0.8574874997138977\n",
      "Loss for batch 23 = 0.8846640586853027\n",
      "Loss for batch 24 = 0.8698555827140808\n",
      "Loss for batch 25 = 0.8535495400428772\n",
      "Loss for batch 26 = 0.9153419137001038\n",
      "Loss for batch 27 = 0.839061439037323\n",
      "Loss for batch 28 = 1.0078740119934082\n",
      "Loss for batch 29 = 0.9370302557945251\n",
      "Loss for batch 30 = 1.0430456399917603\n",
      "Loss for batch 31 = 1.0312869548797607\n",
      "Loss for batch 32 = 0.9704883098602295\n",
      "Loss for batch 33 = 0.8822762370109558\n",
      "Loss for batch 34 = 0.8774109482765198\n",
      "Loss for batch 35 = 0.8543953895568848\n",
      "Loss for batch 36 = 1.0141245126724243\n",
      "Loss for batch 37 = 1.0287717580795288\n",
      "Loss for batch 38 = 0.9677879214286804\n",
      "Loss for batch 39 = 0.8030807971954346\n",
      "Loss for batch 40 = 0.899971067905426\n",
      "Loss for batch 41 = 0.8876513838768005\n",
      "Loss for batch 42 = 0.805860161781311\n",
      "Loss for batch 43 = 0.7710668444633484\n",
      "Loss for batch 44 = 0.8666665554046631\n",
      "Loss for batch 45 = 0.8363562226295471\n",
      "Loss for batch 46 = 0.958848237991333\n",
      "Loss for batch 47 = 0.8377810120582581\n",
      "Loss for batch 48 = 0.8594020009040833\n",
      "Loss for batch 49 = 0.9059086441993713\n",
      "Loss for batch 50 = 0.9248590469360352\n",
      "Loss for batch 51 = 0.8508018255233765\n",
      "Loss for batch 52 = 0.8397490382194519\n",
      "Loss for batch 53 = 0.8109169602394104\n",
      "Loss for batch 54 = 0.9190517663955688\n",
      "Loss for batch 55 = 1.0288692712783813\n",
      "Loss for batch 56 = 0.8799400329589844\n",
      "Loss for batch 57 = 0.6542415022850037\n",
      "Loss for batch 58 = 0.6873234510421753\n",
      "Loss for batch 59 = 1.0769585371017456\n",
      "Loss for batch 60 = 1.0112429857254028\n",
      "Loss for batch 61 = 0.887749969959259\n",
      "Loss for batch 62 = 0.8670343160629272\n",
      "Loss for batch 63 = 0.9763011932373047\n",
      "Loss for batch 64 = 0.6428044438362122\n",
      "Loss for batch 65 = 0.8937976956367493\n",
      "Loss for batch 66 = 0.8983157873153687\n",
      "Loss for batch 67 = 0.9079964756965637\n",
      "Loss for batch 68 = 0.8383601903915405\n",
      "Loss for batch 69 = 0.9453049898147583\n",
      "Loss for batch 70 = 1.0505828857421875\n",
      "Loss for batch 71 = 0.8201362490653992\n",
      "Loss for batch 72 = 0.8791770339012146\n",
      "Loss for batch 73 = 0.9229507446289062\n",
      "Loss for batch 74 = 0.7861202955245972\n",
      "Loss for batch 75 = 0.8640068173408508\n",
      "Loss for batch 76 = 0.8982797265052795\n",
      "Loss for batch 77 = 0.7697932124137878\n",
      "Loss for batch 78 = 0.7645823955535889\n",
      "Loss for batch 79 = 0.8359767198562622\n",
      "Loss for batch 80 = 0.7352273464202881\n",
      "Loss for batch 81 = 0.92880779504776\n",
      "Loss for batch 82 = 1.003859519958496\n",
      "Loss for batch 83 = 0.9936710596084595\n",
      "Loss for batch 84 = 0.7790014743804932\n",
      "Loss for batch 85 = 0.7822819948196411\n",
      "Loss for batch 86 = 0.8079383969306946\n",
      "Loss for batch 87 = 0.8478831052780151\n",
      "Loss for batch 88 = 0.7495036125183105\n",
      "Loss for batch 89 = 0.8961698412895203\n",
      "Loss for batch 90 = 0.8809598088264465\n",
      "Loss for batch 91 = 0.8588317036628723\n",
      "Loss for batch 92 = 0.6789399981498718\n",
      "Loss for batch 93 = 0.9724372625350952\n",
      "Loss for batch 94 = 0.776609480381012\n",
      "Loss for batch 95 = 0.8576209545135498\n",
      "Loss for batch 96 = 0.986702024936676\n",
      "Loss for batch 97 = 0.8386617302894592\n",
      "\n",
      "Training Loss for epoch 8 = 85.2103271484375\n",
      "\n",
      "Current Validation Loss = 23.00428581237793\n",
      "Best Validation Loss = 23.00428581237793\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 64.60%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 9\n",
      "----------\n",
      "Loss for batch 0 = 0.7542614936828613\n",
      "Loss for batch 1 = 0.7294536828994751\n",
      "Loss for batch 2 = 0.7912993431091309\n",
      "Loss for batch 3 = 0.7272730469703674\n",
      "Loss for batch 4 = 0.8314031958580017\n",
      "Loss for batch 5 = 0.8250786662101746\n",
      "Loss for batch 6 = 0.7765859365463257\n",
      "Loss for batch 7 = 1.0437664985656738\n",
      "Loss for batch 8 = 0.7881726622581482\n",
      "Loss for batch 9 = 0.6412814855575562\n",
      "Loss for batch 10 = 0.8446033596992493\n",
      "Loss for batch 11 = 0.6925581693649292\n",
      "Loss for batch 12 = 0.7376840710639954\n",
      "Loss for batch 13 = 0.9972670078277588\n",
      "Loss for batch 14 = 0.7780519723892212\n",
      "Loss for batch 15 = 0.9793160557746887\n",
      "Loss for batch 16 = 0.7948850989341736\n",
      "Loss for batch 17 = 1.0346572399139404\n",
      "Loss for batch 18 = 0.8203914165496826\n",
      "Loss for batch 19 = 0.8579162359237671\n",
      "Loss for batch 20 = 0.6887232661247253\n",
      "Loss for batch 21 = 0.8591039180755615\n",
      "Loss for batch 22 = 0.8304005265235901\n",
      "Loss for batch 23 = 0.7292897701263428\n",
      "Loss for batch 24 = 0.8511167764663696\n",
      "Loss for batch 25 = 0.8204867839813232\n",
      "Loss for batch 26 = 0.9713495373725891\n",
      "Loss for batch 27 = 0.8621425032615662\n",
      "Loss for batch 28 = 0.8745036125183105\n",
      "Loss for batch 29 = 0.8910671472549438\n",
      "Loss for batch 30 = 0.9012613892555237\n",
      "Loss for batch 31 = 0.9685096740722656\n",
      "Loss for batch 32 = 0.7575002908706665\n",
      "Loss for batch 33 = 0.8443967700004578\n",
      "Loss for batch 34 = 0.8015172481536865\n",
      "Loss for batch 35 = 0.8545225858688354\n",
      "Loss for batch 36 = 0.9752097725868225\n",
      "Loss for batch 37 = 1.0115588903427124\n",
      "Loss for batch 38 = 1.0365715026855469\n",
      "Loss for batch 39 = 0.8140345811843872\n",
      "Loss for batch 40 = 0.8264006972312927\n",
      "Loss for batch 41 = 0.9376864433288574\n",
      "Loss for batch 42 = 0.7968456745147705\n",
      "Loss for batch 43 = 0.8424415588378906\n",
      "Loss for batch 44 = 0.8503775000572205\n",
      "Loss for batch 45 = 0.7986408472061157\n",
      "Loss for batch 46 = 0.926629900932312\n",
      "Loss for batch 47 = 0.9055729508399963\n",
      "Loss for batch 48 = 0.7899582982063293\n",
      "Loss for batch 49 = 0.8692337274551392\n",
      "Loss for batch 50 = 0.8850929737091064\n",
      "Loss for batch 51 = 0.8497529625892639\n",
      "Loss for batch 52 = 0.8046899437904358\n",
      "Loss for batch 53 = 0.8022803664207458\n",
      "Loss for batch 54 = 0.8126105070114136\n",
      "Loss for batch 55 = 0.9164316654205322\n",
      "Loss for batch 56 = 0.8992310762405396\n",
      "Loss for batch 57 = 0.6150188446044922\n",
      "Loss for batch 58 = 0.6444493532180786\n",
      "Loss for batch 59 = 1.085198163986206\n",
      "Loss for batch 60 = 0.8880375623703003\n",
      "Loss for batch 61 = 0.9782624244689941\n",
      "Loss for batch 62 = 0.8501397371292114\n",
      "Loss for batch 63 = 0.8606235980987549\n",
      "Loss for batch 64 = 0.6228428483009338\n",
      "Loss for batch 65 = 0.8638556599617004\n",
      "Loss for batch 66 = 0.871248185634613\n",
      "Loss for batch 67 = 0.8557051420211792\n",
      "Loss for batch 68 = 0.8570661544799805\n",
      "Loss for batch 69 = 0.8902291655540466\n",
      "Loss for batch 70 = 1.0494375228881836\n",
      "Loss for batch 71 = 0.7598631381988525\n",
      "Loss for batch 72 = 0.9035323262214661\n",
      "Loss for batch 73 = 0.8336546421051025\n",
      "Loss for batch 74 = 0.7582263946533203\n",
      "Loss for batch 75 = 0.9758116006851196\n",
      "Loss for batch 76 = 0.9399893283843994\n",
      "Loss for batch 77 = 0.9469137191772461\n",
      "Loss for batch 78 = 0.9317074418067932\n",
      "Loss for batch 79 = 0.9153093099594116\n",
      "Loss for batch 80 = 0.8791994452476501\n",
      "Loss for batch 81 = 1.0193562507629395\n",
      "Loss for batch 82 = 1.3182178735733032\n",
      "Loss for batch 83 = 1.2302751541137695\n",
      "Loss for batch 84 = 1.1095012426376343\n",
      "Loss for batch 85 = 1.109398603439331\n",
      "Loss for batch 86 = 1.1374716758728027\n",
      "Loss for batch 87 = 1.0948104858398438\n",
      "Loss for batch 88 = 1.0656214952468872\n",
      "Loss for batch 89 = 1.0802053213119507\n",
      "Loss for batch 90 = 1.1055424213409424\n",
      "Loss for batch 91 = 1.1340222358703613\n",
      "Loss for batch 92 = 1.0880107879638672\n",
      "Loss for batch 93 = 1.1074427366256714\n",
      "Loss for batch 94 = 1.0647395849227905\n",
      "Loss for batch 95 = 1.1054656505584717\n",
      "Loss for batch 96 = 1.0971423387527466\n",
      "Loss for batch 97 = 1.0917028188705444\n",
      "\n",
      "Training Loss for epoch 9 = 88.038330078125\n",
      "\n",
      "Current Validation Loss = 27.224151611328125\n",
      "Best Validation Loss = 23.00428581237793\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 36.97%\n",
      "Validation Accuracy: 35.94%\n",
      "\n",
      "Epoch 10\n",
      "----------\n",
      "Loss for batch 0 = 1.0884909629821777\n",
      "Loss for batch 1 = 1.0881457328796387\n",
      "Loss for batch 2 = 1.0915082693099976\n",
      "Loss for batch 3 = 1.078290581703186\n",
      "Loss for batch 4 = 1.0799559354782104\n",
      "Loss for batch 5 = 1.066540241241455\n",
      "Loss for batch 6 = 1.1100919246673584\n",
      "Loss for batch 7 = 1.0670920610427856\n",
      "Loss for batch 8 = 1.0661886930465698\n",
      "Loss for batch 9 = 1.0395596027374268\n",
      "Loss for batch 10 = 1.1816924810409546\n",
      "Loss for batch 11 = 1.069915771484375\n",
      "Loss for batch 12 = 1.0455983877182007\n",
      "Loss for batch 13 = 1.070259928703308\n",
      "Loss for batch 14 = 1.0396347045898438\n",
      "Loss for batch 15 = 1.025810956954956\n",
      "Loss for batch 16 = 1.0284899473190308\n",
      "Loss for batch 17 = 1.0525805950164795\n",
      "Loss for batch 18 = 1.00212562084198\n",
      "Loss for batch 19 = 1.1897146701812744\n",
      "Loss for batch 20 = 1.0023834705352783\n",
      "Loss for batch 21 = 1.038465142250061\n",
      "Loss for batch 22 = 1.0392735004425049\n",
      "Loss for batch 23 = 1.0351802110671997\n",
      "Loss for batch 24 = 1.0851006507873535\n",
      "Loss for batch 25 = 0.9972805976867676\n",
      "Loss for batch 26 = 1.0003631114959717\n",
      "Loss for batch 27 = 0.9627399444580078\n",
      "Loss for batch 28 = 1.1116423606872559\n",
      "Loss for batch 29 = 1.0141311883926392\n",
      "Loss for batch 30 = 1.080675721168518\n",
      "Loss for batch 31 = 1.060121774673462\n",
      "Loss for batch 32 = 0.9856600165367126\n",
      "Loss for batch 33 = 1.0479761362075806\n",
      "Loss for batch 34 = 0.9956016540527344\n",
      "Loss for batch 35 = 0.9358696937561035\n",
      "Loss for batch 36 = 1.0603679418563843\n",
      "Loss for batch 37 = 1.0134927034378052\n",
      "Loss for batch 38 = 1.0406383275985718\n",
      "Loss for batch 39 = 0.9668729901313782\n",
      "Loss for batch 40 = 0.9633722305297852\n",
      "Loss for batch 41 = 1.0562939643859863\n",
      "Loss for batch 42 = 0.9791735410690308\n",
      "Loss for batch 43 = 1.0048410892486572\n",
      "Loss for batch 44 = 0.9750618934631348\n",
      "Loss for batch 45 = 1.0293678045272827\n",
      "Loss for batch 46 = 1.005650520324707\n",
      "Loss for batch 47 = 1.013136625289917\n",
      "Loss for batch 48 = 0.92589271068573\n",
      "Loss for batch 49 = 1.0844320058822632\n",
      "Loss for batch 50 = 0.9936305284500122\n",
      "Loss for batch 51 = 0.9511207938194275\n",
      "Loss for batch 52 = 0.9446521401405334\n",
      "Loss for batch 53 = 0.9490957260131836\n",
      "Loss for batch 54 = 1.051975965499878\n",
      "Loss for batch 55 = 0.8991027474403381\n",
      "Loss for batch 56 = 1.0248533487319946\n",
      "Loss for batch 57 = 0.8505765795707703\n",
      "Loss for batch 58 = 0.8885208368301392\n",
      "Loss for batch 59 = 1.1519007682800293\n",
      "Loss for batch 60 = 1.0517990589141846\n",
      "Loss for batch 61 = 0.9967058897018433\n",
      "Loss for batch 62 = 0.9543312788009644\n",
      "Loss for batch 63 = 1.0133368968963623\n",
      "Loss for batch 64 = 0.916052520275116\n",
      "Loss for batch 65 = 0.9647839665412903\n",
      "Loss for batch 66 = 1.0196386575698853\n",
      "Loss for batch 67 = 0.8977129459381104\n",
      "Loss for batch 68 = 0.9915398955345154\n",
      "Loss for batch 69 = 1.0999633073806763\n",
      "Loss for batch 70 = 1.0963801145553589\n",
      "Loss for batch 71 = 0.8966143131256104\n",
      "Loss for batch 72 = 1.0381118059158325\n",
      "Loss for batch 73 = 1.0473419427871704\n",
      "Loss for batch 74 = 0.871019721031189\n",
      "Loss for batch 75 = 0.9765116572380066\n",
      "Loss for batch 76 = 0.8770344257354736\n",
      "Loss for batch 77 = 0.8830734491348267\n",
      "Loss for batch 78 = 0.9271863102912903\n",
      "Loss for batch 79 = 0.9399808645248413\n",
      "Loss for batch 80 = 1.062226414680481\n",
      "Loss for batch 81 = 0.946761965751648\n",
      "Loss for batch 82 = 1.0711886882781982\n",
      "Loss for batch 83 = 1.0421810150146484\n",
      "Loss for batch 84 = 0.9771633148193359\n",
      "Loss for batch 85 = 0.9427705407142639\n",
      "Loss for batch 86 = 1.0455204248428345\n",
      "Loss for batch 87 = 0.8565325736999512\n",
      "Loss for batch 88 = 0.8388875722885132\n",
      "Loss for batch 89 = 0.9511604309082031\n",
      "Loss for batch 90 = 1.021145224571228\n",
      "Loss for batch 91 = 0.927467942237854\n",
      "Loss for batch 92 = 0.7926356196403503\n",
      "Loss for batch 93 = 0.9485148787498474\n",
      "Loss for batch 94 = 0.9544597864151001\n",
      "Loss for batch 95 = 0.9099152088165283\n",
      "Loss for batch 96 = 1.019368290901184\n",
      "Loss for batch 97 = 0.8967239856719971\n",
      "\n",
      "Training Loss for epoch 10 = 98.36190795898438\n",
      "\n",
      "Current Validation Loss = 23.704082489013672\n",
      "Best Validation Loss = 23.00428581237793\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 59.98%\n",
      "Validation Accuracy: 57.00%\n",
      "\n",
      "Epoch 11\n",
      "----------\n",
      "Loss for batch 0 = 0.9309774041175842\n",
      "Loss for batch 1 = 0.921297013759613\n",
      "Loss for batch 2 = 0.9530083537101746\n",
      "Loss for batch 3 = 0.8194332122802734\n",
      "Loss for batch 4 = 0.9223280549049377\n",
      "Loss for batch 5 = 1.0169156789779663\n",
      "Loss for batch 6 = 0.8379749655723572\n",
      "Loss for batch 7 = 0.9585972428321838\n",
      "Loss for batch 8 = 0.7860591411590576\n",
      "Loss for batch 9 = 0.6883022785186768\n",
      "Loss for batch 10 = 1.0062997341156006\n",
      "Loss for batch 11 = 0.767988383769989\n",
      "Loss for batch 12 = 0.6618617177009583\n",
      "Loss for batch 13 = 0.9269412159919739\n",
      "Loss for batch 14 = 0.804745078086853\n",
      "Loss for batch 15 = 1.0299307107925415\n",
      "Loss for batch 16 = 0.9166166186332703\n",
      "Loss for batch 17 = 0.9966569542884827\n",
      "Loss for batch 18 = 0.7815157175064087\n",
      "Loss for batch 19 = 0.9536824226379395\n",
      "Loss for batch 20 = 0.8257786631584167\n",
      "Loss for batch 21 = 0.8744310736656189\n",
      "Loss for batch 22 = 0.8878800272941589\n",
      "Loss for batch 23 = 0.750671923160553\n",
      "Loss for batch 24 = 0.8519313335418701\n",
      "Loss for batch 25 = 0.8251527547836304\n",
      "Loss for batch 26 = 0.902300238609314\n",
      "Loss for batch 27 = 0.8356956243515015\n",
      "Loss for batch 28 = 1.0720731019973755\n",
      "Loss for batch 29 = 0.8107206225395203\n",
      "Loss for batch 30 = 0.9135683178901672\n",
      "Loss for batch 31 = 0.8990966081619263\n",
      "Loss for batch 32 = 0.8515465259552002\n",
      "Loss for batch 33 = 0.7961289286613464\n",
      "Loss for batch 34 = 0.7789273858070374\n",
      "Loss for batch 35 = 0.8097028732299805\n",
      "Loss for batch 36 = 0.9736937880516052\n",
      "Loss for batch 37 = 1.0012682676315308\n",
      "Loss for batch 38 = 0.946855366230011\n",
      "Loss for batch 39 = 0.9519111514091492\n",
      "Loss for batch 40 = 0.9597630500793457\n",
      "Loss for batch 41 = 0.9453672766685486\n",
      "Loss for batch 42 = 0.9050720930099487\n",
      "Loss for batch 43 = 0.9663313627243042\n",
      "Loss for batch 44 = 0.9050531983375549\n",
      "Loss for batch 45 = 1.0054925680160522\n",
      "Loss for batch 46 = 0.8866183161735535\n",
      "Loss for batch 47 = 0.984492838382721\n",
      "Loss for batch 48 = 0.7867178916931152\n",
      "Loss for batch 49 = 0.8734352588653564\n",
      "Loss for batch 50 = 0.9490191340446472\n",
      "Loss for batch 51 = 0.8659821152687073\n",
      "Loss for batch 52 = 0.7945783734321594\n",
      "Loss for batch 53 = 0.7791833281517029\n",
      "Loss for batch 54 = 0.9270985722541809\n",
      "Loss for batch 55 = 0.8634423613548279\n",
      "Loss for batch 56 = 0.9390063881874084\n",
      "Loss for batch 57 = 0.7172585725784302\n",
      "Loss for batch 58 = 0.7549320459365845\n",
      "Loss for batch 59 = 1.0160574913024902\n",
      "Loss for batch 60 = 0.9563548564910889\n",
      "Loss for batch 61 = 0.9101037979125977\n",
      "Loss for batch 62 = 0.8550848960876465\n",
      "Loss for batch 63 = 0.8852518200874329\n",
      "Loss for batch 64 = 0.682704508304596\n",
      "Loss for batch 65 = 0.8869971036911011\n",
      "Loss for batch 66 = 0.9329663515090942\n",
      "Loss for batch 67 = 0.8134176135063171\n",
      "Loss for batch 68 = 1.0078476667404175\n",
      "Loss for batch 69 = 1.052581787109375\n",
      "Loss for batch 70 = 1.009753942489624\n",
      "Loss for batch 71 = 0.7596220970153809\n",
      "Loss for batch 72 = 0.8693339824676514\n",
      "Loss for batch 73 = 0.7730068564414978\n",
      "Loss for batch 74 = 0.7158722877502441\n",
      "Loss for batch 75 = 1.0019454956054688\n",
      "Loss for batch 76 = 0.8475000858306885\n",
      "Loss for batch 77 = 0.8311626315116882\n",
      "Loss for batch 78 = 0.689100444316864\n",
      "Loss for batch 79 = 0.9307921528816223\n",
      "Loss for batch 80 = 0.9147357940673828\n",
      "Loss for batch 81 = 0.8985783457756042\n",
      "Loss for batch 82 = 0.9822579026222229\n",
      "Loss for batch 83 = 1.0755834579467773\n",
      "Loss for batch 84 = 0.7425362467765808\n",
      "Loss for batch 85 = 0.872286319732666\n",
      "Loss for batch 86 = 0.8623732924461365\n",
      "Loss for batch 87 = 0.7281241416931152\n",
      "Loss for batch 88 = 0.7723650932312012\n",
      "Loss for batch 89 = 0.895167350769043\n",
      "Loss for batch 90 = 0.861130952835083\n",
      "Loss for batch 91 = 0.8528739213943481\n",
      "Loss for batch 92 = 0.8009055256843567\n",
      "Loss for batch 93 = 0.9067230224609375\n",
      "Loss for batch 94 = 0.8887881636619568\n",
      "Loss for batch 95 = 0.8376970887184143\n",
      "Loss for batch 96 = 1.2110824584960938\n",
      "Loss for batch 97 = 1.0752460956573486\n",
      "\n",
      "Training Loss for epoch 11 = 86.65522003173828\n",
      "\n",
      "Current Validation Loss = 24.28004264831543\n",
      "Best Validation Loss = 23.00428581237793\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 56.51%\n",
      "Validation Accuracy: 55.58%\n",
      "\n",
      "Epoch 12\n",
      "----------\n",
      "Loss for batch 0 = 0.8668938279151917\n",
      "Loss for batch 1 = 0.9209147691726685\n",
      "Loss for batch 2 = 0.9274898171424866\n",
      "Loss for batch 3 = 0.8337504863739014\n",
      "Loss for batch 4 = 0.857811450958252\n",
      "Loss for batch 5 = 0.876057505607605\n",
      "Loss for batch 6 = 0.8069712519645691\n",
      "Loss for batch 7 = 0.903752326965332\n",
      "Loss for batch 8 = 0.8670966625213623\n",
      "Loss for batch 9 = 0.7606226205825806\n",
      "Loss for batch 10 = 0.9842091202735901\n",
      "Loss for batch 11 = 0.8357325792312622\n",
      "Loss for batch 12 = 0.7315064668655396\n",
      "Loss for batch 13 = 0.8599843978881836\n",
      "Loss for batch 14 = 0.8057565093040466\n",
      "Loss for batch 15 = 0.8396305441856384\n",
      "Loss for batch 16 = 0.8622984290122986\n",
      "Loss for batch 17 = 0.9820985198020935\n",
      "Loss for batch 18 = 0.8998761177062988\n",
      "Loss for batch 19 = 0.9756972193717957\n",
      "Loss for batch 20 = 0.7072049975395203\n",
      "Loss for batch 21 = 0.8534712195396423\n",
      "Loss for batch 22 = 0.8277058601379395\n",
      "Loss for batch 23 = 0.7604889273643494\n",
      "Loss for batch 24 = 0.7916319370269775\n",
      "Loss for batch 25 = 0.8536831140518188\n",
      "Loss for batch 26 = 0.9033815264701843\n",
      "Loss for batch 27 = 0.8118272423744202\n",
      "Loss for batch 28 = 0.9369511604309082\n",
      "Loss for batch 29 = 0.7281997203826904\n",
      "Loss for batch 30 = 0.8977695107460022\n",
      "Loss for batch 31 = 0.7941797375679016\n",
      "Loss for batch 32 = 0.6974601745605469\n",
      "Loss for batch 33 = 0.7735740542411804\n",
      "Loss for batch 34 = 0.884304404258728\n",
      "Loss for batch 35 = 0.9276304841041565\n",
      "Loss for batch 36 = 0.8750190138816833\n",
      "Loss for batch 37 = 1.0092899799346924\n",
      "Loss for batch 38 = 0.9553583264350891\n",
      "Loss for batch 39 = 0.8962851762771606\n",
      "Loss for batch 40 = 0.8893721103668213\n",
      "Loss for batch 41 = 0.9230347871780396\n",
      "Loss for batch 42 = 0.9301552176475525\n",
      "Loss for batch 43 = 0.9290933012962341\n",
      "Loss for batch 44 = 0.9362742304801941\n",
      "Loss for batch 45 = 0.9113349914550781\n",
      "Loss for batch 46 = 0.835607647895813\n",
      "Loss for batch 47 = 1.0368828773498535\n",
      "Loss for batch 48 = 0.7989077568054199\n",
      "Loss for batch 49 = 0.9400716423988342\n",
      "Loss for batch 50 = 0.9189401865005493\n",
      "Loss for batch 51 = 0.7979955077171326\n",
      "Loss for batch 52 = 0.791130781173706\n",
      "Loss for batch 53 = 0.7452713251113892\n",
      "Loss for batch 54 = 0.8316831588745117\n",
      "Loss for batch 55 = 0.858349621295929\n",
      "Loss for batch 56 = 0.8415642380714417\n",
      "Loss for batch 57 = 0.6314975619316101\n",
      "Loss for batch 58 = 0.7424740195274353\n",
      "Loss for batch 59 = 1.0110293626785278\n",
      "Loss for batch 60 = 0.9153506755828857\n",
      "Loss for batch 61 = 0.9704243540763855\n",
      "Loss for batch 62 = 0.7982755303382874\n",
      "Loss for batch 63 = 0.873195230960846\n",
      "Loss for batch 64 = 0.7056392431259155\n",
      "Loss for batch 65 = 0.8925270438194275\n",
      "Loss for batch 66 = 0.9192259907722473\n",
      "Loss for batch 67 = 0.8634200692176819\n",
      "Loss for batch 68 = 0.8332311511039734\n",
      "Loss for batch 69 = 0.8565176725387573\n",
      "Loss for batch 70 = 0.9343783855438232\n",
      "Loss for batch 71 = 0.7501718997955322\n",
      "Loss for batch 72 = 0.8252490758895874\n",
      "Loss for batch 73 = 0.784329354763031\n",
      "Loss for batch 74 = 0.6695345044136047\n",
      "Loss for batch 75 = 0.7800043821334839\n",
      "Loss for batch 76 = 0.8730284571647644\n",
      "Loss for batch 77 = 0.6707900762557983\n",
      "Loss for batch 78 = 0.7555643916130066\n",
      "Loss for batch 79 = 0.9128496050834656\n",
      "Loss for batch 80 = 0.7387670278549194\n",
      "Loss for batch 81 = 0.9641219973564148\n",
      "Loss for batch 82 = 0.9800863862037659\n",
      "Loss for batch 83 = 0.9478988647460938\n",
      "Loss for batch 84 = 0.7560549378395081\n",
      "Loss for batch 85 = 0.745341420173645\n",
      "Loss for batch 86 = 0.7377869486808777\n",
      "Loss for batch 87 = 0.6931759715080261\n",
      "Loss for batch 88 = 0.7779466509819031\n",
      "Loss for batch 89 = 0.765623927116394\n",
      "Loss for batch 90 = 0.7970901727676392\n",
      "Loss for batch 91 = 0.7833767533302307\n",
      "Loss for batch 92 = 0.7574611306190491\n",
      "Loss for batch 93 = 0.890308678150177\n",
      "Loss for batch 94 = 0.7611904740333557\n",
      "Loss for batch 95 = 0.7675631046295166\n",
      "Loss for batch 96 = 0.9279540777206421\n",
      "Loss for batch 97 = 0.7954465746879578\n",
      "\n",
      "Training Loss for epoch 12 = 82.75515747070312\n",
      "\n",
      "Current Validation Loss = 22.252771377563477\n",
      "Best Validation Loss = 22.252771377563477\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 66.05%\n",
      "Validation Accuracy: 60.33%\n",
      "\n",
      "Epoch 13\n",
      "----------\n",
      "Loss for batch 0 = 0.7178154587745667\n",
      "Loss for batch 1 = 0.7437931895256042\n",
      "Loss for batch 2 = 0.8448969721794128\n",
      "Loss for batch 3 = 0.6748653650283813\n",
      "Loss for batch 4 = 0.7818664908409119\n",
      "Loss for batch 5 = 0.7312816381454468\n",
      "Loss for batch 6 = 0.8220361471176147\n",
      "Loss for batch 7 = 0.8373533487319946\n",
      "Loss for batch 8 = 0.6972756385803223\n",
      "Loss for batch 9 = 0.5937052965164185\n",
      "Loss for batch 10 = 0.9293034672737122\n",
      "Loss for batch 11 = 0.5797945857048035\n",
      "Loss for batch 12 = 0.6570355296134949\n",
      "Loss for batch 13 = 0.8295990824699402\n",
      "Loss for batch 14 = 0.7538635730743408\n",
      "Loss for batch 15 = 0.8368744254112244\n",
      "Loss for batch 16 = 0.7002716064453125\n",
      "Loss for batch 17 = 0.8903250098228455\n",
      "Loss for batch 18 = 0.6881809830665588\n",
      "Loss for batch 19 = 0.6589958071708679\n",
      "Loss for batch 20 = 0.6873449087142944\n",
      "Loss for batch 21 = 0.8054434061050415\n",
      "Loss for batch 22 = 0.6531049013137817\n",
      "Loss for batch 23 = 0.6653047800064087\n",
      "Loss for batch 24 = 0.74843829870224\n",
      "Loss for batch 25 = 0.989726185798645\n",
      "Loss for batch 26 = 0.7915581464767456\n",
      "Loss for batch 27 = 0.8528652191162109\n",
      "Loss for batch 28 = 0.7847728729248047\n",
      "Loss for batch 29 = 0.7127149701118469\n",
      "Loss for batch 30 = 0.928428590297699\n",
      "Loss for batch 31 = 0.8540512919425964\n",
      "Loss for batch 32 = 0.6689290404319763\n",
      "Loss for batch 33 = 0.7568875551223755\n",
      "Loss for batch 34 = 0.7969188094139099\n",
      "Loss for batch 35 = 0.8104885816574097\n",
      "Loss for batch 36 = 0.8544588685035706\n",
      "Loss for batch 37 = 0.9466471076011658\n",
      "Loss for batch 38 = 0.8535547256469727\n",
      "Loss for batch 39 = 0.8589552044868469\n",
      "Loss for batch 40 = 0.879421591758728\n",
      "Loss for batch 41 = 0.8947275280952454\n",
      "Loss for batch 42 = 0.8089106678962708\n",
      "Loss for batch 43 = 0.8397714495658875\n",
      "Loss for batch 44 = 0.8732439279556274\n",
      "Loss for batch 45 = 0.7733014225959778\n",
      "Loss for batch 46 = 0.8353008031845093\n",
      "Loss for batch 47 = 1.0109848976135254\n",
      "Loss for batch 48 = 0.7835226655006409\n",
      "Loss for batch 49 = 0.8792819976806641\n",
      "Loss for batch 50 = 0.8823223114013672\n",
      "Loss for batch 51 = 0.7210296392440796\n",
      "Loss for batch 52 = 0.6779688000679016\n",
      "Loss for batch 53 = 0.621428370475769\n",
      "Loss for batch 54 = 0.7703925967216492\n",
      "Loss for batch 55 = 0.7541546821594238\n",
      "Loss for batch 56 = 0.722275972366333\n",
      "Loss for batch 57 = 0.582028329372406\n",
      "Loss for batch 58 = 0.629716157913208\n",
      "Loss for batch 59 = 1.0323954820632935\n",
      "Loss for batch 60 = 0.8361024856567383\n",
      "Loss for batch 61 = 0.9133341908454895\n",
      "Loss for batch 62 = 0.8110772967338562\n",
      "Loss for batch 63 = 0.799924373626709\n",
      "Loss for batch 64 = 0.6335176825523376\n",
      "Loss for batch 65 = 0.8187713623046875\n",
      "Loss for batch 66 = 0.8801600337028503\n",
      "Loss for batch 67 = 0.8758803009986877\n",
      "Loss for batch 68 = 0.7715557217597961\n",
      "Loss for batch 69 = 0.7793885469436646\n",
      "Loss for batch 70 = 0.9175035953521729\n",
      "Loss for batch 71 = 0.7021328210830688\n",
      "Loss for batch 72 = 0.7800028324127197\n",
      "Loss for batch 73 = 0.7383642196655273\n",
      "Loss for batch 74 = 0.5815948247909546\n",
      "Loss for batch 75 = 0.7909485101699829\n",
      "Loss for batch 76 = 0.8310775756835938\n",
      "Loss for batch 77 = 0.7274919152259827\n",
      "Loss for batch 78 = 0.661555826663971\n",
      "Loss for batch 79 = 0.7779011130332947\n",
      "Loss for batch 80 = 0.7395163774490356\n",
      "Loss for batch 81 = 0.8341505527496338\n",
      "Loss for batch 82 = 0.9110085368156433\n",
      "Loss for batch 83 = 0.9330459237098694\n",
      "Loss for batch 84 = 0.7400973439216614\n",
      "Loss for batch 85 = 0.689712405204773\n",
      "Loss for batch 86 = 0.7118412256240845\n",
      "Loss for batch 87 = 0.6810523867607117\n",
      "Loss for batch 88 = 0.7096320986747742\n",
      "Loss for batch 89 = 0.7489182949066162\n",
      "Loss for batch 90 = 0.7871177792549133\n",
      "Loss for batch 91 = 0.8112512826919556\n",
      "Loss for batch 92 = 0.6604207754135132\n",
      "Loss for batch 93 = 0.87090003490448\n",
      "Loss for batch 94 = 0.7106781601905823\n",
      "Loss for batch 95 = 0.6973514556884766\n",
      "Loss for batch 96 = 0.9043794870376587\n",
      "Loss for batch 97 = 0.8102884888648987\n",
      "\n",
      "Training Loss for epoch 13 = 76.54154968261719\n",
      "\n",
      "Current Validation Loss = 21.867822647094727\n",
      "Best Validation Loss = 21.867822647094727\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 69.48%\n",
      "Validation Accuracy: 61.49%\n",
      "\n",
      "Epoch 14\n",
      "----------\n",
      "Loss for batch 0 = 0.5933773517608643\n",
      "Loss for batch 1 = 0.7442811131477356\n",
      "Loss for batch 2 = 0.7712383270263672\n",
      "Loss for batch 3 = 0.691358208656311\n",
      "Loss for batch 4 = 0.7318946719169617\n",
      "Loss for batch 5 = 0.6689247488975525\n",
      "Loss for batch 6 = 0.7454988956451416\n",
      "Loss for batch 7 = 0.8085871338844299\n",
      "Loss for batch 8 = 0.704258918762207\n",
      "Loss for batch 9 = 0.5474681854248047\n",
      "Loss for batch 10 = 0.9161545634269714\n",
      "Loss for batch 11 = 0.5406710505485535\n",
      "Loss for batch 12 = 0.6502719521522522\n",
      "Loss for batch 13 = 0.7434836626052856\n",
      "Loss for batch 14 = 0.738370418548584\n",
      "Loss for batch 15 = 0.7972086668014526\n",
      "Loss for batch 16 = 0.6529592275619507\n",
      "Loss for batch 17 = 0.8569037318229675\n",
      "Loss for batch 18 = 0.6653846502304077\n",
      "Loss for batch 19 = 0.6589263677597046\n",
      "Loss for batch 20 = 0.6412768363952637\n",
      "Loss for batch 21 = 0.7820197343826294\n",
      "Loss for batch 22 = 0.6108370423316956\n",
      "Loss for batch 23 = 0.6133038401603699\n",
      "Loss for batch 24 = 0.7195054888725281\n",
      "Loss for batch 25 = 0.8416919708251953\n",
      "Loss for batch 26 = 0.7770707607269287\n",
      "Loss for batch 27 = 0.78469318151474\n",
      "Loss for batch 28 = 0.7131876945495605\n",
      "Loss for batch 29 = 0.6892121434211731\n",
      "Loss for batch 30 = 0.8555597066879272\n",
      "Loss for batch 31 = 0.8273402452468872\n",
      "Loss for batch 32 = 0.6825181841850281\n",
      "Loss for batch 33 = 0.7309949994087219\n",
      "Loss for batch 34 = 0.7217488884925842\n",
      "Loss for batch 35 = 0.7705076336860657\n",
      "Loss for batch 36 = 0.7852277159690857\n",
      "Loss for batch 37 = 0.8950591683387756\n",
      "Loss for batch 38 = 0.7694041728973389\n",
      "Loss for batch 39 = 0.8902013301849365\n",
      "Loss for batch 40 = 0.8292352557182312\n",
      "Loss for batch 41 = 0.8575878143310547\n",
      "Loss for batch 42 = 0.8315911889076233\n",
      "Loss for batch 43 = 0.7919707894325256\n",
      "Loss for batch 44 = 0.8591553568840027\n",
      "Loss for batch 45 = 0.7176327109336853\n",
      "Loss for batch 46 = 0.7967738509178162\n",
      "Loss for batch 47 = 0.9841195940971375\n",
      "Loss for batch 48 = 0.7904875874519348\n",
      "Loss for batch 49 = 0.848336935043335\n",
      "Loss for batch 50 = 0.7911782264709473\n",
      "Loss for batch 51 = 0.6708562970161438\n",
      "Loss for batch 52 = 0.6337988972663879\n",
      "Loss for batch 53 = 0.5723757147789001\n",
      "Loss for batch 54 = 0.6441037654876709\n",
      "Loss for batch 55 = 0.710691511631012\n",
      "Loss for batch 56 = 0.6548395156860352\n",
      "Loss for batch 57 = 0.5863298773765564\n",
      "Loss for batch 58 = 0.6018939018249512\n",
      "Loss for batch 59 = 0.9829638600349426\n",
      "Loss for batch 60 = 0.8220465183258057\n",
      "Loss for batch 61 = 0.9259044528007507\n",
      "Loss for batch 62 = 0.8039321303367615\n",
      "Loss for batch 63 = 0.7446445822715759\n",
      "Loss for batch 64 = 0.6190125942230225\n",
      "Loss for batch 65 = 0.7563696503639221\n",
      "Loss for batch 66 = 0.7921574115753174\n",
      "Loss for batch 67 = 0.9150118827819824\n",
      "Loss for batch 68 = 0.7348688840866089\n",
      "Loss for batch 69 = 0.7642396688461304\n",
      "Loss for batch 70 = 0.9063770174980164\n",
      "Loss for batch 71 = 0.6794357299804688\n",
      "Loss for batch 72 = 0.6670102477073669\n",
      "Loss for batch 73 = 0.6893326044082642\n",
      "Loss for batch 74 = 0.5235223174095154\n",
      "Loss for batch 75 = 0.7819873690605164\n",
      "Loss for batch 76 = 0.8067350387573242\n",
      "Loss for batch 77 = 0.6550089716911316\n",
      "Loss for batch 78 = 0.5669108033180237\n",
      "Loss for batch 79 = 0.7115530371665955\n",
      "Loss for batch 80 = 0.6747365593910217\n",
      "Loss for batch 81 = 0.915194034576416\n",
      "Loss for batch 82 = 0.8946729302406311\n",
      "Loss for batch 83 = 0.928663432598114\n",
      "Loss for batch 84 = 0.6817993521690369\n",
      "Loss for batch 85 = 0.6647254824638367\n",
      "Loss for batch 86 = 0.6981096863746643\n",
      "Loss for batch 87 = 0.6806744933128357\n",
      "Loss for batch 88 = 0.6860126256942749\n",
      "Loss for batch 89 = 0.692099392414093\n",
      "Loss for batch 90 = 0.7738495469093323\n",
      "Loss for batch 91 = 0.7806540131568909\n",
      "Loss for batch 92 = 0.6232903599739075\n",
      "Loss for batch 93 = 0.8554039001464844\n",
      "Loss for batch 94 = 0.6531324982643127\n",
      "Loss for batch 95 = 0.6143785715103149\n",
      "Loss for batch 96 = 0.9043042063713074\n",
      "Loss for batch 97 = 0.8351245522499084\n",
      "\n",
      "Training Loss for epoch 14 = 72.90738677978516\n",
      "\n",
      "Current Validation Loss = 21.759511947631836\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 71.18%\n",
      "Validation Accuracy: 62.00%\n",
      "\n",
      "Epoch 15\n",
      "----------\n",
      "Loss for batch 0 = 0.5543472766876221\n",
      "Loss for batch 1 = 0.6474127769470215\n",
      "Loss for batch 2 = 0.6928723454475403\n",
      "Loss for batch 3 = 0.6412011384963989\n",
      "Loss for batch 4 = 0.7213293313980103\n",
      "Loss for batch 5 = 0.6664036512374878\n",
      "Loss for batch 6 = 0.6841748952865601\n",
      "Loss for batch 7 = 0.7517462968826294\n",
      "Loss for batch 8 = 0.6567095518112183\n",
      "Loss for batch 9 = 0.513283371925354\n",
      "Loss for batch 10 = 0.8694922924041748\n",
      "Loss for batch 11 = 0.4953778386116028\n",
      "Loss for batch 12 = 0.598755419254303\n",
      "Loss for batch 13 = 0.695156455039978\n",
      "Loss for batch 14 = 0.7454433441162109\n",
      "Loss for batch 15 = 0.7984252572059631\n",
      "Loss for batch 16 = 0.6013531684875488\n",
      "Loss for batch 17 = 0.7629094123840332\n",
      "Loss for batch 18 = 0.6372475028038025\n",
      "Loss for batch 19 = 0.6177547574043274\n",
      "Loss for batch 20 = 0.6133527159690857\n",
      "Loss for batch 21 = 0.7043156027793884\n",
      "Loss for batch 22 = 0.5837913155555725\n",
      "Loss for batch 23 = 0.6057106256484985\n",
      "Loss for batch 24 = 0.6633491516113281\n",
      "Loss for batch 25 = 0.7177078723907471\n",
      "Loss for batch 26 = 0.7317337989807129\n",
      "Loss for batch 27 = 0.7425550222396851\n",
      "Loss for batch 28 = 0.7083382606506348\n",
      "Loss for batch 29 = 0.6501680016517639\n",
      "Loss for batch 30 = 0.7234027981758118\n",
      "Loss for batch 31 = 0.6888606548309326\n",
      "Loss for batch 32 = 0.65074223279953\n",
      "Loss for batch 33 = 0.6727917194366455\n",
      "Loss for batch 34 = 0.695081353187561\n",
      "Loss for batch 35 = 0.7605123519897461\n",
      "Loss for batch 36 = 0.7797114849090576\n",
      "Loss for batch 37 = 0.8780571222305298\n",
      "Loss for batch 38 = 0.6827747225761414\n",
      "Loss for batch 39 = 0.8931832909584045\n",
      "Loss for batch 40 = 0.7798474431037903\n",
      "Loss for batch 41 = 0.7647632360458374\n",
      "Loss for batch 42 = 0.7584769129753113\n",
      "Loss for batch 43 = 0.8115803599357605\n",
      "Loss for batch 44 = 0.8279715776443481\n",
      "Loss for batch 45 = 0.6355161666870117\n",
      "Loss for batch 46 = 0.800872266292572\n",
      "Loss for batch 47 = 0.8985178470611572\n",
      "Loss for batch 48 = 0.7735468745231628\n",
      "Loss for batch 49 = 0.8089502453804016\n",
      "Loss for batch 50 = 0.7739331126213074\n",
      "Loss for batch 51 = 0.6333639025688171\n",
      "Loss for batch 52 = 0.6162879467010498\n",
      "Loss for batch 53 = 0.5455098152160645\n",
      "Loss for batch 54 = 0.7103300094604492\n",
      "Loss for batch 55 = 0.6764011383056641\n",
      "Loss for batch 56 = 0.6481842994689941\n",
      "Loss for batch 57 = 0.5358520150184631\n",
      "Loss for batch 58 = 0.5932101011276245\n",
      "Loss for batch 59 = 0.9414146542549133\n",
      "Loss for batch 60 = 0.7434125542640686\n",
      "Loss for batch 61 = 0.9172581434249878\n",
      "Loss for batch 62 = 0.7427178025245667\n",
      "Loss for batch 63 = 0.7438058257102966\n",
      "Loss for batch 64 = 0.5590788125991821\n",
      "Loss for batch 65 = 0.7333865165710449\n",
      "Loss for batch 66 = 0.7446597218513489\n",
      "Loss for batch 67 = 0.8959093689918518\n",
      "Loss for batch 68 = 0.6963515877723694\n",
      "Loss for batch 69 = 0.7455307245254517\n",
      "Loss for batch 70 = 0.8567054271697998\n",
      "Loss for batch 71 = 0.6629653573036194\n",
      "Loss for batch 72 = 0.618130624294281\n",
      "Loss for batch 73 = 0.6790332198143005\n",
      "Loss for batch 74 = 0.49381521344184875\n",
      "Loss for batch 75 = 0.7980790734291077\n",
      "Loss for batch 76 = 0.7487159371376038\n",
      "Loss for batch 77 = 0.6457479000091553\n",
      "Loss for batch 78 = 0.5606372356414795\n",
      "Loss for batch 79 = 0.6954841613769531\n",
      "Loss for batch 80 = 0.6456763744354248\n",
      "Loss for batch 81 = 0.8913782238960266\n",
      "Loss for batch 82 = 0.8450114727020264\n",
      "Loss for batch 83 = 0.8535658717155457\n",
      "Loss for batch 84 = 0.6472076177597046\n",
      "Loss for batch 85 = 0.6000142693519592\n",
      "Loss for batch 86 = 0.618135392665863\n",
      "Loss for batch 87 = 0.6266257762908936\n",
      "Loss for batch 88 = 0.6655697226524353\n",
      "Loss for batch 89 = 0.6428099870681763\n",
      "Loss for batch 90 = 0.7658856511116028\n",
      "Loss for batch 91 = 0.7739304900169373\n",
      "Loss for batch 92 = 0.5770255327224731\n",
      "Loss for batch 93 = 0.8273068070411682\n",
      "Loss for batch 94 = 0.6197184920310974\n",
      "Loss for batch 95 = 0.584568440914154\n",
      "Loss for batch 96 = 0.9144115447998047\n",
      "Loss for batch 97 = 0.8588263392448425\n",
      "\n",
      "Training Loss for epoch 15 = 69.27116394042969\n",
      "\n",
      "Current Validation Loss = 21.918750762939453\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 72.02%\n",
      "Validation Accuracy: 62.13%\n",
      "\n",
      "Epoch 16\n",
      "----------\n",
      "Loss for batch 0 = 0.5402945876121521\n",
      "Loss for batch 1 = 0.6222347617149353\n",
      "Loss for batch 2 = 0.6616169810295105\n",
      "Loss for batch 3 = 0.6261202096939087\n",
      "Loss for batch 4 = 0.6663177609443665\n",
      "Loss for batch 5 = 0.5933305025100708\n",
      "Loss for batch 6 = 0.6584881544113159\n",
      "Loss for batch 7 = 0.7257224321365356\n",
      "Loss for batch 8 = 0.689577043056488\n",
      "Loss for batch 9 = 0.4864097535610199\n",
      "Loss for batch 10 = 0.853349506855011\n",
      "Loss for batch 11 = 0.45631474256515503\n",
      "Loss for batch 12 = 0.59685218334198\n",
      "Loss for batch 13 = 0.6290100812911987\n",
      "Loss for batch 14 = 0.7045097351074219\n",
      "Loss for batch 15 = 0.7934422492980957\n",
      "Loss for batch 16 = 0.6350979804992676\n",
      "Loss for batch 17 = 0.7408084273338318\n",
      "Loss for batch 18 = 0.6266330480575562\n",
      "Loss for batch 19 = 0.6188371777534485\n",
      "Loss for batch 20 = 0.5687780976295471\n",
      "Loss for batch 21 = 0.6609585881233215\n",
      "Loss for batch 22 = 0.5596581697463989\n",
      "Loss for batch 23 = 0.5251775979995728\n",
      "Loss for batch 24 = 0.6226476430892944\n",
      "Loss for batch 25 = 0.665865957736969\n",
      "Loss for batch 26 = 0.8061909675598145\n",
      "Loss for batch 27 = 0.7103962898254395\n",
      "Loss for batch 28 = 0.6520663499832153\n",
      "Loss for batch 29 = 0.6488909125328064\n",
      "Loss for batch 30 = 0.689810037612915\n",
      "Loss for batch 31 = 0.6473609209060669\n",
      "Loss for batch 32 = 0.6382526755332947\n",
      "Loss for batch 33 = 0.6407564282417297\n",
      "Loss for batch 34 = 0.6300787925720215\n",
      "Loss for batch 35 = 0.712478518486023\n",
      "Loss for batch 36 = 0.7514488101005554\n",
      "Loss for batch 37 = 0.8991525769233704\n",
      "Loss for batch 38 = 0.6325858235359192\n",
      "Loss for batch 39 = 0.770681619644165\n",
      "Loss for batch 40 = 0.728300929069519\n",
      "Loss for batch 41 = 0.7506027221679688\n",
      "Loss for batch 42 = 0.7543895244598389\n",
      "Loss for batch 43 = 0.7604202032089233\n",
      "Loss for batch 44 = 0.7748512625694275\n",
      "Loss for batch 45 = 0.5994083285331726\n",
      "Loss for batch 46 = 0.7397672533988953\n",
      "Loss for batch 47 = 0.8125714063644409\n",
      "Loss for batch 48 = 0.7247083187103271\n",
      "Loss for batch 49 = 0.7926433086395264\n",
      "Loss for batch 50 = 0.7710657119750977\n",
      "Loss for batch 51 = 0.5914708971977234\n",
      "Loss for batch 52 = 0.5503227710723877\n",
      "Loss for batch 53 = 0.5102093815803528\n",
      "Loss for batch 54 = 0.6685420870780945\n",
      "Loss for batch 55 = 0.6591968536376953\n",
      "Loss for batch 56 = 0.5963447690010071\n",
      "Loss for batch 57 = 0.5103409290313721\n",
      "Loss for batch 58 = 0.588279664516449\n",
      "Loss for batch 59 = 0.8753641843795776\n",
      "Loss for batch 60 = 0.7395483255386353\n",
      "Loss for batch 61 = 0.9667344093322754\n",
      "Loss for batch 62 = 0.7532643675804138\n",
      "Loss for batch 63 = 0.7005002498626709\n",
      "Loss for batch 64 = 0.5168062448501587\n",
      "Loss for batch 65 = 0.6933794021606445\n",
      "Loss for batch 66 = 0.7538456320762634\n",
      "Loss for batch 67 = 0.9009667634963989\n",
      "Loss for batch 68 = 0.6850562691688538\n",
      "Loss for batch 69 = 0.7104249000549316\n",
      "Loss for batch 70 = 0.8458729386329651\n",
      "Loss for batch 71 = 0.6350098848342896\n",
      "Loss for batch 72 = 0.5814456343650818\n",
      "Loss for batch 73 = 0.6658165454864502\n",
      "Loss for batch 74 = 0.5013968348503113\n",
      "Loss for batch 75 = 0.7738940119743347\n",
      "Loss for batch 76 = 0.7453206777572632\n",
      "Loss for batch 77 = 0.6246519684791565\n",
      "Loss for batch 78 = 0.5252451300621033\n",
      "Loss for batch 79 = 0.6729114651679993\n",
      "Loss for batch 80 = 0.6099640130996704\n",
      "Loss for batch 81 = 0.8544304966926575\n",
      "Loss for batch 82 = 0.7825060486793518\n",
      "Loss for batch 83 = 0.7924496531486511\n",
      "Loss for batch 84 = 0.6235156059265137\n",
      "Loss for batch 85 = 0.619640052318573\n",
      "Loss for batch 86 = 0.4712861180305481\n",
      "Loss for batch 87 = 0.5542714595794678\n",
      "Loss for batch 88 = 0.6168805360794067\n",
      "Loss for batch 89 = 0.6453127861022949\n",
      "Loss for batch 90 = 0.768348753452301\n",
      "Loss for batch 91 = 0.7438090443611145\n",
      "Loss for batch 92 = 0.5665126442909241\n",
      "Loss for batch 93 = 0.8092696666717529\n",
      "Loss for batch 94 = 0.5832598805427551\n",
      "Loss for batch 95 = 0.5219392776489258\n",
      "Loss for batch 96 = 0.8503710627555847\n",
      "Loss for batch 97 = 0.7377145290374756\n",
      "\n",
      "Training Loss for epoch 16 = 66.26058959960938\n",
      "\n",
      "Current Validation Loss = 22.159093856811523\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 72.72%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 17\n",
      "----------\n",
      "Loss for batch 0 = 0.5323804020881653\n",
      "Loss for batch 1 = 0.6363480091094971\n",
      "Loss for batch 2 = 0.6268587112426758\n",
      "Loss for batch 3 = 0.6929230690002441\n",
      "Loss for batch 4 = 0.6265316605567932\n",
      "Loss for batch 5 = 0.5559177994728088\n",
      "Loss for batch 6 = 0.644840657711029\n",
      "Loss for batch 7 = 0.678467333316803\n",
      "Loss for batch 8 = 0.6516979932785034\n",
      "Loss for batch 9 = 0.4583825170993805\n",
      "Loss for batch 10 = 0.7700802087783813\n",
      "Loss for batch 11 = 0.43032902479171753\n",
      "Loss for batch 12 = 0.5555233955383301\n",
      "Loss for batch 13 = 0.6108529567718506\n",
      "Loss for batch 14 = 0.621216893196106\n",
      "Loss for batch 15 = 0.7160252928733826\n",
      "Loss for batch 16 = 0.583965539932251\n",
      "Loss for batch 17 = 0.6927157640457153\n",
      "Loss for batch 18 = 0.560438871383667\n",
      "Loss for batch 19 = 0.5826582908630371\n",
      "Loss for batch 20 = 0.4924951493740082\n",
      "Loss for batch 21 = 0.6216445565223694\n",
      "Loss for batch 22 = 0.5538185238838196\n",
      "Loss for batch 23 = 0.49131134152412415\n",
      "Loss for batch 24 = 0.5858171582221985\n",
      "Loss for batch 25 = 0.6148667931556702\n",
      "Loss for batch 26 = 0.7400826215744019\n",
      "Loss for batch 27 = 0.6761676669120789\n",
      "Loss for batch 28 = 0.6677694916725159\n",
      "Loss for batch 29 = 0.6205654740333557\n",
      "Loss for batch 30 = 0.690487265586853\n",
      "Loss for batch 31 = 0.5812771916389465\n",
      "Loss for batch 32 = 0.644888162612915\n",
      "Loss for batch 33 = 0.610885739326477\n",
      "Loss for batch 34 = 0.5956722497940063\n",
      "Loss for batch 35 = 0.6970536112785339\n",
      "Loss for batch 36 = 0.7099472284317017\n",
      "Loss for batch 37 = 0.8787426352500916\n",
      "Loss for batch 38 = 0.5869050621986389\n",
      "Loss for batch 39 = 0.7222381830215454\n",
      "Loss for batch 40 = 0.7080418467521667\n",
      "Loss for batch 41 = 0.644006609916687\n",
      "Loss for batch 42 = 0.6978647708892822\n",
      "Loss for batch 43 = 0.6857389211654663\n",
      "Loss for batch 44 = 0.7573412656784058\n",
      "Loss for batch 45 = 0.6106332540512085\n",
      "Loss for batch 46 = 0.7060866355895996\n",
      "Loss for batch 47 = 0.7866595387458801\n",
      "Loss for batch 48 = 0.6962311267852783\n",
      "Loss for batch 49 = 0.7574034333229065\n",
      "Loss for batch 50 = 0.6932774186134338\n",
      "Loss for batch 51 = 0.5823764204978943\n",
      "Loss for batch 52 = 0.5177625417709351\n",
      "Loss for batch 53 = 0.41368335485458374\n",
      "Loss for batch 54 = 0.6151596903800964\n",
      "Loss for batch 55 = 0.6393778920173645\n",
      "Loss for batch 56 = 0.534380316734314\n",
      "Loss for batch 57 = 0.501305341720581\n",
      "Loss for batch 58 = 0.5779442191123962\n",
      "Loss for batch 59 = 0.8121708035469055\n",
      "Loss for batch 60 = 0.6508700251579285\n",
      "Loss for batch 61 = 0.913573145866394\n",
      "Loss for batch 62 = 0.7524263858795166\n",
      "Loss for batch 63 = 0.6508566737174988\n",
      "Loss for batch 64 = 0.466475248336792\n",
      "Loss for batch 65 = 0.6100814342498779\n",
      "Loss for batch 66 = 0.6875833868980408\n",
      "Loss for batch 67 = 0.8487899303436279\n",
      "Loss for batch 68 = 0.6432002186775208\n",
      "Loss for batch 69 = 0.699840784072876\n",
      "Loss for batch 70 = 0.8504770398139954\n",
      "Loss for batch 71 = 0.6608723402023315\n",
      "Loss for batch 72 = 0.5663276314735413\n",
      "Loss for batch 73 = 0.7188199758529663\n",
      "Loss for batch 74 = 0.46618494391441345\n",
      "Loss for batch 75 = 0.8191286325454712\n",
      "Loss for batch 76 = 0.7005109190940857\n",
      "Loss for batch 77 = 0.6976293921470642\n",
      "Loss for batch 78 = 0.5249033570289612\n",
      "Loss for batch 79 = 0.6698174476623535\n",
      "Loss for batch 80 = 0.5363606810569763\n",
      "Loss for batch 81 = 0.8533380031585693\n",
      "Loss for batch 82 = 0.7280989289283752\n",
      "Loss for batch 83 = 0.7865442633628845\n",
      "Loss for batch 84 = 0.5748040080070496\n",
      "Loss for batch 85 = 0.5314887166023254\n",
      "Loss for batch 86 = 0.45508259534835815\n",
      "Loss for batch 87 = 0.5263907313346863\n",
      "Loss for batch 88 = 0.6555041670799255\n",
      "Loss for batch 89 = 0.6120899319648743\n",
      "Loss for batch 90 = 0.7290368676185608\n",
      "Loss for batch 91 = 0.7161452770233154\n",
      "Loss for batch 92 = 0.5569334626197815\n",
      "Loss for batch 93 = 0.7586384415626526\n",
      "Loss for batch 94 = 0.5512734651565552\n",
      "Loss for batch 95 = 0.47503623366355896\n",
      "Loss for batch 96 = 0.8578316569328308\n",
      "Loss for batch 97 = 0.656443178653717\n",
      "\n",
      "Training Loss for epoch 17 = 63.1076545715332\n",
      "\n",
      "Current Validation Loss = 23.069345474243164\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 74.33%\n",
      "Validation Accuracy: 61.62%\n",
      "\n",
      "Epoch 18\n",
      "----------\n",
      "Loss for batch 0 = 0.431983083486557\n",
      "Loss for batch 1 = 0.5769438743591309\n",
      "Loss for batch 2 = 0.5725355744361877\n",
      "Loss for batch 3 = 0.593326985836029\n",
      "Loss for batch 4 = 0.5776572227478027\n",
      "Loss for batch 5 = 0.545518159866333\n",
      "Loss for batch 6 = 0.635959267616272\n",
      "Loss for batch 7 = 0.6487511396408081\n",
      "Loss for batch 8 = 0.5890085101127625\n",
      "Loss for batch 9 = 0.4066982865333557\n",
      "Loss for batch 10 = 0.740854024887085\n",
      "Loss for batch 11 = 0.37904977798461914\n",
      "Loss for batch 12 = 0.5548045039176941\n",
      "Loss for batch 13 = 0.5422013998031616\n",
      "Loss for batch 14 = 0.6174910664558411\n",
      "Loss for batch 15 = 0.6450227499008179\n",
      "Loss for batch 16 = 0.4984765350818634\n",
      "Loss for batch 17 = 0.6028912663459778\n",
      "Loss for batch 18 = 0.5417644381523132\n",
      "Loss for batch 19 = 0.48491913080215454\n",
      "Loss for batch 20 = 0.4267062544822693\n",
      "Loss for batch 21 = 0.623365044593811\n",
      "Loss for batch 22 = 0.5310558080673218\n",
      "Loss for batch 23 = 0.4511457681655884\n",
      "Loss for batch 24 = 0.5518221855163574\n",
      "Loss for batch 25 = 0.5909603834152222\n",
      "Loss for batch 26 = 0.6850089430809021\n",
      "Loss for batch 27 = 0.6085860729217529\n",
      "Loss for batch 28 = 0.6996769905090332\n",
      "Loss for batch 29 = 0.6221285462379456\n",
      "Loss for batch 30 = 0.7195196151733398\n",
      "Loss for batch 31 = 0.5743839144706726\n",
      "Loss for batch 32 = 0.6258001327514648\n",
      "Loss for batch 33 = 0.5912157893180847\n",
      "Loss for batch 34 = 0.6666151881217957\n",
      "Loss for batch 35 = 0.6375508904457092\n",
      "Loss for batch 36 = 0.7053616642951965\n",
      "Loss for batch 37 = 0.8281732201576233\n",
      "Loss for batch 38 = 0.6541002988815308\n",
      "Loss for batch 39 = 0.6545528769493103\n",
      "Loss for batch 40 = 0.6887394189834595\n",
      "Loss for batch 41 = 0.6457516551017761\n",
      "Loss for batch 42 = 0.6462488174438477\n",
      "Loss for batch 43 = 0.6878774762153625\n",
      "Loss for batch 44 = 0.6815245747566223\n",
      "Loss for batch 45 = 0.6159543991088867\n",
      "Loss for batch 46 = 0.7204016447067261\n",
      "Loss for batch 47 = 0.7625424861907959\n",
      "Loss for batch 48 = 0.6197471022605896\n",
      "Loss for batch 49 = 0.687228798866272\n",
      "Loss for batch 50 = 0.6411799192428589\n",
      "Loss for batch 51 = 0.5658481121063232\n",
      "Loss for batch 52 = 0.49342915415763855\n",
      "Loss for batch 53 = 0.33535975217819214\n",
      "Loss for batch 54 = 0.7134085893630981\n",
      "Loss for batch 55 = 0.6326017379760742\n",
      "Loss for batch 56 = 0.5123072862625122\n",
      "Loss for batch 57 = 0.4845843017101288\n",
      "Loss for batch 58 = 0.5878116488456726\n",
      "Loss for batch 59 = 0.7922311425209045\n",
      "Loss for batch 60 = 0.6371026635169983\n",
      "Loss for batch 61 = 0.8938209414482117\n",
      "Loss for batch 62 = 0.7417264580726624\n",
      "Loss for batch 63 = 0.6631687879562378\n",
      "Loss for batch 64 = 0.41838717460632324\n",
      "Loss for batch 65 = 0.5608358979225159\n",
      "Loss for batch 66 = 0.6527675986289978\n",
      "Loss for batch 67 = 0.7961386442184448\n",
      "Loss for batch 68 = 0.5998831391334534\n",
      "Loss for batch 69 = 0.6223294138908386\n",
      "Loss for batch 70 = 0.7481899261474609\n",
      "Loss for batch 71 = 0.5971131324768066\n",
      "Loss for batch 72 = 0.5583193898200989\n",
      "Loss for batch 73 = 0.652786374092102\n",
      "Loss for batch 74 = 0.45045217871665955\n",
      "Loss for batch 75 = 0.7816053032875061\n",
      "Loss for batch 76 = 0.6776124835014343\n",
      "Loss for batch 77 = 0.5677397847175598\n",
      "Loss for batch 78 = 0.50681471824646\n",
      "Loss for batch 79 = 0.5818742513656616\n",
      "Loss for batch 80 = 0.5228420495986938\n",
      "Loss for batch 81 = 0.8278539776802063\n",
      "Loss for batch 82 = 0.7537667155265808\n",
      "Loss for batch 83 = 0.7936181426048279\n",
      "Loss for batch 84 = 0.5724146366119385\n",
      "Loss for batch 85 = 0.5267757773399353\n",
      "Loss for batch 86 = 0.5404713749885559\n",
      "Loss for batch 87 = 0.5340092778205872\n",
      "Loss for batch 88 = 0.5942951440811157\n",
      "Loss for batch 89 = 0.6254201531410217\n",
      "Loss for batch 90 = 0.6781558990478516\n",
      "Loss for batch 91 = 0.7850877046585083\n",
      "Loss for batch 92 = 0.5509439706802368\n",
      "Loss for batch 93 = 0.7117795944213867\n",
      "Loss for batch 94 = 0.5122400522232056\n",
      "Loss for batch 95 = 0.4709315896034241\n",
      "Loss for batch 96 = 0.8326267600059509\n",
      "Loss for batch 97 = 0.639807403087616\n",
      "\n",
      "Training Loss for epoch 18 = 60.330074310302734\n",
      "\n",
      "Current Validation Loss = 23.028959274291992\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 4\n",
      "Train Accuracy: 75.48%\n",
      "Validation Accuracy: 61.10%\n",
      "\n",
      "Epoch 19\n",
      "----------\n",
      "Loss for batch 0 = 0.412200391292572\n",
      "Loss for batch 1 = 0.6039473414421082\n",
      "Loss for batch 2 = 0.5762750506401062\n",
      "Loss for batch 3 = 0.5602127313613892\n",
      "Loss for batch 4 = 0.5761719942092896\n",
      "Loss for batch 5 = 0.5638432502746582\n",
      "Loss for batch 6 = 0.6068137884140015\n",
      "Loss for batch 7 = 0.6126400232315063\n",
      "Loss for batch 8 = 0.5760021805763245\n",
      "Loss for batch 9 = 0.37088125944137573\n",
      "Loss for batch 10 = 0.7226698398590088\n",
      "Loss for batch 11 = 0.3740403950214386\n",
      "Loss for batch 12 = 0.511753261089325\n",
      "Loss for batch 13 = 0.5458434820175171\n",
      "Loss for batch 14 = 0.5451845526695251\n",
      "Loss for batch 15 = 0.5775743126869202\n",
      "Loss for batch 16 = 0.49559152126312256\n",
      "Loss for batch 17 = 0.5655530691146851\n",
      "Loss for batch 18 = 0.47563794255256653\n",
      "Loss for batch 19 = 0.47556936740875244\n",
      "Loss for batch 20 = 0.393926203250885\n",
      "Loss for batch 21 = 0.5094733834266663\n",
      "Loss for batch 22 = 0.4790324568748474\n",
      "Loss for batch 23 = 0.4083268344402313\n",
      "Loss for batch 24 = 0.6217236518859863\n",
      "Loss for batch 25 = 0.5748916268348694\n",
      "Loss for batch 26 = 0.7040331959724426\n",
      "Loss for batch 27 = 0.6182807683944702\n",
      "Loss for batch 28 = 0.6322677135467529\n",
      "Loss for batch 29 = 0.5207315683364868\n",
      "Loss for batch 30 = 0.6025750041007996\n",
      "Loss for batch 31 = 0.5157821774482727\n",
      "Loss for batch 32 = 0.6273438334465027\n",
      "Loss for batch 33 = 0.5634080767631531\n",
      "Loss for batch 34 = 0.6095427870750427\n",
      "Loss for batch 35 = 0.5983192920684814\n",
      "Loss for batch 36 = 0.669405460357666\n",
      "Loss for batch 37 = 0.8607713580131531\n",
      "Loss for batch 38 = 0.5005252361297607\n",
      "Loss for batch 39 = 0.6251134276390076\n",
      "Loss for batch 40 = 0.6527854204177856\n",
      "Loss for batch 41 = 0.5554420948028564\n",
      "Loss for batch 42 = 0.6042759418487549\n",
      "Loss for batch 43 = 0.6338254809379578\n",
      "Loss for batch 44 = 0.6362351775169373\n",
      "Loss for batch 45 = 0.5081422328948975\n",
      "Loss for batch 46 = 0.7106019854545593\n",
      "Loss for batch 47 = 0.7220378518104553\n",
      "Loss for batch 48 = 0.5883142948150635\n",
      "Loss for batch 49 = 0.6507452130317688\n",
      "Loss for batch 50 = 0.5823224782943726\n",
      "Loss for batch 51 = 0.4944579005241394\n",
      "Loss for batch 52 = 0.44414860010147095\n",
      "Loss for batch 53 = 0.3389294445514679\n",
      "Loss for batch 54 = 0.5981324911117554\n",
      "Loss for batch 55 = 0.5344568490982056\n",
      "Loss for batch 56 = 0.5210293531417847\n",
      "Loss for batch 57 = 0.4080468416213989\n",
      "Loss for batch 58 = 0.5609496235847473\n",
      "Loss for batch 59 = 0.7352010011672974\n",
      "Loss for batch 60 = 0.5766347646713257\n",
      "Loss for batch 61 = 0.7951749563217163\n",
      "Loss for batch 62 = 0.8065229058265686\n",
      "Loss for batch 63 = 0.6363098621368408\n",
      "Loss for batch 64 = 0.39907413721084595\n",
      "Loss for batch 65 = 0.49909359216690063\n",
      "Loss for batch 66 = 0.5880995988845825\n",
      "Loss for batch 67 = 0.7825915217399597\n",
      "Loss for batch 68 = 0.6243555545806885\n",
      "Loss for batch 69 = 0.5515329837799072\n",
      "Loss for batch 70 = 0.7315570712089539\n",
      "Loss for batch 71 = 0.5136813521385193\n",
      "Loss for batch 72 = 0.5205731987953186\n",
      "Loss for batch 73 = 0.6130506992340088\n",
      "Loss for batch 74 = 0.42267516255378723\n",
      "Loss for batch 75 = 0.8053597807884216\n",
      "Loss for batch 76 = 0.6044846773147583\n",
      "Loss for batch 77 = 0.552355170249939\n",
      "Loss for batch 78 = 0.44979628920555115\n",
      "Loss for batch 79 = 0.5413134694099426\n",
      "Loss for batch 80 = 0.4979924261569977\n",
      "Loss for batch 81 = 0.8461185097694397\n",
      "Loss for batch 82 = 0.701741635799408\n",
      "Loss for batch 83 = 0.7981143593788147\n",
      "Loss for batch 84 = 0.49443134665489197\n",
      "Loss for batch 85 = 0.5467239022254944\n",
      "Loss for batch 86 = 0.46765607595443726\n",
      "Loss for batch 87 = 0.5660355091094971\n",
      "Loss for batch 88 = 0.5425967574119568\n",
      "Loss for batch 89 = 0.5958405137062073\n",
      "Loss for batch 90 = 0.6039786338806152\n",
      "Loss for batch 91 = 0.7707646489143372\n",
      "Loss for batch 92 = 0.49450355768203735\n",
      "Loss for batch 93 = 0.6934762001037598\n",
      "Loss for batch 94 = 0.5127552151679993\n",
      "Loss for batch 95 = 0.5200870037078857\n",
      "Loss for batch 96 = 0.8207584023475647\n",
      "Loss for batch 97 = 0.6513099670410156\n",
      "\n",
      "Training Loss for epoch 19 = 57.003082275390625\n",
      "\n",
      "Current Validation Loss = 24.015981674194336\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 5\n",
      "Train Accuracy: 76.67%\n",
      "Validation Accuracy: 62.13%\n",
      "\n",
      "Epoch 20\n",
      "----------\n",
      "Loss for batch 0 = 0.3510061800479889\n",
      "Loss for batch 1 = 0.5161088109016418\n",
      "Loss for batch 2 = 0.5520370006561279\n",
      "Loss for batch 3 = 0.5122252106666565\n",
      "Loss for batch 4 = 0.5576028823852539\n",
      "Loss for batch 5 = 0.5248324871063232\n",
      "Loss for batch 6 = 0.5935243368148804\n",
      "Loss for batch 7 = 0.6401919722557068\n",
      "Loss for batch 8 = 0.5519996881484985\n",
      "Loss for batch 9 = 0.3531118333339691\n",
      "Loss for batch 10 = 0.7050043344497681\n",
      "Loss for batch 11 = 0.3651329278945923\n",
      "Loss for batch 12 = 0.48274239897727966\n",
      "Loss for batch 13 = 0.505913496017456\n",
      "Loss for batch 14 = 0.525524914264679\n",
      "Loss for batch 15 = 0.4841596782207489\n",
      "Loss for batch 16 = 0.47952988743782043\n",
      "Loss for batch 17 = 0.5939850807189941\n",
      "Loss for batch 18 = 0.4171881675720215\n",
      "Loss for batch 19 = 0.5123022198677063\n",
      "Loss for batch 20 = 0.35289883613586426\n",
      "Loss for batch 21 = 0.4437738060951233\n",
      "Loss for batch 22 = 0.43981698155403137\n",
      "Loss for batch 23 = 0.390403151512146\n",
      "Loss for batch 24 = 0.5600140690803528\n",
      "Loss for batch 25 = 0.5105199813842773\n",
      "Loss for batch 26 = 0.6769054532051086\n",
      "Loss for batch 27 = 0.5700240731239319\n",
      "Loss for batch 28 = 0.6193088293075562\n",
      "Loss for batch 29 = 0.5784257054328918\n",
      "Loss for batch 30 = 0.5962649583816528\n",
      "Loss for batch 31 = 0.5116943717002869\n",
      "Loss for batch 32 = 0.652525782585144\n",
      "Loss for batch 33 = 0.5681061148643494\n",
      "Loss for batch 34 = 0.6082302927970886\n",
      "Loss for batch 35 = 0.5272157788276672\n",
      "Loss for batch 36 = 0.7036449313163757\n",
      "Loss for batch 37 = 0.8632788062095642\n",
      "Loss for batch 38 = 0.4857880175113678\n",
      "Loss for batch 39 = 0.6222353577613831\n",
      "Loss for batch 40 = 0.661633312702179\n",
      "Loss for batch 41 = 0.5090665817260742\n",
      "Loss for batch 42 = 0.5662829279899597\n",
      "Loss for batch 43 = 0.6051021814346313\n",
      "Loss for batch 44 = 0.5673046708106995\n",
      "Loss for batch 45 = 0.555545449256897\n",
      "Loss for batch 46 = 0.6848171353340149\n",
      "Loss for batch 47 = 0.7125025987625122\n",
      "Loss for batch 48 = 0.6282216310501099\n",
      "Loss for batch 49 = 0.651604413986206\n",
      "Loss for batch 50 = 0.5957629680633545\n",
      "Loss for batch 51 = 0.43416768312454224\n",
      "Loss for batch 52 = 0.4323178827762604\n",
      "Loss for batch 53 = 0.27939876914024353\n",
      "Loss for batch 54 = 0.5254493951797485\n",
      "Loss for batch 55 = 0.6006302237510681\n",
      "Loss for batch 56 = 0.5520772337913513\n",
      "Loss for batch 57 = 0.43780121207237244\n",
      "Loss for batch 58 = 0.530028223991394\n",
      "Loss for batch 59 = 0.7768535614013672\n",
      "Loss for batch 60 = 0.6297746896743774\n",
      "Loss for batch 61 = 0.7705860733985901\n",
      "Loss for batch 62 = 0.6418912410736084\n",
      "Loss for batch 63 = 0.6008328199386597\n",
      "Loss for batch 64 = 0.3780262768268585\n",
      "Loss for batch 65 = 0.540446400642395\n",
      "Loss for batch 66 = 0.7233307361602783\n",
      "Loss for batch 67 = 0.7306691408157349\n",
      "Loss for batch 68 = 0.6688318252563477\n",
      "Loss for batch 69 = 0.6316719055175781\n",
      "Loss for batch 70 = 0.6811118125915527\n",
      "Loss for batch 71 = 0.6965664625167847\n",
      "Loss for batch 72 = 0.5700385570526123\n",
      "Loss for batch 73 = 0.5549502968788147\n",
      "Loss for batch 74 = 0.4338887631893158\n",
      "Loss for batch 75 = 0.7589945197105408\n",
      "Loss for batch 76 = 0.5908583402633667\n",
      "Loss for batch 77 = 0.5182129740715027\n",
      "Loss for batch 78 = 0.4717836081981659\n",
      "Loss for batch 79 = 0.49829086661338806\n",
      "Loss for batch 80 = 0.5367465615272522\n",
      "Loss for batch 81 = 0.6988373398780823\n",
      "Loss for batch 82 = 0.7189120650291443\n",
      "Loss for batch 83 = 0.7766872048377991\n",
      "Loss for batch 84 = 0.4855603873729706\n",
      "Loss for batch 85 = 0.503259539604187\n",
      "Loss for batch 86 = 0.40710386633872986\n",
      "Loss for batch 87 = 0.49799299240112305\n",
      "Loss for batch 88 = 0.593054473400116\n",
      "Loss for batch 89 = 0.5717557668685913\n",
      "Loss for batch 90 = 0.6121081113815308\n",
      "Loss for batch 91 = 0.6527053117752075\n",
      "Loss for batch 92 = 0.48274847865104675\n",
      "Loss for batch 93 = 0.6578891277313232\n",
      "Loss for batch 94 = 0.43849509954452515\n",
      "Loss for batch 95 = 0.41299402713775635\n",
      "Loss for batch 96 = 0.7948594093322754\n",
      "Loss for batch 97 = 0.5660384297370911\n",
      "\n",
      "Training Loss for epoch 20 = 55.310279846191406\n",
      "\n",
      "Current Validation Loss = 24.298067092895508\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 6\n",
      "Train Accuracy: 77.18%\n",
      "Validation Accuracy: 63.41%\n",
      "\n",
      "Epoch 21\n",
      "----------\n",
      "Loss for batch 0 = 0.3085619807243347\n",
      "Loss for batch 1 = 0.5529240369796753\n",
      "Loss for batch 2 = 0.5697615146636963\n",
      "Loss for batch 3 = 0.5935195684432983\n",
      "Loss for batch 4 = 0.6262156367301941\n",
      "Loss for batch 5 = 0.5282155275344849\n",
      "Loss for batch 6 = 0.5829429626464844\n",
      "Loss for batch 7 = 0.5820971727371216\n",
      "Loss for batch 8 = 0.543798565864563\n",
      "Loss for batch 9 = 0.3776727020740509\n",
      "Loss for batch 10 = 0.6954807639122009\n",
      "Loss for batch 11 = 0.34244510531425476\n",
      "Loss for batch 12 = 0.492313414812088\n",
      "Loss for batch 13 = 0.5022709369659424\n",
      "Loss for batch 14 = 0.4766116738319397\n",
      "Loss for batch 15 = 0.5372305512428284\n",
      "Loss for batch 16 = 0.4466085135936737\n",
      "Loss for batch 17 = 0.4917832016944885\n",
      "Loss for batch 18 = 0.4122186303138733\n",
      "Loss for batch 19 = 0.4764035642147064\n",
      "Loss for batch 20 = 0.3662707209587097\n",
      "Loss for batch 21 = 0.4471030533313751\n",
      "Loss for batch 22 = 0.4080367088317871\n",
      "Loss for batch 23 = 0.37414178252220154\n",
      "Loss for batch 24 = 0.5057586431503296\n",
      "Loss for batch 25 = 0.5492475032806396\n",
      "Loss for batch 26 = 0.6691043376922607\n",
      "Loss for batch 27 = 0.6344016194343567\n",
      "Loss for batch 28 = 0.6110187768936157\n",
      "Loss for batch 29 = 0.5800484418869019\n",
      "Loss for batch 30 = 0.5780473947525024\n",
      "Loss for batch 31 = 0.540769100189209\n",
      "Loss for batch 32 = 0.6160550713539124\n",
      "Loss for batch 33 = 0.5421358942985535\n",
      "Loss for batch 34 = 0.6240807175636292\n",
      "Loss for batch 35 = 0.5987599492073059\n",
      "Loss for batch 36 = 0.6266863942146301\n",
      "Loss for batch 37 = 0.856617271900177\n",
      "Loss for batch 38 = 0.4574505388736725\n",
      "Loss for batch 39 = 0.6053924560546875\n",
      "Loss for batch 40 = 0.650610625743866\n",
      "Loss for batch 41 = 0.5008873343467712\n",
      "Loss for batch 42 = 0.570094108581543\n",
      "Loss for batch 43 = 0.6373546719551086\n",
      "Loss for batch 44 = 0.6209622025489807\n",
      "Loss for batch 45 = 0.4714144766330719\n",
      "Loss for batch 46 = 0.6121301651000977\n",
      "Loss for batch 47 = 0.7072830200195312\n",
      "Loss for batch 48 = 0.5194406509399414\n",
      "Loss for batch 49 = 0.6262571215629578\n",
      "Loss for batch 50 = 0.5810573101043701\n",
      "Loss for batch 51 = 0.47584590315818787\n",
      "Loss for batch 52 = 0.43248361349105835\n",
      "Loss for batch 53 = 0.3327861428260803\n",
      "Loss for batch 54 = 0.5849102139472961\n",
      "Loss for batch 55 = 0.5363677144050598\n",
      "Loss for batch 56 = 0.5051224827766418\n",
      "Loss for batch 57 = 0.3902222812175751\n",
      "Loss for batch 58 = 0.5318068265914917\n",
      "Loss for batch 59 = 0.7672994136810303\n",
      "Loss for batch 60 = 0.578462541103363\n",
      "Loss for batch 61 = 0.7406399250030518\n",
      "Loss for batch 62 = 0.6176244616508484\n",
      "Loss for batch 63 = 0.6748791933059692\n",
      "Loss for batch 64 = 0.35881343483924866\n",
      "Loss for batch 65 = 0.502465009689331\n",
      "Loss for batch 66 = 0.6162925362586975\n",
      "Loss for batch 67 = 0.7663904428482056\n",
      "Loss for batch 68 = 0.6181924343109131\n",
      "Loss for batch 69 = 0.5754150152206421\n",
      "Loss for batch 70 = 0.7063244581222534\n",
      "Loss for batch 71 = 0.53887540102005\n",
      "Loss for batch 72 = 0.5316956639289856\n",
      "Loss for batch 73 = 0.5902588963508606\n",
      "Loss for batch 74 = 0.4104633629322052\n",
      "Loss for batch 75 = 0.7241269946098328\n",
      "Loss for batch 76 = 0.6480559706687927\n",
      "Loss for batch 77 = 0.5429814457893372\n",
      "Loss for batch 78 = 0.4523046612739563\n",
      "Loss for batch 79 = 0.5468840599060059\n",
      "Loss for batch 80 = 0.4619594216346741\n",
      "Loss for batch 81 = 0.7102658152580261\n",
      "Loss for batch 82 = 0.7149483561515808\n",
      "Loss for batch 83 = 0.6969367861747742\n",
      "Loss for batch 84 = 0.4526861906051636\n",
      "Loss for batch 85 = 0.4573352336883545\n",
      "Loss for batch 86 = 0.31105488538742065\n",
      "Loss for batch 87 = 0.4721185863018036\n",
      "Loss for batch 88 = 0.5059701204299927\n",
      "Loss for batch 89 = 0.5649670362472534\n",
      "Loss for batch 90 = 0.5714660286903381\n",
      "Loss for batch 91 = 0.6039156317710876\n",
      "Loss for batch 92 = 0.45361360907554626\n",
      "Loss for batch 93 = 0.6066296696662903\n",
      "Loss for batch 94 = 0.4320387840270996\n",
      "Loss for batch 95 = 0.36946815252304077\n",
      "Loss for batch 96 = 0.7076238989830017\n",
      "Loss for batch 97 = 0.6990787386894226\n",
      "\n",
      "Training Loss for epoch 21 = 53.917755126953125\n",
      "\n",
      "Current Validation Loss = 26.012569427490234\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 7\n",
      "Train Accuracy: 77.02%\n",
      "Validation Accuracy: 61.10%\n",
      "\n",
      "Epoch 22\n",
      "----------\n",
      "Loss for batch 0 = 0.26592448353767395\n",
      "Loss for batch 1 = 0.637344479560852\n",
      "Loss for batch 2 = 0.5216119289398193\n",
      "Loss for batch 3 = 0.466737300157547\n",
      "Loss for batch 4 = 0.6882820725440979\n",
      "Loss for batch 5 = 0.3948330879211426\n",
      "Loss for batch 6 = 0.5336018800735474\n",
      "Loss for batch 7 = 0.5615921020507812\n",
      "Loss for batch 8 = 0.5677765607833862\n",
      "Loss for batch 9 = 0.3480258584022522\n",
      "Loss for batch 10 = 0.7103115320205688\n",
      "Loss for batch 11 = 0.34277796745300293\n",
      "Loss for batch 12 = 0.4921523630619049\n",
      "Loss for batch 13 = 0.5102009773254395\n",
      "Loss for batch 14 = 0.5122627019882202\n",
      "Loss for batch 15 = 0.4863191843032837\n",
      "Loss for batch 16 = 0.5226780772209167\n",
      "Loss for batch 17 = 0.42104077339172363\n",
      "Loss for batch 18 = 0.4333103895187378\n",
      "Loss for batch 19 = 0.4250684976577759\n",
      "Loss for batch 20 = 0.31317436695098877\n",
      "Loss for batch 21 = 0.39663851261138916\n",
      "Loss for batch 22 = 0.37762677669525146\n",
      "Loss for batch 23 = 0.3926903009414673\n",
      "Loss for batch 24 = 0.46850287914276123\n",
      "Loss for batch 25 = 0.48991724848747253\n",
      "Loss for batch 26 = 0.6727680563926697\n",
      "Loss for batch 27 = 0.5237772464752197\n",
      "Loss for batch 28 = 0.5561696887016296\n",
      "Loss for batch 29 = 0.48257946968078613\n",
      "Loss for batch 30 = 0.5722248554229736\n",
      "Loss for batch 31 = 0.5150209069252014\n",
      "Loss for batch 32 = 0.6019860506057739\n",
      "Loss for batch 33 = 0.4979099929332733\n",
      "Loss for batch 34 = 0.6124116778373718\n",
      "Loss for batch 35 = 0.4812031686306\n",
      "Loss for batch 36 = 0.6390790343284607\n",
      "Loss for batch 37 = 0.824692964553833\n",
      "Loss for batch 38 = 0.4294871389865875\n",
      "Loss for batch 39 = 0.43617159128189087\n",
      "Loss for batch 40 = 0.6072088479995728\n",
      "Loss for batch 41 = 0.48121586441993713\n",
      "Loss for batch 42 = 0.5251851081848145\n",
      "Loss for batch 43 = 0.7217114567756653\n",
      "Loss for batch 44 = 0.5898489952087402\n",
      "Loss for batch 45 = 0.4361194968223572\n",
      "Loss for batch 46 = 0.6831865906715393\n",
      "Loss for batch 47 = 0.7629581689834595\n",
      "Loss for batch 48 = 0.48218458890914917\n",
      "Loss for batch 49 = 0.4940289258956909\n",
      "Loss for batch 50 = 0.587306559085846\n",
      "Loss for batch 51 = 0.39557886123657227\n",
      "Loss for batch 52 = 0.393338143825531\n",
      "Loss for batch 53 = 0.28759050369262695\n",
      "Loss for batch 54 = 0.4608691334724426\n",
      "Loss for batch 55 = 0.4808991253376007\n",
      "Loss for batch 56 = 0.4794907569885254\n",
      "Loss for batch 57 = 0.3980337977409363\n",
      "Loss for batch 58 = 0.4741561710834503\n",
      "Loss for batch 59 = 0.7126482725143433\n",
      "Loss for batch 60 = 0.46537670493125916\n",
      "Loss for batch 61 = 0.7167006731033325\n",
      "Loss for batch 62 = 0.5352678894996643\n",
      "Loss for batch 63 = 0.5761237144470215\n",
      "Loss for batch 64 = 0.3560160994529724\n",
      "Loss for batch 65 = 0.49533215165138245\n",
      "Loss for batch 66 = 0.5986277461051941\n",
      "Loss for batch 67 = 0.7819538116455078\n",
      "Loss for batch 68 = 0.5974118709564209\n",
      "Loss for batch 69 = 0.5583503842353821\n",
      "Loss for batch 70 = 0.6620690226554871\n",
      "Loss for batch 71 = 0.5128164887428284\n",
      "Loss for batch 72 = 0.4909932017326355\n",
      "Loss for batch 73 = 0.5636971592903137\n",
      "Loss for batch 74 = 0.4068966805934906\n",
      "Loss for batch 75 = 0.6618158221244812\n",
      "Loss for batch 76 = 0.5000911355018616\n",
      "Loss for batch 77 = 0.48460063338279724\n",
      "Loss for batch 78 = 0.4433932900428772\n",
      "Loss for batch 79 = 0.6402629017829895\n",
      "Loss for batch 80 = 0.4864276647567749\n",
      "Loss for batch 81 = 0.603325605392456\n",
      "Loss for batch 82 = 0.6555002331733704\n",
      "Loss for batch 83 = 0.7758377194404602\n",
      "Loss for batch 84 = 0.44314178824424744\n",
      "Loss for batch 85 = 0.414381206035614\n",
      "Loss for batch 86 = 0.3565200865268707\n",
      "Loss for batch 87 = 0.4807980954647064\n",
      "Loss for batch 88 = 0.5103211998939514\n",
      "Loss for batch 89 = 0.5701796412467957\n",
      "Loss for batch 90 = 0.5467519760131836\n",
      "Loss for batch 91 = 0.6522459387779236\n",
      "Loss for batch 92 = 0.45027559995651245\n",
      "Loss for batch 93 = 0.6121326684951782\n",
      "Loss for batch 94 = 0.3675934076309204\n",
      "Loss for batch 95 = 0.3321322500705719\n",
      "Loss for batch 96 = 0.6876921057701111\n",
      "Loss for batch 97 = 0.5392129421234131\n",
      "\n",
      "Training Loss for epoch 22 = 51.111698150634766\n",
      "\n",
      "Current Validation Loss = 26.281139373779297\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 8\n",
      "Train Accuracy: 79.59%\n",
      "Validation Accuracy: 62.52%\n",
      "\n",
      "Epoch 23\n",
      "----------\n",
      "Loss for batch 0 = 0.23166263103485107\n",
      "Loss for batch 1 = 0.5439756512641907\n",
      "Loss for batch 2 = 0.5267096161842346\n",
      "Loss for batch 3 = 0.42847082018852234\n",
      "Loss for batch 4 = 0.6032456755638123\n",
      "Loss for batch 5 = 0.3931483328342438\n",
      "Loss for batch 6 = 0.5557679533958435\n",
      "Loss for batch 7 = 0.5526106357574463\n",
      "Loss for batch 8 = 0.48763638734817505\n",
      "Loss for batch 9 = 0.3510429263114929\n",
      "Loss for batch 10 = 0.7152884006500244\n",
      "Loss for batch 11 = 0.4118931293487549\n",
      "Loss for batch 12 = 0.4689779281616211\n",
      "Loss for batch 13 = 0.47540992498397827\n",
      "Loss for batch 14 = 0.4392940402030945\n",
      "Loss for batch 15 = 0.49877938628196716\n",
      "Loss for batch 16 = 0.44587019085884094\n",
      "Loss for batch 17 = 0.4261035919189453\n",
      "Loss for batch 18 = 0.39948076009750366\n",
      "Loss for batch 19 = 0.5240280628204346\n",
      "Loss for batch 20 = 0.30715474486351013\n",
      "Loss for batch 21 = 0.44222700595855713\n",
      "Loss for batch 22 = 0.34907132387161255\n",
      "Loss for batch 23 = 0.3387134373188019\n",
      "Loss for batch 24 = 0.5387773513793945\n",
      "Loss for batch 25 = 0.46171852946281433\n",
      "Loss for batch 26 = 0.6789320111274719\n",
      "Loss for batch 27 = 0.47262656688690186\n",
      "Loss for batch 28 = 0.4879499077796936\n",
      "Loss for batch 29 = 0.43999576568603516\n",
      "Loss for batch 30 = 0.5618937015533447\n",
      "Loss for batch 31 = 0.4816371500492096\n",
      "Loss for batch 32 = 0.581709086894989\n",
      "Loss for batch 33 = 0.49773454666137695\n",
      "Loss for batch 34 = 0.5799967646598816\n",
      "Loss for batch 35 = 0.45895931124687195\n",
      "Loss for batch 36 = 0.6797473430633545\n",
      "Loss for batch 37 = 0.693598210811615\n",
      "Loss for batch 38 = 0.4098021686077118\n",
      "Loss for batch 39 = 0.38493943214416504\n",
      "Loss for batch 40 = 0.6466426253318787\n",
      "Loss for batch 41 = 0.46190744638442993\n",
      "Loss for batch 42 = 0.5070621967315674\n",
      "Loss for batch 43 = 0.6002098321914673\n",
      "Loss for batch 44 = 0.47726675868034363\n",
      "Loss for batch 45 = 0.4763549864292145\n",
      "Loss for batch 46 = 0.5925203561782837\n",
      "Loss for batch 47 = 0.6434483528137207\n",
      "Loss for batch 48 = 0.47562408447265625\n",
      "Loss for batch 49 = 0.47112521529197693\n",
      "Loss for batch 50 = 0.5840142965316772\n",
      "Loss for batch 51 = 0.35763484239578247\n",
      "Loss for batch 52 = 0.37686389684677124\n",
      "Loss for batch 53 = 0.2377297580242157\n",
      "Loss for batch 54 = 0.40925857424736023\n",
      "Loss for batch 55 = 0.48673638701438904\n",
      "Loss for batch 56 = 0.5139772891998291\n",
      "Loss for batch 57 = 0.3982715904712677\n",
      "Loss for batch 58 = 0.5083402395248413\n",
      "Loss for batch 59 = 0.690791666507721\n",
      "Loss for batch 60 = 0.4121832549571991\n",
      "Loss for batch 61 = 0.6353873014450073\n",
      "Loss for batch 62 = 0.5189578533172607\n",
      "Loss for batch 63 = 0.5611875057220459\n",
      "Loss for batch 64 = 0.3022073805332184\n",
      "Loss for batch 65 = 0.5484578013420105\n",
      "Loss for batch 66 = 0.4689689874649048\n",
      "Loss for batch 67 = 0.7917778491973877\n",
      "Loss for batch 68 = 0.5887489318847656\n",
      "Loss for batch 69 = 0.5244407653808594\n",
      "Loss for batch 70 = 0.7523303031921387\n",
      "Loss for batch 71 = 0.5012791156768799\n",
      "Loss for batch 72 = 0.4735713303089142\n",
      "Loss for batch 73 = 0.535407304763794\n",
      "Loss for batch 74 = 0.4562019407749176\n",
      "Loss for batch 75 = 0.6064635515213013\n",
      "Loss for batch 76 = 0.5299739837646484\n",
      "Loss for batch 77 = 0.48247045278549194\n",
      "Loss for batch 78 = 0.33413538336753845\n",
      "Loss for batch 79 = 0.46155089139938354\n",
      "Loss for batch 80 = 0.43870046734809875\n",
      "Loss for batch 81 = 0.5658256411552429\n",
      "Loss for batch 82 = 0.6562926173210144\n",
      "Loss for batch 83 = 0.6941577196121216\n",
      "Loss for batch 84 = 0.45559802651405334\n",
      "Loss for batch 85 = 0.3939060568809509\n",
      "Loss for batch 86 = 0.3031684458255768\n",
      "Loss for batch 87 = 0.41832393407821655\n",
      "Loss for batch 88 = 0.5462762713432312\n",
      "Loss for batch 89 = 0.6322888135910034\n",
      "Loss for batch 90 = 0.5283733606338501\n",
      "Loss for batch 91 = 0.5893716812133789\n",
      "Loss for batch 92 = 0.4207964539527893\n",
      "Loss for batch 93 = 0.5891779065132141\n",
      "Loss for batch 94 = 0.42410552501678467\n",
      "Loss for batch 95 = 0.33806657791137695\n",
      "Loss for batch 96 = 0.6579009294509888\n",
      "Loss for batch 97 = 0.5172866582870483\n",
      "\n",
      "Training Loss for epoch 23 = 48.897682189941406\n",
      "\n",
      "Current Validation Loss = 27.103532791137695\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 9\n",
      "Train Accuracy: 80.68%\n",
      "Validation Accuracy: 61.10%\n",
      "\n",
      "Epoch 24\n",
      "----------\n",
      "Loss for batch 0 = 0.21991926431655884\n",
      "Loss for batch 1 = 0.5038301348686218\n",
      "Loss for batch 2 = 0.5141847729682922\n",
      "Loss for batch 3 = 0.4104054570198059\n",
      "Loss for batch 4 = 0.5123146176338196\n",
      "Loss for batch 5 = 0.34987443685531616\n",
      "Loss for batch 6 = 0.5430442690849304\n",
      "Loss for batch 7 = 0.5021321773529053\n",
      "Loss for batch 8 = 0.4208810329437256\n",
      "Loss for batch 9 = 0.3455134928226471\n",
      "Loss for batch 10 = 0.6524393558502197\n",
      "Loss for batch 11 = 0.3438881039619446\n",
      "Loss for batch 12 = 0.49521633982658386\n",
      "Loss for batch 13 = 0.4435517191886902\n",
      "Loss for batch 14 = 0.36064600944519043\n",
      "Loss for batch 15 = 0.4662008285522461\n",
      "Loss for batch 16 = 0.49148398637771606\n",
      "Loss for batch 17 = 0.43406665325164795\n",
      "Loss for batch 18 = 0.41259679198265076\n",
      "Loss for batch 19 = 0.4139655828475952\n",
      "Loss for batch 20 = 0.32148751616477966\n",
      "Loss for batch 21 = 0.4572501480579376\n",
      "Loss for batch 22 = 0.3339499533176422\n",
      "Loss for batch 23 = 0.330268919467926\n",
      "Loss for batch 24 = 0.4323062002658844\n",
      "Loss for batch 25 = 0.45579251646995544\n",
      "Loss for batch 26 = 0.6076847314834595\n",
      "Loss for batch 27 = 0.5523867607116699\n",
      "Loss for batch 28 = 0.4952557682991028\n",
      "Loss for batch 29 = 0.3921393156051636\n",
      "Loss for batch 30 = 0.5387359857559204\n",
      "Loss for batch 31 = 0.4581986665725708\n",
      "Loss for batch 32 = 0.541980504989624\n",
      "Loss for batch 33 = 0.43955254554748535\n",
      "Loss for batch 34 = 0.5528396964073181\n",
      "Loss for batch 35 = 0.42816266417503357\n",
      "Loss for batch 36 = 0.5531997680664062\n",
      "Loss for batch 37 = 0.7307875156402588\n",
      "Loss for batch 38 = 0.3822677731513977\n",
      "Loss for batch 39 = 0.33030927181243896\n",
      "Loss for batch 40 = 0.6375458836555481\n",
      "Loss for batch 41 = 0.4362964928150177\n",
      "Loss for batch 42 = 0.39463284611701965\n",
      "Loss for batch 43 = 0.5705253481864929\n",
      "Loss for batch 44 = 0.4379993677139282\n",
      "Loss for batch 45 = 0.4546593427658081\n",
      "Loss for batch 46 = 0.5529493093490601\n",
      "Loss for batch 47 = 0.6206814646720886\n",
      "Loss for batch 48 = 0.439410537481308\n",
      "Loss for batch 49 = 0.41357511281967163\n",
      "Loss for batch 50 = 0.5533329844474792\n",
      "Loss for batch 51 = 0.36249053478240967\n",
      "Loss for batch 52 = 0.37287822365760803\n",
      "Loss for batch 53 = 0.2257561832666397\n",
      "Loss for batch 54 = 0.31497740745544434\n",
      "Loss for batch 55 = 0.45353633165359497\n",
      "Loss for batch 56 = 0.4363230764865875\n",
      "Loss for batch 57 = 0.383107990026474\n",
      "Loss for batch 58 = 0.4533193111419678\n",
      "Loss for batch 59 = 0.6500032544136047\n",
      "Loss for batch 60 = 0.4114284813404083\n",
      "Loss for batch 61 = 0.6837632060050964\n",
      "Loss for batch 62 = 0.4520733952522278\n",
      "Loss for batch 63 = 0.5263193845748901\n",
      "Loss for batch 64 = 0.27632248401641846\n",
      "Loss for batch 65 = 0.4297069311141968\n",
      "Loss for batch 66 = 0.4441473186016083\n",
      "Loss for batch 67 = 0.7240508198738098\n",
      "Loss for batch 68 = 0.49199002981185913\n",
      "Loss for batch 69 = 0.5334200859069824\n",
      "Loss for batch 70 = 0.6136516332626343\n",
      "Loss for batch 71 = 0.4736180901527405\n",
      "Loss for batch 72 = 0.419951856136322\n",
      "Loss for batch 73 = 0.45696189999580383\n",
      "Loss for batch 74 = 0.38556861877441406\n",
      "Loss for batch 75 = 0.6153490543365479\n",
      "Loss for batch 76 = 0.519039511680603\n",
      "Loss for batch 77 = 0.4219834506511688\n",
      "Loss for batch 78 = 0.33719879388809204\n",
      "Loss for batch 79 = 0.43323197960853577\n",
      "Loss for batch 80 = 0.4095950424671173\n",
      "Loss for batch 81 = 0.5389297604560852\n",
      "Loss for batch 82 = 0.5171040892601013\n",
      "Loss for batch 83 = 0.6531344056129456\n",
      "Loss for batch 84 = 0.4018078148365021\n",
      "Loss for batch 85 = 0.4166870415210724\n",
      "Loss for batch 86 = 0.287489652633667\n",
      "Loss for batch 87 = 0.39019253849983215\n",
      "Loss for batch 88 = 0.49406611919403076\n",
      "Loss for batch 89 = 0.5998185873031616\n",
      "Loss for batch 90 = 0.49353837966918945\n",
      "Loss for batch 91 = 0.6283775568008423\n",
      "Loss for batch 92 = 0.3887060284614563\n",
      "Loss for batch 93 = 0.566953718662262\n",
      "Loss for batch 94 = 0.3475199043750763\n",
      "Loss for batch 95 = 0.2680107355117798\n",
      "Loss for batch 96 = 0.6399916410446167\n",
      "Loss for batch 97 = 0.5204066634178162\n",
      "\n",
      "Training Loss for epoch 24 = 45.54681396484375\n",
      "\n",
      "Current Validation Loss = 28.37677574157715\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 10\n",
      "Train Accuracy: 80.65%\n",
      "Validation Accuracy: 61.10%\n",
      "\n",
      "Epoch 25\n",
      "----------\n",
      "Loss for batch 0 = 0.19182924926280975\n",
      "Loss for batch 1 = 0.4769265055656433\n",
      "Loss for batch 2 = 0.6415022611618042\n",
      "Loss for batch 3 = 0.474468857049942\n",
      "Loss for batch 4 = 0.49643221497535706\n",
      "Loss for batch 5 = 0.4153859615325928\n",
      "Loss for batch 6 = 0.5578909516334534\n",
      "Loss for batch 7 = 0.49293744564056396\n",
      "Loss for batch 8 = 0.40954655408859253\n",
      "Loss for batch 9 = 0.2507231831550598\n",
      "Loss for batch 10 = 0.6825430989265442\n",
      "Loss for batch 11 = 0.31304728984832764\n",
      "Loss for batch 12 = 0.4740087687969208\n",
      "Loss for batch 13 = 0.4150933623313904\n",
      "Loss for batch 14 = 0.33806541562080383\n",
      "Loss for batch 15 = 0.4340302646160126\n",
      "Loss for batch 16 = 0.44367584586143494\n",
      "Loss for batch 17 = 0.3761890232563019\n",
      "Loss for batch 18 = 0.37619736790657043\n",
      "Loss for batch 19 = 0.3670823872089386\n",
      "Loss for batch 20 = 0.2841038703918457\n",
      "Loss for batch 21 = 0.4184047281742096\n",
      "Loss for batch 22 = 0.312151700258255\n",
      "Loss for batch 23 = 0.3223459720611572\n",
      "Loss for batch 24 = 0.40181633830070496\n",
      "Loss for batch 25 = 0.44036099314689636\n",
      "Loss for batch 26 = 0.5726802945137024\n",
      "Loss for batch 27 = 0.4882681667804718\n",
      "Loss for batch 28 = 0.46344175934791565\n",
      "Loss for batch 29 = 0.45747852325439453\n",
      "Loss for batch 30 = 0.5203855633735657\n",
      "Loss for batch 31 = 0.42046770453453064\n",
      "Loss for batch 32 = 0.5183044075965881\n",
      "Loss for batch 33 = 0.38969501852989197\n",
      "Loss for batch 34 = 0.553235650062561\n",
      "Loss for batch 35 = 0.4067719578742981\n",
      "Loss for batch 36 = 0.5801306366920471\n",
      "Loss for batch 37 = 0.6812971830368042\n",
      "Loss for batch 38 = 0.36027026176452637\n",
      "Loss for batch 39 = 0.34983521699905396\n",
      "Loss for batch 40 = 0.612419605255127\n",
      "Loss for batch 41 = 0.4290236234664917\n",
      "Loss for batch 42 = 0.3878535032272339\n",
      "Loss for batch 43 = 0.5168962478637695\n",
      "Loss for batch 44 = 0.4331161379814148\n",
      "Loss for batch 45 = 0.4727526307106018\n",
      "Loss for batch 46 = 0.4931749999523163\n",
      "Loss for batch 47 = 0.611347496509552\n",
      "Loss for batch 48 = 0.42364394664764404\n",
      "Loss for batch 49 = 0.4179622232913971\n",
      "Loss for batch 50 = 0.5536994934082031\n",
      "Loss for batch 51 = 0.3343825936317444\n",
      "Loss for batch 52 = 0.37308305501937866\n",
      "Loss for batch 53 = 0.2058887779712677\n",
      "Loss for batch 54 = 0.3091481029987335\n",
      "Loss for batch 55 = 0.4484221041202545\n",
      "Loss for batch 56 = 0.4323762357234955\n",
      "Loss for batch 57 = 0.350967139005661\n",
      "Loss for batch 58 = 0.4062316119670868\n",
      "Loss for batch 59 = 0.6619156002998352\n",
      "Loss for batch 60 = 0.36532139778137207\n",
      "Loss for batch 61 = 0.6755562424659729\n",
      "Loss for batch 62 = 0.4294798970222473\n",
      "Loss for batch 63 = 0.4982096552848816\n",
      "Loss for batch 64 = 0.26692360639572144\n",
      "Loss for batch 65 = 0.4136122167110443\n",
      "Loss for batch 66 = 0.4395367503166199\n",
      "Loss for batch 67 = 0.710701584815979\n",
      "Loss for batch 68 = 0.4887024462223053\n",
      "Loss for batch 69 = 0.5291837453842163\n",
      "Loss for batch 70 = 0.6094810366630554\n",
      "Loss for batch 71 = 0.4675760567188263\n",
      "Loss for batch 72 = 0.37428078055381775\n",
      "Loss for batch 73 = 0.4425244927406311\n",
      "Loss for batch 74 = 0.3657745122909546\n",
      "Loss for batch 75 = 0.5769692659378052\n",
      "Loss for batch 76 = 0.3916861414909363\n",
      "Loss for batch 77 = 0.375067800283432\n",
      "Loss for batch 78 = 0.31297311186790466\n",
      "Loss for batch 79 = 0.4628470838069916\n",
      "Loss for batch 80 = 0.4003891348838806\n",
      "Loss for batch 81 = 0.5222775340080261\n",
      "Loss for batch 82 = 0.5227202773094177\n",
      "Loss for batch 83 = 0.6169556975364685\n",
      "Loss for batch 84 = 0.40821632742881775\n",
      "Loss for batch 85 = 0.35958558320999146\n",
      "Loss for batch 86 = 0.2760113775730133\n",
      "Loss for batch 87 = 0.384417861700058\n",
      "Loss for batch 88 = 0.46809056401252747\n",
      "Loss for batch 89 = 0.6051953434944153\n",
      "Loss for batch 90 = 0.4962076246738434\n",
      "Loss for batch 91 = 0.5416064262390137\n",
      "Loss for batch 92 = 0.38790974020957947\n",
      "Loss for batch 93 = 0.5341280698776245\n",
      "Loss for batch 94 = 0.3010147213935852\n",
      "Loss for batch 95 = 0.26672524213790894\n",
      "Loss for batch 96 = 0.676341712474823\n",
      "Loss for batch 97 = 0.4909828007221222\n",
      "\n",
      "Training Loss for epoch 25 = 43.89850616455078\n",
      "\n",
      "Current Validation Loss = 29.566272735595703\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 11\n",
      "Train Accuracy: 80.94%\n",
      "Validation Accuracy: 60.08%\n",
      "\n",
      "Epoch 26\n",
      "----------\n",
      "Loss for batch 0 = 0.19906507432460785\n",
      "Loss for batch 1 = 0.491140753030777\n",
      "Loss for batch 2 = 0.5858685970306396\n",
      "Loss for batch 3 = 0.3892615735530853\n",
      "Loss for batch 4 = 0.4866621196269989\n",
      "Loss for batch 5 = 0.33069124817848206\n",
      "Loss for batch 6 = 0.47525110840797424\n",
      "Loss for batch 7 = 0.47303780913352966\n",
      "Loss for batch 8 = 0.4093387722969055\n",
      "Loss for batch 9 = 0.2267996221780777\n",
      "Loss for batch 10 = 0.6407396793365479\n",
      "Loss for batch 11 = 0.20714496076107025\n",
      "Loss for batch 12 = 0.4146187901496887\n",
      "Loss for batch 13 = 0.3992031216621399\n",
      "Loss for batch 14 = 0.3388533890247345\n",
      "Loss for batch 15 = 0.43671518564224243\n",
      "Loss for batch 16 = 0.4238473176956177\n",
      "Loss for batch 17 = 0.345934122800827\n",
      "Loss for batch 18 = 0.36176976561546326\n",
      "Loss for batch 19 = 0.35674935579299927\n",
      "Loss for batch 20 = 0.27212339639663696\n",
      "Loss for batch 21 = 0.4075827896595001\n",
      "Loss for batch 22 = 0.28628501296043396\n",
      "Loss for batch 23 = 0.30972594022750854\n",
      "Loss for batch 24 = 0.3557780086994171\n",
      "Loss for batch 25 = 0.4367794692516327\n",
      "Loss for batch 26 = 0.5563540458679199\n",
      "Loss for batch 27 = 0.5090911984443665\n",
      "Loss for batch 28 = 0.4178787171840668\n",
      "Loss for batch 29 = 0.3616342544555664\n",
      "Loss for batch 30 = 0.5099294185638428\n",
      "Loss for batch 31 = 0.38872796297073364\n",
      "Loss for batch 32 = 0.5144795179367065\n",
      "Loss for batch 33 = 0.3911040425300598\n",
      "Loss for batch 34 = 0.5467439889907837\n",
      "Loss for batch 35 = 0.44268909096717834\n",
      "Loss for batch 36 = 0.5221518278121948\n",
      "Loss for batch 37 = 0.6544378399848938\n",
      "Loss for batch 38 = 0.3173554539680481\n",
      "Loss for batch 39 = 0.34788867831230164\n",
      "Loss for batch 40 = 0.5856184959411621\n",
      "Loss for batch 41 = 0.4087767004966736\n",
      "Loss for batch 42 = 0.4098474383354187\n",
      "Loss for batch 43 = 0.48817673325538635\n",
      "Loss for batch 44 = 0.4197169244289398\n",
      "Loss for batch 45 = 0.4264489412307739\n",
      "Loss for batch 46 = 0.4694112539291382\n",
      "Loss for batch 47 = 0.5807608366012573\n",
      "Loss for batch 48 = 0.41960206627845764\n",
      "Loss for batch 49 = 0.41313374042510986\n",
      "Loss for batch 50 = 0.5440383553504944\n",
      "Loss for batch 51 = 0.32961076498031616\n",
      "Loss for batch 52 = 0.37233859300613403\n",
      "Loss for batch 53 = 0.22430437803268433\n",
      "Loss for batch 54 = 0.36838382482528687\n",
      "Loss for batch 55 = 0.40924710035324097\n",
      "Loss for batch 56 = 0.4236888885498047\n",
      "Loss for batch 57 = 0.34144124388694763\n",
      "Loss for batch 58 = 0.40195998549461365\n",
      "Loss for batch 59 = 0.6415989398956299\n",
      "Loss for batch 60 = 0.3341199457645416\n",
      "Loss for batch 61 = 0.6601900458335876\n",
      "Loss for batch 62 = 0.418621689081192\n",
      "Loss for batch 63 = 0.49208852648735046\n",
      "Loss for batch 64 = 0.26426365971565247\n",
      "Loss for batch 65 = 0.39516863226890564\n",
      "Loss for batch 66 = 0.42850595712661743\n",
      "Loss for batch 67 = 0.7048794627189636\n",
      "Loss for batch 68 = 0.48280417919158936\n",
      "Loss for batch 69 = 0.5289183259010315\n",
      "Loss for batch 70 = 0.5867668986320496\n",
      "Loss for batch 71 = 0.45497527718544006\n",
      "Loss for batch 72 = 0.34711953997612\n",
      "Loss for batch 73 = 0.4272783696651459\n",
      "Loss for batch 74 = 0.33152300119400024\n",
      "Loss for batch 75 = 0.5439353585243225\n",
      "Loss for batch 76 = 0.36857545375823975\n",
      "Loss for batch 77 = 0.3704789876937866\n",
      "Loss for batch 78 = 0.31420567631721497\n",
      "Loss for batch 79 = 0.3790753185749054\n",
      "Loss for batch 80 = 0.3909969925880432\n",
      "Loss for batch 81 = 0.5103873610496521\n",
      "Loss for batch 82 = 0.48703473806381226\n",
      "Loss for batch 83 = 0.5976682305335999\n",
      "Loss for batch 84 = 0.40001699328422546\n",
      "Loss for batch 85 = 0.33759552240371704\n",
      "Loss for batch 86 = 0.27001386880874634\n",
      "Loss for batch 87 = 0.3780581057071686\n",
      "Loss for batch 88 = 0.49644747376441956\n",
      "Loss for batch 89 = 0.6189509630203247\n",
      "Loss for batch 90 = 0.47817134857177734\n",
      "Loss for batch 91 = 0.48414790630340576\n",
      "Loss for batch 92 = 0.38481611013412476\n",
      "Loss for batch 93 = 0.5787270069122314\n",
      "Loss for batch 94 = 0.30776095390319824\n",
      "Loss for batch 95 = 0.2360624223947525\n",
      "Loss for batch 96 = 0.6000081300735474\n",
      "Loss for batch 97 = 0.474590539932251\n",
      "\n",
      "Training Loss for epoch 26 = 42.084495544433594\n",
      "\n",
      "Current Validation Loss = 31.213699340820312\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 12\n",
      "Train Accuracy: 81.68%\n",
      "Validation Accuracy: 59.95%\n",
      "\n",
      "Epoch 27\n",
      "----------\n",
      "Loss for batch 0 = 0.18374650180339813\n",
      "Loss for batch 1 = 0.4587712585926056\n",
      "Loss for batch 2 = 0.5162648558616638\n",
      "Loss for batch 3 = 0.4848112165927887\n",
      "Loss for batch 4 = 0.4798380732536316\n",
      "Loss for batch 5 = 0.3713214695453644\n",
      "Loss for batch 6 = 0.4384567439556122\n",
      "Loss for batch 7 = 0.47218579053878784\n",
      "Loss for batch 8 = 0.3879063129425049\n",
      "Loss for batch 9 = 0.21162337064743042\n",
      "Loss for batch 10 = 0.6071444153785706\n",
      "Loss for batch 11 = 0.16881030797958374\n",
      "Loss for batch 12 = 0.36724555492401123\n",
      "Loss for batch 13 = 0.3934745490550995\n",
      "Loss for batch 14 = 0.3197149932384491\n",
      "Loss for batch 15 = 0.42010512948036194\n",
      "Loss for batch 16 = 0.4101268947124481\n",
      "Loss for batch 17 = 0.32878655195236206\n",
      "Loss for batch 18 = 0.357509046792984\n",
      "Loss for batch 19 = 0.34270182251930237\n",
      "Loss for batch 20 = 0.26479098200798035\n",
      "Loss for batch 21 = 0.3882075846195221\n",
      "Loss for batch 22 = 0.28140783309936523\n",
      "Loss for batch 23 = 0.3041251301765442\n",
      "Loss for batch 24 = 0.3335161507129669\n",
      "Loss for batch 25 = 0.4317144751548767\n",
      "Loss for batch 26 = 0.5756877660751343\n",
      "Loss for batch 27 = 0.45338594913482666\n",
      "Loss for batch 28 = 0.44199395179748535\n",
      "Loss for batch 29 = 0.3588370084762573\n",
      "Loss for batch 30 = 0.527624785900116\n",
      "Loss for batch 31 = 0.3632746636867523\n",
      "Loss for batch 32 = 0.5050415396690369\n",
      "Loss for batch 33 = 0.38989660143852234\n",
      "Loss for batch 34 = 0.5482852458953857\n",
      "Loss for batch 35 = 0.4072206914424896\n",
      "Loss for batch 36 = 0.5155333280563354\n",
      "Loss for batch 37 = 0.6290780305862427\n",
      "Loss for batch 38 = 0.31212738156318665\n",
      "Loss for batch 39 = 0.30844685435295105\n",
      "Loss for batch 40 = 0.5540295839309692\n",
      "Loss for batch 41 = 0.37313729524612427\n",
      "Loss for batch 42 = 0.3900277614593506\n",
      "Loss for batch 43 = 0.4737190008163452\n",
      "Loss for batch 44 = 0.40762051939964294\n",
      "Loss for batch 45 = 0.41767752170562744\n",
      "Loss for batch 46 = 0.46557101607322693\n",
      "Loss for batch 47 = 0.4790182113647461\n",
      "Loss for batch 48 = 0.42640623450279236\n",
      "Loss for batch 49 = 0.3999210298061371\n",
      "Loss for batch 50 = 0.5673065185546875\n",
      "Loss for batch 51 = 0.3248421549797058\n",
      "Loss for batch 52 = 0.3582957684993744\n",
      "Loss for batch 53 = 0.21074333786964417\n",
      "Loss for batch 54 = 0.39203473925590515\n",
      "Loss for batch 55 = 0.40263181924819946\n",
      "Loss for batch 56 = 0.4256380796432495\n",
      "Loss for batch 57 = 0.32056328654289246\n",
      "Loss for batch 58 = 0.39395856857299805\n",
      "Loss for batch 59 = 0.6128196120262146\n",
      "Loss for batch 60 = 0.31410232186317444\n",
      "Loss for batch 61 = 0.6066381931304932\n",
      "Loss for batch 62 = 0.4092704653739929\n",
      "Loss for batch 63 = 0.47097456455230713\n",
      "Loss for batch 64 = 0.2356899082660675\n",
      "Loss for batch 65 = 0.4047720432281494\n",
      "Loss for batch 66 = 0.4133388102054596\n",
      "Loss for batch 67 = 0.6807610392570496\n",
      "Loss for batch 68 = 0.48604536056518555\n",
      "Loss for batch 69 = 0.5307322144508362\n",
      "Loss for batch 70 = 0.5758850574493408\n",
      "Loss for batch 71 = 0.4749172031879425\n",
      "Loss for batch 72 = 0.31510433554649353\n",
      "Loss for batch 73 = 0.40724897384643555\n",
      "Loss for batch 74 = 0.32364681363105774\n",
      "Loss for batch 75 = 0.5205632448196411\n",
      "Loss for batch 76 = 0.40892791748046875\n",
      "Loss for batch 77 = 0.35188689827919006\n",
      "Loss for batch 78 = 0.29514554142951965\n",
      "Loss for batch 79 = 0.3648521900177002\n",
      "Loss for batch 80 = 0.37385424971580505\n",
      "Loss for batch 81 = 0.5132849812507629\n",
      "Loss for batch 82 = 0.5003460049629211\n",
      "Loss for batch 83 = 0.5844789743423462\n",
      "Loss for batch 84 = 0.39592888951301575\n",
      "Loss for batch 85 = 0.3372509181499481\n",
      "Loss for batch 86 = 0.27051979303359985\n",
      "Loss for batch 87 = 0.38194820284843445\n",
      "Loss for batch 88 = 0.4741509258747101\n",
      "Loss for batch 89 = 0.5726045966148376\n",
      "Loss for batch 90 = 0.4622914791107178\n",
      "Loss for batch 91 = 0.5208262205123901\n",
      "Loss for batch 92 = 0.37723955512046814\n",
      "Loss for batch 93 = 0.5105337500572205\n",
      "Loss for batch 94 = 0.27996301651000977\n",
      "Loss for batch 95 = 0.23606911301612854\n",
      "Loss for batch 96 = 0.6853283047676086\n",
      "Loss for batch 97 = 0.4692986011505127\n",
      "\n",
      "Training Loss for epoch 27 = 40.993125915527344\n",
      "\n",
      "Current Validation Loss = 31.964269638061523\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 13\n",
      "Train Accuracy: 81.84%\n",
      "Validation Accuracy: 59.95%\n",
      "\n",
      "Epoch 28\n",
      "----------\n",
      "Loss for batch 0 = 0.16719144582748413\n",
      "Loss for batch 1 = 0.47143808007240295\n",
      "Loss for batch 2 = 0.5071497559547424\n",
      "Loss for batch 3 = 0.48235464096069336\n",
      "Loss for batch 4 = 0.45802780985832214\n",
      "Loss for batch 5 = 0.31235069036483765\n",
      "Loss for batch 6 = 0.42531511187553406\n",
      "Loss for batch 7 = 0.5022438764572144\n",
      "Loss for batch 8 = 0.41069138050079346\n",
      "Loss for batch 9 = 0.21952110528945923\n",
      "Loss for batch 10 = 0.5710934996604919\n",
      "Loss for batch 11 = 0.15540507435798645\n",
      "Loss for batch 12 = 0.35492753982543945\n",
      "Loss for batch 13 = 0.3978961408138275\n",
      "Loss for batch 14 = 0.3057998716831207\n",
      "Loss for batch 15 = 0.3991081416606903\n",
      "Loss for batch 16 = 0.43864938616752625\n",
      "Loss for batch 17 = 0.3475043475627899\n",
      "Loss for batch 18 = 0.3797813355922699\n",
      "Loss for batch 19 = 0.34126389026641846\n",
      "Loss for batch 20 = 0.2649223506450653\n",
      "Loss for batch 21 = 0.3897998332977295\n",
      "Loss for batch 22 = 0.28940334916114807\n",
      "Loss for batch 23 = 0.30086758732795715\n",
      "Loss for batch 24 = 0.33164182305336\n",
      "Loss for batch 25 = 0.4297497868537903\n",
      "Loss for batch 26 = 0.5313378572463989\n",
      "Loss for batch 27 = 0.41898995637893677\n",
      "Loss for batch 28 = 0.3770572245121002\n",
      "Loss for batch 29 = 0.34565240144729614\n",
      "Loss for batch 30 = 0.46801453828811646\n",
      "Loss for batch 31 = 0.3397845923900604\n",
      "Loss for batch 32 = 0.48722612857818604\n",
      "Loss for batch 33 = 0.3743058443069458\n",
      "Loss for batch 34 = 0.5246649384498596\n",
      "Loss for batch 35 = 0.43967264890670776\n",
      "Loss for batch 36 = 0.5152826309204102\n",
      "Loss for batch 37 = 0.6241750121116638\n",
      "Loss for batch 38 = 0.30155840516090393\n",
      "Loss for batch 39 = 0.31625545024871826\n",
      "Loss for batch 40 = 0.5731425285339355\n",
      "Loss for batch 41 = 0.367192804813385\n",
      "Loss for batch 42 = 0.3693326413631439\n",
      "Loss for batch 43 = 0.4670601189136505\n",
      "Loss for batch 44 = 0.3711322844028473\n",
      "Loss for batch 45 = 0.386535108089447\n",
      "Loss for batch 46 = 0.4205152690410614\n",
      "Loss for batch 47 = 0.5551914572715759\n",
      "Loss for batch 48 = 0.4118233621120453\n",
      "Loss for batch 49 = 0.39276525378227234\n",
      "Loss for batch 50 = 0.5307266712188721\n",
      "Loss for batch 51 = 0.3753625154495239\n",
      "Loss for batch 52 = 0.3537977337837219\n",
      "Loss for batch 53 = 0.17988944053649902\n",
      "Loss for batch 54 = 0.3482532203197479\n",
      "Loss for batch 55 = 0.4116300642490387\n",
      "Loss for batch 56 = 0.4299277663230896\n",
      "Loss for batch 57 = 0.27817338705062866\n",
      "Loss for batch 58 = 0.385990172624588\n",
      "Loss for batch 59 = 0.635714054107666\n",
      "Loss for batch 60 = 0.33166638016700745\n",
      "Loss for batch 61 = 0.6046239137649536\n",
      "Loss for batch 62 = 0.39167243242263794\n",
      "Loss for batch 63 = 0.46652883291244507\n",
      "Loss for batch 64 = 0.23078344762325287\n",
      "Loss for batch 65 = 0.3839651346206665\n",
      "Loss for batch 66 = 0.4202038645744324\n",
      "Loss for batch 67 = 0.7062469124794006\n",
      "Loss for batch 68 = 0.48535868525505066\n",
      "Loss for batch 69 = 0.47530844807624817\n",
      "Loss for batch 70 = 0.5621128678321838\n",
      "Loss for batch 71 = 0.4001481235027313\n",
      "Loss for batch 72 = 0.30204838514328003\n",
      "Loss for batch 73 = 0.4263545274734497\n",
      "Loss for batch 74 = 0.3044772446155548\n",
      "Loss for batch 75 = 0.5076473355293274\n",
      "Loss for batch 76 = 0.33964213728904724\n",
      "Loss for batch 77 = 0.3295208811759949\n",
      "Loss for batch 78 = 0.26848962903022766\n",
      "Loss for batch 79 = 0.35598164796829224\n",
      "Loss for batch 80 = 0.3677481710910797\n",
      "Loss for batch 81 = 0.44411566853523254\n",
      "Loss for batch 82 = 0.4613212049007416\n",
      "Loss for batch 83 = 0.5446444749832153\n",
      "Loss for batch 84 = 0.3998164236545563\n",
      "Loss for batch 85 = 0.33559122681617737\n",
      "Loss for batch 86 = 0.2709978520870209\n",
      "Loss for batch 87 = 0.36915352940559387\n",
      "Loss for batch 88 = 0.4842020273208618\n",
      "Loss for batch 89 = 0.54523766040802\n",
      "Loss for batch 90 = 0.44138020277023315\n",
      "Loss for batch 91 = 0.3949616551399231\n",
      "Loss for batch 92 = 0.36754265427589417\n",
      "Loss for batch 93 = 0.49577999114990234\n",
      "Loss for batch 94 = 0.42827412486076355\n",
      "Loss for batch 95 = 0.23122671246528625\n",
      "Loss for batch 96 = 0.5156350135803223\n",
      "Loss for batch 97 = 0.44566047191619873\n",
      "\n",
      "Training Loss for epoch 28 = 39.79829788208008\n",
      "\n",
      "Current Validation Loss = 33.67975616455078\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 14\n",
      "Train Accuracy: 79.04%\n",
      "Validation Accuracy: 59.31%\n",
      "\n",
      "Epoch 29\n",
      "----------\n",
      "Loss for batch 0 = 0.2026086151599884\n",
      "Loss for batch 1 = 0.5613759756088257\n",
      "Loss for batch 2 = 0.511515736579895\n",
      "Loss for batch 3 = 0.44506505131721497\n",
      "Loss for batch 4 = 0.4567399024963379\n",
      "Loss for batch 5 = 0.31544509530067444\n",
      "Loss for batch 6 = 0.387376070022583\n",
      "Loss for batch 7 = 0.46257805824279785\n",
      "Loss for batch 8 = 0.3941378891468048\n",
      "Loss for batch 9 = 0.22937580943107605\n",
      "Loss for batch 10 = 0.6838254928588867\n",
      "Loss for batch 11 = 0.23576810956001282\n",
      "Loss for batch 12 = 0.3487907946109772\n",
      "Loss for batch 13 = 0.40563124418258667\n",
      "Loss for batch 14 = 0.3011966347694397\n",
      "Loss for batch 15 = 0.4147005081176758\n",
      "Loss for batch 16 = 0.40998366475105286\n",
      "Loss for batch 17 = 0.30499860644340515\n",
      "Loss for batch 18 = 0.36137914657592773\n",
      "Loss for batch 19 = 0.32615959644317627\n",
      "Loss for batch 20 = 0.2448415458202362\n",
      "Loss for batch 21 = 0.3828096091747284\n",
      "Loss for batch 22 = 0.29638054966926575\n",
      "Loss for batch 23 = 0.29719278216362\n",
      "Loss for batch 24 = 0.31620270013809204\n",
      "Loss for batch 25 = 0.4246384799480438\n",
      "Loss for batch 26 = 0.5370700359344482\n",
      "Loss for batch 27 = 0.4304811656475067\n",
      "Loss for batch 28 = 0.3666069507598877\n",
      "Loss for batch 29 = 0.3703759014606476\n",
      "Loss for batch 30 = 0.4498906135559082\n",
      "Loss for batch 31 = 0.44688740372657776\n",
      "Loss for batch 32 = 0.4878571033477783\n",
      "Loss for batch 33 = 0.37927713990211487\n",
      "Loss for batch 34 = 0.5184754133224487\n",
      "Loss for batch 35 = 0.40336936712265015\n",
      "Loss for batch 36 = 0.5351555347442627\n",
      "Loss for batch 37 = 0.6269408464431763\n",
      "Loss for batch 38 = 0.3030635118484497\n",
      "Loss for batch 39 = 0.2989637851715088\n",
      "Loss for batch 40 = 0.5597562193870544\n",
      "Loss for batch 41 = 0.35394972562789917\n",
      "Loss for batch 42 = 0.3613908588886261\n",
      "Loss for batch 43 = 0.4277207851409912\n",
      "Loss for batch 44 = 0.351479709148407\n",
      "Loss for batch 45 = 0.34240901470184326\n",
      "Loss for batch 46 = 0.4062859117984772\n",
      "Loss for batch 47 = 0.464851975440979\n",
      "Loss for batch 48 = 0.4166366457939148\n",
      "Loss for batch 49 = 0.37204694747924805\n",
      "Loss for batch 50 = 0.5445568561553955\n",
      "Loss for batch 51 = 0.349760502576828\n",
      "Loss for batch 52 = 0.36523377895355225\n",
      "Loss for batch 53 = 0.18287457525730133\n",
      "Loss for batch 54 = 0.29665789008140564\n",
      "Loss for batch 55 = 0.4020344018936157\n",
      "Loss for batch 56 = 0.41135212779045105\n",
      "Loss for batch 57 = 0.23950029909610748\n",
      "Loss for batch 58 = 0.3736002445220947\n",
      "Loss for batch 59 = 0.6082512140274048\n",
      "Loss for batch 60 = 0.32160255312919617\n",
      "Loss for batch 61 = 0.5860253572463989\n",
      "Loss for batch 62 = 0.38427555561065674\n",
      "Loss for batch 63 = 0.44262295961380005\n",
      "Loss for batch 64 = 0.23995959758758545\n",
      "Loss for batch 65 = 0.39476636052131653\n",
      "Loss for batch 66 = 0.4154224097728729\n",
      "Loss for batch 67 = 0.6265705227851868\n",
      "Loss for batch 68 = 0.5017857551574707\n",
      "Loss for batch 69 = 0.43113136291503906\n",
      "Loss for batch 70 = 0.5467188358306885\n",
      "Loss for batch 71 = 0.38378122448921204\n",
      "Loss for batch 72 = 0.27511218190193176\n",
      "Loss for batch 73 = 0.4067220687866211\n",
      "Loss for batch 74 = 0.27180910110473633\n",
      "Loss for batch 75 = 0.5034980177879333\n",
      "Loss for batch 76 = 0.3345506191253662\n",
      "Loss for batch 77 = 0.3082502484321594\n",
      "Loss for batch 78 = 0.26215580105781555\n",
      "Loss for batch 79 = 0.3335135281085968\n",
      "Loss for batch 80 = 0.3648478388786316\n",
      "Loss for batch 81 = 0.4996008276939392\n",
      "Loss for batch 82 = 0.45491263270378113\n",
      "Loss for batch 83 = 0.5009924173355103\n",
      "Loss for batch 84 = 0.3782530426979065\n",
      "Loss for batch 85 = 0.3326447010040283\n",
      "Loss for batch 86 = 0.264882892370224\n",
      "Loss for batch 87 = 0.3643926978111267\n",
      "Loss for batch 88 = 0.43803825974464417\n",
      "Loss for batch 89 = 0.5166590213775635\n",
      "Loss for batch 90 = 0.4492575526237488\n",
      "Loss for batch 91 = 0.3811308741569519\n",
      "Loss for batch 92 = 0.3640178143978119\n",
      "Loss for batch 93 = 0.4883215129375458\n",
      "Loss for batch 94 = 0.2717493772506714\n",
      "Loss for batch 95 = 0.21164019405841827\n",
      "Loss for batch 96 = 0.48747584223747253\n",
      "Loss for batch 97 = 0.4481004476547241\n",
      "\n",
      "Training Loss for epoch 29 = 38.89266586303711\n",
      "\n",
      "Current Validation Loss = 32.90449523925781\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 15\n",
      "Train Accuracy: 82.67%\n",
      "Validation Accuracy: 59.95%\n",
      "\n",
      "Epoch 30\n",
      "----------\n",
      "Loss for batch 0 = 0.18310146033763885\n",
      "Loss for batch 1 = 0.4580313265323639\n",
      "Loss for batch 2 = 0.501096785068512\n",
      "Loss for batch 3 = 0.4197370409965515\n",
      "Loss for batch 4 = 0.44649195671081543\n",
      "Loss for batch 5 = 0.2975439727306366\n",
      "Loss for batch 6 = 0.3776055872440338\n",
      "Loss for batch 7 = 0.46522969007492065\n",
      "Loss for batch 8 = 0.3549959659576416\n",
      "Loss for batch 9 = 0.20795653760433197\n",
      "Loss for batch 10 = 0.6433472037315369\n",
      "Loss for batch 11 = 0.15955761075019836\n",
      "Loss for batch 12 = 0.3725041151046753\n",
      "Loss for batch 13 = 0.3993024230003357\n",
      "Loss for batch 14 = 0.2552095949649811\n",
      "Loss for batch 15 = 0.3595837950706482\n",
      "Loss for batch 16 = 0.404906690120697\n",
      "Loss for batch 17 = 0.281308650970459\n",
      "Loss for batch 18 = 0.3705243766307831\n",
      "Loss for batch 19 = 0.3260119557380676\n",
      "Loss for batch 20 = 0.1800939291715622\n",
      "Loss for batch 21 = 0.3180316090583801\n",
      "Loss for batch 22 = 0.26197734475135803\n",
      "Loss for batch 23 = 0.3395814299583435\n",
      "Loss for batch 24 = 0.3290330767631531\n",
      "Loss for batch 25 = 0.4559958875179291\n",
      "Loss for batch 26 = 0.5072450637817383\n",
      "Loss for batch 27 = 0.41605639457702637\n",
      "Loss for batch 28 = 0.3859238028526306\n",
      "Loss for batch 29 = 0.31398865580558777\n",
      "Loss for batch 30 = 0.40085119009017944\n",
      "Loss for batch 31 = 0.2752890884876251\n",
      "Loss for batch 32 = 0.520169734954834\n",
      "Loss for batch 33 = 0.35816362500190735\n",
      "Loss for batch 34 = 0.5175456404685974\n",
      "Loss for batch 35 = 0.39881807565689087\n",
      "Loss for batch 36 = 0.5413411259651184\n",
      "Loss for batch 37 = 0.6842705011367798\n",
      "Loss for batch 38 = 0.29794496297836304\n",
      "Loss for batch 39 = 0.3472858667373657\n",
      "Loss for batch 40 = 0.5723152160644531\n",
      "Loss for batch 41 = 0.3474653661251068\n",
      "Loss for batch 42 = 0.345689594745636\n",
      "Loss for batch 43 = 0.4000702202320099\n",
      "Loss for batch 44 = 0.30848145484924316\n",
      "Loss for batch 45 = 0.35643482208251953\n",
      "Loss for batch 46 = 0.4059276878833771\n",
      "Loss for batch 47 = 0.4706825017929077\n",
      "Loss for batch 48 = 0.4193013310432434\n",
      "Loss for batch 49 = 0.34499847888946533\n",
      "Loss for batch 50 = 0.5098384022712708\n",
      "Loss for batch 51 = 0.23589298129081726\n",
      "Loss for batch 52 = 0.3320668041706085\n",
      "Loss for batch 53 = 0.16421687602996826\n",
      "Loss for batch 54 = 0.2879641354084015\n",
      "Loss for batch 55 = 0.39054644107818604\n",
      "Loss for batch 56 = 0.41236427426338196\n",
      "Loss for batch 57 = 0.22860020399093628\n",
      "Loss for batch 58 = 0.37046971917152405\n",
      "Loss for batch 59 = 0.6126353144645691\n",
      "Loss for batch 60 = 0.28734639286994934\n",
      "Loss for batch 61 = 0.5943459868431091\n",
      "Loss for batch 62 = 0.36174243688583374\n",
      "Loss for batch 63 = 0.495694637298584\n",
      "Loss for batch 64 = 0.20472855865955353\n",
      "Loss for batch 65 = 0.38076746463775635\n",
      "Loss for batch 66 = 0.42529773712158203\n",
      "Loss for batch 67 = 0.5985340476036072\n",
      "Loss for batch 68 = 0.4866134822368622\n",
      "Loss for batch 69 = 0.41237980127334595\n",
      "Loss for batch 70 = 0.5473672151565552\n",
      "Loss for batch 71 = 0.3751216530799866\n",
      "Loss for batch 72 = 0.22891865670681\n",
      "Loss for batch 73 = 0.3906693756580353\n",
      "Loss for batch 74 = 0.24603402614593506\n",
      "Loss for batch 75 = 0.5246371626853943\n",
      "Loss for batch 76 = 0.330427885055542\n",
      "Loss for batch 77 = 0.31741559505462646\n",
      "Loss for batch 78 = 0.24585793912410736\n",
      "Loss for batch 79 = 0.32213690876960754\n",
      "Loss for batch 80 = 0.36048659682273865\n",
      "Loss for batch 81 = 0.49101951718330383\n",
      "Loss for batch 82 = 0.43414321541786194\n",
      "Loss for batch 83 = 0.512466549873352\n",
      "Loss for batch 84 = 0.38229134678840637\n",
      "Loss for batch 85 = 0.28909242153167725\n",
      "Loss for batch 86 = 0.28618520498275757\n",
      "Loss for batch 87 = 0.35749274492263794\n",
      "Loss for batch 88 = 0.4232789874076843\n",
      "Loss for batch 89 = 0.5275532007217407\n",
      "Loss for batch 90 = 0.4244173765182495\n",
      "Loss for batch 91 = 0.3607584238052368\n",
      "Loss for batch 92 = 0.3734886646270752\n",
      "Loss for batch 93 = 0.41529709100723267\n",
      "Loss for batch 94 = 0.29565444588661194\n",
      "Loss for batch 95 = 0.21842561662197113\n",
      "Loss for batch 96 = 0.47158563137054443\n",
      "Loss for batch 97 = 0.4174922704696655\n",
      "\n",
      "Training Loss for epoch 30 = 37.4667854309082\n",
      "\n",
      "Current Validation Loss = 35.34668731689453\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 16\n",
      "Train Accuracy: 83.44%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 31\n",
      "----------\n",
      "Loss for batch 0 = 0.15559571981430054\n",
      "Loss for batch 1 = 0.43740296363830566\n",
      "Loss for batch 2 = 0.5058091878890991\n",
      "Loss for batch 3 = 0.4126491844654083\n",
      "Loss for batch 4 = 0.43372008204460144\n",
      "Loss for batch 5 = 0.30006250739097595\n",
      "Loss for batch 6 = 0.3128325939178467\n",
      "Loss for batch 7 = 0.44911593198776245\n",
      "Loss for batch 8 = 0.3145674467086792\n",
      "Loss for batch 9 = 0.1938059777021408\n",
      "Loss for batch 10 = 0.6429958343505859\n",
      "Loss for batch 11 = 0.12746480107307434\n",
      "Loss for batch 12 = 0.33922868967056274\n",
      "Loss for batch 13 = 0.46657654643058777\n",
      "Loss for batch 14 = 0.24638788402080536\n",
      "Loss for batch 15 = 0.30865558981895447\n",
      "Loss for batch 16 = 0.3326186537742615\n",
      "Loss for batch 17 = 0.29725897312164307\n",
      "Loss for batch 18 = 0.34285780787467957\n",
      "Loss for batch 19 = 0.32247909903526306\n",
      "Loss for batch 20 = 0.1787392646074295\n",
      "Loss for batch 21 = 0.32413819432258606\n",
      "Loss for batch 22 = 0.24569325149059296\n",
      "Loss for batch 23 = 0.28278791904449463\n",
      "Loss for batch 24 = 0.2843756675720215\n",
      "Loss for batch 25 = 0.5008945465087891\n",
      "Loss for batch 26 = 0.5342869162559509\n",
      "Loss for batch 27 = 0.37797561287879944\n",
      "Loss for batch 28 = 0.33128517866134644\n",
      "Loss for batch 29 = 0.28431469202041626\n",
      "Loss for batch 30 = 0.4021197557449341\n",
      "Loss for batch 31 = 0.3031395673751831\n",
      "Loss for batch 32 = 0.47280558943748474\n",
      "Loss for batch 33 = 0.338299423456192\n",
      "Loss for batch 34 = 0.4513869881629944\n",
      "Loss for batch 35 = 0.37439998984336853\n",
      "Loss for batch 36 = 0.5030958652496338\n",
      "Loss for batch 37 = 0.5795658826828003\n",
      "Loss for batch 38 = 0.2720605432987213\n",
      "Loss for batch 39 = 0.30108508467674255\n",
      "Loss for batch 40 = 0.5884010791778564\n",
      "Loss for batch 41 = 0.3409932553768158\n",
      "Loss for batch 42 = 0.37461739778518677\n",
      "Loss for batch 43 = 0.3785131573677063\n",
      "Loss for batch 44 = 0.3399360179901123\n",
      "Loss for batch 45 = 0.2699381709098816\n",
      "Loss for batch 46 = 0.36927586793899536\n",
      "Loss for batch 47 = 0.5305195450782776\n",
      "Loss for batch 48 = 0.3964131474494934\n",
      "Loss for batch 49 = 0.3652920722961426\n",
      "Loss for batch 50 = 0.4895043969154358\n",
      "Loss for batch 51 = 0.44389551877975464\n",
      "Loss for batch 52 = 0.3439735770225525\n",
      "Loss for batch 53 = 0.16928039491176605\n",
      "Loss for batch 54 = 0.3255518674850464\n",
      "Loss for batch 55 = 0.460684597492218\n",
      "Loss for batch 56 = 0.3734794855117798\n",
      "Loss for batch 57 = 0.23314204812049866\n",
      "Loss for batch 58 = 0.3632781505584717\n",
      "Loss for batch 59 = 0.5875743627548218\n",
      "Loss for batch 60 = 0.2852476239204407\n",
      "Loss for batch 61 = 0.6180494427680969\n",
      "Loss for batch 62 = 0.3698856830596924\n",
      "Loss for batch 63 = 0.4768284261226654\n",
      "Loss for batch 64 = 0.31159600615501404\n",
      "Loss for batch 65 = 0.3975338339805603\n",
      "Loss for batch 66 = 0.423132985830307\n",
      "Loss for batch 67 = 0.6315721273422241\n",
      "Loss for batch 68 = 0.48220402002334595\n",
      "Loss for batch 69 = 0.4021236002445221\n",
      "Loss for batch 70 = 0.539992094039917\n",
      "Loss for batch 71 = 0.3813837766647339\n",
      "Loss for batch 72 = 0.4291155934333801\n",
      "Loss for batch 73 = 0.3967423141002655\n",
      "Loss for batch 74 = 0.2567286491394043\n",
      "Loss for batch 75 = 0.4710354208946228\n",
      "Loss for batch 76 = 0.33021286129951477\n",
      "Loss for batch 77 = 0.289441853761673\n",
      "Loss for batch 78 = 0.223361074924469\n",
      "Loss for batch 79 = 0.33312562108039856\n",
      "Loss for batch 80 = 0.34594252705574036\n",
      "Loss for batch 81 = 0.50869220495224\n",
      "Loss for batch 82 = 0.4413149654865265\n",
      "Loss for batch 83 = 0.454892098903656\n",
      "Loss for batch 84 = 0.36955225467681885\n",
      "Loss for batch 85 = 0.2742834985256195\n",
      "Loss for batch 86 = 0.261381059885025\n",
      "Loss for batch 87 = 0.3588659465312958\n",
      "Loss for batch 88 = 0.41043609380722046\n",
      "Loss for batch 89 = 0.5383856892585754\n",
      "Loss for batch 90 = 0.4446822702884674\n",
      "Loss for batch 91 = 0.4545999765396118\n",
      "Loss for batch 92 = 0.36609339714050293\n",
      "Loss for batch 93 = 0.37633952498435974\n",
      "Loss for batch 94 = 0.28921234607696533\n",
      "Loss for batch 95 = 0.2357931286096573\n",
      "Loss for batch 96 = 0.49839967489242554\n",
      "Loss for batch 97 = 0.47486385703086853\n",
      "\n",
      "Training Loss for epoch 31 = 37.181846618652344\n",
      "\n",
      "Current Validation Loss = 34.04604721069336\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 17\n",
      "Train Accuracy: 83.22%\n",
      "Validation Accuracy: 60.85%\n",
      "\n",
      "Epoch 32\n",
      "----------\n",
      "Loss for batch 0 = 0.15279264748096466\n",
      "Loss for batch 1 = 0.37987276911735535\n",
      "Loss for batch 2 = 0.5451667308807373\n",
      "Loss for batch 3 = 0.3790280222892761\n",
      "Loss for batch 4 = 0.4496726989746094\n",
      "Loss for batch 5 = 0.31404662132263184\n",
      "Loss for batch 6 = 0.31916144490242004\n",
      "Loss for batch 7 = 0.4577881693840027\n",
      "Loss for batch 8 = 0.3597331643104553\n",
      "Loss for batch 9 = 0.18299996852874756\n",
      "Loss for batch 10 = 0.5901181101799011\n",
      "Loss for batch 11 = 0.13207940757274628\n",
      "Loss for batch 12 = 0.34031665325164795\n",
      "Loss for batch 13 = 0.3882986605167389\n",
      "Loss for batch 14 = 0.23529726266860962\n",
      "Loss for batch 15 = 0.3165922462940216\n",
      "Loss for batch 16 = 0.3681880235671997\n",
      "Loss for batch 17 = 0.26405423879623413\n",
      "Loss for batch 18 = 0.39419010281562805\n",
      "Loss for batch 19 = 0.3257167339324951\n",
      "Loss for batch 20 = 0.19441185891628265\n",
      "Loss for batch 21 = 0.32896050810813904\n",
      "Loss for batch 22 = 0.2924859821796417\n",
      "Loss for batch 23 = 0.3140227198600769\n",
      "Loss for batch 24 = 0.34539857506752014\n",
      "Loss for batch 25 = 0.44118794798851013\n",
      "Loss for batch 26 = 0.5064170360565186\n",
      "Loss for batch 27 = 0.39776483178138733\n",
      "Loss for batch 28 = 0.3591713607311249\n",
      "Loss for batch 29 = 0.3158891201019287\n",
      "Loss for batch 30 = 0.34851089119911194\n",
      "Loss for batch 31 = 0.28100886940956116\n",
      "Loss for batch 32 = 0.4758451581001282\n",
      "Loss for batch 33 = 0.33450713753700256\n",
      "Loss for batch 34 = 0.5121335387229919\n",
      "Loss for batch 35 = 0.3762175440788269\n",
      "Loss for batch 36 = 0.4868786036968231\n",
      "Loss for batch 37 = 0.5675258636474609\n",
      "Loss for batch 38 = 0.2830410897731781\n",
      "Loss for batch 39 = 0.4221241772174835\n",
      "Loss for batch 40 = 0.5367382764816284\n",
      "Loss for batch 41 = 0.3332973122596741\n",
      "Loss for batch 42 = 0.36977124214172363\n",
      "Loss for batch 43 = 0.5253952741622925\n",
      "Loss for batch 44 = 0.3396117687225342\n",
      "Loss for batch 45 = 0.292696475982666\n",
      "Loss for batch 46 = 0.45229947566986084\n",
      "Loss for batch 47 = 0.42520344257354736\n",
      "Loss for batch 48 = 0.38591036200523376\n",
      "Loss for batch 49 = 0.43543222546577454\n",
      "Loss for batch 50 = 0.5185667276382446\n",
      "Loss for batch 51 = 0.22973139584064484\n",
      "Loss for batch 52 = 0.3462376594543457\n",
      "Loss for batch 53 = 0.1871875673532486\n",
      "Loss for batch 54 = 0.2926367521286011\n",
      "Loss for batch 55 = 0.40349042415618896\n",
      "Loss for batch 56 = 0.44181716442108154\n",
      "Loss for batch 57 = 0.2294449508190155\n",
      "Loss for batch 58 = 0.38690897822380066\n",
      "Loss for batch 59 = 0.5452108979225159\n",
      "Loss for batch 60 = 0.2796032428741455\n",
      "Loss for batch 61 = 0.5760727524757385\n",
      "Loss for batch 62 = 0.3529621362686157\n",
      "Loss for batch 63 = 0.4425850510597229\n",
      "Loss for batch 64 = 0.28676193952560425\n",
      "Loss for batch 65 = 0.3688899874687195\n",
      "Loss for batch 66 = 0.4395192265510559\n",
      "Loss for batch 67 = 0.5995137095451355\n",
      "Loss for batch 68 = 0.5095449090003967\n",
      "Loss for batch 69 = 0.413139671087265\n",
      "Loss for batch 70 = 0.6003998517990112\n",
      "Loss for batch 71 = 0.5103368759155273\n",
      "Loss for batch 72 = 0.38328275084495544\n",
      "Loss for batch 73 = 0.38870882987976074\n",
      "Loss for batch 74 = 0.26237303018569946\n",
      "Loss for batch 75 = 0.6723078489303589\n",
      "Loss for batch 76 = 0.3713264465332031\n",
      "Loss for batch 77 = 0.3015511929988861\n",
      "Loss for batch 78 = 0.23913687467575073\n",
      "Loss for batch 79 = 0.3807501494884491\n",
      "Loss for batch 80 = 0.3526788353919983\n",
      "Loss for batch 81 = 0.4181978404521942\n",
      "Loss for batch 82 = 0.4633708596229553\n",
      "Loss for batch 83 = 0.45592352747917175\n",
      "Loss for batch 84 = 0.3682907223701477\n",
      "Loss for batch 85 = 0.2832377254962921\n",
      "Loss for batch 86 = 0.29196763038635254\n",
      "Loss for batch 87 = 0.35042011737823486\n",
      "Loss for batch 88 = 0.4372829794883728\n",
      "Loss for batch 89 = 0.5343706011772156\n",
      "Loss for batch 90 = 0.41907066106796265\n",
      "Loss for batch 91 = 0.38743630051612854\n",
      "Loss for batch 92 = 0.3874777555465698\n",
      "Loss for batch 93 = 0.3352265954017639\n",
      "Loss for batch 94 = 0.2684900760650635\n",
      "Loss for batch 95 = 0.2563285231590271\n",
      "Loss for batch 96 = 0.4807496964931488\n",
      "Loss for batch 97 = 0.4175308644771576\n",
      "\n",
      "Training Loss for epoch 32 = 37.443023681640625\n",
      "\n",
      "Current Validation Loss = 33.59243392944336\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 18\n",
      "Train Accuracy: 83.92%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 33\n",
      "----------\n",
      "Loss for batch 0 = 0.17185162007808685\n",
      "Loss for batch 1 = 0.41318947076797485\n",
      "Loss for batch 2 = 0.49782896041870117\n",
      "Loss for batch 3 = 0.373860627412796\n",
      "Loss for batch 4 = 0.43588024377822876\n",
      "Loss for batch 5 = 0.32221534848213196\n",
      "Loss for batch 6 = 0.4177686870098114\n",
      "Loss for batch 7 = 0.42137590050697327\n",
      "Loss for batch 8 = 0.346283495426178\n",
      "Loss for batch 9 = 0.20308896899223328\n",
      "Loss for batch 10 = 0.5279613733291626\n",
      "Loss for batch 11 = 0.1362375020980835\n",
      "Loss for batch 12 = 0.3804475963115692\n",
      "Loss for batch 13 = 0.3995436131954193\n",
      "Loss for batch 14 = 0.2701103687286377\n",
      "Loss for batch 15 = 0.2882249355316162\n",
      "Loss for batch 16 = 0.3715290427207947\n",
      "Loss for batch 17 = 0.22944419085979462\n",
      "Loss for batch 18 = 0.36151278018951416\n",
      "Loss for batch 19 = 0.29956164956092834\n",
      "Loss for batch 20 = 0.16503728926181793\n",
      "Loss for batch 21 = 0.31748735904693604\n",
      "Loss for batch 22 = 0.26194998621940613\n",
      "Loss for batch 23 = 0.27957481145858765\n",
      "Loss for batch 24 = 0.2675999402999878\n",
      "Loss for batch 25 = 0.4363718032836914\n",
      "Loss for batch 26 = 0.45554426312446594\n",
      "Loss for batch 27 = 0.38366401195526123\n",
      "Loss for batch 28 = 0.3266794979572296\n",
      "Loss for batch 29 = 0.2880229949951172\n",
      "Loss for batch 30 = 0.3692860007286072\n",
      "Loss for batch 31 = 0.2389848679304123\n",
      "Loss for batch 32 = 0.44637858867645264\n",
      "Loss for batch 33 = 0.327210932970047\n",
      "Loss for batch 34 = 0.4855532944202423\n",
      "Loss for batch 35 = 0.3684304356575012\n",
      "Loss for batch 36 = 0.4398864209651947\n",
      "Loss for batch 37 = 0.4925537109375\n",
      "Loss for batch 38 = 0.3102007210254669\n",
      "Loss for batch 39 = 0.31722936034202576\n",
      "Loss for batch 40 = 0.564681887626648\n",
      "Loss for batch 41 = 0.35375428199768066\n",
      "Loss for batch 42 = 0.375479519367218\n",
      "Loss for batch 43 = 0.3685683310031891\n",
      "Loss for batch 44 = 0.30267444252967834\n",
      "Loss for batch 45 = 0.29579630494117737\n",
      "Loss for batch 46 = 0.3525683283805847\n",
      "Loss for batch 47 = 0.4146483242511749\n",
      "Loss for batch 48 = 0.3639267086982727\n",
      "Loss for batch 49 = 0.3315476179122925\n",
      "Loss for batch 50 = 0.4417777359485626\n",
      "Loss for batch 51 = 0.22492673993110657\n",
      "Loss for batch 52 = 0.3133941888809204\n",
      "Loss for batch 53 = 0.0937475860118866\n",
      "Loss for batch 54 = 0.230695441365242\n",
      "Loss for batch 55 = 0.37968218326568604\n",
      "Loss for batch 56 = 0.3681733012199402\n",
      "Loss for batch 57 = 0.23704387247562408\n",
      "Loss for batch 58 = 0.3465624451637268\n",
      "Loss for batch 59 = 0.5289995670318604\n",
      "Loss for batch 60 = 0.23462767899036407\n",
      "Loss for batch 61 = 0.5694495439529419\n",
      "Loss for batch 62 = 0.33447587490081787\n",
      "Loss for batch 63 = 0.36403146386146545\n",
      "Loss for batch 64 = 0.1688206046819687\n",
      "Loss for batch 65 = 0.32631978392601013\n",
      "Loss for batch 66 = 0.4039857089519501\n",
      "Loss for batch 67 = 0.5345998406410217\n",
      "Loss for batch 68 = 0.48522108793258667\n",
      "Loss for batch 69 = 0.39247041940689087\n",
      "Loss for batch 70 = 0.5169404149055481\n",
      "Loss for batch 71 = 0.3969942331314087\n",
      "Loss for batch 72 = 0.23380248248577118\n",
      "Loss for batch 73 = 0.37844783067703247\n",
      "Loss for batch 74 = 0.22278280556201935\n",
      "Loss for batch 75 = 0.4174567759037018\n",
      "Loss for batch 76 = 0.31259509921073914\n",
      "Loss for batch 77 = 0.2956574857234955\n",
      "Loss for batch 78 = 0.2009151428937912\n",
      "Loss for batch 79 = 0.2626917064189911\n",
      "Loss for batch 80 = 0.31748151779174805\n",
      "Loss for batch 81 = 0.4377173185348511\n",
      "Loss for batch 82 = 0.3914499282836914\n",
      "Loss for batch 83 = 0.4232828915119171\n",
      "Loss for batch 84 = 0.37056902050971985\n",
      "Loss for batch 85 = 0.25653213262557983\n",
      "Loss for batch 86 = 0.24618040025234222\n",
      "Loss for batch 87 = 0.32991576194763184\n",
      "Loss for batch 88 = 0.3356289565563202\n",
      "Loss for batch 89 = 0.5027433037757874\n",
      "Loss for batch 90 = 0.41155123710632324\n",
      "Loss for batch 91 = 0.3524712920188904\n",
      "Loss for batch 92 = 0.3437396287918091\n",
      "Loss for batch 93 = 0.2891249656677246\n",
      "Loss for batch 94 = 0.26945212483406067\n",
      "Loss for batch 95 = 0.1820167601108551\n",
      "Loss for batch 96 = 0.4866698682308197\n",
      "Loss for batch 97 = 0.3792060315608978\n",
      "\n",
      "Training Loss for epoch 33 = 34.11223602294922\n",
      "\n",
      "Current Validation Loss = 34.57661819458008\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 19\n",
      "Train Accuracy: 85.69%\n",
      "Validation Accuracy: 60.59%\n",
      "\n",
      "Epoch 34\n",
      "----------\n",
      "Loss for batch 0 = 0.16694201529026031\n",
      "Loss for batch 1 = 0.3360203504562378\n",
      "Loss for batch 2 = 0.4849966764450073\n",
      "Loss for batch 3 = 0.34173208475112915\n",
      "Loss for batch 4 = 0.40299665927886963\n",
      "Loss for batch 5 = 0.29973089694976807\n",
      "Loss for batch 6 = 0.2983376383781433\n",
      "Loss for batch 7 = 0.40929943323135376\n",
      "Loss for batch 8 = 0.33988314867019653\n",
      "Loss for batch 9 = 0.19107526540756226\n",
      "Loss for batch 10 = 0.5254601836204529\n",
      "Loss for batch 11 = 0.13927516341209412\n",
      "Loss for batch 12 = 0.3494024872779846\n",
      "Loss for batch 13 = 0.39697882533073425\n",
      "Loss for batch 14 = 0.21487978100776672\n",
      "Loss for batch 15 = 0.28798454999923706\n",
      "Loss for batch 16 = 0.3517521321773529\n",
      "Loss for batch 17 = 0.20819224417209625\n",
      "Loss for batch 18 = 0.3590370714664459\n",
      "Loss for batch 19 = 0.2914126515388489\n",
      "Loss for batch 20 = 0.15376609563827515\n",
      "Loss for batch 21 = 0.316569447517395\n",
      "Loss for batch 22 = 0.26223912835121155\n",
      "Loss for batch 23 = 0.26385247707366943\n",
      "Loss for batch 24 = 0.2697940766811371\n",
      "Loss for batch 25 = 0.43843287229537964\n",
      "Loss for batch 26 = 0.44324618577957153\n",
      "Loss for batch 27 = 0.35946813225746155\n",
      "Loss for batch 28 = 0.3233855962753296\n",
      "Loss for batch 29 = 0.24991846084594727\n",
      "Loss for batch 30 = 0.30249983072280884\n",
      "Loss for batch 31 = 0.19710773229599\n",
      "Loss for batch 32 = 0.45237573981285095\n",
      "Loss for batch 33 = 0.32566529512405396\n",
      "Loss for batch 34 = 0.4428005814552307\n",
      "Loss for batch 35 = 0.35725679993629456\n",
      "Loss for batch 36 = 0.42075812816619873\n",
      "Loss for batch 37 = 0.443477064371109\n",
      "Loss for batch 38 = 0.2964780330657959\n",
      "Loss for batch 39 = 0.2991798222064972\n",
      "Loss for batch 40 = 0.5359827280044556\n",
      "Loss for batch 41 = 0.34882113337516785\n",
      "Loss for batch 42 = 0.3522794842720032\n",
      "Loss for batch 43 = 0.3596360981464386\n",
      "Loss for batch 44 = 0.2926456928253174\n",
      "Loss for batch 45 = 0.27420470118522644\n",
      "Loss for batch 46 = 0.3255626857280731\n",
      "Loss for batch 47 = 0.3972964286804199\n",
      "Loss for batch 48 = 0.3486645221710205\n",
      "Loss for batch 49 = 0.3145999312400818\n",
      "Loss for batch 50 = 0.43168216943740845\n",
      "Loss for batch 51 = 0.22167572379112244\n",
      "Loss for batch 52 = 0.30966779589653015\n",
      "Loss for batch 53 = 0.0831141471862793\n",
      "Loss for batch 54 = 0.21161124110221863\n",
      "Loss for batch 55 = 0.3652268052101135\n",
      "Loss for batch 56 = 0.36789214611053467\n",
      "Loss for batch 57 = 0.22045589983463287\n",
      "Loss for batch 58 = 0.3391413986682892\n",
      "Loss for batch 59 = 0.54036945104599\n",
      "Loss for batch 60 = 0.20573657751083374\n",
      "Loss for batch 61 = 0.5620425343513489\n",
      "Loss for batch 62 = 0.327756404876709\n",
      "Loss for batch 63 = 0.3221098482608795\n",
      "Loss for batch 64 = 0.16262215375900269\n",
      "Loss for batch 65 = 0.3046274185180664\n",
      "Loss for batch 66 = 0.42193520069122314\n",
      "Loss for batch 67 = 0.4891760051250458\n",
      "Loss for batch 68 = 0.4853661060333252\n",
      "Loss for batch 69 = 0.31984904408454895\n",
      "Loss for batch 70 = 0.5265551209449768\n",
      "Loss for batch 71 = 0.3596878945827484\n",
      "Loss for batch 72 = 0.20203553140163422\n",
      "Loss for batch 73 = 0.3071926534175873\n",
      "Loss for batch 74 = 0.21271824836730957\n",
      "Loss for batch 75 = 0.4227200746536255\n",
      "Loss for batch 76 = 0.3069349527359009\n",
      "Loss for batch 77 = 0.30518248677253723\n",
      "Loss for batch 78 = 0.19125208258628845\n",
      "Loss for batch 79 = 0.23485074937343597\n",
      "Loss for batch 80 = 0.3028869032859802\n",
      "Loss for batch 81 = 0.5014925003051758\n",
      "Loss for batch 82 = 0.3910878598690033\n",
      "Loss for batch 83 = 0.386640727519989\n",
      "Loss for batch 84 = 0.37338802218437195\n",
      "Loss for batch 85 = 0.24202971160411835\n",
      "Loss for batch 86 = 0.2544710636138916\n",
      "Loss for batch 87 = 0.32946282625198364\n",
      "Loss for batch 88 = 0.3169894516468048\n",
      "Loss for batch 89 = 0.5094447731971741\n",
      "Loss for batch 90 = 0.3966630697250366\n",
      "Loss for batch 91 = 0.33018043637275696\n",
      "Loss for batch 92 = 0.33559849858283997\n",
      "Loss for batch 93 = 0.2872769236564636\n",
      "Loss for batch 94 = 0.26598265767097473\n",
      "Loss for batch 95 = 0.17503991723060608\n",
      "Loss for batch 96 = 0.46702802181243896\n",
      "Loss for batch 97 = 0.35080477595329285\n",
      "\n",
      "Training Loss for epoch 34 = 32.54100799560547\n",
      "\n",
      "Current Validation Loss = 36.103572845458984\n",
      "Best Validation Loss = 21.759511947631836\n",
      "Epochs without Improvement = 20\n",
      "Train Accuracy: 86.36%\n",
      "Validation Accuracy: 61.36%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainLoopText(text_modelv2, optimizer, loss_fn, train_loader, val_loader, scheduler, 100, 20, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\College\\Projects\\Multimodal Sentiment Analysis using Text and Images\\Notebooks\\lstm.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/College/Projects/Multimodal%20Sentiment%20Analysis%20using%20Text%20and%20Images/Notebooks/lstm.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m true_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/College/Projects/Multimodal%20Sentiment%20Analysis%20using%20Text%20and%20Images/Notebooks/lstm.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pred_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/College/Projects/Multimodal%20Sentiment%20Analysis%20using%20Text%20and%20Images/Notebooks/lstm.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/College/Projects/Multimodal%20Sentiment%20Analysis%20using%20Text%20and%20Images/Notebooks/lstm.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/College/Projects/Multimodal%20Sentiment%20Analysis%20using%20Text%20and%20Images/Notebooks/lstm.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         texts \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mtext_indices\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv2(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_modelv2.state_dict(), 'LSTMv2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "text_modelv3 = LSTMmodel(4, 25, 256, bidirectionality=True, freeze=True)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.NAdam(text_modelv3.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d17186fd904e448b08fef751918342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "----------\n",
      "Loss for batch 0 = 1.096352458000183\n",
      "Loss for batch 1 = 1.1008837223052979\n",
      "Loss for batch 2 = 1.1001369953155518\n",
      "Loss for batch 3 = 1.0810010433197021\n",
      "Loss for batch 4 = 1.1035044193267822\n",
      "Loss for batch 5 = 1.1053858995437622\n",
      "Loss for batch 6 = 1.1106619834899902\n",
      "Loss for batch 7 = 1.0957162380218506\n",
      "Loss for batch 8 = 1.0877461433410645\n",
      "Loss for batch 9 = 1.0609874725341797\n",
      "Loss for batch 10 = 1.1880054473876953\n",
      "Loss for batch 11 = 1.1047719717025757\n",
      "Loss for batch 12 = 1.1022535562515259\n",
      "Loss for batch 13 = 1.1054356098175049\n",
      "Loss for batch 14 = 1.090705156326294\n",
      "Loss for batch 15 = 1.0813504457473755\n",
      "Loss for batch 16 = 1.0923484563827515\n",
      "Loss for batch 17 = 1.0970937013626099\n",
      "Loss for batch 18 = 1.0876621007919312\n",
      "Loss for batch 19 = 1.0764578580856323\n",
      "Loss for batch 20 = 1.0691678524017334\n",
      "Loss for batch 21 = 1.0835752487182617\n",
      "Loss for batch 22 = 1.0935145616531372\n",
      "Loss for batch 23 = 1.0986700057983398\n",
      "Loss for batch 24 = 1.142267107963562\n",
      "Loss for batch 25 = 1.1083630323410034\n",
      "Loss for batch 26 = 1.09646737575531\n",
      "Loss for batch 27 = 1.0759538412094116\n",
      "Loss for batch 28 = 1.1060025691986084\n",
      "Loss for batch 29 = 1.1109998226165771\n",
      "Loss for batch 30 = 1.1033239364624023\n",
      "Loss for batch 31 = 1.120260238647461\n",
      "Loss for batch 32 = 1.0821346044540405\n",
      "Loss for batch 33 = 1.0995242595672607\n",
      "Loss for batch 34 = 1.0939643383026123\n",
      "Loss for batch 35 = 1.0971124172210693\n",
      "Loss for batch 36 = 1.1035568714141846\n",
      "Loss for batch 37 = 1.0956230163574219\n",
      "Loss for batch 38 = 1.0843226909637451\n",
      "Loss for batch 39 = 1.0909130573272705\n",
      "Loss for batch 40 = 1.0695592164993286\n",
      "Loss for batch 41 = 1.0530285835266113\n",
      "Loss for batch 42 = 1.2378839254379272\n",
      "Loss for batch 43 = 1.0906822681427002\n",
      "Loss for batch 44 = 1.0798156261444092\n",
      "Loss for batch 45 = 1.0937798023223877\n",
      "Loss for batch 46 = 1.0997962951660156\n",
      "Loss for batch 47 = 1.0769282579421997\n",
      "Loss for batch 48 = 1.104761004447937\n",
      "Loss for batch 49 = 1.0949667692184448\n",
      "Loss for batch 50 = 1.0802916288375854\n",
      "Loss for batch 51 = 1.0688376426696777\n",
      "Loss for batch 52 = 1.1678320169448853\n",
      "Loss for batch 53 = 1.0912277698516846\n",
      "Loss for batch 54 = 1.0954281091690063\n",
      "Loss for batch 55 = 1.0933750867843628\n",
      "Loss for batch 56 = 1.0715487003326416\n",
      "Loss for batch 57 = 1.0842392444610596\n",
      "Loss for batch 58 = 1.0281120538711548\n",
      "Loss for batch 59 = 1.071677803993225\n",
      "Loss for batch 60 = 1.148876428604126\n",
      "Loss for batch 61 = 1.0708019733428955\n",
      "Loss for batch 62 = 1.0298707485198975\n",
      "Loss for batch 63 = 1.0656039714813232\n",
      "Loss for batch 64 = 1.0374412536621094\n",
      "Loss for batch 65 = 1.0724776983261108\n",
      "Loss for batch 66 = 1.271774172782898\n",
      "Loss for batch 67 = 0.9872077107429504\n",
      "Loss for batch 68 = 1.129454493522644\n",
      "Loss for batch 69 = 1.144583821296692\n",
      "Loss for batch 70 = 1.1268187761306763\n",
      "Loss for batch 71 = 1.0826356410980225\n",
      "Loss for batch 72 = 1.0666422843933105\n",
      "Loss for batch 73 = 1.104905366897583\n",
      "Loss for batch 74 = 1.0746560096740723\n",
      "Loss for batch 75 = 1.0915286540985107\n",
      "Loss for batch 76 = 1.0694966316223145\n",
      "Loss for batch 77 = 1.0589052438735962\n",
      "Loss for batch 78 = 1.0885798931121826\n",
      "Loss for batch 79 = 1.064563274383545\n",
      "Loss for batch 80 = 1.1065329313278198\n",
      "Loss for batch 81 = 1.1090210676193237\n",
      "Loss for batch 82 = 1.097622036933899\n",
      "Loss for batch 83 = 1.1178867816925049\n",
      "Loss for batch 84 = 1.0929197072982788\n",
      "Loss for batch 85 = 1.1099578142166138\n",
      "Loss for batch 86 = 1.0730153322219849\n",
      "Loss for batch 87 = 1.0998406410217285\n",
      "Loss for batch 88 = 1.04448664188385\n",
      "Loss for batch 89 = 1.088677167892456\n",
      "Loss for batch 90 = 1.0934938192367554\n",
      "Loss for batch 91 = 1.1409962177276611\n",
      "Loss for batch 92 = 1.0480960607528687\n",
      "Loss for batch 93 = 1.0672165155410767\n",
      "Loss for batch 94 = 1.1223485469818115\n",
      "Loss for batch 95 = 1.1110457181930542\n",
      "Loss for batch 96 = 1.1126905679702759\n",
      "Loss for batch 97 = 1.0821044445037842\n",
      "\n",
      "Training Loss for epoch 0 = 107.28270721435547\n",
      "\n",
      "Current Validation Loss = 27.217479705810547\n",
      "Best Validation Loss = 27.217479705810547\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.75%\n",
      "Validation Accuracy: 40.56%\n",
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss for batch 0 = 1.0722407102584839\n",
      "Loss for batch 1 = 1.0622245073318481\n",
      "Loss for batch 2 = 1.0766687393188477\n",
      "Loss for batch 3 = 1.0377180576324463\n",
      "Loss for batch 4 = 1.0461608171463013\n",
      "Loss for batch 5 = 1.0587403774261475\n",
      "Loss for batch 6 = 1.0803064107894897\n",
      "Loss for batch 7 = 1.0851467847824097\n",
      "Loss for batch 8 = 1.084412693977356\n",
      "Loss for batch 9 = 1.0076298713684082\n",
      "Loss for batch 10 = 1.1514391899108887\n",
      "Loss for batch 11 = 1.088680386543274\n",
      "Loss for batch 12 = 1.0594596862792969\n",
      "Loss for batch 13 = 1.11464262008667\n",
      "Loss for batch 14 = 1.0308663845062256\n",
      "Loss for batch 15 = 1.116922378540039\n",
      "Loss for batch 16 = 1.0499602556228638\n",
      "Loss for batch 17 = 0.9937428832054138\n",
      "Loss for batch 18 = 0.9998365044593811\n",
      "Loss for batch 19 = 1.1622045040130615\n",
      "Loss for batch 20 = 1.0230342149734497\n",
      "Loss for batch 21 = 1.0656636953353882\n",
      "Loss for batch 22 = 1.020624041557312\n",
      "Loss for batch 23 = 1.0192339420318604\n",
      "Loss for batch 24 = 1.039624810218811\n",
      "Loss for batch 25 = 1.0560472011566162\n",
      "Loss for batch 26 = 1.1042507886886597\n",
      "Loss for batch 27 = 1.030026912689209\n",
      "Loss for batch 28 = 1.093854546546936\n",
      "Loss for batch 29 = 1.1462277173995972\n",
      "Loss for batch 30 = 1.074716567993164\n",
      "Loss for batch 31 = 1.0832573175430298\n",
      "Loss for batch 32 = 1.0907282829284668\n",
      "Loss for batch 33 = 1.1148271560668945\n",
      "Loss for batch 34 = 0.9901129603385925\n",
      "Loss for batch 35 = 1.1253678798675537\n",
      "Loss for batch 36 = 1.0830166339874268\n",
      "Loss for batch 37 = 1.1059032678604126\n",
      "Loss for batch 38 = 1.0695840120315552\n",
      "Loss for batch 39 = 1.0822690725326538\n",
      "Loss for batch 40 = 1.0704425573349\n",
      "Loss for batch 41 = 1.1119256019592285\n",
      "Loss for batch 42 = 1.0934383869171143\n",
      "Loss for batch 43 = 1.0356340408325195\n",
      "Loss for batch 44 = 1.0708637237548828\n",
      "Loss for batch 45 = 1.0485939979553223\n",
      "Loss for batch 46 = 1.0838520526885986\n",
      "Loss for batch 47 = 1.0601170063018799\n",
      "Loss for batch 48 = 1.1154353618621826\n",
      "Loss for batch 49 = 1.0306687355041504\n",
      "Loss for batch 50 = 0.999573290348053\n",
      "Loss for batch 51 = 1.0460329055786133\n",
      "Loss for batch 52 = 1.1045809984207153\n",
      "Loss for batch 53 = 1.0741723775863647\n",
      "Loss for batch 54 = 1.11247980594635\n",
      "Loss for batch 55 = 1.1303532123565674\n",
      "Loss for batch 56 = 1.0282443761825562\n",
      "Loss for batch 57 = 1.0869450569152832\n",
      "Loss for batch 58 = 0.9487240314483643\n",
      "Loss for batch 59 = 1.0997756719589233\n",
      "Loss for batch 60 = 1.1225601434707642\n",
      "Loss for batch 61 = 1.0480272769927979\n",
      "Loss for batch 62 = 1.0178122520446777\n",
      "Loss for batch 63 = 1.0481029748916626\n",
      "Loss for batch 64 = 1.0138713121414185\n",
      "Loss for batch 65 = 1.0646591186523438\n",
      "Loss for batch 66 = 1.174530267715454\n",
      "Loss for batch 67 = 1.0614490509033203\n",
      "Loss for batch 68 = 1.0971370935440063\n",
      "Loss for batch 69 = 1.061362624168396\n",
      "Loss for batch 70 = 1.1369391679763794\n",
      "Loss for batch 71 = 1.0651922225952148\n",
      "Loss for batch 72 = 1.0425491333007812\n",
      "Loss for batch 73 = 1.1214168071746826\n",
      "Loss for batch 74 = 1.0672062635421753\n",
      "Loss for batch 75 = 1.0808215141296387\n",
      "Loss for batch 76 = 1.0332432985305786\n",
      "Loss for batch 77 = 1.0699689388275146\n",
      "Loss for batch 78 = 1.034432291984558\n",
      "Loss for batch 79 = 1.0209145545959473\n",
      "Loss for batch 80 = 1.1261383295059204\n",
      "Loss for batch 81 = 1.1096726655960083\n",
      "Loss for batch 82 = 1.0992172956466675\n",
      "Loss for batch 83 = 1.0976861715316772\n",
      "Loss for batch 84 = 1.1064050197601318\n",
      "Loss for batch 85 = 1.0930147171020508\n",
      "Loss for batch 86 = 1.0748660564422607\n",
      "Loss for batch 87 = 1.0851314067840576\n",
      "Loss for batch 88 = 1.0045299530029297\n",
      "Loss for batch 89 = 1.081192135810852\n",
      "Loss for batch 90 = 1.0730501413345337\n",
      "Loss for batch 91 = 1.1538546085357666\n",
      "Loss for batch 92 = 1.012999415397644\n",
      "Loss for batch 93 = 1.1052623987197876\n",
      "Loss for batch 94 = 1.1089377403259277\n",
      "Loss for batch 95 = 1.089673638343811\n",
      "Loss for batch 96 = 1.1082292795181274\n",
      "Loss for batch 97 = 1.0646573305130005\n",
      "\n",
      "Training Loss for epoch 1 = 105.12593841552734\n",
      "\n",
      "Current Validation Loss = 26.927459716796875\n",
      "Best Validation Loss = 26.927459716796875\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 44.09%\n",
      "Validation Accuracy: 42.23%\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss for batch 0 = 1.0317952632904053\n",
      "Loss for batch 1 = 1.0523183345794678\n",
      "Loss for batch 2 = 1.0928207635879517\n",
      "Loss for batch 3 = 0.9963135719299316\n",
      "Loss for batch 4 = 1.0255539417266846\n",
      "Loss for batch 5 = 1.025961995124817\n",
      "Loss for batch 6 = 1.066172480583191\n",
      "Loss for batch 7 = 1.0397316217422485\n",
      "Loss for batch 8 = 1.0607331991195679\n",
      "Loss for batch 9 = 0.9846327900886536\n",
      "Loss for batch 10 = 1.161671757698059\n",
      "Loss for batch 11 = 1.082518219947815\n",
      "Loss for batch 12 = 1.0265783071517944\n",
      "Loss for batch 13 = 1.1081585884094238\n",
      "Loss for batch 14 = 1.0453823804855347\n",
      "Loss for batch 15 = 1.0798311233520508\n",
      "Loss for batch 16 = 1.0272881984710693\n",
      "Loss for batch 17 = 0.9775409698486328\n",
      "Loss for batch 18 = 0.9715512990951538\n",
      "Loss for batch 19 = 1.0956356525421143\n",
      "Loss for batch 20 = 0.9686879515647888\n",
      "Loss for batch 21 = 1.1003962755203247\n",
      "Loss for batch 22 = 0.9817337393760681\n",
      "Loss for batch 23 = 0.9589128494262695\n",
      "Loss for batch 24 = 1.0302605628967285\n",
      "Loss for batch 25 = 1.0548046827316284\n",
      "Loss for batch 26 = 1.1019771099090576\n",
      "Loss for batch 27 = 1.000131607055664\n",
      "Loss for batch 28 = 1.1055934429168701\n",
      "Loss for batch 29 = 1.1318494081497192\n",
      "Loss for batch 30 = 1.0492839813232422\n",
      "Loss for batch 31 = 1.0889390707015991\n",
      "Loss for batch 32 = 1.0681655406951904\n",
      "Loss for batch 33 = 1.08562433719635\n",
      "Loss for batch 34 = 0.9782538414001465\n",
      "Loss for batch 35 = 1.1101114749908447\n",
      "Loss for batch 36 = 1.089694857597351\n",
      "Loss for batch 37 = 1.0703059434890747\n",
      "Loss for batch 38 = 1.0744808912277222\n",
      "Loss for batch 39 = 1.0734025239944458\n",
      "Loss for batch 40 = 1.0561742782592773\n",
      "Loss for batch 41 = 1.0491942167282104\n",
      "Loss for batch 42 = 1.099022626876831\n",
      "Loss for batch 43 = 1.044096827507019\n",
      "Loss for batch 44 = 1.0526741743087769\n",
      "Loss for batch 45 = 1.0526255369186401\n",
      "Loss for batch 46 = 1.082435965538025\n",
      "Loss for batch 47 = 1.0402851104736328\n",
      "Loss for batch 48 = 1.0760940313339233\n",
      "Loss for batch 49 = 1.0451381206512451\n",
      "Loss for batch 50 = 0.9687569737434387\n",
      "Loss for batch 51 = 1.0330482721328735\n",
      "Loss for batch 52 = 1.1664985418319702\n",
      "Loss for batch 53 = 1.062803030014038\n",
      "Loss for batch 54 = 1.1170415878295898\n",
      "Loss for batch 55 = 1.089057445526123\n",
      "Loss for batch 56 = 1.0560424327850342\n",
      "Loss for batch 57 = 1.0491586923599243\n",
      "Loss for batch 58 = 0.9540733695030212\n",
      "Loss for batch 59 = 1.1046966314315796\n",
      "Loss for batch 60 = 1.1023423671722412\n",
      "Loss for batch 61 = 1.0054328441619873\n",
      "Loss for batch 62 = 1.0234345197677612\n",
      "Loss for batch 63 = 1.0443888902664185\n",
      "Loss for batch 64 = 0.9691530466079712\n",
      "Loss for batch 65 = 1.0947123765945435\n",
      "Loss for batch 66 = 1.1268243789672852\n",
      "Loss for batch 67 = 1.0316433906555176\n",
      "Loss for batch 68 = 1.037001609802246\n",
      "Loss for batch 69 = 1.1011109352111816\n",
      "Loss for batch 70 = 1.1789178848266602\n",
      "Loss for batch 71 = 1.0302069187164307\n",
      "Loss for batch 72 = 1.0033204555511475\n",
      "Loss for batch 73 = 1.0981379747390747\n",
      "Loss for batch 74 = 0.9857202768325806\n",
      "Loss for batch 75 = 1.0546973943710327\n",
      "Loss for batch 76 = 1.0428037643432617\n",
      "Loss for batch 77 = 1.1241345405578613\n",
      "Loss for batch 78 = 0.966421365737915\n",
      "Loss for batch 79 = 0.99577796459198\n",
      "Loss for batch 80 = 1.07521390914917\n",
      "Loss for batch 81 = 1.0660452842712402\n",
      "Loss for batch 82 = 1.1033611297607422\n",
      "Loss for batch 83 = 1.1040886640548706\n",
      "Loss for batch 84 = 1.0695056915283203\n",
      "Loss for batch 85 = 1.0346479415893555\n",
      "Loss for batch 86 = 1.0429738759994507\n",
      "Loss for batch 87 = 1.0108615159988403\n",
      "Loss for batch 88 = 1.0038059949874878\n",
      "Loss for batch 89 = 1.057000994682312\n",
      "Loss for batch 90 = 1.0343092679977417\n",
      "Loss for batch 91 = 1.1706212759017944\n",
      "Loss for batch 92 = 0.9191661477088928\n",
      "Loss for batch 93 = 1.08220374584198\n",
      "Loss for batch 94 = 1.0374623537063599\n",
      "Loss for batch 95 = 1.1791518926620483\n",
      "Loss for batch 96 = 1.134029746055603\n",
      "Loss for batch 97 = 1.1197540760040283\n",
      "\n",
      "Training Loss for epoch 2 = 103.53411865234375\n",
      "\n",
      "Current Validation Loss = 26.93675994873047\n",
      "Best Validation Loss = 26.927459716796875\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 43.77%\n",
      "Validation Accuracy: 42.88%\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss for batch 0 = 1.0832469463348389\n",
      "Loss for batch 1 = 1.0770822763442993\n",
      "Loss for batch 2 = 1.0652656555175781\n",
      "Loss for batch 3 = 1.0190223455429077\n",
      "Loss for batch 4 = 1.071600079536438\n",
      "Loss for batch 5 = 1.06312894821167\n",
      "Loss for batch 6 = 1.0285613536834717\n",
      "Loss for batch 7 = 1.064481258392334\n",
      "Loss for batch 8 = 1.0488102436065674\n",
      "Loss for batch 9 = 0.9965662956237793\n",
      "Loss for batch 10 = 1.1398953199386597\n",
      "Loss for batch 11 = 1.026317834854126\n",
      "Loss for batch 12 = 1.0017225742340088\n",
      "Loss for batch 13 = 1.113023042678833\n",
      "Loss for batch 14 = 0.9958804845809937\n",
      "Loss for batch 15 = 1.0651016235351562\n",
      "Loss for batch 16 = 0.9769973754882812\n",
      "Loss for batch 17 = 0.9304289817810059\n",
      "Loss for batch 18 = 0.9355189204216003\n",
      "Loss for batch 19 = 1.0475471019744873\n",
      "Loss for batch 20 = 0.9031026363372803\n",
      "Loss for batch 21 = 0.9761480093002319\n",
      "Loss for batch 22 = 1.0798887014389038\n",
      "Loss for batch 23 = 0.9600422382354736\n",
      "Loss for batch 24 = 0.9547410607337952\n",
      "Loss for batch 25 = 1.026812195777893\n",
      "Loss for batch 26 = 0.9869282245635986\n",
      "Loss for batch 27 = 0.9770055413246155\n",
      "Loss for batch 28 = 1.0741223096847534\n",
      "Loss for batch 29 = 1.1295483112335205\n",
      "Loss for batch 30 = 1.026734709739685\n",
      "Loss for batch 31 = 1.1180835962295532\n",
      "Loss for batch 32 = 1.1125283241271973\n",
      "Loss for batch 33 = 1.0227924585342407\n",
      "Loss for batch 34 = 0.945783257484436\n",
      "Loss for batch 35 = 1.0195460319519043\n",
      "Loss for batch 36 = 1.070875883102417\n",
      "Loss for batch 37 = 1.0494834184646606\n",
      "Loss for batch 38 = 1.1374704837799072\n",
      "Loss for batch 39 = 1.070685625076294\n",
      "Loss for batch 40 = 1.0396322011947632\n",
      "Loss for batch 41 = 1.0387533903121948\n",
      "Loss for batch 42 = 1.088699221611023\n",
      "Loss for batch 43 = 1.0256820917129517\n",
      "Loss for batch 44 = 1.0085177421569824\n",
      "Loss for batch 45 = 1.0075513124465942\n",
      "Loss for batch 46 = 1.0742878913879395\n",
      "Loss for batch 47 = 0.9765370488166809\n",
      "Loss for batch 48 = 0.934441864490509\n",
      "Loss for batch 49 = 1.026648998260498\n",
      "Loss for batch 50 = 0.9847880005836487\n",
      "Loss for batch 51 = 0.9996362328529358\n",
      "Loss for batch 52 = 1.2351012229919434\n",
      "Loss for batch 53 = 1.0613079071044922\n",
      "Loss for batch 54 = 1.0796878337860107\n",
      "Loss for batch 55 = 1.030727744102478\n",
      "Loss for batch 56 = 1.0415154695510864\n",
      "Loss for batch 57 = 1.0098704099655151\n",
      "Loss for batch 58 = 1.0100451707839966\n",
      "Loss for batch 59 = 1.133728265762329\n",
      "Loss for batch 60 = 1.117080807685852\n",
      "Loss for batch 61 = 1.0445301532745361\n",
      "Loss for batch 62 = 0.9623507857322693\n",
      "Loss for batch 63 = 1.0672544240951538\n",
      "Loss for batch 64 = 0.9426287412643433\n",
      "Loss for batch 65 = 1.0235127210617065\n",
      "Loss for batch 66 = 1.1063706874847412\n",
      "Loss for batch 67 = 1.005429744720459\n",
      "Loss for batch 68 = 1.0439625978469849\n",
      "Loss for batch 69 = 1.1098302602767944\n",
      "Loss for batch 70 = 1.1124109029769897\n",
      "Loss for batch 71 = 1.0318206548690796\n",
      "Loss for batch 72 = 0.9937515258789062\n",
      "Loss for batch 73 = 1.106543779373169\n",
      "Loss for batch 74 = 0.9851260781288147\n",
      "Loss for batch 75 = 1.0129202604293823\n",
      "Loss for batch 76 = 0.9756031632423401\n",
      "Loss for batch 77 = 0.943599283695221\n",
      "Loss for batch 78 = 0.9015008211135864\n",
      "Loss for batch 79 = 0.9706974625587463\n",
      "Loss for batch 80 = 1.0208934545516968\n",
      "Loss for batch 81 = 1.10262131690979\n",
      "Loss for batch 82 = 1.1042498350143433\n",
      "Loss for batch 83 = 1.088853359222412\n",
      "Loss for batch 84 = 1.0182057619094849\n",
      "Loss for batch 85 = 0.9701146483421326\n",
      "Loss for batch 86 = 1.030547022819519\n",
      "Loss for batch 87 = 1.0384703874588013\n",
      "Loss for batch 88 = 1.0078781843185425\n",
      "Loss for batch 89 = 0.9888505339622498\n",
      "Loss for batch 90 = 0.9981188178062439\n",
      "Loss for batch 91 = 0.9918683767318726\n",
      "Loss for batch 92 = 1.1252110004425049\n",
      "Loss for batch 93 = 1.1460976600646973\n",
      "Loss for batch 94 = 1.0926127433776855\n",
      "Loss for batch 95 = 0.9398224353790283\n",
      "Loss for batch 96 = 1.0960348844528198\n",
      "Loss for batch 97 = 1.0812989473342896\n",
      "\n",
      "Training Loss for epoch 3 = 101.49833679199219\n",
      "\n",
      "Current Validation Loss = 27.42998504638672\n",
      "Best Validation Loss = 26.927459716796875\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 32.77%\n",
      "Validation Accuracy: 33.12%\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss for batch 0 = 1.1140289306640625\n",
      "Loss for batch 1 = 1.0871665477752686\n",
      "Loss for batch 2 = 1.0997051000595093\n",
      "Loss for batch 3 = 1.016290545463562\n",
      "Loss for batch 4 = 1.0692044496536255\n",
      "Loss for batch 5 = 1.0467469692230225\n",
      "Loss for batch 6 = 1.0078728199005127\n",
      "Loss for batch 7 = 1.0795042514801025\n",
      "Loss for batch 8 = 1.069667100906372\n",
      "Loss for batch 9 = 1.0463733673095703\n",
      "Loss for batch 10 = 1.1239577531814575\n",
      "Loss for batch 11 = 0.9934295415878296\n",
      "Loss for batch 12 = 0.9405660629272461\n",
      "Loss for batch 13 = 1.0633177757263184\n",
      "Loss for batch 14 = 0.9319769144058228\n",
      "Loss for batch 15 = 1.0927561521530151\n",
      "Loss for batch 16 = 1.013360857963562\n",
      "Loss for batch 17 = 1.070003628730774\n",
      "Loss for batch 18 = 1.0462700128555298\n",
      "Loss for batch 19 = 1.0053924322128296\n",
      "Loss for batch 20 = 0.9753590822219849\n",
      "Loss for batch 21 = 0.9666758179664612\n",
      "Loss for batch 22 = 1.0122278928756714\n",
      "Loss for batch 23 = 1.0296010971069336\n",
      "Loss for batch 24 = 1.0233958959579468\n",
      "Loss for batch 25 = 0.9891760945320129\n",
      "Loss for batch 26 = 0.9304614067077637\n",
      "Loss for batch 27 = 0.8386822938919067\n",
      "Loss for batch 28 = 0.9992676973342896\n",
      "Loss for batch 29 = 1.0794137716293335\n",
      "Loss for batch 30 = 0.9553157687187195\n",
      "Loss for batch 31 = 1.1428470611572266\n",
      "Loss for batch 32 = 1.0492078065872192\n",
      "Loss for batch 33 = 1.0894609689712524\n",
      "Loss for batch 34 = 0.9299147725105286\n",
      "Loss for batch 35 = 1.0209778547286987\n",
      "Loss for batch 36 = 1.128113031387329\n",
      "Loss for batch 37 = 1.055185079574585\n",
      "Loss for batch 38 = 1.1747130155563354\n",
      "Loss for batch 39 = 1.0659046173095703\n",
      "Loss for batch 40 = 1.0363855361938477\n",
      "Loss for batch 41 = 1.0824048519134521\n",
      "Loss for batch 42 = 1.054361343383789\n",
      "Loss for batch 43 = 1.005707025527954\n",
      "Loss for batch 44 = 0.9512959122657776\n",
      "Loss for batch 45 = 1.0323073863983154\n",
      "Loss for batch 46 = 1.0453952550888062\n",
      "Loss for batch 47 = 0.9636539816856384\n",
      "Loss for batch 48 = 0.8697977662086487\n",
      "Loss for batch 49 = 0.9977513551712036\n",
      "Loss for batch 50 = 0.961643397808075\n",
      "Loss for batch 51 = 0.9884755611419678\n",
      "Loss for batch 52 = 1.093506097793579\n",
      "Loss for batch 53 = 1.0115039348602295\n",
      "Loss for batch 54 = 1.09940505027771\n",
      "Loss for batch 55 = 0.9515224099159241\n",
      "Loss for batch 56 = 0.9774273037910461\n",
      "Loss for batch 57 = 0.9237790703773499\n",
      "Loss for batch 58 = 0.9860000014305115\n",
      "Loss for batch 59 = 1.1881495714187622\n",
      "Loss for batch 60 = 1.1153010129928589\n",
      "Loss for batch 61 = 1.0051100254058838\n",
      "Loss for batch 62 = 0.9558917284011841\n",
      "Loss for batch 63 = 0.9888753890991211\n",
      "Loss for batch 64 = 1.0118533372879028\n",
      "Loss for batch 65 = 1.1352529525756836\n",
      "Loss for batch 66 = 1.0140386819839478\n",
      "Loss for batch 67 = 1.065973162651062\n",
      "Loss for batch 68 = 1.0532643795013428\n",
      "Loss for batch 69 = 1.0904461145401\n",
      "Loss for batch 70 = 1.1094363927841187\n",
      "Loss for batch 71 = 1.0279582738876343\n",
      "Loss for batch 72 = 0.9714275598526001\n",
      "Loss for batch 73 = 1.0784008502960205\n",
      "Loss for batch 74 = 0.936091423034668\n",
      "Loss for batch 75 = 0.953653872013092\n",
      "Loss for batch 76 = 1.0121990442276\n",
      "Loss for batch 77 = 0.998528242111206\n",
      "Loss for batch 78 = 0.8960843086242676\n",
      "Loss for batch 79 = 0.958318829536438\n",
      "Loss for batch 80 = 0.9694131016731262\n",
      "Loss for batch 81 = 1.0749471187591553\n",
      "Loss for batch 82 = 1.1516907215118408\n",
      "Loss for batch 83 = 1.1767383813858032\n",
      "Loss for batch 84 = 0.9825824499130249\n",
      "Loss for batch 85 = 0.966575026512146\n",
      "Loss for batch 86 = 1.0633436441421509\n",
      "Loss for batch 87 = 1.0547316074371338\n",
      "Loss for batch 88 = 0.9761379361152649\n",
      "Loss for batch 89 = 1.0107827186584473\n",
      "Loss for batch 90 = 0.9533019661903381\n",
      "Loss for batch 91 = 0.9908596873283386\n",
      "Loss for batch 92 = 0.8922433853149414\n",
      "Loss for batch 93 = 1.066537857055664\n",
      "Loss for batch 94 = 1.0021809339523315\n",
      "Loss for batch 95 = 0.9026721119880676\n",
      "Loss for batch 96 = 1.0202335119247437\n",
      "Loss for batch 97 = 1.0764552354812622\n",
      "\n",
      "Training Loss for epoch 4 = 100.3034896850586\n",
      "\n",
      "Current Validation Loss = 26.068296432495117\n",
      "Best Validation Loss = 26.068296432495117\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 43.23%\n",
      "Validation Accuracy: 41.21%\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss for batch 0 = 1.0453953742980957\n",
      "Loss for batch 1 = 0.9823415875434875\n",
      "Loss for batch 2 = 1.0510523319244385\n",
      "Loss for batch 3 = 0.8342331647872925\n",
      "Loss for batch 4 = 0.9203713536262512\n",
      "Loss for batch 5 = 0.8766348958015442\n",
      "Loss for batch 6 = 0.9741395711898804\n",
      "Loss for batch 7 = 1.1834850311279297\n",
      "Loss for batch 8 = 0.9748156666755676\n",
      "Loss for batch 9 = 0.9512537717819214\n",
      "Loss for batch 10 = 1.0232367515563965\n",
      "Loss for batch 11 = 0.882790207862854\n",
      "Loss for batch 12 = 0.9530337452888489\n",
      "Loss for batch 13 = 1.11720609664917\n",
      "Loss for batch 14 = 0.9761902689933777\n",
      "Loss for batch 15 = 1.0563489198684692\n",
      "Loss for batch 16 = 0.9734636545181274\n",
      "Loss for batch 17 = 1.001718282699585\n",
      "Loss for batch 18 = 0.9488368034362793\n",
      "Loss for batch 19 = 1.012196660041809\n",
      "Loss for batch 20 = 0.8971275091171265\n",
      "Loss for batch 21 = 0.9479511380195618\n",
      "Loss for batch 22 = 0.9521492123603821\n",
      "Loss for batch 23 = 0.9303721785545349\n",
      "Loss for batch 24 = 0.9353039264678955\n",
      "Loss for batch 25 = 0.9392400979995728\n",
      "Loss for batch 26 = 0.9452754259109497\n",
      "Loss for batch 27 = 0.907649040222168\n",
      "Loss for batch 28 = 1.032195806503296\n",
      "Loss for batch 29 = 1.017975926399231\n",
      "Loss for batch 30 = 1.0124893188476562\n",
      "Loss for batch 31 = 1.2095582485198975\n",
      "Loss for batch 32 = 1.021825909614563\n",
      "Loss for batch 33 = 1.0271680355072021\n",
      "Loss for batch 34 = 0.9175329208374023\n",
      "Loss for batch 35 = 0.9620926976203918\n",
      "Loss for batch 36 = 1.0099740028381348\n",
      "Loss for batch 37 = 0.9996206164360046\n",
      "Loss for batch 38 = 1.164386510848999\n",
      "Loss for batch 39 = 0.9663974642753601\n",
      "Loss for batch 40 = 0.9967188239097595\n",
      "Loss for batch 41 = 1.1024582386016846\n",
      "Loss for batch 42 = 0.9476180076599121\n",
      "Loss for batch 43 = 0.973193883895874\n",
      "Loss for batch 44 = 0.9522994756698608\n",
      "Loss for batch 45 = 0.9787663221359253\n",
      "Loss for batch 46 = 1.0803552865982056\n",
      "Loss for batch 47 = 0.9270815253257751\n",
      "Loss for batch 48 = 0.9147089123725891\n",
      "Loss for batch 49 = 0.9697045683860779\n",
      "Loss for batch 50 = 0.9399961829185486\n",
      "Loss for batch 51 = 0.9308279752731323\n",
      "Loss for batch 52 = 1.015944480895996\n",
      "Loss for batch 53 = 1.0348169803619385\n",
      "Loss for batch 54 = 1.0995837450027466\n",
      "Loss for batch 55 = 0.9718302488327026\n",
      "Loss for batch 56 = 0.9450482130050659\n",
      "Loss for batch 57 = 0.8936241865158081\n",
      "Loss for batch 58 = 0.8029921650886536\n",
      "Loss for batch 59 = 1.1177879571914673\n",
      "Loss for batch 60 = 1.0162063837051392\n",
      "Loss for batch 61 = 1.0340014696121216\n",
      "Loss for batch 62 = 0.8919951319694519\n",
      "Loss for batch 63 = 0.9412097334861755\n",
      "Loss for batch 64 = 0.8614266514778137\n",
      "Loss for batch 65 = 0.950131893157959\n",
      "Loss for batch 66 = 1.0823980569839478\n",
      "Loss for batch 67 = 0.9754666090011597\n",
      "Loss for batch 68 = 0.9928929805755615\n",
      "Loss for batch 69 = 1.0214556455612183\n",
      "Loss for batch 70 = 1.0276427268981934\n",
      "Loss for batch 71 = 0.9869685173034668\n",
      "Loss for batch 72 = 0.9764840006828308\n",
      "Loss for batch 73 = 1.117467999458313\n",
      "Loss for batch 74 = 0.951771080493927\n",
      "Loss for batch 75 = 0.8764579892158508\n",
      "Loss for batch 76 = 0.9796231389045715\n",
      "Loss for batch 77 = 0.8661910891532898\n",
      "Loss for batch 78 = 0.7905066013336182\n",
      "Loss for batch 79 = 0.9426909685134888\n",
      "Loss for batch 80 = 0.9804660081863403\n",
      "Loss for batch 81 = 1.1202704906463623\n",
      "Loss for batch 82 = 1.1342731714248657\n",
      "Loss for batch 83 = 1.1128721237182617\n",
      "Loss for batch 84 = 0.9594272375106812\n",
      "Loss for batch 85 = 0.8903837203979492\n",
      "Loss for batch 86 = 1.0032544136047363\n",
      "Loss for batch 87 = 1.020184874534607\n",
      "Loss for batch 88 = 0.8784316778182983\n",
      "Loss for batch 89 = 0.925125777721405\n",
      "Loss for batch 90 = 0.9739850163459778\n",
      "Loss for batch 91 = 1.1120656728744507\n",
      "Loss for batch 92 = 0.9201861619949341\n",
      "Loss for batch 93 = 1.050771951675415\n",
      "Loss for batch 94 = 0.9123210310935974\n",
      "Loss for batch 95 = 0.9099372625350952\n",
      "Loss for batch 96 = 1.0724906921386719\n",
      "Loss for batch 97 = 0.9942038059234619\n",
      "\n",
      "Training Loss for epoch 5 = 96.38401794433594\n",
      "\n",
      "Current Validation Loss = 25.2655029296875\n",
      "Best Validation Loss = 25.2655029296875\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 53.53%\n",
      "Validation Accuracy: 53.02%\n",
      "\n",
      "Epoch 6\n",
      "----------\n",
      "Loss for batch 0 = 1.0186141729354858\n",
      "Loss for batch 1 = 0.9047831296920776\n",
      "Loss for batch 2 = 1.0293375253677368\n",
      "Loss for batch 3 = 0.8037667870521545\n",
      "Loss for batch 4 = 0.8129850625991821\n",
      "Loss for batch 5 = 0.8398250937461853\n",
      "Loss for batch 6 = 0.9271477460861206\n",
      "Loss for batch 7 = 1.1569081544876099\n",
      "Loss for batch 8 = 0.9629591703414917\n",
      "Loss for batch 9 = 0.8873761892318726\n",
      "Loss for batch 10 = 1.003796100616455\n",
      "Loss for batch 11 = 0.8406074643135071\n",
      "Loss for batch 12 = 0.8437583446502686\n",
      "Loss for batch 13 = 1.0307800769805908\n",
      "Loss for batch 14 = 0.8850342035293579\n",
      "Loss for batch 15 = 1.0455628633499146\n",
      "Loss for batch 16 = 0.9686233401298523\n",
      "Loss for batch 17 = 0.9614997506141663\n",
      "Loss for batch 18 = 0.97965407371521\n",
      "Loss for batch 19 = 1.0050067901611328\n",
      "Loss for batch 20 = 0.8773150444030762\n",
      "Loss for batch 21 = 0.968532919883728\n",
      "Loss for batch 22 = 0.9396912455558777\n",
      "Loss for batch 23 = 0.9385785460472107\n",
      "Loss for batch 24 = 0.9238941073417664\n",
      "Loss for batch 25 = 1.0509597063064575\n",
      "Loss for batch 26 = 1.0328657627105713\n",
      "Loss for batch 27 = 0.8515297174453735\n",
      "Loss for batch 28 = 1.0648893117904663\n",
      "Loss for batch 29 = 0.8794903755187988\n",
      "Loss for batch 30 = 1.014293909072876\n",
      "Loss for batch 31 = 1.138704538345337\n",
      "Loss for batch 32 = 0.902774453163147\n",
      "Loss for batch 33 = 1.106569766998291\n",
      "Loss for batch 34 = 0.8941035866737366\n",
      "Loss for batch 35 = 0.9314491748809814\n",
      "Loss for batch 36 = 0.9308894276618958\n",
      "Loss for batch 37 = 0.9850849509239197\n",
      "Loss for batch 38 = 1.0314698219299316\n",
      "Loss for batch 39 = 1.016556978225708\n",
      "Loss for batch 40 = 0.9641360640525818\n",
      "Loss for batch 41 = 1.115248441696167\n",
      "Loss for batch 42 = 0.9993664026260376\n",
      "Loss for batch 43 = 0.9545313119888306\n",
      "Loss for batch 44 = 0.9886625409126282\n",
      "Loss for batch 45 = 1.0525453090667725\n",
      "Loss for batch 46 = 1.0081217288970947\n",
      "Loss for batch 47 = 0.9698233604431152\n",
      "Loss for batch 48 = 0.8946292400360107\n",
      "Loss for batch 49 = 0.9003583788871765\n",
      "Loss for batch 50 = 0.9867380261421204\n",
      "Loss for batch 51 = 0.9086658954620361\n",
      "Loss for batch 52 = 0.9837948679924011\n",
      "Loss for batch 53 = 0.8990969061851501\n",
      "Loss for batch 54 = 1.1153950691223145\n",
      "Loss for batch 55 = 0.9504604339599609\n",
      "Loss for batch 56 = 0.9721589088439941\n",
      "Loss for batch 57 = 0.9071224331855774\n",
      "Loss for batch 58 = 0.8675926923751831\n",
      "Loss for batch 59 = 1.0767582654953003\n",
      "Loss for batch 60 = 1.0085941553115845\n",
      "Loss for batch 61 = 1.0302015542984009\n",
      "Loss for batch 62 = 0.8420092463493347\n",
      "Loss for batch 63 = 0.8531000018119812\n",
      "Loss for batch 64 = 0.8630999326705933\n",
      "Loss for batch 65 = 0.9312158823013306\n",
      "Loss for batch 66 = 1.0554425716400146\n",
      "Loss for batch 67 = 0.980690062046051\n",
      "Loss for batch 68 = 0.9234387278556824\n",
      "Loss for batch 69 = 1.0058071613311768\n",
      "Loss for batch 70 = 1.0708009004592896\n",
      "Loss for batch 71 = 0.9592929482460022\n",
      "Loss for batch 72 = 1.080359935760498\n",
      "Loss for batch 73 = 1.0381680727005005\n",
      "Loss for batch 74 = 0.9042651057243347\n",
      "Loss for batch 75 = 0.8322945237159729\n",
      "Loss for batch 76 = 1.0474164485931396\n",
      "Loss for batch 77 = 0.8598392605781555\n",
      "Loss for batch 78 = 0.7801288366317749\n",
      "Loss for batch 79 = 0.9168671369552612\n",
      "Loss for batch 80 = 0.9811617732048035\n",
      "Loss for batch 81 = 1.067264437675476\n",
      "Loss for batch 82 = 1.126865029335022\n",
      "Loss for batch 83 = 1.1072056293487549\n",
      "Loss for batch 84 = 0.9732065200805664\n",
      "Loss for batch 85 = 0.8668802976608276\n",
      "Loss for batch 86 = 0.9515089988708496\n",
      "Loss for batch 87 = 1.0132265090942383\n",
      "Loss for batch 88 = 0.810401976108551\n",
      "Loss for batch 89 = 0.9039553999900818\n",
      "Loss for batch 90 = 0.9942007064819336\n",
      "Loss for batch 91 = 0.972526490688324\n",
      "Loss for batch 92 = 0.8714478611946106\n",
      "Loss for batch 93 = 1.0353763103485107\n",
      "Loss for batch 94 = 0.8825753927230835\n",
      "Loss for batch 95 = 0.8836796283721924\n",
      "Loss for batch 96 = 1.074493646621704\n",
      "Loss for batch 97 = 0.8354225754737854\n",
      "\n",
      "Training Loss for epoch 6 = 94.23731994628906\n",
      "\n",
      "Current Validation Loss = 24.808773040771484\n",
      "Best Validation Loss = 24.808773040771484\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 56.87%\n",
      "Validation Accuracy: 54.56%\n",
      "\n",
      "Epoch 7\n",
      "----------\n",
      "Loss for batch 0 = 0.9800459146499634\n",
      "Loss for batch 1 = 0.8950774073600769\n",
      "Loss for batch 2 = 1.0115464925765991\n",
      "Loss for batch 3 = 0.6934506893157959\n",
      "Loss for batch 4 = 0.8075380325317383\n",
      "Loss for batch 5 = 0.9777781963348389\n",
      "Loss for batch 6 = 0.9187924265861511\n",
      "Loss for batch 7 = 0.9973486661911011\n",
      "Loss for batch 8 = 0.9429407715797424\n",
      "Loss for batch 9 = 0.8623080849647522\n",
      "Loss for batch 10 = 0.9816069006919861\n",
      "Loss for batch 11 = 0.8011784553527832\n",
      "Loss for batch 12 = 0.7689533829689026\n",
      "Loss for batch 13 = 1.1121206283569336\n",
      "Loss for batch 14 = 0.7704962491989136\n",
      "Loss for batch 15 = 1.0427837371826172\n",
      "Loss for batch 16 = 1.0895930528640747\n",
      "Loss for batch 17 = 0.9680084586143494\n",
      "Loss for batch 18 = 0.8265733122825623\n",
      "Loss for batch 19 = 0.9081669449806213\n",
      "Loss for batch 20 = 0.8128407597541809\n",
      "Loss for batch 21 = 0.9664393663406372\n",
      "Loss for batch 22 = 0.8494985103607178\n",
      "Loss for batch 23 = 0.9418520927429199\n",
      "Loss for batch 24 = 0.8812983632087708\n",
      "Loss for batch 25 = 0.9838935136795044\n",
      "Loss for batch 26 = 1.0263124704360962\n",
      "Loss for batch 27 = 0.874660849571228\n",
      "Loss for batch 28 = 0.9300991296768188\n",
      "Loss for batch 29 = 0.9399100542068481\n",
      "Loss for batch 30 = 1.0197668075561523\n",
      "Loss for batch 31 = 1.0887597799301147\n",
      "Loss for batch 32 = 0.8843868970870972\n",
      "Loss for batch 33 = 1.0367158651351929\n",
      "Loss for batch 34 = 0.9259658455848694\n",
      "Loss for batch 35 = 0.912713348865509\n",
      "Loss for batch 36 = 0.9584226608276367\n",
      "Loss for batch 37 = 0.9800992608070374\n",
      "Loss for batch 38 = 1.0856174230575562\n",
      "Loss for batch 39 = 0.9194546341896057\n",
      "Loss for batch 40 = 0.966992974281311\n",
      "Loss for batch 41 = 1.0838407278060913\n",
      "Loss for batch 42 = 0.994410514831543\n",
      "Loss for batch 43 = 0.925218939781189\n",
      "Loss for batch 44 = 0.935062825679779\n",
      "Loss for batch 45 = 1.0457851886749268\n",
      "Loss for batch 46 = 1.0275710821151733\n",
      "Loss for batch 47 = 0.9810203313827515\n",
      "Loss for batch 48 = 0.86360102891922\n",
      "Loss for batch 49 = 0.925090491771698\n",
      "Loss for batch 50 = 0.9783650040626526\n",
      "Loss for batch 51 = 0.8959222435951233\n",
      "Loss for batch 52 = 0.938088059425354\n",
      "Loss for batch 53 = 0.9276039004325867\n",
      "Loss for batch 54 = 0.9570898413658142\n",
      "Loss for batch 55 = 0.9464392066001892\n",
      "Loss for batch 56 = 0.9765446782112122\n",
      "Loss for batch 57 = 0.9159122705459595\n",
      "Loss for batch 58 = 0.8172898888587952\n",
      "Loss for batch 59 = 1.1200382709503174\n",
      "Loss for batch 60 = 1.0012760162353516\n",
      "Loss for batch 61 = 1.0360580682754517\n",
      "Loss for batch 62 = 0.8597412109375\n",
      "Loss for batch 63 = 0.8993080258369446\n",
      "Loss for batch 64 = 0.8068848252296448\n",
      "Loss for batch 65 = 0.9044815301895142\n",
      "Loss for batch 66 = 1.0339038372039795\n",
      "Loss for batch 67 = 0.9325956702232361\n",
      "Loss for batch 68 = 0.9839121103286743\n",
      "Loss for batch 69 = 0.9670605063438416\n",
      "Loss for batch 70 = 1.080153226852417\n",
      "Loss for batch 71 = 0.9479526281356812\n",
      "Loss for batch 72 = 0.9746418595314026\n",
      "Loss for batch 73 = 0.9939576983451843\n",
      "Loss for batch 74 = 0.8776023387908936\n",
      "Loss for batch 75 = 0.8703259825706482\n",
      "Loss for batch 76 = 1.0003912448883057\n",
      "Loss for batch 77 = 0.8694779872894287\n",
      "Loss for batch 78 = 0.753167450428009\n",
      "Loss for batch 79 = 0.8495250344276428\n",
      "Loss for batch 80 = 1.016757607460022\n",
      "Loss for batch 81 = 1.050253987312317\n",
      "Loss for batch 82 = 1.1071951389312744\n",
      "Loss for batch 83 = 1.0574150085449219\n",
      "Loss for batch 84 = 0.9579307436943054\n",
      "Loss for batch 85 = 0.8205313682556152\n",
      "Loss for batch 86 = 0.9263801574707031\n",
      "Loss for batch 87 = 0.9436136484146118\n",
      "Loss for batch 88 = 0.7978218197822571\n",
      "Loss for batch 89 = 0.9359363913536072\n",
      "Loss for batch 90 = 0.9693387150764465\n",
      "Loss for batch 91 = 0.9521790146827698\n",
      "Loss for batch 92 = 0.843491792678833\n",
      "Loss for batch 93 = 0.977536141872406\n",
      "Loss for batch 94 = 0.821986198425293\n",
      "Loss for batch 95 = 0.8645635843276978\n",
      "Loss for batch 96 = 1.1001887321472168\n",
      "Loss for batch 97 = 0.8949680328369141\n",
      "\n",
      "Training Loss for epoch 7 = 92.27739715576172\n",
      "\n",
      "Current Validation Loss = 24.660404205322266\n",
      "Best Validation Loss = 24.660404205322266\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 56.00%\n",
      "Validation Accuracy: 51.99%\n",
      "\n",
      "Epoch 8\n",
      "----------\n",
      "Loss for batch 0 = 0.9316376447677612\n",
      "Loss for batch 1 = 0.8381451964378357\n",
      "Loss for batch 2 = 0.9963347315788269\n",
      "Loss for batch 3 = 0.7426108121871948\n",
      "Loss for batch 4 = 0.7532738447189331\n",
      "Loss for batch 5 = 0.8646162748336792\n",
      "Loss for batch 6 = 0.9065190553665161\n",
      "Loss for batch 7 = 1.0026639699935913\n",
      "Loss for batch 8 = 0.9596301913261414\n",
      "Loss for batch 9 = 0.9422289133071899\n",
      "Loss for batch 10 = 0.9523898363113403\n",
      "Loss for batch 11 = 0.7921072244644165\n",
      "Loss for batch 12 = 0.7658859491348267\n",
      "Loss for batch 13 = 1.102358102798462\n",
      "Loss for batch 14 = 0.8482315540313721\n",
      "Loss for batch 15 = 1.0115989446640015\n",
      "Loss for batch 16 = 0.991133451461792\n",
      "Loss for batch 17 = 0.8908846378326416\n",
      "Loss for batch 18 = 0.8625822067260742\n",
      "Loss for batch 19 = 0.9248245358467102\n",
      "Loss for batch 20 = 0.8217633962631226\n",
      "Loss for batch 21 = 0.917398989200592\n",
      "Loss for batch 22 = 0.835621178150177\n",
      "Loss for batch 23 = 0.9261454343795776\n",
      "Loss for batch 24 = 0.8420971632003784\n",
      "Loss for batch 25 = 0.899603545665741\n",
      "Loss for batch 26 = 1.0858511924743652\n",
      "Loss for batch 27 = 0.8099343180656433\n",
      "Loss for batch 28 = 0.9644728899002075\n",
      "Loss for batch 29 = 0.8840709328651428\n",
      "Loss for batch 30 = 0.9277148246765137\n",
      "Loss for batch 31 = 1.160088300704956\n",
      "Loss for batch 32 = 0.8350445032119751\n",
      "Loss for batch 33 = 0.9998323321342468\n",
      "Loss for batch 34 = 0.8720421195030212\n",
      "Loss for batch 35 = 0.9661920070648193\n",
      "Loss for batch 36 = 0.884269118309021\n",
      "Loss for batch 37 = 1.1099538803100586\n",
      "Loss for batch 38 = 1.0968166589736938\n",
      "Loss for batch 39 = 0.8562898635864258\n",
      "Loss for batch 40 = 0.9807757139205933\n",
      "Loss for batch 41 = 1.1025797128677368\n",
      "Loss for batch 42 = 0.8871506452560425\n",
      "Loss for batch 43 = 0.8906123638153076\n",
      "Loss for batch 44 = 0.9097254872322083\n",
      "Loss for batch 45 = 0.9152954816818237\n",
      "Loss for batch 46 = 0.9843044877052307\n",
      "Loss for batch 47 = 0.9482324719429016\n",
      "Loss for batch 48 = 0.8483112454414368\n",
      "Loss for batch 49 = 0.9254572987556458\n",
      "Loss for batch 50 = 0.935815155506134\n",
      "Loss for batch 51 = 0.876416027545929\n",
      "Loss for batch 52 = 0.9306168556213379\n",
      "Loss for batch 53 = 0.8753535151481628\n",
      "Loss for batch 54 = 0.9989062547683716\n",
      "Loss for batch 55 = 0.9147709608078003\n",
      "Loss for batch 56 = 0.9101906418800354\n",
      "Loss for batch 57 = 0.8180230855941772\n",
      "Loss for batch 58 = 0.7826863527297974\n",
      "Loss for batch 59 = 1.167460560798645\n",
      "Loss for batch 60 = 0.9601869583129883\n",
      "Loss for batch 61 = 1.0390121936798096\n",
      "Loss for batch 62 = 0.8759379386901855\n",
      "Loss for batch 63 = 0.9350156188011169\n",
      "Loss for batch 64 = 0.760802149772644\n",
      "Loss for batch 65 = 0.9071087837219238\n",
      "Loss for batch 66 = 0.9585987329483032\n",
      "Loss for batch 67 = 0.965890645980835\n",
      "Loss for batch 68 = 0.8919367790222168\n",
      "Loss for batch 69 = 0.9811408519744873\n",
      "Loss for batch 70 = 1.0648775100708008\n",
      "Loss for batch 71 = 0.8981001973152161\n",
      "Loss for batch 72 = 1.015434741973877\n",
      "Loss for batch 73 = 0.9420685768127441\n",
      "Loss for batch 74 = 0.8350721597671509\n",
      "Loss for batch 75 = 0.8343157768249512\n",
      "Loss for batch 76 = 1.0228028297424316\n",
      "Loss for batch 77 = 0.7921494841575623\n",
      "Loss for batch 78 = 0.6943589448928833\n",
      "Loss for batch 79 = 0.887446939945221\n",
      "Loss for batch 80 = 1.0510520935058594\n",
      "Loss for batch 81 = 1.0574767589569092\n",
      "Loss for batch 82 = 1.1413402557373047\n",
      "Loss for batch 83 = 1.0469762086868286\n",
      "Loss for batch 84 = 0.9391738772392273\n",
      "Loss for batch 85 = 0.81608647108078\n",
      "Loss for batch 86 = 0.8931154608726501\n",
      "Loss for batch 87 = 0.9231270551681519\n",
      "Loss for batch 88 = 0.8176344633102417\n",
      "Loss for batch 89 = 0.9166345000267029\n",
      "Loss for batch 90 = 0.9677487015724182\n",
      "Loss for batch 91 = 0.8956798315048218\n",
      "Loss for batch 92 = 0.8772172331809998\n",
      "Loss for batch 93 = 0.9737611413002014\n",
      "Loss for batch 94 = 0.7894096374511719\n",
      "Loss for batch 95 = 0.8182980418205261\n",
      "Loss for batch 96 = 1.0709645748138428\n",
      "Loss for batch 97 = 0.8835204243659973\n",
      "\n",
      "Training Loss for epoch 8 = 90.51904296875\n",
      "\n",
      "Current Validation Loss = 24.691774368286133\n",
      "Best Validation Loss = 24.660404205322266\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 56.51%\n",
      "Validation Accuracy: 52.63%\n",
      "\n",
      "Epoch 9\n",
      "----------\n",
      "Loss for batch 0 = 0.9061179757118225\n",
      "Loss for batch 1 = 0.8269489407539368\n",
      "Loss for batch 2 = 0.9913737773895264\n",
      "Loss for batch 3 = 0.7544410824775696\n",
      "Loss for batch 4 = 0.7376275658607483\n",
      "Loss for batch 5 = 0.8282744884490967\n",
      "Loss for batch 6 = 0.9057009816169739\n",
      "Loss for batch 7 = 1.004551649093628\n",
      "Loss for batch 8 = 0.8699474334716797\n",
      "Loss for batch 9 = 0.8082234859466553\n",
      "Loss for batch 10 = 0.9151470065116882\n",
      "Loss for batch 11 = 0.714242160320282\n",
      "Loss for batch 12 = 0.7168219089508057\n",
      "Loss for batch 13 = 0.946963369846344\n",
      "Loss for batch 14 = 0.8075481653213501\n",
      "Loss for batch 15 = 1.044507384300232\n",
      "Loss for batch 16 = 0.9159318208694458\n",
      "Loss for batch 17 = 0.8809733986854553\n",
      "Loss for batch 18 = 0.8087048530578613\n",
      "Loss for batch 19 = 0.8982656002044678\n",
      "Loss for batch 20 = 0.809916615486145\n",
      "Loss for batch 21 = 0.9439234733581543\n",
      "Loss for batch 22 = 0.7633352875709534\n",
      "Loss for batch 23 = 0.9040637016296387\n",
      "Loss for batch 24 = 0.8531860709190369\n",
      "Loss for batch 25 = 0.8536714315414429\n",
      "Loss for batch 26 = 1.156623363494873\n",
      "Loss for batch 27 = 0.7994720935821533\n",
      "Loss for batch 28 = 0.9421231150627136\n",
      "Loss for batch 29 = 0.860489547252655\n",
      "Loss for batch 30 = 0.9874094724655151\n",
      "Loss for batch 31 = 1.1408625841140747\n",
      "Loss for batch 32 = 0.7825935482978821\n",
      "Loss for batch 33 = 1.0503082275390625\n",
      "Loss for batch 34 = 0.8627167344093323\n",
      "Loss for batch 35 = 0.8991084098815918\n",
      "Loss for batch 36 = 0.9092656970024109\n",
      "Loss for batch 37 = 1.053057074546814\n",
      "Loss for batch 38 = 1.0688385963439941\n",
      "Loss for batch 39 = 0.8712696433067322\n",
      "Loss for batch 40 = 0.9331092834472656\n",
      "Loss for batch 41 = 1.009768009185791\n",
      "Loss for batch 42 = 0.9818935990333557\n",
      "Loss for batch 43 = 0.8934077024459839\n",
      "Loss for batch 44 = 0.9444500207901001\n",
      "Loss for batch 45 = 0.9093456864356995\n",
      "Loss for batch 46 = 0.9727266430854797\n",
      "Loss for batch 47 = 0.9800388216972351\n",
      "Loss for batch 48 = 0.8758883476257324\n",
      "Loss for batch 49 = 0.9036685228347778\n",
      "Loss for batch 50 = 0.9489558339118958\n",
      "Loss for batch 51 = 0.8527921438217163\n",
      "Loss for batch 52 = 0.8778332471847534\n",
      "Loss for batch 53 = 0.8047918081283569\n",
      "Loss for batch 54 = 1.006545901298523\n",
      "Loss for batch 55 = 0.9110044836997986\n",
      "Loss for batch 56 = 0.8871369957923889\n",
      "Loss for batch 57 = 0.8373153209686279\n",
      "Loss for batch 58 = 0.7967719435691833\n",
      "Loss for batch 59 = 1.0846529006958008\n",
      "Loss for batch 60 = 0.9602419137954712\n",
      "Loss for batch 61 = 0.9806634783744812\n",
      "Loss for batch 62 = 0.8698107004165649\n",
      "Loss for batch 63 = 0.8794269561767578\n",
      "Loss for batch 64 = 0.7227542996406555\n",
      "Loss for batch 65 = 0.9059152007102966\n",
      "Loss for batch 66 = 0.9733097553253174\n",
      "Loss for batch 67 = 0.9359092712402344\n",
      "Loss for batch 68 = 0.8851842284202576\n",
      "Loss for batch 69 = 0.9888339042663574\n",
      "Loss for batch 70 = 1.0848088264465332\n",
      "Loss for batch 71 = 0.845560610294342\n",
      "Loss for batch 72 = 1.01168692111969\n",
      "Loss for batch 73 = 0.9315506219863892\n",
      "Loss for batch 74 = 0.8365259766578674\n",
      "Loss for batch 75 = 0.8007639646530151\n",
      "Loss for batch 76 = 0.968773365020752\n",
      "Loss for batch 77 = 0.7838213443756104\n",
      "Loss for batch 78 = 0.6256792545318604\n",
      "Loss for batch 79 = 0.8417076468467712\n",
      "Loss for batch 80 = 0.9569632411003113\n",
      "Loss for batch 81 = 1.065852165222168\n",
      "Loss for batch 82 = 1.0813301801681519\n",
      "Loss for batch 83 = 1.0339137315750122\n",
      "Loss for batch 84 = 0.8920091986656189\n",
      "Loss for batch 85 = 0.8007637858390808\n",
      "Loss for batch 86 = 0.8961233496665955\n",
      "Loss for batch 87 = 0.8995451331138611\n",
      "Loss for batch 88 = 0.7766846418380737\n",
      "Loss for batch 89 = 0.9336608648300171\n",
      "Loss for batch 90 = 0.9367982745170593\n",
      "Loss for batch 91 = 0.9532991647720337\n",
      "Loss for batch 92 = 0.8526332974433899\n",
      "Loss for batch 93 = 0.9372032284736633\n",
      "Loss for batch 94 = 0.8721247911453247\n",
      "Loss for batch 95 = 0.8105502724647522\n",
      "Loss for batch 96 = 1.1001628637313843\n",
      "Loss for batch 97 = 0.8103416562080383\n",
      "\n",
      "Training Loss for epoch 9 = 88.6495361328125\n",
      "\n",
      "Current Validation Loss = 24.01258659362793\n",
      "Best Validation Loss = 24.01258659362793\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 60.53%\n",
      "Validation Accuracy: 55.84%\n",
      "\n",
      "Epoch 10\n",
      "----------\n",
      "Loss for batch 0 = 0.8693880438804626\n",
      "Loss for batch 1 = 0.8471546769142151\n",
      "Loss for batch 2 = 0.9392796158790588\n",
      "Loss for batch 3 = 0.7648724317550659\n",
      "Loss for batch 4 = 0.7150885462760925\n",
      "Loss for batch 5 = 0.795644998550415\n",
      "Loss for batch 6 = 0.908543050289154\n",
      "Loss for batch 7 = 0.9796009659767151\n",
      "Loss for batch 8 = 0.8260994553565979\n",
      "Loss for batch 9 = 0.8237050175666809\n",
      "Loss for batch 10 = 0.9192495346069336\n",
      "Loss for batch 11 = 0.7209754586219788\n",
      "Loss for batch 12 = 0.7368703484535217\n",
      "Loss for batch 13 = 0.937233567237854\n",
      "Loss for batch 14 = 0.762111246585846\n",
      "Loss for batch 15 = 1.0433510541915894\n",
      "Loss for batch 16 = 0.9117959141731262\n",
      "Loss for batch 17 = 0.8478971123695374\n",
      "Loss for batch 18 = 0.7751407623291016\n",
      "Loss for batch 19 = 0.8615427613258362\n",
      "Loss for batch 20 = 0.8022276163101196\n",
      "Loss for batch 21 = 0.9440855979919434\n",
      "Loss for batch 22 = 0.7454125881195068\n",
      "Loss for batch 23 = 0.9003467559814453\n",
      "Loss for batch 24 = 0.8588321805000305\n",
      "Loss for batch 25 = 0.8076106905937195\n",
      "Loss for batch 26 = 1.0446064472198486\n",
      "Loss for batch 27 = 0.8116059899330139\n",
      "Loss for batch 28 = 0.9249922037124634\n",
      "Loss for batch 29 = 0.8923130035400391\n",
      "Loss for batch 30 = 0.9756457209587097\n",
      "Loss for batch 31 = 1.094403862953186\n",
      "Loss for batch 32 = 0.8137781620025635\n",
      "Loss for batch 33 = 0.9686815738677979\n",
      "Loss for batch 34 = 0.8700074553489685\n",
      "Loss for batch 35 = 0.9501170516014099\n",
      "Loss for batch 36 = 0.9162441492080688\n",
      "Loss for batch 37 = 1.016870379447937\n",
      "Loss for batch 38 = 1.0626239776611328\n",
      "Loss for batch 39 = 0.8992372751235962\n",
      "Loss for batch 40 = 0.9476358890533447\n",
      "Loss for batch 41 = 1.0249556303024292\n",
      "Loss for batch 42 = 0.9995388388633728\n",
      "Loss for batch 43 = 0.8721880316734314\n",
      "Loss for batch 44 = 0.9184966087341309\n",
      "Loss for batch 45 = 0.8792810440063477\n",
      "Loss for batch 46 = 0.9687396883964539\n",
      "Loss for batch 47 = 0.9925227761268616\n",
      "Loss for batch 48 = 0.8727200031280518\n",
      "Loss for batch 49 = 0.9358783960342407\n",
      "Loss for batch 50 = 0.9287476539611816\n",
      "Loss for batch 51 = 0.8425246477127075\n",
      "Loss for batch 52 = 0.8490586876869202\n",
      "Loss for batch 53 = 0.8140016198158264\n",
      "Loss for batch 54 = 0.9671434164047241\n",
      "Loss for batch 55 = 0.9108716249465942\n",
      "Loss for batch 56 = 0.8861757516860962\n",
      "Loss for batch 57 = 0.7994540929794312\n",
      "Loss for batch 58 = 0.7622165083885193\n",
      "Loss for batch 59 = 1.142777681350708\n",
      "Loss for batch 60 = 0.940619945526123\n",
      "Loss for batch 61 = 1.0059984922409058\n",
      "Loss for batch 62 = 0.883783221244812\n",
      "Loss for batch 63 = 0.8624224066734314\n",
      "Loss for batch 64 = 0.7598952054977417\n",
      "Loss for batch 65 = 0.8684892654418945\n",
      "Loss for batch 66 = 0.933209240436554\n",
      "Loss for batch 67 = 0.9076027870178223\n",
      "Loss for batch 68 = 0.8806052207946777\n",
      "Loss for batch 69 = 0.990742564201355\n",
      "Loss for batch 70 = 1.0766894817352295\n",
      "Loss for batch 71 = 0.8160363435745239\n",
      "Loss for batch 72 = 0.9293533563613892\n",
      "Loss for batch 73 = 0.9329125285148621\n",
      "Loss for batch 74 = 0.8403477072715759\n",
      "Loss for batch 75 = 0.8090486526489258\n",
      "Loss for batch 76 = 0.9321224689483643\n",
      "Loss for batch 77 = 0.7766402363777161\n",
      "Loss for batch 78 = 0.614247739315033\n",
      "Loss for batch 79 = 0.7749733924865723\n",
      "Loss for batch 80 = 0.8723381161689758\n",
      "Loss for batch 81 = 1.0705240964889526\n",
      "Loss for batch 82 = 1.1396336555480957\n",
      "Loss for batch 83 = 1.0310051441192627\n",
      "Loss for batch 84 = 0.8458648920059204\n",
      "Loss for batch 85 = 0.8048547506332397\n",
      "Loss for batch 86 = 0.9121506214141846\n",
      "Loss for batch 87 = 0.9173237681388855\n",
      "Loss for batch 88 = 0.7456486821174622\n",
      "Loss for batch 89 = 0.912510871887207\n",
      "Loss for batch 90 = 0.9221411347389221\n",
      "Loss for batch 91 = 0.9294089078903198\n",
      "Loss for batch 92 = 0.8176596760749817\n",
      "Loss for batch 93 = 0.9456307888031006\n",
      "Loss for batch 94 = 0.8810399770736694\n",
      "Loss for batch 95 = 0.7861438393592834\n",
      "Loss for batch 96 = 1.0653514862060547\n",
      "Loss for batch 97 = 0.8120694756507874\n",
      "\n",
      "Training Loss for epoch 10 = 87.54715728759766\n",
      "\n",
      "Current Validation Loss = 23.862327575683594\n",
      "Best Validation Loss = 23.862327575683594\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 60.82%\n",
      "Validation Accuracy: 55.07%\n",
      "\n",
      "Epoch 11\n",
      "----------\n",
      "Loss for batch 0 = 0.8610584735870361\n",
      "Loss for batch 1 = 0.8322033882141113\n",
      "Loss for batch 2 = 0.9618144035339355\n",
      "Loss for batch 3 = 0.8068662881851196\n",
      "Loss for batch 4 = 0.7355442643165588\n",
      "Loss for batch 5 = 0.8615294694900513\n",
      "Loss for batch 6 = 0.93426513671875\n",
      "Loss for batch 7 = 0.9353353977203369\n",
      "Loss for batch 8 = 0.8576489090919495\n",
      "Loss for batch 9 = 0.8247667551040649\n",
      "Loss for batch 10 = 0.9218054413795471\n",
      "Loss for batch 11 = 0.6957261562347412\n",
      "Loss for batch 12 = 0.6845777034759521\n",
      "Loss for batch 13 = 0.9362875819206238\n",
      "Loss for batch 14 = 0.746099054813385\n",
      "Loss for batch 15 = 1.0904805660247803\n",
      "Loss for batch 16 = 0.9388008713722229\n",
      "Loss for batch 17 = 0.8696065545082092\n",
      "Loss for batch 18 = 0.7720236778259277\n",
      "Loss for batch 19 = 0.8149409890174866\n",
      "Loss for batch 20 = 0.7467982769012451\n",
      "Loss for batch 21 = 0.9276167750358582\n",
      "Loss for batch 22 = 0.7317101359367371\n",
      "Loss for batch 23 = 0.8915043473243713\n",
      "Loss for batch 24 = 0.8526389598846436\n",
      "Loss for batch 25 = 0.8163419961929321\n",
      "Loss for batch 26 = 0.9750909805297852\n",
      "Loss for batch 27 = 0.8258702754974365\n",
      "Loss for batch 28 = 0.8924714922904968\n",
      "Loss for batch 29 = 0.8632392287254333\n",
      "Loss for batch 30 = 0.9731121063232422\n",
      "Loss for batch 31 = 1.0307576656341553\n",
      "Loss for batch 32 = 0.7903048992156982\n",
      "Loss for batch 33 = 0.9381880164146423\n",
      "Loss for batch 34 = 0.8330259323120117\n",
      "Loss for batch 35 = 0.9084859490394592\n",
      "Loss for batch 36 = 0.927278459072113\n",
      "Loss for batch 37 = 1.039487361907959\n",
      "Loss for batch 38 = 1.02780282497406\n",
      "Loss for batch 39 = 0.8823114633560181\n",
      "Loss for batch 40 = 0.9003794193267822\n",
      "Loss for batch 41 = 0.9814460277557373\n",
      "Loss for batch 42 = 0.94446861743927\n",
      "Loss for batch 43 = 0.8605422973632812\n",
      "Loss for batch 44 = 0.903236985206604\n",
      "Loss for batch 45 = 0.8151331543922424\n",
      "Loss for batch 46 = 0.9888846278190613\n",
      "Loss for batch 47 = 0.9822673797607422\n",
      "Loss for batch 48 = 0.8361818194389343\n",
      "Loss for batch 49 = 0.9334492683410645\n",
      "Loss for batch 50 = 0.9321330189704895\n",
      "Loss for batch 51 = 0.8503491282463074\n",
      "Loss for batch 52 = 0.8757093548774719\n",
      "Loss for batch 53 = 0.798373818397522\n",
      "Loss for batch 54 = 0.9422807693481445\n",
      "Loss for batch 55 = 0.8957018256187439\n",
      "Loss for batch 56 = 0.8615063428878784\n",
      "Loss for batch 57 = 0.8138952851295471\n",
      "Loss for batch 58 = 0.7606787085533142\n",
      "Loss for batch 59 = 1.1037830114364624\n",
      "Loss for batch 60 = 0.9485201239585876\n",
      "Loss for batch 61 = 1.005384922027588\n",
      "Loss for batch 62 = 0.8845259547233582\n",
      "Loss for batch 63 = 0.8659194111824036\n",
      "Loss for batch 64 = 0.7611262202262878\n",
      "Loss for batch 65 = 0.865759015083313\n",
      "Loss for batch 66 = 0.8970985412597656\n",
      "Loss for batch 67 = 0.9532504677772522\n",
      "Loss for batch 68 = 0.8643091320991516\n",
      "Loss for batch 69 = 0.9325850009918213\n",
      "Loss for batch 70 = 1.0610179901123047\n",
      "Loss for batch 71 = 0.8050148487091064\n",
      "Loss for batch 72 = 0.9117723107337952\n",
      "Loss for batch 73 = 0.8868050575256348\n",
      "Loss for batch 74 = 0.8191102743148804\n",
      "Loss for batch 75 = 0.8130337595939636\n",
      "Loss for batch 76 = 0.9012453556060791\n",
      "Loss for batch 77 = 0.7537864446640015\n",
      "Loss for batch 78 = 0.6180102825164795\n",
      "Loss for batch 79 = 0.7425766587257385\n",
      "Loss for batch 80 = 0.8792139887809753\n",
      "Loss for batch 81 = 1.011780858039856\n",
      "Loss for batch 82 = 1.093671202659607\n",
      "Loss for batch 83 = 1.0397424697875977\n",
      "Loss for batch 84 = 0.812272310256958\n",
      "Loss for batch 85 = 0.8195661902427673\n",
      "Loss for batch 86 = 0.8696046471595764\n",
      "Loss for batch 87 = 0.8666350245475769\n",
      "Loss for batch 88 = 0.7303582429885864\n",
      "Loss for batch 89 = 0.8933990597724915\n",
      "Loss for batch 90 = 0.9223964810371399\n",
      "Loss for batch 91 = 0.9337421655654907\n",
      "Loss for batch 92 = 0.8361292481422424\n",
      "Loss for batch 93 = 0.9668510556221008\n",
      "Loss for batch 94 = 0.8918981552124023\n",
      "Loss for batch 95 = 0.7838256359100342\n",
      "Loss for batch 96 = 1.0216596126556396\n",
      "Loss for batch 97 = 0.807316780090332\n",
      "\n",
      "Training Loss for epoch 11 = 86.40673828125\n",
      "\n",
      "Current Validation Loss = 23.6885986328125\n",
      "Best Validation Loss = 23.6885986328125\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 62.13%\n",
      "Validation Accuracy: 57.12%\n",
      "\n",
      "Epoch 12\n",
      "----------\n",
      "Loss for batch 0 = 0.9218477010726929\n",
      "Loss for batch 1 = 0.7969790697097778\n",
      "Loss for batch 2 = 0.9394627213478088\n",
      "Loss for batch 3 = 0.7634918689727783\n",
      "Loss for batch 4 = 0.7550482749938965\n",
      "Loss for batch 5 = 0.8435295820236206\n",
      "Loss for batch 6 = 0.9036173820495605\n",
      "Loss for batch 7 = 0.8960679769515991\n",
      "Loss for batch 8 = 0.8380661010742188\n",
      "Loss for batch 9 = 0.784822940826416\n",
      "Loss for batch 10 = 0.8579109907150269\n",
      "Loss for batch 11 = 0.695941686630249\n",
      "Loss for batch 12 = 0.6926059722900391\n",
      "Loss for batch 13 = 0.914063572883606\n",
      "Loss for batch 14 = 0.732779860496521\n",
      "Loss for batch 15 = 1.0165022611618042\n",
      "Loss for batch 16 = 0.8760827779769897\n",
      "Loss for batch 17 = 0.8441710472106934\n",
      "Loss for batch 18 = 0.7712377309799194\n",
      "Loss for batch 19 = 0.8212435841560364\n",
      "Loss for batch 20 = 0.769425094127655\n",
      "Loss for batch 21 = 0.9322690367698669\n",
      "Loss for batch 22 = 0.7240848541259766\n",
      "Loss for batch 23 = 0.8573275804519653\n",
      "Loss for batch 24 = 0.8574198484420776\n",
      "Loss for batch 25 = 0.7665776610374451\n",
      "Loss for batch 26 = 1.0285629034042358\n",
      "Loss for batch 27 = 0.7969258427619934\n",
      "Loss for batch 28 = 0.8529613018035889\n",
      "Loss for batch 29 = 0.8446053862571716\n",
      "Loss for batch 30 = 0.9196564555168152\n",
      "Loss for batch 31 = 1.0873762369155884\n",
      "Loss for batch 32 = 0.7675246000289917\n",
      "Loss for batch 33 = 0.8664225935935974\n",
      "Loss for batch 34 = 0.8603911399841309\n",
      "Loss for batch 35 = 0.9337176084518433\n",
      "Loss for batch 36 = 0.9554718136787415\n",
      "Loss for batch 37 = 0.9667618274688721\n",
      "Loss for batch 38 = 1.020372748374939\n",
      "Loss for batch 39 = 0.8878670334815979\n",
      "Loss for batch 40 = 0.9122059941291809\n",
      "Loss for batch 41 = 0.9899887442588806\n",
      "Loss for batch 42 = 0.8970887064933777\n",
      "Loss for batch 43 = 0.8395815491676331\n",
      "Loss for batch 44 = 0.9143235087394714\n",
      "Loss for batch 45 = 0.8313937187194824\n",
      "Loss for batch 46 = 0.9436142444610596\n",
      "Loss for batch 47 = 1.031657099723816\n",
      "Loss for batch 48 = 0.8931283950805664\n",
      "Loss for batch 49 = 0.9224357604980469\n",
      "Loss for batch 50 = 0.8788024187088013\n",
      "Loss for batch 51 = 0.8337984085083008\n",
      "Loss for batch 52 = 0.8428311347961426\n",
      "Loss for batch 53 = 0.7642230987548828\n",
      "Loss for batch 54 = 0.9207099676132202\n",
      "Loss for batch 55 = 0.884094774723053\n",
      "Loss for batch 56 = 0.8450610041618347\n",
      "Loss for batch 57 = 0.7837662100791931\n",
      "Loss for batch 58 = 0.7613357305526733\n",
      "Loss for batch 59 = 1.111353874206543\n",
      "Loss for batch 60 = 0.9310634732246399\n",
      "Loss for batch 61 = 0.9940050840377808\n",
      "Loss for batch 62 = 0.8798503875732422\n",
      "Loss for batch 63 = 0.8581104874610901\n",
      "Loss for batch 64 = 0.7264451384544373\n",
      "Loss for batch 65 = 0.8616704940795898\n",
      "Loss for batch 66 = 0.8808370232582092\n",
      "Loss for batch 67 = 0.9670261740684509\n",
      "Loss for batch 68 = 0.8420965671539307\n",
      "Loss for batch 69 = 0.9134342074394226\n",
      "Loss for batch 70 = 1.0339936017990112\n",
      "Loss for batch 71 = 0.7944713234901428\n",
      "Loss for batch 72 = 0.8836389183998108\n",
      "Loss for batch 73 = 0.9049637913703918\n",
      "Loss for batch 74 = 0.7889243960380554\n",
      "Loss for batch 75 = 0.8024091124534607\n",
      "Loss for batch 76 = 0.8954309225082397\n",
      "Loss for batch 77 = 0.7565596699714661\n",
      "Loss for batch 78 = 0.604884684085846\n",
      "Loss for batch 79 = 0.7252490520477295\n",
      "Loss for batch 80 = 0.8570126295089722\n",
      "Loss for batch 81 = 0.979284942150116\n",
      "Loss for batch 82 = 1.0670000314712524\n",
      "Loss for batch 83 = 1.0616252422332764\n",
      "Loss for batch 84 = 0.8144265413284302\n",
      "Loss for batch 85 = 0.7927507162094116\n",
      "Loss for batch 86 = 0.8713423609733582\n",
      "Loss for batch 87 = 0.9150484204292297\n",
      "Loss for batch 88 = 0.7102195024490356\n",
      "Loss for batch 89 = 0.8941048383712769\n",
      "Loss for batch 90 = 0.9323256015777588\n",
      "Loss for batch 91 = 0.9232153296470642\n",
      "Loss for batch 92 = 0.8010966777801514\n",
      "Loss for batch 93 = 0.9983934760093689\n",
      "Loss for batch 94 = 0.8317826986312866\n",
      "Loss for batch 95 = 0.7544432878494263\n",
      "Loss for batch 96 = 1.0467941761016846\n",
      "Loss for batch 97 = 0.7554932236671448\n",
      "\n",
      "Training Loss for epoch 12 = 85.21399688720703\n",
      "\n",
      "Current Validation Loss = 24.66366195678711\n",
      "Best Validation Loss = 23.6885986328125\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 61.75%\n",
      "Validation Accuracy: 57.00%\n",
      "\n",
      "Epoch 13\n",
      "----------\n",
      "Loss for batch 0 = 0.9062403440475464\n",
      "Loss for batch 1 = 0.771783173084259\n",
      "Loss for batch 2 = 0.8955895304679871\n",
      "Loss for batch 3 = 0.7374238967895508\n",
      "Loss for batch 4 = 0.746039867401123\n",
      "Loss for batch 5 = 0.8570665717124939\n",
      "Loss for batch 6 = 0.9210280776023865\n",
      "Loss for batch 7 = 0.9738070964813232\n",
      "Loss for batch 8 = 0.8273296356201172\n",
      "Loss for batch 9 = 0.7537649869918823\n",
      "Loss for batch 10 = 0.8798493146896362\n",
      "Loss for batch 11 = 0.67936110496521\n",
      "Loss for batch 12 = 0.7164403200149536\n",
      "Loss for batch 13 = 0.8951606154441833\n",
      "Loss for batch 14 = 0.7300443649291992\n",
      "Loss for batch 15 = 0.9984309077262878\n",
      "Loss for batch 16 = 0.8401358127593994\n",
      "Loss for batch 17 = 0.8753364086151123\n",
      "Loss for batch 18 = 0.7383651733398438\n",
      "Loss for batch 19 = 0.7958069443702698\n",
      "Loss for batch 20 = 0.70585697889328\n",
      "Loss for batch 21 = 0.9255495071411133\n",
      "Loss for batch 22 = 0.7303640246391296\n",
      "Loss for batch 23 = 0.8296648263931274\n",
      "Loss for batch 24 = 0.8677438497543335\n",
      "Loss for batch 25 = 0.7983586192131042\n",
      "Loss for batch 26 = 1.0307917594909668\n",
      "Loss for batch 27 = 0.7986475229263306\n",
      "Loss for batch 28 = 0.8319075107574463\n",
      "Loss for batch 29 = 0.8325360417366028\n",
      "Loss for batch 30 = 0.8769475221633911\n",
      "Loss for batch 31 = 1.091081976890564\n",
      "Loss for batch 32 = 0.74355149269104\n",
      "Loss for batch 33 = 0.8504986763000488\n",
      "Loss for batch 34 = 0.8570172786712646\n",
      "Loss for batch 35 = 0.9469789266586304\n",
      "Loss for batch 36 = 0.9760727286338806\n",
      "Loss for batch 37 = 0.941444456577301\n",
      "Loss for batch 38 = 1.0082868337631226\n",
      "Loss for batch 39 = 0.8771807551383972\n",
      "Loss for batch 40 = 0.9044850468635559\n",
      "Loss for batch 41 = 0.9654509425163269\n",
      "Loss for batch 42 = 0.9209407567977905\n",
      "Loss for batch 43 = 0.8312377333641052\n",
      "Loss for batch 44 = 0.8862350583076477\n",
      "Loss for batch 45 = 0.8549999594688416\n",
      "Loss for batch 46 = 0.9262322783470154\n",
      "Loss for batch 47 = 1.0603835582733154\n",
      "Loss for batch 48 = 0.9284240007400513\n",
      "Loss for batch 49 = 0.8776556849479675\n",
      "Loss for batch 50 = 0.8652467727661133\n",
      "Loss for batch 51 = 0.8286686539649963\n",
      "Loss for batch 52 = 0.803168535232544\n",
      "Loss for batch 53 = 0.7634938955307007\n",
      "Loss for batch 54 = 0.9229337573051453\n",
      "Loss for batch 55 = 0.8895577788352966\n",
      "Loss for batch 56 = 0.8392499685287476\n",
      "Loss for batch 57 = 0.7959742546081543\n",
      "Loss for batch 58 = 0.70810467004776\n",
      "Loss for batch 59 = 1.1163294315338135\n",
      "Loss for batch 60 = 0.9769157767295837\n",
      "Loss for batch 61 = 1.0622648000717163\n",
      "Loss for batch 62 = 0.828303873538971\n",
      "Loss for batch 63 = 0.8650882244110107\n",
      "Loss for batch 64 = 0.6907931566238403\n",
      "Loss for batch 65 = 0.8621108531951904\n",
      "Loss for batch 66 = 0.8665675520896912\n",
      "Loss for batch 67 = 0.9523802399635315\n",
      "Loss for batch 68 = 0.8499857783317566\n",
      "Loss for batch 69 = 0.936470627784729\n",
      "Loss for batch 70 = 1.0167592763900757\n",
      "Loss for batch 71 = 0.7703908681869507\n",
      "Loss for batch 72 = 0.9132843613624573\n",
      "Loss for batch 73 = 0.8895665407180786\n",
      "Loss for batch 74 = 0.7288033366203308\n",
      "Loss for batch 75 = 0.763378918170929\n",
      "Loss for batch 76 = 0.888247549533844\n",
      "Loss for batch 77 = 0.7166972160339355\n",
      "Loss for batch 78 = 0.6145530343055725\n",
      "Loss for batch 79 = 0.7052626013755798\n",
      "Loss for batch 80 = 0.8390357494354248\n",
      "Loss for batch 81 = 0.9437146186828613\n",
      "Loss for batch 82 = 0.9554428458213806\n",
      "Loss for batch 83 = 1.1097354888916016\n",
      "Loss for batch 84 = 0.8024908900260925\n",
      "Loss for batch 85 = 0.8534607291221619\n",
      "Loss for batch 86 = 0.8459594249725342\n",
      "Loss for batch 87 = 0.8694551587104797\n",
      "Loss for batch 88 = 0.7335686683654785\n",
      "Loss for batch 89 = 0.9252538681030273\n",
      "Loss for batch 90 = 0.9228230714797974\n",
      "Loss for batch 91 = 0.8609420657157898\n",
      "Loss for batch 92 = 0.8534940481185913\n",
      "Loss for batch 93 = 0.9257428050041199\n",
      "Loss for batch 94 = 0.8193066120147705\n",
      "Loss for batch 95 = 0.7541877627372742\n",
      "Loss for batch 96 = 1.0359454154968262\n",
      "Loss for batch 97 = 0.7876257300376892\n",
      "\n",
      "Training Loss for epoch 13 = 84.48426055908203\n",
      "\n",
      "Current Validation Loss = 23.56192970275879\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 63.13%\n",
      "Validation Accuracy: 57.12%\n",
      "\n",
      "Epoch 14\n",
      "----------\n",
      "Loss for batch 0 = 0.832053005695343\n",
      "Loss for batch 1 = 0.7878872752189636\n",
      "Loss for batch 2 = 0.8806930184364319\n",
      "Loss for batch 3 = 0.7249808311462402\n",
      "Loss for batch 4 = 0.7089795470237732\n",
      "Loss for batch 5 = 0.7900431752204895\n",
      "Loss for batch 6 = 0.9000380635261536\n",
      "Loss for batch 7 = 0.9060431122779846\n",
      "Loss for batch 8 = 0.8149369955062866\n",
      "Loss for batch 9 = 0.7445282936096191\n",
      "Loss for batch 10 = 0.8724666237831116\n",
      "Loss for batch 11 = 0.644597053527832\n",
      "Loss for batch 12 = 0.7274916172027588\n",
      "Loss for batch 13 = 0.8411328196525574\n",
      "Loss for batch 14 = 0.7371381521224976\n",
      "Loss for batch 15 = 0.9648566246032715\n",
      "Loss for batch 16 = 0.8038926720619202\n",
      "Loss for batch 17 = 0.8742982745170593\n",
      "Loss for batch 18 = 0.7159725427627563\n",
      "Loss for batch 19 = 0.8277998566627502\n",
      "Loss for batch 20 = 0.8101683855056763\n",
      "Loss for batch 21 = 0.9259648323059082\n",
      "Loss for batch 22 = 0.8047453165054321\n",
      "Loss for batch 23 = 0.8699167370796204\n",
      "Loss for batch 24 = 0.8397498726844788\n",
      "Loss for batch 25 = 0.7800746560096741\n",
      "Loss for batch 26 = 0.8775063753128052\n",
      "Loss for batch 27 = 0.8041656017303467\n",
      "Loss for batch 28 = 0.8679379224777222\n",
      "Loss for batch 29 = 0.8992193937301636\n",
      "Loss for batch 30 = 0.909514844417572\n",
      "Loss for batch 31 = 1.0607317686080933\n",
      "Loss for batch 32 = 0.6963071227073669\n",
      "Loss for batch 33 = 0.8658616542816162\n",
      "Loss for batch 34 = 0.8430193662643433\n",
      "Loss for batch 35 = 0.838080644607544\n",
      "Loss for batch 36 = 0.913314700126648\n",
      "Loss for batch 37 = 1.0193792581558228\n",
      "Loss for batch 38 = 0.9921907782554626\n",
      "Loss for batch 39 = 0.8862755298614502\n",
      "Loss for batch 40 = 0.870388388633728\n",
      "Loss for batch 41 = 0.9961992502212524\n",
      "Loss for batch 42 = 0.9476664662361145\n",
      "Loss for batch 43 = 0.834808349609375\n",
      "Loss for batch 44 = 0.861760139465332\n",
      "Loss for batch 45 = 0.8248767256736755\n",
      "Loss for batch 46 = 0.9131330847740173\n",
      "Loss for batch 47 = 0.9951140284538269\n",
      "Loss for batch 48 = 0.861924946308136\n",
      "Loss for batch 49 = 0.9166555404663086\n",
      "Loss for batch 50 = 0.9212148785591125\n",
      "Loss for batch 51 = 0.8247570991516113\n",
      "Loss for batch 52 = 0.8159160017967224\n",
      "Loss for batch 53 = 0.7551677823066711\n",
      "Loss for batch 54 = 0.9332013726234436\n",
      "Loss for batch 55 = 0.8864302039146423\n",
      "Loss for batch 56 = 0.81898432970047\n",
      "Loss for batch 57 = 0.752854585647583\n",
      "Loss for batch 58 = 0.7309455275535583\n",
      "Loss for batch 59 = 1.0854095220565796\n",
      "Loss for batch 60 = 0.9538902640342712\n",
      "Loss for batch 61 = 0.9656850695610046\n",
      "Loss for batch 62 = 0.8724249601364136\n",
      "Loss for batch 63 = 0.87575364112854\n",
      "Loss for batch 64 = 0.7152313590049744\n",
      "Loss for batch 65 = 0.8451721668243408\n",
      "Loss for batch 66 = 0.8576805591583252\n",
      "Loss for batch 67 = 0.9685184359550476\n",
      "Loss for batch 68 = 0.8428744673728943\n",
      "Loss for batch 69 = 0.8856825828552246\n",
      "Loss for batch 70 = 1.0019428730010986\n",
      "Loss for batch 71 = 0.7522844672203064\n",
      "Loss for batch 72 = 0.895902693271637\n",
      "Loss for batch 73 = 0.8754653334617615\n",
      "Loss for batch 74 = 0.7754101157188416\n",
      "Loss for batch 75 = 0.7921243906021118\n",
      "Loss for batch 76 = 0.8816041946411133\n",
      "Loss for batch 77 = 0.7304487228393555\n",
      "Loss for batch 78 = 0.6038709878921509\n",
      "Loss for batch 79 = 0.6798570156097412\n",
      "Loss for batch 80 = 0.8184238076210022\n",
      "Loss for batch 81 = 0.9312195181846619\n",
      "Loss for batch 82 = 0.9756202697753906\n",
      "Loss for batch 83 = 1.0883569717407227\n",
      "Loss for batch 84 = 0.8149357438087463\n",
      "Loss for batch 85 = 0.7843807339668274\n",
      "Loss for batch 86 = 0.8668797612190247\n",
      "Loss for batch 87 = 0.8544028401374817\n",
      "Loss for batch 88 = 0.6934341788291931\n",
      "Loss for batch 89 = 0.8918076157569885\n",
      "Loss for batch 90 = 0.9422268867492676\n",
      "Loss for batch 91 = 0.8495997786521912\n",
      "Loss for batch 92 = 0.7867224812507629\n",
      "Loss for batch 93 = 0.9606157541275024\n",
      "Loss for batch 94 = 0.7883774638175964\n",
      "Loss for batch 95 = 0.7197341322898865\n",
      "Loss for batch 96 = 1.0447156429290771\n",
      "Loss for batch 97 = 0.7446486949920654\n",
      "\n",
      "Training Loss for epoch 14 = 83.47929382324219\n",
      "\n",
      "Current Validation Loss = 23.612438201904297\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 62.93%\n",
      "Validation Accuracy: 57.12%\n",
      "\n",
      "Epoch 15\n",
      "----------\n",
      "Loss for batch 0 = 0.8206702470779419\n",
      "Loss for batch 1 = 0.7522861957550049\n",
      "Loss for batch 2 = 0.8680869936943054\n",
      "Loss for batch 3 = 0.7041133642196655\n",
      "Loss for batch 4 = 0.6844003200531006\n",
      "Loss for batch 5 = 0.7976072430610657\n",
      "Loss for batch 6 = 0.8613641858100891\n",
      "Loss for batch 7 = 0.8971443772315979\n",
      "Loss for batch 8 = 0.8515438437461853\n",
      "Loss for batch 9 = 0.7402597069740295\n",
      "Loss for batch 10 = 0.8691443204879761\n",
      "Loss for batch 11 = 0.6450240612030029\n",
      "Loss for batch 12 = 0.7589315176010132\n",
      "Loss for batch 13 = 0.8721828460693359\n",
      "Loss for batch 14 = 0.7397752404212952\n",
      "Loss for batch 15 = 0.9646763801574707\n",
      "Loss for batch 16 = 0.7733919024467468\n",
      "Loss for batch 17 = 0.8657827973365784\n",
      "Loss for batch 18 = 0.7203381061553955\n",
      "Loss for batch 19 = 0.7534404993057251\n",
      "Loss for batch 20 = 0.7231426239013672\n",
      "Loss for batch 21 = 0.9688339829444885\n",
      "Loss for batch 22 = 0.6886310577392578\n",
      "Loss for batch 23 = 0.8312419056892395\n",
      "Loss for batch 24 = 0.865820586681366\n",
      "Loss for batch 25 = 0.7443755269050598\n",
      "Loss for batch 26 = 0.8692941069602966\n",
      "Loss for batch 27 = 0.7569319605827332\n",
      "Loss for batch 28 = 0.804714024066925\n",
      "Loss for batch 29 = 0.7640794515609741\n",
      "Loss for batch 30 = 0.8485509157180786\n",
      "Loss for batch 31 = 1.0228744745254517\n",
      "Loss for batch 32 = 0.7248782515525818\n",
      "Loss for batch 33 = 0.845608115196228\n",
      "Loss for batch 34 = 0.7852213382720947\n",
      "Loss for batch 35 = 0.8762344121932983\n",
      "Loss for batch 36 = 0.9280413389205933\n",
      "Loss for batch 37 = 0.9802986979484558\n",
      "Loss for batch 38 = 0.9961566925048828\n",
      "Loss for batch 39 = 0.8522753119468689\n",
      "Loss for batch 40 = 0.9057663083076477\n",
      "Loss for batch 41 = 0.9409754872322083\n",
      "Loss for batch 42 = 0.8695499897003174\n",
      "Loss for batch 43 = 0.8415908813476562\n",
      "Loss for batch 44 = 0.9122186899185181\n",
      "Loss for batch 45 = 0.769132673740387\n",
      "Loss for batch 46 = 0.8997040390968323\n",
      "Loss for batch 47 = 0.9672361016273499\n",
      "Loss for batch 48 = 0.870061457157135\n",
      "Loss for batch 49 = 0.8944521546363831\n",
      "Loss for batch 50 = 0.8239656686782837\n",
      "Loss for batch 51 = 0.8160597085952759\n",
      "Loss for batch 52 = 0.8187576532363892\n",
      "Loss for batch 53 = 0.7436643838882446\n",
      "Loss for batch 54 = 0.8667219281196594\n",
      "Loss for batch 55 = 0.8805857300758362\n",
      "Loss for batch 56 = 0.7964779138565063\n",
      "Loss for batch 57 = 0.7665721774101257\n",
      "Loss for batch 58 = 0.6923454403877258\n",
      "Loss for batch 59 = 1.0636732578277588\n",
      "Loss for batch 60 = 0.9372783899307251\n",
      "Loss for batch 61 = 0.9457792639732361\n",
      "Loss for batch 62 = 0.8255935311317444\n",
      "Loss for batch 63 = 0.8096339106559753\n",
      "Loss for batch 64 = 0.6812326908111572\n",
      "Loss for batch 65 = 0.850000262260437\n",
      "Loss for batch 66 = 0.8582368493080139\n",
      "Loss for batch 67 = 0.9612416625022888\n",
      "Loss for batch 68 = 0.8281312584877014\n",
      "Loss for batch 69 = 0.8232421875\n",
      "Loss for batch 70 = 0.990684449672699\n",
      "Loss for batch 71 = 0.744233250617981\n",
      "Loss for batch 72 = 0.824551522731781\n",
      "Loss for batch 73 = 0.897981584072113\n",
      "Loss for batch 74 = 0.7543025016784668\n",
      "Loss for batch 75 = 0.8606721758842468\n",
      "Loss for batch 76 = 1.0113773345947266\n",
      "Loss for batch 77 = 0.7667977809906006\n",
      "Loss for batch 78 = 0.6162492036819458\n",
      "Loss for batch 79 = 0.6770102381706238\n",
      "Loss for batch 80 = 0.8357954025268555\n",
      "Loss for batch 81 = 0.8907743692398071\n",
      "Loss for batch 82 = 0.9066702723503113\n",
      "Loss for batch 83 = 0.9745693206787109\n",
      "Loss for batch 84 = 0.810642659664154\n",
      "Loss for batch 85 = 0.8007051348686218\n",
      "Loss for batch 86 = 0.7971888184547424\n",
      "Loss for batch 87 = 0.8673468828201294\n",
      "Loss for batch 88 = 0.6705582737922668\n",
      "Loss for batch 89 = 0.892958402633667\n",
      "Loss for batch 90 = 0.8946118354797363\n",
      "Loss for batch 91 = 0.8541424870491028\n",
      "Loss for batch 92 = 0.7797223925590515\n",
      "Loss for batch 93 = 0.9017703533172607\n",
      "Loss for batch 94 = 0.7789506316184998\n",
      "Loss for batch 95 = 0.701347827911377\n",
      "Loss for batch 96 = 0.9854303598403931\n",
      "Loss for batch 97 = 0.7134590148925781\n",
      "\n",
      "Training Loss for epoch 15 = 81.67774963378906\n",
      "\n",
      "Current Validation Loss = 24.014480590820312\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 63.32%\n",
      "Validation Accuracy: 56.61%\n",
      "\n",
      "Epoch 16\n",
      "----------\n",
      "Loss for batch 0 = 0.8121299147605896\n",
      "Loss for batch 1 = 0.7375167012214661\n",
      "Loss for batch 2 = 0.8496893048286438\n",
      "Loss for batch 3 = 0.6830142140388489\n",
      "Loss for batch 4 = 0.669597864151001\n",
      "Loss for batch 5 = 0.790447473526001\n",
      "Loss for batch 6 = 0.8723998665809631\n",
      "Loss for batch 7 = 0.906754732131958\n",
      "Loss for batch 8 = 0.7875102758407593\n",
      "Loss for batch 9 = 0.712134599685669\n",
      "Loss for batch 10 = 0.8916594386100769\n",
      "Loss for batch 11 = 0.6350814700126648\n",
      "Loss for batch 12 = 0.7592262625694275\n",
      "Loss for batch 13 = 0.8675532341003418\n",
      "Loss for batch 14 = 0.7631442546844482\n",
      "Loss for batch 15 = 0.9324442148208618\n",
      "Loss for batch 16 = 0.7531043291091919\n",
      "Loss for batch 17 = 0.8487462997436523\n",
      "Loss for batch 18 = 0.6923724412918091\n",
      "Loss for batch 19 = 0.7591716647148132\n",
      "Loss for batch 20 = 0.6813834309577942\n",
      "Loss for batch 21 = 0.9217909574508667\n",
      "Loss for batch 22 = 0.7028073072433472\n",
      "Loss for batch 23 = 0.8058173060417175\n",
      "Loss for batch 24 = 0.8561129570007324\n",
      "Loss for batch 25 = 0.7509745359420776\n",
      "Loss for batch 26 = 0.8531439900398254\n",
      "Loss for batch 27 = 0.7599124908447266\n",
      "Loss for batch 28 = 0.810197651386261\n",
      "Loss for batch 29 = 0.7708308100700378\n",
      "Loss for batch 30 = 0.835218071937561\n",
      "Loss for batch 31 = 0.9357638955116272\n",
      "Loss for batch 32 = 0.7068845629692078\n",
      "Loss for batch 33 = 0.8326143026351929\n",
      "Loss for batch 34 = 0.7749465107917786\n",
      "Loss for batch 35 = 0.9195223450660706\n",
      "Loss for batch 36 = 0.9235170483589172\n",
      "Loss for batch 37 = 0.9952993392944336\n",
      "Loss for batch 38 = 0.9515389204025269\n",
      "Loss for batch 39 = 0.8355201482772827\n",
      "Loss for batch 40 = 0.888623833656311\n",
      "Loss for batch 41 = 0.9083006978034973\n",
      "Loss for batch 42 = 0.8714959621429443\n",
      "Loss for batch 43 = 0.8460195064544678\n",
      "Loss for batch 44 = 0.8611144423484802\n",
      "Loss for batch 45 = 0.7656350135803223\n",
      "Loss for batch 46 = 0.9157652854919434\n",
      "Loss for batch 47 = 0.993898332118988\n",
      "Loss for batch 48 = 0.8948013782501221\n",
      "Loss for batch 49 = 0.8855246305465698\n",
      "Loss for batch 50 = 0.7869345545768738\n",
      "Loss for batch 51 = 0.7517743706703186\n",
      "Loss for batch 52 = 0.7515354156494141\n",
      "Loss for batch 53 = 0.687309980392456\n",
      "Loss for batch 54 = 0.891165554523468\n",
      "Loss for batch 55 = 0.8735938668251038\n",
      "Loss for batch 56 = 0.7586789727210999\n",
      "Loss for batch 57 = 0.7488662600517273\n",
      "Loss for batch 58 = 0.6744540929794312\n",
      "Loss for batch 59 = 1.0650185346603394\n",
      "Loss for batch 60 = 0.943368673324585\n",
      "Loss for batch 61 = 0.9627142548561096\n",
      "Loss for batch 62 = 0.8308199048042297\n",
      "Loss for batch 63 = 0.8178707957267761\n",
      "Loss for batch 64 = 0.6753218173980713\n",
      "Loss for batch 65 = 0.8897613286972046\n",
      "Loss for batch 66 = 0.8495952486991882\n",
      "Loss for batch 67 = 0.9632617235183716\n",
      "Loss for batch 68 = 0.7884388566017151\n",
      "Loss for batch 69 = 0.8223430514335632\n",
      "Loss for batch 70 = 0.9798434376716614\n",
      "Loss for batch 71 = 0.6976210474967957\n",
      "Loss for batch 72 = 0.840253472328186\n",
      "Loss for batch 73 = 0.872986376285553\n",
      "Loss for batch 74 = 0.7086114287376404\n",
      "Loss for batch 75 = 0.7478992938995361\n",
      "Loss for batch 76 = 0.8361865282058716\n",
      "Loss for batch 77 = 0.7568735480308533\n",
      "Loss for batch 78 = 0.5549433827400208\n",
      "Loss for batch 79 = 0.6977599263191223\n",
      "Loss for batch 80 = 0.8582282662391663\n",
      "Loss for batch 81 = 0.9024675488471985\n",
      "Loss for batch 82 = 0.8971908092498779\n",
      "Loss for batch 83 = 0.967542290687561\n",
      "Loss for batch 84 = 0.8107413053512573\n",
      "Loss for batch 85 = 0.7783781290054321\n",
      "Loss for batch 86 = 0.7640112042427063\n",
      "Loss for batch 87 = 0.8317956924438477\n",
      "Loss for batch 88 = 0.6691116690635681\n",
      "Loss for batch 89 = 0.870906412601471\n",
      "Loss for batch 90 = 0.8975378274917603\n",
      "Loss for batch 91 = 0.8795517683029175\n",
      "Loss for batch 92 = 0.8286589980125427\n",
      "Loss for batch 93 = 0.8968299031257629\n",
      "Loss for batch 94 = 0.8153854608535767\n",
      "Loss for batch 95 = 0.6816416382789612\n",
      "Loss for batch 96 = 1.0056684017181396\n",
      "Loss for batch 97 = 0.7224722504615784\n",
      "\n",
      "Training Loss for epoch 16 = 80.48258972167969\n",
      "\n",
      "Current Validation Loss = 24.148550033569336\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 63.03%\n",
      "Validation Accuracy: 56.87%\n",
      "\n",
      "Epoch 17\n",
      "----------\n",
      "Loss for batch 0 = 0.7557616233825684\n",
      "Loss for batch 1 = 0.6846891045570374\n",
      "Loss for batch 2 = 0.8418118357658386\n",
      "Loss for batch 3 = 0.7217998504638672\n",
      "Loss for batch 4 = 0.6188321709632874\n",
      "Loss for batch 5 = 0.8803539872169495\n",
      "Loss for batch 6 = 0.8869991302490234\n",
      "Loss for batch 7 = 0.9297205805778503\n",
      "Loss for batch 8 = 0.7554828524589539\n",
      "Loss for batch 9 = 0.6852855682373047\n",
      "Loss for batch 10 = 0.8611042499542236\n",
      "Loss for batch 11 = 0.6558653116226196\n",
      "Loss for batch 12 = 0.761633038520813\n",
      "Loss for batch 13 = 0.8703404664993286\n",
      "Loss for batch 14 = 0.7105305194854736\n",
      "Loss for batch 15 = 0.9279567003250122\n",
      "Loss for batch 16 = 0.7472479343414307\n",
      "Loss for batch 17 = 0.9025716781616211\n",
      "Loss for batch 18 = 0.7340838313102722\n",
      "Loss for batch 19 = 0.756846010684967\n",
      "Loss for batch 20 = 0.6814408302307129\n",
      "Loss for batch 21 = 0.9013599157333374\n",
      "Loss for batch 22 = 0.685082197189331\n",
      "Loss for batch 23 = 0.7850804328918457\n",
      "Loss for batch 24 = 0.8046914935112\n",
      "Loss for batch 25 = 0.7385901808738708\n",
      "Loss for batch 26 = 0.8327051997184753\n",
      "Loss for batch 27 = 0.7305163145065308\n",
      "Loss for batch 28 = 0.8304156064987183\n",
      "Loss for batch 29 = 0.7666921615600586\n",
      "Loss for batch 30 = 0.8276055455207825\n",
      "Loss for batch 31 = 0.9083245992660522\n",
      "Loss for batch 32 = 0.6922081112861633\n",
      "Loss for batch 33 = 0.7732553482055664\n",
      "Loss for batch 34 = 0.7636997699737549\n",
      "Loss for batch 35 = 0.8786770105361938\n",
      "Loss for batch 36 = 0.8533877730369568\n",
      "Loss for batch 37 = 1.0309922695159912\n",
      "Loss for batch 38 = 0.9079248309135437\n",
      "Loss for batch 39 = 0.8488993644714355\n",
      "Loss for batch 40 = 0.8942880034446716\n",
      "Loss for batch 41 = 0.919510006904602\n",
      "Loss for batch 42 = 0.8392907381057739\n",
      "Loss for batch 43 = 0.8060283064842224\n",
      "Loss for batch 44 = 0.856248140335083\n",
      "Loss for batch 45 = 0.729483425617218\n",
      "Loss for batch 46 = 0.9053263664245605\n",
      "Loss for batch 47 = 0.9469478726387024\n",
      "Loss for batch 48 = 0.8872717022895813\n",
      "Loss for batch 49 = 0.8559138774871826\n",
      "Loss for batch 50 = 0.7953901886940002\n",
      "Loss for batch 51 = 0.7646567821502686\n",
      "Loss for batch 52 = 0.7814074754714966\n",
      "Loss for batch 53 = 0.6890368461608887\n",
      "Loss for batch 54 = 0.8945844173431396\n",
      "Loss for batch 55 = 0.873988926410675\n",
      "Loss for batch 56 = 0.7441645264625549\n",
      "Loss for batch 57 = 0.7407534122467041\n",
      "Loss for batch 58 = 0.7270088791847229\n",
      "Loss for batch 59 = 1.0793614387512207\n",
      "Loss for batch 60 = 0.9199148416519165\n",
      "Loss for batch 61 = 0.9205237030982971\n",
      "Loss for batch 62 = 0.8370984196662903\n",
      "Loss for batch 63 = 0.8957422375679016\n",
      "Loss for batch 64 = 0.699009358882904\n",
      "Loss for batch 65 = 0.8413533568382263\n",
      "Loss for batch 66 = 0.8493698835372925\n",
      "Loss for batch 67 = 0.9604992270469666\n",
      "Loss for batch 68 = 0.8043800592422485\n",
      "Loss for batch 69 = 0.7870776057243347\n",
      "Loss for batch 70 = 0.9778210520744324\n",
      "Loss for batch 71 = 0.6773441433906555\n",
      "Loss for batch 72 = 0.8310438394546509\n",
      "Loss for batch 73 = 0.817648708820343\n",
      "Loss for batch 74 = 0.7543368339538574\n",
      "Loss for batch 75 = 0.824052631855011\n",
      "Loss for batch 76 = 0.9792514443397522\n",
      "Loss for batch 77 = 0.7265037894248962\n",
      "Loss for batch 78 = 0.6177502274513245\n",
      "Loss for batch 79 = 0.7687368988990784\n",
      "Loss for batch 80 = 0.8124285340309143\n",
      "Loss for batch 81 = 0.8975050449371338\n",
      "Loss for batch 82 = 0.9243021607398987\n",
      "Loss for batch 83 = 0.925029456615448\n",
      "Loss for batch 84 = 0.7912493348121643\n",
      "Loss for batch 85 = 0.8627809882164001\n",
      "Loss for batch 86 = 0.7796361446380615\n",
      "Loss for batch 87 = 0.8008859157562256\n",
      "Loss for batch 88 = 0.7343831658363342\n",
      "Loss for batch 89 = 0.8963150382041931\n",
      "Loss for batch 90 = 0.8852863311767578\n",
      "Loss for batch 91 = 0.8351736664772034\n",
      "Loss for batch 92 = 0.7736629843711853\n",
      "Loss for batch 93 = 0.845437228679657\n",
      "Loss for batch 94 = 0.7839822769165039\n",
      "Loss for batch 95 = 0.6648048162460327\n",
      "Loss for batch 96 = 0.9392313957214355\n",
      "Loss for batch 97 = 0.8463037014007568\n",
      "\n",
      "Training Loss for epoch 17 = 80.14897918701172\n",
      "\n",
      "Current Validation Loss = 24.26314353942871\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 4\n",
      "Train Accuracy: 62.42%\n",
      "Validation Accuracy: 56.35%\n",
      "\n",
      "Epoch 18\n",
      "----------\n",
      "Loss for batch 0 = 0.7401752471923828\n",
      "Loss for batch 1 = 0.7069243788719177\n",
      "Loss for batch 2 = 0.8863928914070129\n",
      "Loss for batch 3 = 0.7295642495155334\n",
      "Loss for batch 4 = 0.6799688339233398\n",
      "Loss for batch 5 = 0.7616188526153564\n",
      "Loss for batch 6 = 0.8799448013305664\n",
      "Loss for batch 7 = 0.9081528782844543\n",
      "Loss for batch 8 = 0.7505359053611755\n",
      "Loss for batch 9 = 0.7530763745307922\n",
      "Loss for batch 10 = 0.8825777769088745\n",
      "Loss for batch 11 = 0.6585174798965454\n",
      "Loss for batch 12 = 0.7894665002822876\n",
      "Loss for batch 13 = 0.8403654098510742\n",
      "Loss for batch 14 = 0.7498788237571716\n",
      "Loss for batch 15 = 0.9547287225723267\n",
      "Loss for batch 16 = 0.8041805028915405\n",
      "Loss for batch 17 = 0.8156931400299072\n",
      "Loss for batch 18 = 0.7511100769042969\n",
      "Loss for batch 19 = 0.7577393651008606\n",
      "Loss for batch 20 = 0.7050537467002869\n",
      "Loss for batch 21 = 0.8669055104255676\n",
      "Loss for batch 22 = 0.7292102575302124\n",
      "Loss for batch 23 = 0.8691506385803223\n",
      "Loss for batch 24 = 0.8422805070877075\n",
      "Loss for batch 25 = 0.7520507574081421\n",
      "Loss for batch 26 = 0.9086787700653076\n",
      "Loss for batch 27 = 0.7095860242843628\n",
      "Loss for batch 28 = 0.8260648846626282\n",
      "Loss for batch 29 = 0.8139452338218689\n",
      "Loss for batch 30 = 0.7834259867668152\n",
      "Loss for batch 31 = 0.9347746968269348\n",
      "Loss for batch 32 = 0.7375085353851318\n",
      "Loss for batch 33 = 0.7314568758010864\n",
      "Loss for batch 34 = 0.8026314377784729\n",
      "Loss for batch 35 = 0.8327703475952148\n",
      "Loss for batch 36 = 0.9298376441001892\n",
      "Loss for batch 37 = 0.9692263603210449\n",
      "Loss for batch 38 = 0.977425217628479\n",
      "Loss for batch 39 = 0.8427378535270691\n",
      "Loss for batch 40 = 0.880500853061676\n",
      "Loss for batch 41 = 0.9143555760383606\n",
      "Loss for batch 42 = 0.8781622648239136\n",
      "Loss for batch 43 = 0.7961854934692383\n",
      "Loss for batch 44 = 0.8886548280715942\n",
      "Loss for batch 45 = 0.7344660758972168\n",
      "Loss for batch 46 = 0.9468284249305725\n",
      "Loss for batch 47 = 0.9589654803276062\n",
      "Loss for batch 48 = 0.8205369710922241\n",
      "Loss for batch 49 = 0.805166482925415\n",
      "Loss for batch 50 = 0.7787823677062988\n",
      "Loss for batch 51 = 0.7559923529624939\n",
      "Loss for batch 52 = 0.7274587154388428\n",
      "Loss for batch 53 = 0.7273237109184265\n",
      "Loss for batch 54 = 0.8928337097167969\n",
      "Loss for batch 55 = 0.8699918985366821\n",
      "Loss for batch 56 = 0.7888726592063904\n",
      "Loss for batch 57 = 0.7371066212654114\n",
      "Loss for batch 58 = 0.6709166169166565\n",
      "Loss for batch 59 = 1.041664481163025\n",
      "Loss for batch 60 = 0.982988715171814\n",
      "Loss for batch 61 = 0.9528384208679199\n",
      "Loss for batch 62 = 0.8260669112205505\n",
      "Loss for batch 63 = 0.8619197010993958\n",
      "Loss for batch 64 = 0.7017840147018433\n",
      "Loss for batch 65 = 0.8095038533210754\n",
      "Loss for batch 66 = 0.8526147603988647\n",
      "Loss for batch 67 = 0.988772988319397\n",
      "Loss for batch 68 = 0.7736387848854065\n",
      "Loss for batch 69 = 0.8378456234931946\n",
      "Loss for batch 70 = 0.998985230922699\n",
      "Loss for batch 71 = 0.7119288444519043\n",
      "Loss for batch 72 = 0.8469859957695007\n",
      "Loss for batch 73 = 0.8306032419204712\n",
      "Loss for batch 74 = 0.7183135747909546\n",
      "Loss for batch 75 = 0.7797237038612366\n",
      "Loss for batch 76 = 0.7924267649650574\n",
      "Loss for batch 77 = 0.7093836665153503\n",
      "Loss for batch 78 = 0.663028359413147\n",
      "Loss for batch 79 = 0.6803030967712402\n",
      "Loss for batch 80 = 0.847894549369812\n",
      "Loss for batch 81 = 0.9018846750259399\n",
      "Loss for batch 82 = 0.9017878770828247\n",
      "Loss for batch 83 = 0.9486055374145508\n",
      "Loss for batch 84 = 0.8430488109588623\n",
      "Loss for batch 85 = 0.7690916657447815\n",
      "Loss for batch 86 = 0.8054749965667725\n",
      "Loss for batch 87 = 0.7613940834999084\n",
      "Loss for batch 88 = 0.6889326572418213\n",
      "Loss for batch 89 = 0.8462093472480774\n",
      "Loss for batch 90 = 0.8879305720329285\n",
      "Loss for batch 91 = 0.8080447316169739\n",
      "Loss for batch 92 = 0.8572796583175659\n",
      "Loss for batch 93 = 0.899748682975769\n",
      "Loss for batch 94 = 0.7638793587684631\n",
      "Loss for batch 95 = 0.6505582332611084\n",
      "Loss for batch 96 = 1.0256301164627075\n",
      "Loss for batch 97 = 0.777928352355957\n",
      "\n",
      "Training Loss for epoch 18 = 80.28507995605469\n",
      "\n",
      "Current Validation Loss = 24.0654354095459\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 5\n",
      "Train Accuracy: 64.86%\n",
      "Validation Accuracy: 58.02%\n",
      "\n",
      "Epoch 19\n",
      "----------\n",
      "Loss for batch 0 = 0.7625401616096497\n",
      "Loss for batch 1 = 0.6850243210792542\n",
      "Loss for batch 2 = 0.8594724535942078\n",
      "Loss for batch 3 = 0.6610656380653381\n",
      "Loss for batch 4 = 0.6891491413116455\n",
      "Loss for batch 5 = 0.8021469116210938\n",
      "Loss for batch 6 = 0.8489260673522949\n",
      "Loss for batch 7 = 0.9499364495277405\n",
      "Loss for batch 8 = 0.7486173510551453\n",
      "Loss for batch 9 = 0.7084275484085083\n",
      "Loss for batch 10 = 0.815132200717926\n",
      "Loss for batch 11 = 0.670182466506958\n",
      "Loss for batch 12 = 0.8411667346954346\n",
      "Loss for batch 13 = 0.8135866522789001\n",
      "Loss for batch 14 = 0.6660707592964172\n",
      "Loss for batch 15 = 0.9730551242828369\n",
      "Loss for batch 16 = 0.7443200349807739\n",
      "Loss for batch 17 = 0.771679699420929\n",
      "Loss for batch 18 = 0.6959208250045776\n",
      "Loss for batch 19 = 0.7188840508460999\n",
      "Loss for batch 20 = 0.6930170059204102\n",
      "Loss for batch 21 = 0.8847302198410034\n",
      "Loss for batch 22 = 0.6458260416984558\n",
      "Loss for batch 23 = 0.8086203932762146\n",
      "Loss for batch 24 = 0.8198411464691162\n",
      "Loss for batch 25 = 0.6899725198745728\n",
      "Loss for batch 26 = 0.8045879602432251\n",
      "Loss for batch 27 = 0.7750124335289001\n",
      "Loss for batch 28 = 0.8069068789482117\n",
      "Loss for batch 29 = 0.8117476105690002\n",
      "Loss for batch 30 = 0.7613993883132935\n",
      "Loss for batch 31 = 0.9289020299911499\n",
      "Loss for batch 32 = 0.7023290991783142\n",
      "Loss for batch 33 = 0.7511234879493713\n",
      "Loss for batch 34 = 0.7387315034866333\n",
      "Loss for batch 35 = 0.8314651250839233\n",
      "Loss for batch 36 = 0.8955150246620178\n",
      "Loss for batch 37 = 0.9605119228363037\n",
      "Loss for batch 38 = 0.9008197784423828\n",
      "Loss for batch 39 = 0.8311581611633301\n",
      "Loss for batch 40 = 0.8479709625244141\n",
      "Loss for batch 41 = 0.8991045951843262\n",
      "Loss for batch 42 = 0.8487825989723206\n",
      "Loss for batch 43 = 0.8338118195533752\n",
      "Loss for batch 44 = 0.8570654392242432\n",
      "Loss for batch 45 = 0.7142845988273621\n",
      "Loss for batch 46 = 0.8757274150848389\n",
      "Loss for batch 47 = 0.9739075899124146\n",
      "Loss for batch 48 = 0.781745433807373\n",
      "Loss for batch 49 = 0.7972984910011292\n",
      "Loss for batch 50 = 0.7576461434364319\n",
      "Loss for batch 51 = 0.75848788022995\n",
      "Loss for batch 52 = 0.7239635586738586\n",
      "Loss for batch 53 = 0.6431578993797302\n",
      "Loss for batch 54 = 0.8900373578071594\n",
      "Loss for batch 55 = 0.8591955900192261\n",
      "Loss for batch 56 = 0.7211431264877319\n",
      "Loss for batch 57 = 0.7401154041290283\n",
      "Loss for batch 58 = 0.7022629976272583\n",
      "Loss for batch 59 = 1.034470796585083\n",
      "Loss for batch 60 = 0.9176844954490662\n",
      "Loss for batch 61 = 0.9277668595314026\n",
      "Loss for batch 62 = 0.8817277550697327\n",
      "Loss for batch 63 = 0.9534573554992676\n",
      "Loss for batch 64 = 0.7013299465179443\n",
      "Loss for batch 65 = 0.8534745573997498\n",
      "Loss for batch 66 = 0.831121563911438\n",
      "Loss for batch 67 = 0.9265033006668091\n",
      "Loss for batch 68 = 0.7726355791091919\n",
      "Loss for batch 69 = 0.7573307752609253\n",
      "Loss for batch 70 = 0.9148675203323364\n",
      "Loss for batch 71 = 0.6777798533439636\n",
      "Loss for batch 72 = 0.8418850898742676\n",
      "Loss for batch 73 = 0.8728653192520142\n",
      "Loss for batch 74 = 0.7060136198997498\n",
      "Loss for batch 75 = 0.7635020613670349\n",
      "Loss for batch 76 = 0.8112040162086487\n",
      "Loss for batch 77 = 0.6897642612457275\n",
      "Loss for batch 78 = 0.5975056886672974\n",
      "Loss for batch 79 = 0.6699044704437256\n",
      "Loss for batch 80 = 0.7598499059677124\n",
      "Loss for batch 81 = 0.8740496039390564\n",
      "Loss for batch 82 = 0.8733896613121033\n",
      "Loss for batch 83 = 0.9036005139350891\n",
      "Loss for batch 84 = 0.8069298267364502\n",
      "Loss for batch 85 = 0.7075604796409607\n",
      "Loss for batch 86 = 0.7557253837585449\n",
      "Loss for batch 87 = 0.8998379707336426\n",
      "Loss for batch 88 = 0.7274171710014343\n",
      "Loss for batch 89 = 0.968002200126648\n",
      "Loss for batch 90 = 0.9294866919517517\n",
      "Loss for batch 91 = 0.9002747535705566\n",
      "Loss for batch 92 = 0.9538471102714539\n",
      "Loss for batch 93 = 0.8274699449539185\n",
      "Loss for batch 94 = 0.7754321694374084\n",
      "Loss for batch 95 = 0.7575401067733765\n",
      "Loss for batch 96 = 0.962421715259552\n",
      "Loss for batch 97 = 0.766017735004425\n",
      "\n",
      "Training Loss for epoch 19 = 78.94487762451172\n",
      "\n",
      "Current Validation Loss = 24.58347511291504\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 6\n",
      "Train Accuracy: 64.79%\n",
      "Validation Accuracy: 57.38%\n",
      "\n",
      "Epoch 20\n",
      "----------\n",
      "Loss for batch 0 = 0.7710403203964233\n",
      "Loss for batch 1 = 0.739474892616272\n",
      "Loss for batch 2 = 0.8660786747932434\n",
      "Loss for batch 3 = 0.7207052111625671\n",
      "Loss for batch 4 = 0.6269599199295044\n",
      "Loss for batch 5 = 0.7533171772956848\n",
      "Loss for batch 6 = 0.8782367706298828\n",
      "Loss for batch 7 = 0.9376228451728821\n",
      "Loss for batch 8 = 0.7987048029899597\n",
      "Loss for batch 9 = 0.7271062135696411\n",
      "Loss for batch 10 = 0.8427115082740784\n",
      "Loss for batch 11 = 0.6666315793991089\n",
      "Loss for batch 12 = 0.6990085244178772\n",
      "Loss for batch 13 = 0.7819300889968872\n",
      "Loss for batch 14 = 0.6864009499549866\n",
      "Loss for batch 15 = 0.9863438606262207\n",
      "Loss for batch 16 = 0.8152550458908081\n",
      "Loss for batch 17 = 0.7844462394714355\n",
      "Loss for batch 18 = 0.7077199816703796\n",
      "Loss for batch 19 = 0.6803054809570312\n",
      "Loss for batch 20 = 0.6817886829376221\n",
      "Loss for batch 21 = 0.8384890556335449\n",
      "Loss for batch 22 = 0.6238125562667847\n",
      "Loss for batch 23 = 0.7796717882156372\n",
      "Loss for batch 24 = 0.7796822786331177\n",
      "Loss for batch 25 = 0.7284281253814697\n",
      "Loss for batch 26 = 0.8456114530563354\n",
      "Loss for batch 27 = 0.697889506816864\n",
      "Loss for batch 28 = 0.8495820760726929\n",
      "Loss for batch 29 = 0.8247163891792297\n",
      "Loss for batch 30 = 0.8094550967216492\n",
      "Loss for batch 31 = 0.8244291543960571\n",
      "Loss for batch 32 = 0.8463960289955139\n",
      "Loss for batch 33 = 0.7025508284568787\n",
      "Loss for batch 34 = 0.8101680278778076\n",
      "Loss for batch 35 = 0.7951867580413818\n",
      "Loss for batch 36 = 0.8898862600326538\n",
      "Loss for batch 37 = 0.9226592779159546\n",
      "Loss for batch 38 = 0.9399681091308594\n",
      "Loss for batch 39 = 0.7937946319580078\n",
      "Loss for batch 40 = 0.8518839478492737\n",
      "Loss for batch 41 = 0.8847282528877258\n",
      "Loss for batch 42 = 0.7806415557861328\n",
      "Loss for batch 43 = 0.9053426384925842\n",
      "Loss for batch 44 = 0.8661011457443237\n",
      "Loss for batch 45 = 0.6981122493743896\n",
      "Loss for batch 46 = 0.8418999910354614\n",
      "Loss for batch 47 = 1.0141853094100952\n",
      "Loss for batch 48 = 0.8374961018562317\n",
      "Loss for batch 49 = 0.8099890351295471\n",
      "Loss for batch 50 = 0.7637867331504822\n",
      "Loss for batch 51 = 0.7303906083106995\n",
      "Loss for batch 52 = 0.6670567393302917\n",
      "Loss for batch 53 = 0.6818568706512451\n",
      "Loss for batch 54 = 0.8482158184051514\n",
      "Loss for batch 55 = 0.817033588886261\n",
      "Loss for batch 56 = 0.7515652179718018\n",
      "Loss for batch 57 = 0.728198766708374\n",
      "Loss for batch 58 = 0.6478155851364136\n",
      "Loss for batch 59 = 1.085742473602295\n",
      "Loss for batch 60 = 0.9133190512657166\n",
      "Loss for batch 61 = 0.9300785064697266\n",
      "Loss for batch 62 = 0.7800197005271912\n",
      "Loss for batch 63 = 0.821161150932312\n",
      "Loss for batch 64 = 0.6476925611495972\n",
      "Loss for batch 65 = 0.7662964463233948\n",
      "Loss for batch 66 = 0.8351576328277588\n",
      "Loss for batch 67 = 1.0596168041229248\n",
      "Loss for batch 68 = 0.7793995141983032\n",
      "Loss for batch 69 = 0.7638277411460876\n",
      "Loss for batch 70 = 0.9646486639976501\n",
      "Loss for batch 71 = 0.6489726305007935\n",
      "Loss for batch 72 = 0.7889904975891113\n",
      "Loss for batch 73 = 0.8899126052856445\n",
      "Loss for batch 74 = 0.7052014470100403\n",
      "Loss for batch 75 = 0.7551906704902649\n",
      "Loss for batch 76 = 0.7780424952507019\n",
      "Loss for batch 77 = 0.7569940090179443\n",
      "Loss for batch 78 = 0.5902301073074341\n",
      "Loss for batch 79 = 0.6754629611968994\n",
      "Loss for batch 80 = 0.7258919477462769\n",
      "Loss for batch 81 = 0.9250788688659668\n",
      "Loss for batch 82 = 0.9098802804946899\n",
      "Loss for batch 83 = 0.9739832282066345\n",
      "Loss for batch 84 = 0.9022053480148315\n",
      "Loss for batch 85 = 0.7364165186882019\n",
      "Loss for batch 86 = 0.8525375723838806\n",
      "Loss for batch 87 = 0.7481321096420288\n",
      "Loss for batch 88 = 0.6096259355545044\n",
      "Loss for batch 89 = 0.9029492139816284\n",
      "Loss for batch 90 = 0.8861531615257263\n",
      "Loss for batch 91 = 0.7939842343330383\n",
      "Loss for batch 92 = 0.8309890031814575\n",
      "Loss for batch 93 = 0.8016356229782104\n",
      "Loss for batch 94 = 0.743080198764801\n",
      "Loss for batch 95 = 0.634772002696991\n",
      "Loss for batch 96 = 0.9471768140792847\n",
      "Loss for batch 97 = 0.7632527351379395\n",
      "\n",
      "Training Loss for epoch 20 = 78.20417022705078\n",
      "\n",
      "Current Validation Loss = 24.628938674926758\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 7\n",
      "Train Accuracy: 65.66%\n",
      "Validation Accuracy: 58.79%\n",
      "\n",
      "Epoch 21\n",
      "----------\n",
      "Loss for batch 0 = 0.7389481067657471\n",
      "Loss for batch 1 = 0.6866110563278198\n",
      "Loss for batch 2 = 0.813476026058197\n",
      "Loss for batch 3 = 0.6493836641311646\n",
      "Loss for batch 4 = 0.7176252603530884\n",
      "Loss for batch 5 = 0.8320147395133972\n",
      "Loss for batch 6 = 0.8648204803466797\n",
      "Loss for batch 7 = 0.8776296377182007\n",
      "Loss for batch 8 = 0.7435995936393738\n",
      "Loss for batch 9 = 0.7178252935409546\n",
      "Loss for batch 10 = 0.8573195338249207\n",
      "Loss for batch 11 = 0.6506603360176086\n",
      "Loss for batch 12 = 0.768803060054779\n",
      "Loss for batch 13 = 0.7862781882286072\n",
      "Loss for batch 14 = 0.6858739852905273\n",
      "Loss for batch 15 = 0.8679877519607544\n",
      "Loss for batch 16 = 0.6697518229484558\n",
      "Loss for batch 17 = 0.780647337436676\n",
      "Loss for batch 18 = 0.7138190269470215\n",
      "Loss for batch 19 = 0.70135897397995\n",
      "Loss for batch 20 = 0.7170661687850952\n",
      "Loss for batch 21 = 0.8855889439582825\n",
      "Loss for batch 22 = 0.6504577994346619\n",
      "Loss for batch 23 = 0.7899221181869507\n",
      "Loss for batch 24 = 0.754443883895874\n",
      "Loss for batch 25 = 0.6517090201377869\n",
      "Loss for batch 26 = 0.7796127200126648\n",
      "Loss for batch 27 = 0.7219222784042358\n",
      "Loss for batch 28 = 0.7942550778388977\n",
      "Loss for batch 29 = 0.8424004316329956\n",
      "Loss for batch 30 = 0.7794385552406311\n",
      "Loss for batch 31 = 0.8397173881530762\n",
      "Loss for batch 32 = 0.8031110167503357\n",
      "Loss for batch 33 = 0.6468876004219055\n",
      "Loss for batch 34 = 0.7821420431137085\n",
      "Loss for batch 35 = 0.7641480565071106\n",
      "Loss for batch 36 = 0.9392507076263428\n",
      "Loss for batch 37 = 0.9588197469711304\n",
      "Loss for batch 38 = 0.8605637550354004\n",
      "Loss for batch 39 = 0.802207350730896\n",
      "Loss for batch 40 = 0.8468067646026611\n",
      "Loss for batch 41 = 0.8839460611343384\n",
      "Loss for batch 42 = 0.7924729585647583\n",
      "Loss for batch 43 = 0.8392543196678162\n",
      "Loss for batch 44 = 0.8351131677627563\n",
      "Loss for batch 45 = 0.6598184704780579\n",
      "Loss for batch 46 = 0.8779672384262085\n",
      "Loss for batch 47 = 0.9997047185897827\n",
      "Loss for batch 48 = 0.7783288955688477\n",
      "Loss for batch 49 = 0.8288013935089111\n",
      "Loss for batch 50 = 0.7453133463859558\n",
      "Loss for batch 51 = 0.7319381237030029\n",
      "Loss for batch 52 = 0.6854908466339111\n",
      "Loss for batch 53 = 0.6436431407928467\n",
      "Loss for batch 54 = 0.8408204913139343\n",
      "Loss for batch 55 = 0.7678622603416443\n",
      "Loss for batch 56 = 0.7240346670150757\n",
      "Loss for batch 57 = 0.730641782283783\n",
      "Loss for batch 58 = 0.654092013835907\n",
      "Loss for batch 59 = 1.120124340057373\n",
      "Loss for batch 60 = 0.9139115214347839\n",
      "Loss for batch 61 = 0.9607148170471191\n",
      "Loss for batch 62 = 0.7826176285743713\n",
      "Loss for batch 63 = 0.8035129308700562\n",
      "Loss for batch 64 = 0.6233988404273987\n",
      "Loss for batch 65 = 0.8101838827133179\n",
      "Loss for batch 66 = 0.840124249458313\n",
      "Loss for batch 67 = 0.9394498467445374\n",
      "Loss for batch 68 = 0.7374098300933838\n",
      "Loss for batch 69 = 0.7507312297821045\n",
      "Loss for batch 70 = 0.9176436066627502\n",
      "Loss for batch 71 = 0.763765275478363\n",
      "Loss for batch 72 = 0.7992420792579651\n",
      "Loss for batch 73 = 0.8053362369537354\n",
      "Loss for batch 74 = 0.6868335604667664\n",
      "Loss for batch 75 = 0.7368170022964478\n",
      "Loss for batch 76 = 0.7433940172195435\n",
      "Loss for batch 77 = 0.712490975856781\n",
      "Loss for batch 78 = 0.5081906914710999\n",
      "Loss for batch 79 = 0.6779574155807495\n",
      "Loss for batch 80 = 0.7201090455055237\n",
      "Loss for batch 81 = 0.9106271266937256\n",
      "Loss for batch 82 = 0.7783152461051941\n",
      "Loss for batch 83 = 0.8590410947799683\n",
      "Loss for batch 84 = 0.7462228536605835\n",
      "Loss for batch 85 = 0.735685408115387\n",
      "Loss for batch 86 = 0.7261621952056885\n",
      "Loss for batch 87 = 0.8116598725318909\n",
      "Loss for batch 88 = 0.7445548176765442\n",
      "Loss for batch 89 = 0.8814966082572937\n",
      "Loss for batch 90 = 0.9124925136566162\n",
      "Loss for batch 91 = 0.7964813709259033\n",
      "Loss for batch 92 = 0.842069685459137\n",
      "Loss for batch 93 = 0.8217912912368774\n",
      "Loss for batch 94 = 0.6742815375328064\n",
      "Loss for batch 95 = 0.6645846962928772\n",
      "Loss for batch 96 = 1.1962133646011353\n",
      "Loss for batch 97 = 0.8198415637016296\n",
      "\n",
      "Training Loss for epoch 21 = 77.02960968017578\n",
      "\n",
      "Current Validation Loss = 24.532184600830078\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 8\n",
      "Train Accuracy: 66.56%\n",
      "Validation Accuracy: 56.35%\n",
      "\n",
      "Epoch 22\n",
      "----------\n",
      "Loss for batch 0 = 0.7298436760902405\n",
      "Loss for batch 1 = 0.6772797107696533\n",
      "Loss for batch 2 = 0.8492887616157532\n",
      "Loss for batch 3 = 0.6749750971794128\n",
      "Loss for batch 4 = 0.678561270236969\n",
      "Loss for batch 5 = 0.7124979496002197\n",
      "Loss for batch 6 = 0.7537477016448975\n",
      "Loss for batch 7 = 0.8897309303283691\n",
      "Loss for batch 8 = 0.7825313806533813\n",
      "Loss for batch 9 = 0.748293399810791\n",
      "Loss for batch 10 = 0.8272229433059692\n",
      "Loss for batch 11 = 0.6818221807479858\n",
      "Loss for batch 12 = 0.7104101181030273\n",
      "Loss for batch 13 = 0.8070309162139893\n",
      "Loss for batch 14 = 0.6301814317703247\n",
      "Loss for batch 15 = 0.8622758984565735\n",
      "Loss for batch 16 = 0.6829849481582642\n",
      "Loss for batch 17 = 0.7050805687904358\n",
      "Loss for batch 18 = 0.6846280097961426\n",
      "Loss for batch 19 = 0.6783725023269653\n",
      "Loss for batch 20 = 0.6856343150138855\n",
      "Loss for batch 21 = 0.798024594783783\n",
      "Loss for batch 22 = 0.6319532990455627\n",
      "Loss for batch 23 = 0.8426709771156311\n",
      "Loss for batch 24 = 0.8078688979148865\n",
      "Loss for batch 25 = 0.7487368583679199\n",
      "Loss for batch 26 = 0.7801561951637268\n",
      "Loss for batch 27 = 0.7324002385139465\n",
      "Loss for batch 28 = 0.8062742352485657\n",
      "Loss for batch 29 = 0.8872730135917664\n",
      "Loss for batch 30 = 0.7701179385185242\n",
      "Loss for batch 31 = 0.7941351532936096\n",
      "Loss for batch 32 = 0.8640292882919312\n",
      "Loss for batch 33 = 0.6680031418800354\n",
      "Loss for batch 34 = 0.7971356511116028\n",
      "Loss for batch 35 = 0.7438170909881592\n",
      "Loss for batch 36 = 0.8023574352264404\n",
      "Loss for batch 37 = 0.9242395758628845\n",
      "Loss for batch 38 = 0.8282303810119629\n",
      "Loss for batch 39 = 0.8209614753723145\n",
      "Loss for batch 40 = 0.8691148161888123\n",
      "Loss for batch 41 = 0.956915020942688\n",
      "Loss for batch 42 = 0.7410215139389038\n",
      "Loss for batch 43 = 0.7710161805152893\n",
      "Loss for batch 44 = 0.8386263251304626\n",
      "Loss for batch 45 = 0.7011752128601074\n",
      "Loss for batch 46 = 0.8024482131004333\n",
      "Loss for batch 47 = 0.9716222882270813\n",
      "Loss for batch 48 = 0.7795301675796509\n",
      "Loss for batch 49 = 0.7504780292510986\n",
      "Loss for batch 50 = 0.7413347363471985\n",
      "Loss for batch 51 = 0.6918068528175354\n",
      "Loss for batch 52 = 0.6641907691955566\n",
      "Loss for batch 53 = 0.6410884261131287\n",
      "Loss for batch 54 = 0.8645110726356506\n",
      "Loss for batch 55 = 0.7592098116874695\n",
      "Loss for batch 56 = 0.6662203073501587\n",
      "Loss for batch 57 = 0.6650976538658142\n",
      "Loss for batch 58 = 0.5895784497261047\n",
      "Loss for batch 59 = 1.0347530841827393\n",
      "Loss for batch 60 = 0.9239376187324524\n",
      "Loss for batch 61 = 0.9296308755874634\n",
      "Loss for batch 62 = 0.8039538860321045\n",
      "Loss for batch 63 = 0.8569275140762329\n",
      "Loss for batch 64 = 0.6269401907920837\n",
      "Loss for batch 65 = 0.7677657604217529\n",
      "Loss for batch 66 = 0.850635290145874\n",
      "Loss for batch 67 = 0.9564450979232788\n",
      "Loss for batch 68 = 0.7232982516288757\n",
      "Loss for batch 69 = 0.7450417280197144\n",
      "Loss for batch 70 = 0.9609074592590332\n",
      "Loss for batch 71 = 0.6876984238624573\n",
      "Loss for batch 72 = 0.7910529971122742\n",
      "Loss for batch 73 = 0.7784921526908875\n",
      "Loss for batch 74 = 0.7027380466461182\n",
      "Loss for batch 75 = 0.7827028036117554\n",
      "Loss for batch 76 = 0.7685995101928711\n",
      "Loss for batch 77 = 0.7079399228096008\n",
      "Loss for batch 78 = 0.548724889755249\n",
      "Loss for batch 79 = 0.627205491065979\n",
      "Loss for batch 80 = 0.6907210946083069\n",
      "Loss for batch 81 = 0.8567879796028137\n",
      "Loss for batch 82 = 0.8156429529190063\n",
      "Loss for batch 83 = 0.8702743649482727\n",
      "Loss for batch 84 = 0.7676402926445007\n",
      "Loss for batch 85 = 0.6507728099822998\n",
      "Loss for batch 86 = 0.7372642159461975\n",
      "Loss for batch 87 = 0.7710812091827393\n",
      "Loss for batch 88 = 0.692801833152771\n",
      "Loss for batch 89 = 0.8691093921661377\n",
      "Loss for batch 90 = 0.9669827222824097\n",
      "Loss for batch 91 = 0.7727113366127014\n",
      "Loss for batch 92 = 0.8160427212715149\n",
      "Loss for batch 93 = 0.7658340930938721\n",
      "Loss for batch 94 = 0.8079220056533813\n",
      "Loss for batch 95 = 0.6448655128479004\n",
      "Loss for batch 96 = 0.8751224875450134\n",
      "Loss for batch 97 = 0.692485511302948\n",
      "\n",
      "Training Loss for epoch 22 = 75.6052017211914\n",
      "\n",
      "Current Validation Loss = 25.405433654785156\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 9\n",
      "Train Accuracy: 66.05%\n",
      "Validation Accuracy: 58.41%\n",
      "\n",
      "Epoch 23\n",
      "----------\n",
      "Loss for batch 0 = 0.759365975856781\n",
      "Loss for batch 1 = 0.5741358399391174\n",
      "Loss for batch 2 = 0.8692011833190918\n",
      "Loss for batch 3 = 0.6189258694648743\n",
      "Loss for batch 4 = 0.6380274295806885\n",
      "Loss for batch 5 = 0.7856329083442688\n",
      "Loss for batch 6 = 0.7308735251426697\n",
      "Loss for batch 7 = 0.9871973991394043\n",
      "Loss for batch 8 = 0.7697936296463013\n",
      "Loss for batch 9 = 0.670898973941803\n",
      "Loss for batch 10 = 0.7689199447631836\n",
      "Loss for batch 11 = 0.6374810934066772\n",
      "Loss for batch 12 = 0.6768099069595337\n",
      "Loss for batch 13 = 0.7671988010406494\n",
      "Loss for batch 14 = 0.6216148734092712\n",
      "Loss for batch 15 = 0.837338924407959\n",
      "Loss for batch 16 = 0.7495774626731873\n",
      "Loss for batch 17 = 0.7235714197158813\n",
      "Loss for batch 18 = 0.6669226288795471\n",
      "Loss for batch 19 = 0.6830269694328308\n",
      "Loss for batch 20 = 0.7143016457557678\n",
      "Loss for batch 21 = 0.9239559769630432\n",
      "Loss for batch 22 = 0.5961953997612\n",
      "Loss for batch 23 = 0.7739052772521973\n",
      "Loss for batch 24 = 0.7989869713783264\n",
      "Loss for batch 25 = 0.6130110025405884\n",
      "Loss for batch 26 = 0.712683916091919\n",
      "Loss for batch 27 = 0.6848620772361755\n",
      "Loss for batch 28 = 0.7814810276031494\n",
      "Loss for batch 29 = 0.7809253931045532\n",
      "Loss for batch 30 = 0.7552819848060608\n",
      "Loss for batch 31 = 0.792259931564331\n",
      "Loss for batch 32 = 0.875044047832489\n",
      "Loss for batch 33 = 0.6479177474975586\n",
      "Loss for batch 34 = 0.7677398920059204\n",
      "Loss for batch 35 = 0.7477608919143677\n",
      "Loss for batch 36 = 0.8167906999588013\n",
      "Loss for batch 37 = 0.9053778052330017\n",
      "Loss for batch 38 = 0.7925636768341064\n",
      "Loss for batch 39 = 0.7977371215820312\n",
      "Loss for batch 40 = 0.7962542772293091\n",
      "Loss for batch 41 = 0.9283789396286011\n",
      "Loss for batch 42 = 0.722821831703186\n",
      "Loss for batch 43 = 0.7703455090522766\n",
      "Loss for batch 44 = 0.7795348167419434\n",
      "Loss for batch 45 = 0.6990707516670227\n",
      "Loss for batch 46 = 0.8361027836799622\n",
      "Loss for batch 47 = 0.9652100205421448\n",
      "Loss for batch 48 = 0.7606897950172424\n",
      "Loss for batch 49 = 0.7286851406097412\n",
      "Loss for batch 50 = 0.7161500453948975\n",
      "Loss for batch 51 = 0.7429575324058533\n",
      "Loss for batch 52 = 0.6729641556739807\n",
      "Loss for batch 53 = 0.6349695324897766\n",
      "Loss for batch 54 = 0.7771195769309998\n",
      "Loss for batch 55 = 0.7623635530471802\n",
      "Loss for batch 56 = 0.684736967086792\n",
      "Loss for batch 57 = 0.6575838923454285\n",
      "Loss for batch 58 = 0.6744430065155029\n",
      "Loss for batch 59 = 0.9434378743171692\n",
      "Loss for batch 60 = 0.882177472114563\n",
      "Loss for batch 61 = 0.9231986999511719\n",
      "Loss for batch 62 = 0.7204954028129578\n",
      "Loss for batch 63 = 0.7557705044746399\n",
      "Loss for batch 64 = 0.6355656981468201\n",
      "Loss for batch 65 = 0.7661924362182617\n",
      "Loss for batch 66 = 0.839453399181366\n",
      "Loss for batch 67 = 0.981060266494751\n",
      "Loss for batch 68 = 0.721267819404602\n",
      "Loss for batch 69 = 0.7259302735328674\n",
      "Loss for batch 70 = 0.9743657112121582\n",
      "Loss for batch 71 = 0.6718933582305908\n",
      "Loss for batch 72 = 0.7677695155143738\n",
      "Loss for batch 73 = 0.7822716236114502\n",
      "Loss for batch 74 = 0.6492455005645752\n",
      "Loss for batch 75 = 0.7343888282775879\n",
      "Loss for batch 76 = 0.7368482351303101\n",
      "Loss for batch 77 = 0.7132571339607239\n",
      "Loss for batch 78 = 0.5177679061889648\n",
      "Loss for batch 79 = 0.642109215259552\n",
      "Loss for batch 80 = 0.7220322489738464\n",
      "Loss for batch 81 = 0.862140417098999\n",
      "Loss for batch 82 = 0.8101152777671814\n",
      "Loss for batch 83 = 0.845768928527832\n",
      "Loss for batch 84 = 0.757057249546051\n",
      "Loss for batch 85 = 0.6620423197746277\n",
      "Loss for batch 86 = 0.6904558539390564\n",
      "Loss for batch 87 = 0.7200111746788025\n",
      "Loss for batch 88 = 0.5517239570617676\n",
      "Loss for batch 89 = 0.873807430267334\n",
      "Loss for batch 90 = 0.8632786870002747\n",
      "Loss for batch 91 = 0.7453067302703857\n",
      "Loss for batch 92 = 0.7200188636779785\n",
      "Loss for batch 93 = 0.7573537826538086\n",
      "Loss for batch 94 = 0.6895148754119873\n",
      "Loss for batch 95 = 0.6241990923881531\n",
      "Loss for batch 96 = 0.9409797191619873\n",
      "Loss for batch 97 = 0.6853131651878357\n",
      "\n",
      "Training Loss for epoch 23 = 73.73126220703125\n",
      "\n",
      "Current Validation Loss = 25.221633911132812\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 10\n",
      "Train Accuracy: 68.49%\n",
      "Validation Accuracy: 58.15%\n",
      "\n",
      "Epoch 24\n",
      "----------\n",
      "Loss for batch 0 = 0.6734983325004578\n",
      "Loss for batch 1 = 0.6216700077056885\n",
      "Loss for batch 2 = 0.8103951811790466\n",
      "Loss for batch 3 = 0.6457738876342773\n",
      "Loss for batch 4 = 0.6266828775405884\n",
      "Loss for batch 5 = 0.698725700378418\n",
      "Loss for batch 6 = 0.7276747822761536\n",
      "Loss for batch 7 = 0.8418588638305664\n",
      "Loss for batch 8 = 0.7083951830863953\n",
      "Loss for batch 9 = 0.6517925262451172\n",
      "Loss for batch 10 = 0.8236914873123169\n",
      "Loss for batch 11 = 0.5835046172142029\n",
      "Loss for batch 12 = 0.7381051778793335\n",
      "Loss for batch 13 = 0.7560495734214783\n",
      "Loss for batch 14 = 0.6028712391853333\n",
      "Loss for batch 15 = 0.8035979270935059\n",
      "Loss for batch 16 = 0.6373282074928284\n",
      "Loss for batch 17 = 0.670966386795044\n",
      "Loss for batch 18 = 0.6541645526885986\n",
      "Loss for batch 19 = 0.708781898021698\n",
      "Loss for batch 20 = 0.6678308248519897\n",
      "Loss for batch 21 = 0.8937450647354126\n",
      "Loss for batch 22 = 0.5665687322616577\n",
      "Loss for batch 23 = 0.7499228715896606\n",
      "Loss for batch 24 = 0.7876467108726501\n",
      "Loss for batch 25 = 0.5894425511360168\n",
      "Loss for batch 26 = 0.6748293042182922\n",
      "Loss for batch 27 = 0.6250331401824951\n",
      "Loss for batch 28 = 0.7510043382644653\n",
      "Loss for batch 29 = 0.7268348932266235\n",
      "Loss for batch 30 = 0.740123450756073\n",
      "Loss for batch 31 = 0.7452860474586487\n",
      "Loss for batch 32 = 0.8293010592460632\n",
      "Loss for batch 33 = 0.6274341344833374\n",
      "Loss for batch 34 = 0.7656781077384949\n",
      "Loss for batch 35 = 0.7158989310264587\n",
      "Loss for batch 36 = 0.8013083934783936\n",
      "Loss for batch 37 = 0.9021450877189636\n",
      "Loss for batch 38 = 0.7845167517662048\n",
      "Loss for batch 39 = 0.7965896725654602\n",
      "Loss for batch 40 = 0.8309630155563354\n",
      "Loss for batch 41 = 0.8993322849273682\n",
      "Loss for batch 42 = 0.6931876540184021\n",
      "Loss for batch 43 = 0.7713901400566101\n",
      "Loss for batch 44 = 0.7570409178733826\n",
      "Loss for batch 45 = 0.6416780948638916\n",
      "Loss for batch 46 = 0.7841818928718567\n",
      "Loss for batch 47 = 0.928898811340332\n",
      "Loss for batch 48 = 0.7240709662437439\n",
      "Loss for batch 49 = 0.7329992055892944\n",
      "Loss for batch 50 = 0.7297106981277466\n",
      "Loss for batch 51 = 0.7075327038764954\n",
      "Loss for batch 52 = 0.6518986821174622\n",
      "Loss for batch 53 = 0.5388085842132568\n",
      "Loss for batch 54 = 0.7266663908958435\n",
      "Loss for batch 55 = 0.7469220757484436\n",
      "Loss for batch 56 = 0.6472069025039673\n",
      "Loss for batch 57 = 0.6433017253875732\n",
      "Loss for batch 58 = 0.6630496978759766\n",
      "Loss for batch 59 = 0.933768630027771\n",
      "Loss for batch 60 = 0.8201075196266174\n",
      "Loss for batch 61 = 0.9207435846328735\n",
      "Loss for batch 62 = 0.7015674710273743\n",
      "Loss for batch 63 = 0.7254631519317627\n",
      "Loss for batch 64 = 0.63887619972229\n",
      "Loss for batch 65 = 0.7316687703132629\n",
      "Loss for batch 66 = 0.8165333867073059\n",
      "Loss for batch 67 = 0.9719592928886414\n",
      "Loss for batch 68 = 0.6884028315544128\n",
      "Loss for batch 69 = 0.6706331372261047\n",
      "Loss for batch 70 = 0.9047567844390869\n",
      "Loss for batch 71 = 0.6586698889732361\n",
      "Loss for batch 72 = 0.7649266719818115\n",
      "Loss for batch 73 = 0.7353068590164185\n",
      "Loss for batch 74 = 0.6156240105628967\n",
      "Loss for batch 75 = 0.7313693165779114\n",
      "Loss for batch 76 = 0.6927105784416199\n",
      "Loss for batch 77 = 0.7227920889854431\n",
      "Loss for batch 78 = 0.4993191361427307\n",
      "Loss for batch 79 = 0.6252915263175964\n",
      "Loss for batch 80 = 0.6765224933624268\n",
      "Loss for batch 81 = 0.8503175973892212\n",
      "Loss for batch 82 = 0.7992470860481262\n",
      "Loss for batch 83 = 0.7890008687973022\n",
      "Loss for batch 84 = 0.7662600874900818\n",
      "Loss for batch 85 = 0.6504030823707581\n",
      "Loss for batch 86 = 0.6932740807533264\n",
      "Loss for batch 87 = 0.7155402302742004\n",
      "Loss for batch 88 = 0.5461349487304688\n",
      "Loss for batch 89 = 0.8267172574996948\n",
      "Loss for batch 90 = 0.8083525896072388\n",
      "Loss for batch 91 = 0.7301053404808044\n",
      "Loss for batch 92 = 0.7090032696723938\n",
      "Loss for batch 93 = 0.7188878655433655\n",
      "Loss for batch 94 = 0.6326581835746765\n",
      "Loss for batch 95 = 0.5902816653251648\n",
      "Loss for batch 96 = 0.9577544927597046\n",
      "Loss for batch 97 = 0.6847145557403564\n",
      "\n",
      "Training Loss for epoch 24 = 71.26115417480469\n",
      "\n",
      "Current Validation Loss = 26.013957977294922\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 11\n",
      "Train Accuracy: 68.93%\n",
      "Validation Accuracy: 57.64%\n",
      "\n",
      "Epoch 25\n",
      "----------\n",
      "Loss for batch 0 = 0.6472551226615906\n",
      "Loss for batch 1 = 0.5986179113388062\n",
      "Loss for batch 2 = 0.7824901938438416\n",
      "Loss for batch 3 = 0.6302781105041504\n",
      "Loss for batch 4 = 0.6134244203567505\n",
      "Loss for batch 5 = 0.6721184253692627\n",
      "Loss for batch 6 = 0.70712810754776\n",
      "Loss for batch 7 = 0.8425024747848511\n",
      "Loss for batch 8 = 0.6659969687461853\n",
      "Loss for batch 9 = 0.6456727981567383\n",
      "Loss for batch 10 = 0.7986049652099609\n",
      "Loss for batch 11 = 0.5921810865402222\n",
      "Loss for batch 12 = 0.7300674319267273\n",
      "Loss for batch 13 = 0.738126277923584\n",
      "Loss for batch 14 = 0.5807591080665588\n",
      "Loss for batch 15 = 0.7764425277709961\n",
      "Loss for batch 16 = 0.6039879322052002\n",
      "Loss for batch 17 = 0.6609330177307129\n",
      "Loss for batch 18 = 0.6100391149520874\n",
      "Loss for batch 19 = 0.6669833064079285\n",
      "Loss for batch 20 = 0.6594221591949463\n",
      "Loss for batch 21 = 0.8205048441886902\n",
      "Loss for batch 22 = 0.5368068218231201\n",
      "Loss for batch 23 = 0.7208021283149719\n",
      "Loss for batch 24 = 0.7863284945487976\n",
      "Loss for batch 25 = 0.5643031001091003\n",
      "Loss for batch 26 = 0.6675898432731628\n",
      "Loss for batch 27 = 0.584680438041687\n",
      "Loss for batch 28 = 0.7225464582443237\n",
      "Loss for batch 29 = 0.697940468788147\n",
      "Loss for batch 30 = 0.7031856179237366\n",
      "Loss for batch 31 = 0.7136262655258179\n",
      "Loss for batch 32 = 0.8337950706481934\n",
      "Loss for batch 33 = 0.6116634607315063\n",
      "Loss for batch 34 = 0.7376344799995422\n",
      "Loss for batch 35 = 0.6988677978515625\n",
      "Loss for batch 36 = 0.7880067825317383\n",
      "Loss for batch 37 = 0.8993054628372192\n",
      "Loss for batch 38 = 0.7519723773002625\n",
      "Loss for batch 39 = 0.7621045708656311\n",
      "Loss for batch 40 = 0.8301665186882019\n",
      "Loss for batch 41 = 0.8818632960319519\n",
      "Loss for batch 42 = 0.692085862159729\n",
      "Loss for batch 43 = 0.7787383198738098\n",
      "Loss for batch 44 = 0.7718881368637085\n",
      "Loss for batch 45 = 0.6411035060882568\n",
      "Loss for batch 46 = 0.7464088797569275\n",
      "Loss for batch 47 = 0.918174684047699\n",
      "Loss for batch 48 = 0.7391061186790466\n",
      "Loss for batch 49 = 0.7214552164077759\n",
      "Loss for batch 50 = 0.7326513528823853\n",
      "Loss for batch 51 = 0.6871563196182251\n",
      "Loss for batch 52 = 0.6247403621673584\n",
      "Loss for batch 53 = 0.5335364937782288\n",
      "Loss for batch 54 = 0.7025477290153503\n",
      "Loss for batch 55 = 0.7559421062469482\n",
      "Loss for batch 56 = 0.6353439688682556\n",
      "Loss for batch 57 = 0.6248788833618164\n",
      "Loss for batch 58 = 0.6218862533569336\n",
      "Loss for batch 59 = 0.9326693415641785\n",
      "Loss for batch 60 = 0.817810595035553\n",
      "Loss for batch 61 = 0.8899787068367004\n",
      "Loss for batch 62 = 0.7128556370735168\n",
      "Loss for batch 63 = 0.7593325972557068\n",
      "Loss for batch 64 = 0.6515536308288574\n",
      "Loss for batch 65 = 0.7215975522994995\n",
      "Loss for batch 66 = 0.8163758516311646\n",
      "Loss for batch 67 = 0.998096764087677\n",
      "Loss for batch 68 = 0.6743995547294617\n",
      "Loss for batch 69 = 0.7273618578910828\n",
      "Loss for batch 70 = 0.879593014717102\n",
      "Loss for batch 71 = 0.685677170753479\n",
      "Loss for batch 72 = 0.7568591237068176\n",
      "Loss for batch 73 = 0.7223849296569824\n",
      "Loss for batch 74 = 0.6190952658653259\n",
      "Loss for batch 75 = 0.7751430869102478\n",
      "Loss for batch 76 = 0.6908919811248779\n",
      "Loss for batch 77 = 0.6809170842170715\n",
      "Loss for batch 78 = 0.4650879204273224\n",
      "Loss for batch 79 = 0.6826100945472717\n",
      "Loss for batch 80 = 0.6741646528244019\n",
      "Loss for batch 81 = 0.784052848815918\n",
      "Loss for batch 82 = 0.7704962491989136\n",
      "Loss for batch 83 = 0.797681450843811\n",
      "Loss for batch 84 = 0.7685984969139099\n",
      "Loss for batch 85 = 0.6573182344436646\n",
      "Loss for batch 86 = 0.6690611243247986\n",
      "Loss for batch 87 = 0.7100045680999756\n",
      "Loss for batch 88 = 0.5700086951255798\n",
      "Loss for batch 89 = 0.7838339805603027\n",
      "Loss for batch 90 = 0.8257595300674438\n",
      "Loss for batch 91 = 0.7696839570999146\n",
      "Loss for batch 92 = 0.7862673997879028\n",
      "Loss for batch 93 = 0.7524322271347046\n",
      "Loss for batch 94 = 0.6289039850234985\n",
      "Loss for batch 95 = 0.5729973912239075\n",
      "Loss for batch 96 = 0.9812465906143188\n",
      "Loss for batch 97 = 0.6275410056114197\n",
      "\n",
      "Training Loss for epoch 25 = 70.25471496582031\n",
      "\n",
      "Current Validation Loss = 26.830333709716797\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 12\n",
      "Train Accuracy: 68.71%\n",
      "Validation Accuracy: 58.02%\n",
      "\n",
      "Epoch 26\n",
      "----------\n",
      "Loss for batch 0 = 0.6681455969810486\n",
      "Loss for batch 1 = 0.6042640805244446\n",
      "Loss for batch 2 = 0.7747592329978943\n",
      "Loss for batch 3 = 0.6289228796958923\n",
      "Loss for batch 4 = 0.6067525744438171\n",
      "Loss for batch 5 = 0.6903289556503296\n",
      "Loss for batch 6 = 0.6918869614601135\n",
      "Loss for batch 7 = 0.816333532333374\n",
      "Loss for batch 8 = 0.6898184418678284\n",
      "Loss for batch 9 = 0.6820812225341797\n",
      "Loss for batch 10 = 0.782442569732666\n",
      "Loss for batch 11 = 0.578498125076294\n",
      "Loss for batch 12 = 0.720617413520813\n",
      "Loss for batch 13 = 0.7282974123954773\n",
      "Loss for batch 14 = 0.6279507875442505\n",
      "Loss for batch 15 = 0.7539354562759399\n",
      "Loss for batch 16 = 0.6027405858039856\n",
      "Loss for batch 17 = 0.6800804138183594\n",
      "Loss for batch 18 = 0.6130996942520142\n",
      "Loss for batch 19 = 0.578460693359375\n",
      "Loss for batch 20 = 0.6070840954780579\n",
      "Loss for batch 21 = 0.8144460320472717\n",
      "Loss for batch 22 = 0.5323728322982788\n",
      "Loss for batch 23 = 0.6957432627677917\n",
      "Loss for batch 24 = 0.7862560153007507\n",
      "Loss for batch 25 = 0.5805541276931763\n",
      "Loss for batch 26 = 0.7572898864746094\n",
      "Loss for batch 27 = 0.5817671418190002\n",
      "Loss for batch 28 = 0.7083086371421814\n",
      "Loss for batch 29 = 0.6795475482940674\n",
      "Loss for batch 30 = 0.7456958889961243\n",
      "Loss for batch 31 = 0.7161988615989685\n",
      "Loss for batch 32 = 0.7967750430107117\n",
      "Loss for batch 33 = 0.6030412316322327\n",
      "Loss for batch 34 = 0.7158547639846802\n",
      "Loss for batch 35 = 0.6927019357681274\n",
      "Loss for batch 36 = 0.7831369638442993\n",
      "Loss for batch 37 = 0.8783813118934631\n",
      "Loss for batch 38 = 0.7299575805664062\n",
      "Loss for batch 39 = 0.7587832808494568\n",
      "Loss for batch 40 = 0.807437539100647\n",
      "Loss for batch 41 = 0.8778903484344482\n",
      "Loss for batch 42 = 0.7071593403816223\n",
      "Loss for batch 43 = 0.7806762456893921\n",
      "Loss for batch 44 = 0.7549315690994263\n",
      "Loss for batch 45 = 0.6379646062850952\n",
      "Loss for batch 46 = 0.7111653685569763\n",
      "Loss for batch 47 = 0.9227845668792725\n",
      "Loss for batch 48 = 0.689506471157074\n",
      "Loss for batch 49 = 0.7684076428413391\n",
      "Loss for batch 50 = 0.7566852569580078\n",
      "Loss for batch 51 = 0.7438898086547852\n",
      "Loss for batch 52 = 0.6192705631256104\n",
      "Loss for batch 53 = 0.5858602523803711\n",
      "Loss for batch 54 = 0.7058690786361694\n",
      "Loss for batch 55 = 0.7426975965499878\n",
      "Loss for batch 56 = 0.6217658519744873\n",
      "Loss for batch 57 = 0.6177274584770203\n",
      "Loss for batch 58 = 0.6051939725875854\n",
      "Loss for batch 59 = 0.9101165533065796\n",
      "Loss for batch 60 = 0.8073718547821045\n",
      "Loss for batch 61 = 0.9293761849403381\n",
      "Loss for batch 62 = 0.6909146308898926\n",
      "Loss for batch 63 = 0.6728174090385437\n",
      "Loss for batch 64 = 0.6373842358589172\n",
      "Loss for batch 65 = 0.6624125242233276\n",
      "Loss for batch 66 = 0.8392764925956726\n",
      "Loss for batch 67 = 0.9894333481788635\n",
      "Loss for batch 68 = 0.6807737350463867\n",
      "Loss for batch 69 = 0.6713610291481018\n",
      "Loss for batch 70 = 0.8847097158432007\n",
      "Loss for batch 71 = 0.6025730967521667\n",
      "Loss for batch 72 = 0.7154842615127563\n",
      "Loss for batch 73 = 0.6809734106063843\n",
      "Loss for batch 74 = 0.6188157200813293\n",
      "Loss for batch 75 = 0.7037619948387146\n",
      "Loss for batch 76 = 0.6861231327056885\n",
      "Loss for batch 77 = 0.6883811950683594\n",
      "Loss for batch 78 = 0.44748198986053467\n",
      "Loss for batch 79 = 0.6895864605903625\n",
      "Loss for batch 80 = 0.6455253958702087\n",
      "Loss for batch 81 = 0.77997887134552\n",
      "Loss for batch 82 = 0.7672891616821289\n",
      "Loss for batch 83 = 0.7535840272903442\n",
      "Loss for batch 84 = 0.7018797397613525\n",
      "Loss for batch 85 = 0.7183804512023926\n",
      "Loss for batch 86 = 0.6826097369194031\n",
      "Loss for batch 87 = 0.6442176103591919\n",
      "Loss for batch 88 = 0.5289393663406372\n",
      "Loss for batch 89 = 0.8213733434677124\n",
      "Loss for batch 90 = 0.8192856311798096\n",
      "Loss for batch 91 = 0.7232409119606018\n",
      "Loss for batch 92 = 0.6352729797363281\n",
      "Loss for batch 93 = 0.7191187143325806\n",
      "Loss for batch 94 = 0.5954301953315735\n",
      "Loss for batch 95 = 0.6744277477264404\n",
      "Loss for batch 96 = 1.0590605735778809\n",
      "Loss for batch 97 = 0.6459138989448547\n",
      "\n",
      "Training Loss for epoch 26 = 69.46485137939453\n",
      "\n",
      "Current Validation Loss = 27.484243392944336\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 13\n",
      "Train Accuracy: 66.72%\n",
      "Validation Accuracy: 56.74%\n",
      "\n",
      "Epoch 27\n",
      "----------\n",
      "Loss for batch 0 = 0.6940731406211853\n",
      "Loss for batch 1 = 0.7894055843353271\n",
      "Loss for batch 2 = 0.825111985206604\n",
      "Loss for batch 3 = 0.6728719472885132\n",
      "Loss for batch 4 = 0.6675573587417603\n",
      "Loss for batch 5 = 0.6745774745941162\n",
      "Loss for batch 6 = 0.6836110949516296\n",
      "Loss for batch 7 = 0.8410511612892151\n",
      "Loss for batch 8 = 0.7485096454620361\n",
      "Loss for batch 9 = 0.7067006826400757\n",
      "Loss for batch 10 = 0.8295978307723999\n",
      "Loss for batch 11 = 0.5930458903312683\n",
      "Loss for batch 12 = 0.6820873618125916\n",
      "Loss for batch 13 = 0.7442134022712708\n",
      "Loss for batch 14 = 0.5984354019165039\n",
      "Loss for batch 15 = 0.8054267168045044\n",
      "Loss for batch 16 = 0.5952635407447815\n",
      "Loss for batch 17 = 0.7509092092514038\n",
      "Loss for batch 18 = 0.6228194236755371\n",
      "Loss for batch 19 = 0.5710517168045044\n",
      "Loss for batch 20 = 0.6114541888237\n",
      "Loss for batch 21 = 0.7898828983306885\n",
      "Loss for batch 22 = 0.5352268815040588\n",
      "Loss for batch 23 = 0.691608726978302\n",
      "Loss for batch 24 = 0.8061496019363403\n",
      "Loss for batch 25 = 0.5589024424552917\n",
      "Loss for batch 26 = 0.6518027186393738\n",
      "Loss for batch 27 = 0.5878666043281555\n",
      "Loss for batch 28 = 0.6891956925392151\n",
      "Loss for batch 29 = 0.6312946081161499\n",
      "Loss for batch 30 = 0.6868167519569397\n",
      "Loss for batch 31 = 0.7136064171791077\n",
      "Loss for batch 32 = 0.8119393587112427\n",
      "Loss for batch 33 = 0.5872504115104675\n",
      "Loss for batch 34 = 0.7463535070419312\n",
      "Loss for batch 35 = 0.7059383988380432\n",
      "Loss for batch 36 = 0.7939071655273438\n",
      "Loss for batch 37 = 0.8476553559303284\n",
      "Loss for batch 38 = 0.7422170042991638\n",
      "Loss for batch 39 = 0.7773281931877136\n",
      "Loss for batch 40 = 0.7962341904640198\n",
      "Loss for batch 41 = 0.8951764106750488\n",
      "Loss for batch 42 = 0.6739814281463623\n",
      "Loss for batch 43 = 0.7901772856712341\n",
      "Loss for batch 44 = 0.7997006773948669\n",
      "Loss for batch 45 = 0.6420336961746216\n",
      "Loss for batch 46 = 0.7184741497039795\n",
      "Loss for batch 47 = 0.9352976083755493\n",
      "Loss for batch 48 = 0.681076169013977\n",
      "Loss for batch 49 = 0.7065771818161011\n",
      "Loss for batch 50 = 0.727767825126648\n",
      "Loss for batch 51 = 0.7119755744934082\n",
      "Loss for batch 52 = 0.5853562951087952\n",
      "Loss for batch 53 = 0.5423095226287842\n",
      "Loss for batch 54 = 0.7100813984870911\n",
      "Loss for batch 55 = 0.7581077218055725\n",
      "Loss for batch 56 = 0.6358293294906616\n",
      "Loss for batch 57 = 0.5731613636016846\n",
      "Loss for batch 58 = 0.648154616355896\n",
      "Loss for batch 59 = 0.900024950504303\n",
      "Loss for batch 60 = 0.8578365445137024\n",
      "Loss for batch 61 = 0.8910646438598633\n",
      "Loss for batch 62 = 0.6979552507400513\n",
      "Loss for batch 63 = 0.6846489906311035\n",
      "Loss for batch 64 = 0.5373072624206543\n",
      "Loss for batch 65 = 0.6521493792533875\n",
      "Loss for batch 66 = 0.824705183506012\n",
      "Loss for batch 67 = 0.9605588316917419\n",
      "Loss for batch 68 = 0.6844120621681213\n",
      "Loss for batch 69 = 0.6623314619064331\n",
      "Loss for batch 70 = 0.8908743858337402\n",
      "Loss for batch 71 = 0.5819862484931946\n",
      "Loss for batch 72 = 0.7186527252197266\n",
      "Loss for batch 73 = 0.6458269357681274\n",
      "Loss for batch 74 = 0.5816594958305359\n",
      "Loss for batch 75 = 0.6671156287193298\n",
      "Loss for batch 76 = 0.7392390966415405\n",
      "Loss for batch 77 = 0.6755419373512268\n",
      "Loss for batch 78 = 0.43754372000694275\n",
      "Loss for batch 79 = 0.6229490637779236\n",
      "Loss for batch 80 = 0.6596114635467529\n",
      "Loss for batch 81 = 0.7244663834571838\n",
      "Loss for batch 82 = 0.7493123412132263\n",
      "Loss for batch 83 = 0.7088785171508789\n",
      "Loss for batch 84 = 0.6942148208618164\n",
      "Loss for batch 85 = 0.6500189900398254\n",
      "Loss for batch 86 = 0.643022894859314\n",
      "Loss for batch 87 = 0.6719803214073181\n",
      "Loss for batch 88 = 0.5309098958969116\n",
      "Loss for batch 89 = 0.8136307597160339\n",
      "Loss for batch 90 = 0.7489774227142334\n",
      "Loss for batch 91 = 0.7428286075592041\n",
      "Loss for batch 92 = 0.6588031053543091\n",
      "Loss for batch 93 = 0.7279916405677795\n",
      "Loss for batch 94 = 0.5658327341079712\n",
      "Loss for batch 95 = 0.5619785785675049\n",
      "Loss for batch 96 = 0.9745359420776367\n",
      "Loss for batch 97 = 0.5979275107383728\n",
      "\n",
      "Training Loss for epoch 27 = 68.93350219726562\n",
      "\n",
      "Current Validation Loss = 27.61040496826172\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 14\n",
      "Train Accuracy: 70.12%\n",
      "Validation Accuracy: 57.77%\n",
      "\n",
      "Epoch 28\n",
      "----------\n",
      "Loss for batch 0 = 0.6842733025550842\n",
      "Loss for batch 1 = 0.5743392109870911\n",
      "Loss for batch 2 = 0.7614697217941284\n",
      "Loss for batch 3 = 0.583006739616394\n",
      "Loss for batch 4 = 0.598698616027832\n",
      "Loss for batch 5 = 0.6257135272026062\n",
      "Loss for batch 6 = 0.6692330241203308\n",
      "Loss for batch 7 = 0.791731595993042\n",
      "Loss for batch 8 = 0.6257274150848389\n",
      "Loss for batch 9 = 0.6470564007759094\n",
      "Loss for batch 10 = 0.7482635974884033\n",
      "Loss for batch 11 = 0.5665690898895264\n",
      "Loss for batch 12 = 0.6752548217773438\n",
      "Loss for batch 13 = 0.7150489687919617\n",
      "Loss for batch 14 = 0.6087846159934998\n",
      "Loss for batch 15 = 0.7323988676071167\n",
      "Loss for batch 16 = 0.5761634111404419\n",
      "Loss for batch 17 = 0.7632752060890198\n",
      "Loss for batch 18 = 0.6346242427825928\n",
      "Loss for batch 19 = 0.5328410267829895\n",
      "Loss for batch 20 = 0.6046806573867798\n",
      "Loss for batch 21 = 0.7689514756202698\n",
      "Loss for batch 22 = 0.5173760652542114\n",
      "Loss for batch 23 = 0.6815603971481323\n",
      "Loss for batch 24 = 0.777874231338501\n",
      "Loss for batch 25 = 0.5388544797897339\n",
      "Loss for batch 26 = 0.6273977160453796\n",
      "Loss for batch 27 = 0.5552444458007812\n",
      "Loss for batch 28 = 0.6299848556518555\n",
      "Loss for batch 29 = 0.5950798392295837\n",
      "Loss for batch 30 = 0.6760135293006897\n",
      "Loss for batch 31 = 0.6425266265869141\n",
      "Loss for batch 32 = 0.8059289455413818\n",
      "Loss for batch 33 = 0.5577183961868286\n",
      "Loss for batch 34 = 0.7420715093612671\n",
      "Loss for batch 35 = 0.6647765040397644\n",
      "Loss for batch 36 = 0.7557855248451233\n",
      "Loss for batch 37 = 0.8222216963768005\n",
      "Loss for batch 38 = 0.6939645409584045\n",
      "Loss for batch 39 = 0.7975867986679077\n",
      "Loss for batch 40 = 0.8094537854194641\n",
      "Loss for batch 41 = 0.9004924893379211\n",
      "Loss for batch 42 = 0.7078872323036194\n",
      "Loss for batch 43 = 0.7737618088722229\n",
      "Loss for batch 44 = 0.7033711671829224\n",
      "Loss for batch 45 = 0.6371797323226929\n",
      "Loss for batch 46 = 0.6717187166213989\n",
      "Loss for batch 47 = 0.9218215942382812\n",
      "Loss for batch 48 = 0.6957340240478516\n",
      "Loss for batch 49 = 0.7253590226173401\n",
      "Loss for batch 50 = 0.7356705665588379\n",
      "Loss for batch 51 = 0.7014877796173096\n",
      "Loss for batch 52 = 0.5801230669021606\n",
      "Loss for batch 53 = 0.547310471534729\n",
      "Loss for batch 54 = 0.7015300393104553\n",
      "Loss for batch 55 = 0.6862488389015198\n",
      "Loss for batch 56 = 0.6006650924682617\n",
      "Loss for batch 57 = 0.5663040280342102\n",
      "Loss for batch 58 = 0.6355762481689453\n",
      "Loss for batch 59 = 0.8744497299194336\n",
      "Loss for batch 60 = 0.8363939523696899\n",
      "Loss for batch 61 = 0.872886061668396\n",
      "Loss for batch 62 = 0.6817945837974548\n",
      "Loss for batch 63 = 0.6623833775520325\n",
      "Loss for batch 64 = 0.5252553224563599\n",
      "Loss for batch 65 = 0.6722401976585388\n",
      "Loss for batch 66 = 0.7942292094230652\n",
      "Loss for batch 67 = 1.006107211112976\n",
      "Loss for batch 68 = 0.6615905165672302\n",
      "Loss for batch 69 = 0.6284610033035278\n",
      "Loss for batch 70 = 0.8613377213478088\n",
      "Loss for batch 71 = 0.5879310369491577\n",
      "Loss for batch 72 = 0.686386227607727\n",
      "Loss for batch 73 = 0.6571025848388672\n",
      "Loss for batch 74 = 0.6140170097351074\n",
      "Loss for batch 75 = 0.6758639216423035\n",
      "Loss for batch 76 = 0.6949880123138428\n",
      "Loss for batch 77 = 0.6289625763893127\n",
      "Loss for batch 78 = 0.4462660253047943\n",
      "Loss for batch 79 = 0.6325446963310242\n",
      "Loss for batch 80 = 0.640028715133667\n",
      "Loss for batch 81 = 0.7675235867500305\n",
      "Loss for batch 82 = 0.7343912720680237\n",
      "Loss for batch 83 = 0.7297877073287964\n",
      "Loss for batch 84 = 0.7066200971603394\n",
      "Loss for batch 85 = 0.6406857371330261\n",
      "Loss for batch 86 = 0.6039162278175354\n",
      "Loss for batch 87 = 0.6372262835502625\n",
      "Loss for batch 88 = 0.5341695547103882\n",
      "Loss for batch 89 = 0.794610321521759\n",
      "Loss for batch 90 = 0.7170090675354004\n",
      "Loss for batch 91 = 0.6952230334281921\n",
      "Loss for batch 92 = 0.604273796081543\n",
      "Loss for batch 93 = 0.7180007100105286\n",
      "Loss for batch 94 = 0.5500556230545044\n",
      "Loss for batch 95 = 0.5710105299949646\n",
      "Loss for batch 96 = 0.9495641589164734\n",
      "Loss for batch 97 = 0.57913738489151\n",
      "\n",
      "Training Loss for epoch 28 = 66.7461929321289\n",
      "\n",
      "Current Validation Loss = 28.454484939575195\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 15\n",
      "Train Accuracy: 70.19%\n",
      "Validation Accuracy: 57.00%\n",
      "\n",
      "Epoch 29\n",
      "----------\n",
      "Loss for batch 0 = 0.6022261381149292\n",
      "Loss for batch 1 = 0.5205230712890625\n",
      "Loss for batch 2 = 0.7958415150642395\n",
      "Loss for batch 3 = 0.5676375031471252\n",
      "Loss for batch 4 = 0.6158162355422974\n",
      "Loss for batch 5 = 0.6359853148460388\n",
      "Loss for batch 6 = 0.6483282446861267\n",
      "Loss for batch 7 = 0.765268862247467\n",
      "Loss for batch 8 = 0.6037649512290955\n",
      "Loss for batch 9 = 0.6448053121566772\n",
      "Loss for batch 10 = 0.6895059943199158\n",
      "Loss for batch 11 = 0.6035996079444885\n",
      "Loss for batch 12 = 0.6044977307319641\n",
      "Loss for batch 13 = 0.6555397510528564\n",
      "Loss for batch 14 = 0.5881076455116272\n",
      "Loss for batch 15 = 0.7004888653755188\n",
      "Loss for batch 16 = 0.5670122504234314\n",
      "Loss for batch 17 = 0.7437566518783569\n",
      "Loss for batch 18 = 0.6329894661903381\n",
      "Loss for batch 19 = 0.503118634223938\n",
      "Loss for batch 20 = 0.5469692945480347\n",
      "Loss for batch 21 = 0.7463271617889404\n",
      "Loss for batch 22 = 0.5085840225219727\n",
      "Loss for batch 23 = 0.6808378100395203\n",
      "Loss for batch 24 = 0.7879407405853271\n",
      "Loss for batch 25 = 0.5226168632507324\n",
      "Loss for batch 26 = 0.6679683327674866\n",
      "Loss for batch 27 = 0.5375008583068848\n",
      "Loss for batch 28 = 0.5595507621765137\n",
      "Loss for batch 29 = 0.6538569331169128\n",
      "Loss for batch 30 = 0.6884564161300659\n",
      "Loss for batch 31 = 0.635509729385376\n",
      "Loss for batch 32 = 0.7768598794937134\n",
      "Loss for batch 33 = 0.5607722401618958\n",
      "Loss for batch 34 = 0.7642003893852234\n",
      "Loss for batch 35 = 0.6921175122261047\n",
      "Loss for batch 36 = 0.7539040446281433\n",
      "Loss for batch 37 = 0.8614306449890137\n",
      "Loss for batch 38 = 0.7536861300468445\n",
      "Loss for batch 39 = 0.7035113573074341\n",
      "Loss for batch 40 = 0.8298766613006592\n",
      "Loss for batch 41 = 0.8625540733337402\n",
      "Loss for batch 42 = 0.6877952218055725\n",
      "Loss for batch 43 = 0.7650249600410461\n",
      "Loss for batch 44 = 0.6844387054443359\n",
      "Loss for batch 45 = 0.5906296372413635\n",
      "Loss for batch 46 = 0.6820152997970581\n",
      "Loss for batch 47 = 0.9001334309577942\n",
      "Loss for batch 48 = 0.6720197796821594\n",
      "Loss for batch 49 = 0.6829977631568909\n",
      "Loss for batch 50 = 0.7372945547103882\n",
      "Loss for batch 51 = 0.6705431938171387\n",
      "Loss for batch 52 = 0.5954046845436096\n",
      "Loss for batch 53 = 0.5178803205490112\n",
      "Loss for batch 54 = 0.7455607652664185\n",
      "Loss for batch 55 = 0.6470191478729248\n",
      "Loss for batch 56 = 0.5658896565437317\n",
      "Loss for batch 57 = 0.540603518486023\n",
      "Loss for batch 58 = 0.6316429972648621\n",
      "Loss for batch 59 = 0.8974184393882751\n",
      "Loss for batch 60 = 0.7792885303497314\n",
      "Loss for batch 61 = 0.8753549456596375\n",
      "Loss for batch 62 = 0.6565737128257751\n",
      "Loss for batch 63 = 0.6534472703933716\n",
      "Loss for batch 64 = 0.5065996646881104\n",
      "Loss for batch 65 = 0.6491263508796692\n",
      "Loss for batch 66 = 0.7883666157722473\n",
      "Loss for batch 67 = 0.9872920513153076\n",
      "Loss for batch 68 = 0.6619578003883362\n",
      "Loss for batch 69 = 0.6412420272827148\n",
      "Loss for batch 70 = 0.847614049911499\n",
      "Loss for batch 71 = 0.5424548983573914\n",
      "Loss for batch 72 = 0.7537952065467834\n",
      "Loss for batch 73 = 0.6190487146377563\n",
      "Loss for batch 74 = 0.5909464359283447\n",
      "Loss for batch 75 = 0.6984323263168335\n",
      "Loss for batch 76 = 0.7131435871124268\n",
      "Loss for batch 77 = 0.6220686435699463\n",
      "Loss for batch 78 = 0.4248012602329254\n",
      "Loss for batch 79 = 0.7136725783348083\n",
      "Loss for batch 80 = 0.6650264859199524\n",
      "Loss for batch 81 = 0.7291809320449829\n",
      "Loss for batch 82 = 0.7529160380363464\n",
      "Loss for batch 83 = 0.6910937428474426\n",
      "Loss for batch 84 = 0.6964788436889648\n",
      "Loss for batch 85 = 0.637648344039917\n",
      "Loss for batch 86 = 0.6294990181922913\n",
      "Loss for batch 87 = 0.6085144281387329\n",
      "Loss for batch 88 = 0.49520808458328247\n",
      "Loss for batch 89 = 0.7804234027862549\n",
      "Loss for batch 90 = 0.712218165397644\n",
      "Loss for batch 91 = 0.7190316319465637\n",
      "Loss for batch 92 = 0.6138562560081482\n",
      "Loss for batch 93 = 0.7001246809959412\n",
      "Loss for batch 94 = 0.5748071670532227\n",
      "Loss for batch 95 = 0.5584304928779602\n",
      "Loss for batch 96 = 0.9827538132667542\n",
      "Loss for batch 97 = 0.5781779885292053\n",
      "\n",
      "Training Loss for epoch 29 = 65.8487777709961\n",
      "\n",
      "Current Validation Loss = 27.671466827392578\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 16\n",
      "Train Accuracy: 71.57%\n",
      "Validation Accuracy: 58.41%\n",
      "\n",
      "Epoch 30\n",
      "----------\n",
      "Loss for batch 0 = 0.5986121892929077\n",
      "Loss for batch 1 = 0.5531638264656067\n",
      "Loss for batch 2 = 0.7464674115180969\n",
      "Loss for batch 3 = 0.5761703848838806\n",
      "Loss for batch 4 = 0.5383806228637695\n",
      "Loss for batch 5 = 0.58085697889328\n",
      "Loss for batch 6 = 0.5979993343353271\n",
      "Loss for batch 7 = 0.7671625018119812\n",
      "Loss for batch 8 = 0.5670480132102966\n",
      "Loss for batch 9 = 0.6288838386535645\n",
      "Loss for batch 10 = 0.6619936227798462\n",
      "Loss for batch 11 = 0.5447091460227966\n",
      "Loss for batch 12 = 0.5997728109359741\n",
      "Loss for batch 13 = 0.623690664768219\n",
      "Loss for batch 14 = 0.5225223302841187\n",
      "Loss for batch 15 = 0.6853312849998474\n",
      "Loss for batch 16 = 0.5918785333633423\n",
      "Loss for batch 17 = 0.7573801875114441\n",
      "Loss for batch 18 = 0.6039107441902161\n",
      "Loss for batch 19 = 0.5248722434043884\n",
      "Loss for batch 20 = 0.5574445724487305\n",
      "Loss for batch 21 = 0.7361600399017334\n",
      "Loss for batch 22 = 0.4995441138744354\n",
      "Loss for batch 23 = 0.691264808177948\n",
      "Loss for batch 24 = 0.7373229265213013\n",
      "Loss for batch 25 = 0.54326331615448\n",
      "Loss for batch 26 = 0.6163308620452881\n",
      "Loss for batch 27 = 0.5450816750526428\n",
      "Loss for batch 28 = 0.5859084725379944\n",
      "Loss for batch 29 = 0.5387345552444458\n",
      "Loss for batch 30 = 0.6258204579353333\n",
      "Loss for batch 31 = 0.6294743418693542\n",
      "Loss for batch 32 = 0.8033473491668701\n",
      "Loss for batch 33 = 0.5224209427833557\n",
      "Loss for batch 34 = 0.7447353005409241\n",
      "Loss for batch 35 = 0.6630036234855652\n",
      "Loss for batch 36 = 0.7295076251029968\n",
      "Loss for batch 37 = 0.7992364168167114\n",
      "Loss for batch 38 = 0.6662517786026001\n",
      "Loss for batch 39 = 0.7605863213539124\n",
      "Loss for batch 40 = 0.8282091021537781\n",
      "Loss for batch 41 = 0.8509880304336548\n",
      "Loss for batch 42 = 0.6878305673599243\n",
      "Loss for batch 43 = 0.7237467765808105\n",
      "Loss for batch 44 = 0.6656127572059631\n",
      "Loss for batch 45 = 0.6095457077026367\n",
      "Loss for batch 46 = 0.7104573249816895\n",
      "Loss for batch 47 = 0.9000539183616638\n",
      "Loss for batch 48 = 0.6447920799255371\n",
      "Loss for batch 49 = 0.6927129626274109\n",
      "Loss for batch 50 = 0.7102793455123901\n",
      "Loss for batch 51 = 0.6792583465576172\n",
      "Loss for batch 52 = 0.5101854205131531\n",
      "Loss for batch 53 = 0.523903489112854\n",
      "Loss for batch 54 = 0.7179855108261108\n",
      "Loss for batch 55 = 0.6208546161651611\n",
      "Loss for batch 56 = 0.6530476212501526\n",
      "Loss for batch 57 = 0.5258681774139404\n",
      "Loss for batch 58 = 0.6199973821640015\n",
      "Loss for batch 59 = 0.8781000971794128\n",
      "Loss for batch 60 = 0.7600623965263367\n",
      "Loss for batch 61 = 0.8585585355758667\n",
      "Loss for batch 62 = 0.6499820351600647\n",
      "Loss for batch 63 = 0.6306838393211365\n",
      "Loss for batch 64 = 0.47485116124153137\n",
      "Loss for batch 65 = 0.6084988117218018\n",
      "Loss for batch 66 = 0.8337204456329346\n",
      "Loss for batch 67 = 0.9707112908363342\n",
      "Loss for batch 68 = 0.6140968799591064\n",
      "Loss for batch 69 = 0.6876926422119141\n",
      "Loss for batch 70 = 0.8489492535591125\n",
      "Loss for batch 71 = 0.604880690574646\n",
      "Loss for batch 72 = 0.6351640224456787\n",
      "Loss for batch 73 = 0.5685279369354248\n",
      "Loss for batch 74 = 0.6542066335678101\n",
      "Loss for batch 75 = 0.6374498605728149\n",
      "Loss for batch 76 = 0.6885879039764404\n",
      "Loss for batch 77 = 0.5462048053741455\n",
      "Loss for batch 78 = 0.4309113025665283\n",
      "Loss for batch 79 = 0.6130523085594177\n",
      "Loss for batch 80 = 0.6368682384490967\n",
      "Loss for batch 81 = 0.7377278804779053\n",
      "Loss for batch 82 = 0.6881195902824402\n",
      "Loss for batch 83 = 0.692409098148346\n",
      "Loss for batch 84 = 0.691527247428894\n",
      "Loss for batch 85 = 0.653517484664917\n",
      "Loss for batch 86 = 0.6424462795257568\n",
      "Loss for batch 87 = 0.5746347904205322\n",
      "Loss for batch 88 = 0.4716435968875885\n",
      "Loss for batch 89 = 0.743525505065918\n",
      "Loss for batch 90 = 0.7196604609489441\n",
      "Loss for batch 91 = 0.6874693632125854\n",
      "Loss for batch 92 = 0.6005393862724304\n",
      "Loss for batch 93 = 0.6627320051193237\n",
      "Loss for batch 94 = 0.5397724509239197\n",
      "Loss for batch 95 = 0.5394024848937988\n",
      "Loss for batch 96 = 0.987668514251709\n",
      "Loss for batch 97 = 0.5590527653694153\n",
      "\n",
      "Training Loss for epoch 30 = 64.1651840209961\n",
      "\n",
      "Current Validation Loss = 29.03005599975586\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 17\n",
      "Train Accuracy: 71.89%\n",
      "Validation Accuracy: 56.10%\n",
      "\n",
      "Epoch 31\n",
      "----------\n",
      "Loss for batch 0 = 0.5755422711372375\n",
      "Loss for batch 1 = 0.5734948515892029\n",
      "Loss for batch 2 = 0.7111628651618958\n",
      "Loss for batch 3 = 0.560318648815155\n",
      "Loss for batch 4 = 0.580803394317627\n",
      "Loss for batch 5 = 0.5618314743041992\n",
      "Loss for batch 6 = 0.5871126055717468\n",
      "Loss for batch 7 = 0.7349021434783936\n",
      "Loss for batch 8 = 0.5674135684967041\n",
      "Loss for batch 9 = 0.651695191860199\n",
      "Loss for batch 10 = 0.6735082268714905\n",
      "Loss for batch 11 = 0.5331253409385681\n",
      "Loss for batch 12 = 0.5532190203666687\n",
      "Loss for batch 13 = 0.6247215270996094\n",
      "Loss for batch 14 = 0.5162493586540222\n",
      "Loss for batch 15 = 0.720533013343811\n",
      "Loss for batch 16 = 0.5553038120269775\n",
      "Loss for batch 17 = 0.7267332673072815\n",
      "Loss for batch 18 = 0.5844601392745972\n",
      "Loss for batch 19 = 0.5468783378601074\n",
      "Loss for batch 20 = 0.5656265020370483\n",
      "Loss for batch 21 = 0.7572531700134277\n",
      "Loss for batch 22 = 0.49471983313560486\n",
      "Loss for batch 23 = 0.6719885468482971\n",
      "Loss for batch 24 = 0.7446475625038147\n",
      "Loss for batch 25 = 0.5503539443016052\n",
      "Loss for batch 26 = 0.6016778945922852\n",
      "Loss for batch 27 = 0.5174167156219482\n",
      "Loss for batch 28 = 0.5582597255706787\n",
      "Loss for batch 29 = 0.5703822374343872\n",
      "Loss for batch 30 = 0.6254978775978088\n",
      "Loss for batch 31 = 0.6052905321121216\n",
      "Loss for batch 32 = 0.8049317002296448\n",
      "Loss for batch 33 = 0.5357406735420227\n",
      "Loss for batch 34 = 0.6254110932350159\n",
      "Loss for batch 35 = 0.6041877865791321\n",
      "Loss for batch 36 = 0.7233091592788696\n",
      "Loss for batch 37 = 0.7958787679672241\n",
      "Loss for batch 38 = 0.711130678653717\n",
      "Loss for batch 39 = 0.8527846336364746\n",
      "Loss for batch 40 = 0.7670174241065979\n",
      "Loss for batch 41 = 0.8686099648475647\n",
      "Loss for batch 42 = 0.712178111076355\n",
      "Loss for batch 43 = 0.7373172044754028\n",
      "Loss for batch 44 = 0.7050734162330627\n",
      "Loss for batch 45 = 0.5957504510879517\n",
      "Loss for batch 46 = 0.6444718837738037\n",
      "Loss for batch 47 = 0.8997546434402466\n",
      "Loss for batch 48 = 0.7081630229949951\n",
      "Loss for batch 49 = 0.8272497653961182\n",
      "Loss for batch 50 = 0.7160637378692627\n",
      "Loss for batch 51 = 0.6397004723548889\n",
      "Loss for batch 52 = 0.532080352306366\n",
      "Loss for batch 53 = 0.6247348785400391\n",
      "Loss for batch 54 = 0.7031495571136475\n",
      "Loss for batch 55 = 0.6566737294197083\n",
      "Loss for batch 56 = 0.5514013767242432\n",
      "Loss for batch 57 = 0.4814945161342621\n",
      "Loss for batch 58 = 0.6026179194450378\n",
      "Loss for batch 59 = 0.9031893014907837\n",
      "Loss for batch 60 = 0.7852960228919983\n",
      "Loss for batch 61 = 0.8602715730667114\n",
      "Loss for batch 62 = 0.6355196237564087\n",
      "Loss for batch 63 = 0.5818787813186646\n",
      "Loss for batch 64 = 0.44372910261154175\n",
      "Loss for batch 65 = 0.7556167840957642\n",
      "Loss for batch 66 = 0.7642667889595032\n",
      "Loss for batch 67 = 1.0190415382385254\n",
      "Loss for batch 68 = 0.6339687705039978\n",
      "Loss for batch 69 = 0.627421498298645\n",
      "Loss for batch 70 = 0.9078783988952637\n",
      "Loss for batch 71 = 0.5985704660415649\n",
      "Loss for batch 72 = 0.6226999163627625\n",
      "Loss for batch 73 = 0.6035494208335876\n",
      "Loss for batch 74 = 0.5648806095123291\n",
      "Loss for batch 75 = 0.6857367157936096\n",
      "Loss for batch 76 = 0.6598535776138306\n",
      "Loss for batch 77 = 0.5972914099693298\n",
      "Loss for batch 78 = 0.3886282742023468\n",
      "Loss for batch 79 = 0.6972654461860657\n",
      "Loss for batch 80 = 0.6292969584465027\n",
      "Loss for batch 81 = 0.7274843454360962\n",
      "Loss for batch 82 = 0.7555351257324219\n",
      "Loss for batch 83 = 0.6454207897186279\n",
      "Loss for batch 84 = 0.6991944313049316\n",
      "Loss for batch 85 = 0.6511763334274292\n",
      "Loss for batch 86 = 0.6052316427230835\n",
      "Loss for batch 87 = 0.6447091698646545\n",
      "Loss for batch 88 = 0.5058903098106384\n",
      "Loss for batch 89 = 0.7848827242851257\n",
      "Loss for batch 90 = 0.72846919298172\n",
      "Loss for batch 91 = 0.7275856137275696\n",
      "Loss for batch 92 = 0.5994112491607666\n",
      "Loss for batch 93 = 0.6286383271217346\n",
      "Loss for batch 94 = 0.5624582171440125\n",
      "Loss for batch 95 = 0.5081687569618225\n",
      "Loss for batch 96 = 0.9468887448310852\n",
      "Loss for batch 97 = 0.5709947347640991\n",
      "\n",
      "Training Loss for epoch 31 = 64.28700256347656\n",
      "\n",
      "Current Validation Loss = 27.358768463134766\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 18\n",
      "Train Accuracy: 72.34%\n",
      "Validation Accuracy: 56.74%\n",
      "\n",
      "Epoch 32\n",
      "----------\n",
      "Loss for batch 0 = 0.5718395709991455\n",
      "Loss for batch 1 = 0.5628147125244141\n",
      "Loss for batch 2 = 0.7187476754188538\n",
      "Loss for batch 3 = 0.5791097283363342\n",
      "Loss for batch 4 = 0.5481573343276978\n",
      "Loss for batch 5 = 0.6026830673217773\n",
      "Loss for batch 6 = 0.6333554983139038\n",
      "Loss for batch 7 = 0.7426554560661316\n",
      "Loss for batch 8 = 0.6272702217102051\n",
      "Loss for batch 9 = 0.6518787741661072\n",
      "Loss for batch 10 = 0.6846024990081787\n",
      "Loss for batch 11 = 0.5297715663909912\n",
      "Loss for batch 12 = 0.5595629215240479\n",
      "Loss for batch 13 = 0.6142302751541138\n",
      "Loss for batch 14 = 0.5434309244155884\n",
      "Loss for batch 15 = 0.6585037112236023\n",
      "Loss for batch 16 = 0.6163700222969055\n",
      "Loss for batch 17 = 0.7079037427902222\n",
      "Loss for batch 18 = 0.6604112386703491\n",
      "Loss for batch 19 = 0.5971447229385376\n",
      "Loss for batch 20 = 0.5881403684616089\n",
      "Loss for batch 21 = 0.663013756275177\n",
      "Loss for batch 22 = 0.4908320903778076\n",
      "Loss for batch 23 = 0.632310152053833\n",
      "Loss for batch 24 = 0.6753847599029541\n",
      "Loss for batch 25 = 0.48194849491119385\n",
      "Loss for batch 26 = 0.6231910586357117\n",
      "Loss for batch 27 = 0.5346601009368896\n",
      "Loss for batch 28 = 0.5797560811042786\n",
      "Loss for batch 29 = 0.5202615261077881\n",
      "Loss for batch 30 = 0.5758519172668457\n",
      "Loss for batch 31 = 0.6029782891273499\n",
      "Loss for batch 32 = 0.8364554643630981\n",
      "Loss for batch 33 = 0.5153734683990479\n",
      "Loss for batch 34 = 0.6093993782997131\n",
      "Loss for batch 35 = 0.6103081107139587\n",
      "Loss for batch 36 = 0.7142037749290466\n",
      "Loss for batch 37 = 0.7791608572006226\n",
      "Loss for batch 38 = 0.6482663154602051\n",
      "Loss for batch 39 = 0.7102435827255249\n",
      "Loss for batch 40 = 0.7859892845153809\n",
      "Loss for batch 41 = 0.7734730839729309\n",
      "Loss for batch 42 = 0.6816022992134094\n",
      "Loss for batch 43 = 0.6997472047805786\n",
      "Loss for batch 44 = 0.6368100643157959\n",
      "Loss for batch 45 = 0.4603857696056366\n",
      "Loss for batch 46 = 0.583051860332489\n",
      "Loss for batch 47 = 0.8667094111442566\n",
      "Loss for batch 48 = 0.6211604475975037\n",
      "Loss for batch 49 = 0.6419186592102051\n",
      "Loss for batch 50 = 0.6720123291015625\n",
      "Loss for batch 51 = 0.6624887585639954\n",
      "Loss for batch 52 = 0.49672767519950867\n",
      "Loss for batch 53 = 0.42485368251800537\n",
      "Loss for batch 54 = 0.6651671528816223\n",
      "Loss for batch 55 = 0.5823156237602234\n",
      "Loss for batch 56 = 0.5673242211341858\n",
      "Loss for batch 57 = 0.4610154926776886\n",
      "Loss for batch 58 = 0.5859602093696594\n",
      "Loss for batch 59 = 0.8170504570007324\n",
      "Loss for batch 60 = 0.7676199078559875\n",
      "Loss for batch 61 = 0.8780142664909363\n",
      "Loss for batch 62 = 0.6056215167045593\n",
      "Loss for batch 63 = 0.6119283437728882\n",
      "Loss for batch 64 = 0.4283788204193115\n",
      "Loss for batch 65 = 0.6274257898330688\n",
      "Loss for batch 66 = 0.7108821272850037\n",
      "Loss for batch 67 = 0.9718400239944458\n",
      "Loss for batch 68 = 0.6849493980407715\n",
      "Loss for batch 69 = 0.6167318224906921\n",
      "Loss for batch 70 = 0.771394670009613\n",
      "Loss for batch 71 = 0.5471493005752563\n",
      "Loss for batch 72 = 0.5651682615280151\n",
      "Loss for batch 73 = 0.5365398526191711\n",
      "Loss for batch 74 = 0.5172528028488159\n",
      "Loss for batch 75 = 0.6274788975715637\n",
      "Loss for batch 76 = 0.6425477862358093\n",
      "Loss for batch 77 = 0.5201855301856995\n",
      "Loss for batch 78 = 0.37921494245529175\n",
      "Loss for batch 79 = 0.6150025129318237\n",
      "Loss for batch 80 = 0.6343562602996826\n",
      "Loss for batch 81 = 0.670326828956604\n",
      "Loss for batch 82 = 0.7180861830711365\n",
      "Loss for batch 83 = 0.6755332946777344\n",
      "Loss for batch 84 = 0.6287849545478821\n",
      "Loss for batch 85 = 0.6785838603973389\n",
      "Loss for batch 86 = 0.5259999632835388\n",
      "Loss for batch 87 = 0.5936185717582703\n",
      "Loss for batch 88 = 0.4730585217475891\n",
      "Loss for batch 89 = 0.7507297396659851\n",
      "Loss for batch 90 = 0.6961944103240967\n",
      "Loss for batch 91 = 0.6135489344596863\n",
      "Loss for batch 92 = 0.5533162355422974\n",
      "Loss for batch 93 = 0.6875109076499939\n",
      "Loss for batch 94 = 0.5142133831977844\n",
      "Loss for batch 95 = 0.4977455735206604\n",
      "Loss for batch 96 = 0.9389795064926147\n",
      "Loss for batch 97 = 0.5511646866798401\n",
      "\n",
      "Training Loss for epoch 32 = 61.51502990722656\n",
      "\n",
      "Current Validation Loss = 29.207414627075195\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 19\n",
      "Train Accuracy: 73.62%\n",
      "Validation Accuracy: 57.12%\n",
      "\n",
      "Epoch 33\n",
      "----------\n",
      "Loss for batch 0 = 0.5428693294525146\n",
      "Loss for batch 1 = 0.48957791924476624\n",
      "Loss for batch 2 = 0.6744983792304993\n",
      "Loss for batch 3 = 0.5453453660011292\n",
      "Loss for batch 4 = 0.5636967420578003\n",
      "Loss for batch 5 = 0.5868447422981262\n",
      "Loss for batch 6 = 0.5840982794761658\n",
      "Loss for batch 7 = 0.7530069351196289\n",
      "Loss for batch 8 = 0.5483623147010803\n",
      "Loss for batch 9 = 0.6224988698959351\n",
      "Loss for batch 10 = 0.6360868811607361\n",
      "Loss for batch 11 = 0.480180948972702\n",
      "Loss for batch 12 = 0.49179619550704956\n",
      "Loss for batch 13 = 0.5942014455795288\n",
      "Loss for batch 14 = 0.5085218548774719\n",
      "Loss for batch 15 = 0.6328622698783875\n",
      "Loss for batch 16 = 0.5764944553375244\n",
      "Loss for batch 17 = 0.7082677483558655\n",
      "Loss for batch 18 = 0.6046778559684753\n",
      "Loss for batch 19 = 0.5331693291664124\n",
      "Loss for batch 20 = 0.5116748809814453\n",
      "Loss for batch 21 = 0.7271088361740112\n",
      "Loss for batch 22 = 0.46213680505752563\n",
      "Loss for batch 23 = 0.6257375478744507\n",
      "Loss for batch 24 = 0.6707472801208496\n",
      "Loss for batch 25 = 0.48533105850219727\n",
      "Loss for batch 26 = 0.5980184674263\n",
      "Loss for batch 27 = 0.5073935389518738\n",
      "Loss for batch 28 = 0.5372097492218018\n",
      "Loss for batch 29 = 0.4892738163471222\n",
      "Loss for batch 30 = 0.5789324045181274\n",
      "Loss for batch 31 = 0.6012192964553833\n",
      "Loss for batch 32 = 0.796594500541687\n",
      "Loss for batch 33 = 0.4787026345729828\n",
      "Loss for batch 34 = 0.6241971254348755\n",
      "Loss for batch 35 = 0.5963267087936401\n",
      "Loss for batch 36 = 0.6958564519882202\n",
      "Loss for batch 37 = 0.7300695180892944\n",
      "Loss for batch 38 = 0.6046047210693359\n",
      "Loss for batch 39 = 0.697256326675415\n",
      "Loss for batch 40 = 0.809035062789917\n",
      "Loss for batch 41 = 0.7516785264015198\n",
      "Loss for batch 42 = 0.6954777836799622\n",
      "Loss for batch 43 = 0.6925007700920105\n",
      "Loss for batch 44 = 0.6153368949890137\n",
      "Loss for batch 45 = 0.5384783744812012\n",
      "Loss for batch 46 = 0.547217845916748\n",
      "Loss for batch 47 = 0.8515211939811707\n",
      "Loss for batch 48 = 0.6147937774658203\n",
      "Loss for batch 49 = 0.6293624639511108\n",
      "Loss for batch 50 = 0.6345527172088623\n",
      "Loss for batch 51 = 0.5980722904205322\n",
      "Loss for batch 52 = 0.4799373149871826\n",
      "Loss for batch 53 = 0.42162102460861206\n",
      "Loss for batch 54 = 0.6648005843162537\n",
      "Loss for batch 55 = 0.5752260684967041\n",
      "Loss for batch 56 = 0.5192424654960632\n",
      "Loss for batch 57 = 0.4159153997898102\n",
      "Loss for batch 58 = 0.6037593483924866\n",
      "Loss for batch 59 = 0.7998245358467102\n",
      "Loss for batch 60 = 0.7381719350814819\n",
      "Loss for batch 61 = 0.8683342933654785\n",
      "Loss for batch 62 = 0.5973390340805054\n",
      "Loss for batch 63 = 0.6054920554161072\n",
      "Loss for batch 64 = 0.39634406566619873\n",
      "Loss for batch 65 = 0.6094589233398438\n",
      "Loss for batch 66 = 0.6960715651512146\n",
      "Loss for batch 67 = 0.9753917455673218\n",
      "Loss for batch 68 = 0.6479175686836243\n",
      "Loss for batch 69 = 0.5920472741127014\n",
      "Loss for batch 70 = 0.7452028393745422\n",
      "Loss for batch 71 = 0.5444441437721252\n",
      "Loss for batch 72 = 0.5463477373123169\n",
      "Loss for batch 73 = 0.4829433858394623\n",
      "Loss for batch 74 = 0.5292887091636658\n",
      "Loss for batch 75 = 0.6073753833770752\n",
      "Loss for batch 76 = 0.6214284300804138\n",
      "Loss for batch 77 = 0.5057239532470703\n",
      "Loss for batch 78 = 0.3706178665161133\n",
      "Loss for batch 79 = 0.5853343605995178\n",
      "Loss for batch 80 = 0.6279049515724182\n",
      "Loss for batch 81 = 0.6218532919883728\n",
      "Loss for batch 82 = 0.7263838648796082\n",
      "Loss for batch 83 = 0.615709662437439\n",
      "Loss for batch 84 = 0.6059711575508118\n",
      "Loss for batch 85 = 0.6400384306907654\n",
      "Loss for batch 86 = 0.5207040905952454\n",
      "Loss for batch 87 = 0.6182736158370972\n",
      "Loss for batch 88 = 0.46555614471435547\n",
      "Loss for batch 89 = 0.7623760104179382\n",
      "Loss for batch 90 = 0.6565849184989929\n",
      "Loss for batch 91 = 0.6243243217468262\n",
      "Loss for batch 92 = 0.5564556121826172\n",
      "Loss for batch 93 = 0.6458812355995178\n",
      "Loss for batch 94 = 0.5188745260238647\n",
      "Loss for batch 95 = 0.47456029057502747\n",
      "Loss for batch 96 = 0.9323052167892456\n",
      "Loss for batch 97 = 0.548159122467041\n",
      "\n",
      "Training Loss for epoch 33 = 59.58100128173828\n",
      "\n",
      "Current Validation Loss = 29.773635864257812\n",
      "Best Validation Loss = 23.56192970275879\n",
      "Epochs without Improvement = 20\n",
      "Train Accuracy: 74.58%\n",
      "Validation Accuracy: 56.23%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainLoopText(text_modelv3, optimizer, loss_fn, train_loader, val_loader, scheduler, 100, 20, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.11%\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv3(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodelv2(torch.nn.Module):\n",
    "    def __init__(self, n_layers, embed_dim, hidden_dim, embedding:str=\"twitter.27B\", bidirectionality:bool=False) -> None:\n",
    "        super().__init__()\n",
    "        glove_embeddings = torchtext.vocab.GloVe(embedding, embed_dim)\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(glove_embeddings.vectors, freeze=False)\n",
    "        self.lstm = torch.nn.LSTM(embed_dim, hidden_dim, n_layers, batch_first=True, bidirectional=bidirectionality)\n",
    "        if bidirectionality == False:\n",
    "            self.linear = torch.nn.Linear(hidden_dim, 3)\n",
    "        else:\n",
    "            self.linear = torch.nn.Linear(2*hidden_dim, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.embedding(x)\n",
    "        a, _ = self.lstm(a)\n",
    "        a =  a[:,-1,:]\n",
    "        a = self.linear(a)\n",
    "        return torch.nn.functional.log_softmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_modelv4 = LSTMmodelv2(4, 25, 256, bidirectionality=True)\n",
    "text_modelv4.load_state_dict(torch.load(\"../Models/lstm11.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.35%\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "text_modelv4.to('cuda')\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv4(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redoing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, shuffle=True, stratify=data['LABEL'], random_state=3)\n",
    "train, val = train_test_split(train, test_size=0.2, shuffle=True, stratify=train['LABEL'], random_state=3)\n",
    "train_text = np.array(train['Caption'])\n",
    "test_text = np.array(test['Caption'])\n",
    "val_text = np.array(val['Caption'])\n",
    "\n",
    "train_label = np.array(train['LABEL'])\n",
    "test_label = np.array(test['LABEL'])\n",
    "val_label = np.array(val['LABEL'])\n",
    "train_set = TextDataset(train_text, train_label, word_to_index)\n",
    "test_set = TextDataset(test_text, test_label, word_to_index)\n",
    "val_set = TextDataset(val_text, val_label, word_to_index)\n",
    "train_loader = DataLoader(train_set, 32)\n",
    "test_loader = DataLoader(test_set, 32)\n",
    "val_loader = DataLoader(val_set, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling new data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2441a09ed10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "text_modelv5 = LSTMmodel(4, 25, 256, bidirectionality=True, freeze=False)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.NAdam(text_modelv5.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21690f30142c4f4aa8cd8687702aa250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "----------\n",
      "Loss for batch 0 = 1.1016056537628174\n",
      "Loss for batch 1 = 1.1035573482513428\n",
      "Loss for batch 2 = 1.100522756576538\n",
      "Loss for batch 3 = 1.1023117303848267\n",
      "Loss for batch 4 = 1.103891134262085\n",
      "Loss for batch 5 = 1.0902734994888306\n",
      "Loss for batch 6 = 1.1057451963424683\n",
      "Loss for batch 7 = 1.1012133359909058\n",
      "Loss for batch 8 = 1.1072429418563843\n",
      "Loss for batch 9 = 1.0965120792388916\n",
      "Loss for batch 10 = 1.0863991975784302\n",
      "Loss for batch 11 = 1.1025625467300415\n",
      "Loss for batch 12 = 1.0887972116470337\n",
      "Loss for batch 13 = 1.1037406921386719\n",
      "Loss for batch 14 = 1.0829473733901978\n",
      "Loss for batch 15 = 1.1173230409622192\n",
      "Loss for batch 16 = 1.111648678779602\n",
      "Loss for batch 17 = 1.10023832321167\n",
      "Loss for batch 18 = 1.0874381065368652\n",
      "Loss for batch 19 = 1.0996061563491821\n",
      "Loss for batch 20 = 1.1191585063934326\n",
      "Loss for batch 21 = 1.0968074798583984\n",
      "Loss for batch 22 = 1.0963106155395508\n",
      "Loss for batch 23 = 1.1032721996307373\n",
      "Loss for batch 24 = 1.0978889465332031\n",
      "Loss for batch 25 = 1.0935157537460327\n",
      "Loss for batch 26 = 1.089272141456604\n",
      "Loss for batch 27 = 1.0884199142456055\n",
      "Loss for batch 28 = 1.0996909141540527\n",
      "Loss for batch 29 = 1.0850473642349243\n",
      "Loss for batch 30 = 1.0642379522323608\n",
      "Loss for batch 31 = 1.085587501525879\n",
      "Loss for batch 32 = 1.1103848218917847\n",
      "Loss for batch 33 = 1.0807063579559326\n",
      "Loss for batch 34 = 1.0949639081954956\n",
      "Loss for batch 35 = 1.1107659339904785\n",
      "Loss for batch 36 = 1.1089205741882324\n",
      "Loss for batch 37 = 1.0876493453979492\n",
      "Loss for batch 38 = 1.0615270137786865\n",
      "Loss for batch 39 = 1.1045207977294922\n",
      "Loss for batch 40 = 1.090183973312378\n",
      "Loss for batch 41 = 1.143824577331543\n",
      "Loss for batch 42 = 1.0925418138504028\n",
      "Loss for batch 43 = 1.0984678268432617\n",
      "Loss for batch 44 = 1.100404143333435\n",
      "Loss for batch 45 = 1.0949352979660034\n",
      "Loss for batch 46 = 1.0934041738510132\n",
      "Loss for batch 47 = 1.08688223361969\n",
      "Loss for batch 48 = 1.0953923463821411\n",
      "Loss for batch 49 = 1.113884687423706\n",
      "Loss for batch 50 = 1.0882622003555298\n",
      "Loss for batch 51 = 1.101013422012329\n",
      "Loss for batch 52 = 1.099222183227539\n",
      "Loss for batch 53 = 1.0824131965637207\n",
      "Loss for batch 54 = 1.056835651397705\n",
      "Loss for batch 55 = 1.0714190006256104\n",
      "Loss for batch 56 = 1.1130801439285278\n",
      "Loss for batch 57 = 1.102885365486145\n",
      "Loss for batch 58 = 1.0700416564941406\n",
      "Loss for batch 59 = 1.0802561044692993\n",
      "Loss for batch 60 = 1.0855779647827148\n",
      "Loss for batch 61 = 1.049665093421936\n",
      "Loss for batch 62 = 1.1147918701171875\n",
      "Loss for batch 63 = 1.0907909870147705\n",
      "Loss for batch 64 = 1.125096082687378\n",
      "Loss for batch 65 = 1.0518676042556763\n",
      "Loss for batch 66 = 1.0922132730484009\n",
      "Loss for batch 67 = 1.0746182203292847\n",
      "Loss for batch 68 = 1.0483171939849854\n",
      "Loss for batch 69 = 1.149247646331787\n",
      "Loss for batch 70 = 1.0853744745254517\n",
      "Loss for batch 71 = 1.1267776489257812\n",
      "Loss for batch 72 = 1.083514928817749\n",
      "Loss for batch 73 = 1.077483892440796\n",
      "Loss for batch 74 = 1.0833728313446045\n",
      "Loss for batch 75 = 1.1118429899215698\n",
      "Loss for batch 76 = 1.1161271333694458\n",
      "Loss for batch 77 = 1.0804702043533325\n",
      "Loss for batch 78 = 1.0769916772842407\n",
      "Loss for batch 79 = 1.0937951803207397\n",
      "Loss for batch 80 = 1.0875760316848755\n",
      "Loss for batch 81 = 0.9910686016082764\n",
      "Loss for batch 82 = 2.156951427459717\n",
      "Loss for batch 83 = 0.9687880277633667\n",
      "Loss for batch 84 = 0.9940322041511536\n",
      "Loss for batch 85 = 0.9944183230400085\n",
      "Loss for batch 86 = 1.1582661867141724\n",
      "Loss for batch 87 = 1.0519803762435913\n",
      "Loss for batch 88 = 1.1006332635879517\n",
      "Loss for batch 89 = 1.062687635421753\n",
      "Loss for batch 90 = 1.0847668647766113\n",
      "Loss for batch 91 = 1.0268657207489014\n",
      "Loss for batch 92 = 1.0616389513015747\n",
      "Loss for batch 93 = 1.1266812086105347\n",
      "Loss for batch 94 = 1.0860340595245361\n",
      "Loss for batch 95 = 1.1474571228027344\n",
      "Loss for batch 96 = 1.1436591148376465\n",
      "Loss for batch 97 = 1.1462815999984741\n",
      "\n",
      "Training Loss for epoch 0 = 107.95526885986328\n",
      "\n",
      "Current Validation Loss = 27.467853546142578\n",
      "Best Validation Loss = 27.467853546142578\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 35.27%\n",
      "Validation Accuracy: 34.27%\n",
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss for batch 0 = 1.115615725517273\n",
      "Loss for batch 1 = 1.0906177759170532\n",
      "Loss for batch 2 = 1.0894352197647095\n",
      "Loss for batch 3 = 1.0886560678482056\n",
      "Loss for batch 4 = 1.122073769569397\n",
      "Loss for batch 5 = 1.061179280281067\n",
      "Loss for batch 6 = 1.1220866441726685\n",
      "Loss for batch 7 = 1.0943093299865723\n",
      "Loss for batch 8 = 1.1170823574066162\n",
      "Loss for batch 9 = 1.1043150424957275\n",
      "Loss for batch 10 = 1.1023164987564087\n",
      "Loss for batch 11 = 1.1079063415527344\n",
      "Loss for batch 12 = 1.0797150135040283\n",
      "Loss for batch 13 = 1.107465386390686\n",
      "Loss for batch 14 = 1.0903946161270142\n",
      "Loss for batch 15 = 1.1248846054077148\n",
      "Loss for batch 16 = 1.1043860912322998\n",
      "Loss for batch 17 = 1.1006110906600952\n",
      "Loss for batch 18 = 1.0938830375671387\n",
      "Loss for batch 19 = 1.081046462059021\n",
      "Loss for batch 20 = 1.0925986766815186\n",
      "Loss for batch 21 = 1.0391706228256226\n",
      "Loss for batch 22 = 1.0748199224472046\n",
      "Loss for batch 23 = 1.082597017288208\n",
      "Loss for batch 24 = 1.0676721334457397\n",
      "Loss for batch 25 = 0.993035078048706\n",
      "Loss for batch 26 = 0.9921245574951172\n",
      "Loss for batch 27 = 0.9609635472297668\n",
      "Loss for batch 28 = 1.053920030593872\n",
      "Loss for batch 29 = 1.244410514831543\n",
      "Loss for batch 30 = 0.9282487034797668\n",
      "Loss for batch 31 = 0.9546111822128296\n",
      "Loss for batch 32 = 1.1478477716445923\n",
      "Loss for batch 33 = 1.0852899551391602\n",
      "Loss for batch 34 = 1.1433498859405518\n",
      "Loss for batch 35 = 1.030303955078125\n",
      "Loss for batch 36 = 1.0616320371627808\n",
      "Loss for batch 37 = 1.0639375448226929\n",
      "Loss for batch 38 = 0.9873152375221252\n",
      "Loss for batch 39 = 1.1425995826721191\n",
      "Loss for batch 40 = 1.1133441925048828\n",
      "Loss for batch 41 = 1.150469422340393\n",
      "Loss for batch 42 = 1.0808424949645996\n",
      "Loss for batch 43 = 1.0685207843780518\n",
      "Loss for batch 44 = 1.1215866804122925\n",
      "Loss for batch 45 = 1.1452107429504395\n",
      "Loss for batch 46 = 1.0798040628433228\n",
      "Loss for batch 47 = 1.0617159605026245\n",
      "Loss for batch 48 = 1.1003286838531494\n",
      "Loss for batch 49 = 1.1204767227172852\n",
      "Loss for batch 50 = 1.0823992490768433\n",
      "Loss for batch 51 = 1.0766035318374634\n",
      "Loss for batch 52 = 1.0841805934906006\n",
      "Loss for batch 53 = 1.094523310661316\n",
      "Loss for batch 54 = 1.0186306238174438\n",
      "Loss for batch 55 = 1.064766764640808\n",
      "Loss for batch 56 = 1.1216434240341187\n",
      "Loss for batch 57 = 1.0917110443115234\n",
      "Loss for batch 58 = 1.0348150730133057\n",
      "Loss for batch 59 = 1.0905067920684814\n",
      "Loss for batch 60 = 1.0443776845932007\n",
      "Loss for batch 61 = 1.0532073974609375\n",
      "Loss for batch 62 = 1.0872082710266113\n",
      "Loss for batch 63 = 1.0809059143066406\n",
      "Loss for batch 64 = 1.1195316314697266\n",
      "Loss for batch 65 = 1.0461653470993042\n",
      "Loss for batch 66 = 1.0447044372558594\n",
      "Loss for batch 67 = 1.0185009241104126\n",
      "Loss for batch 68 = 1.021423101425171\n",
      "Loss for batch 69 = 1.1898061037063599\n",
      "Loss for batch 70 = 1.0523535013198853\n",
      "Loss for batch 71 = 1.0557280778884888\n",
      "Loss for batch 72 = 1.0513360500335693\n",
      "Loss for batch 73 = 1.1005160808563232\n",
      "Loss for batch 74 = 1.0539660453796387\n",
      "Loss for batch 75 = 1.1121892929077148\n",
      "Loss for batch 76 = 1.187811255455017\n",
      "Loss for batch 77 = 1.0616577863693237\n",
      "Loss for batch 78 = 1.1158647537231445\n",
      "Loss for batch 79 = 1.083760380744934\n",
      "Loss for batch 80 = 1.0793930292129517\n",
      "Loss for batch 81 = 1.0607942342758179\n",
      "Loss for batch 82 = 1.0832269191741943\n",
      "Loss for batch 83 = 1.0083422660827637\n",
      "Loss for batch 84 = 1.0024635791778564\n",
      "Loss for batch 85 = 1.0854475498199463\n",
      "Loss for batch 86 = 1.1143946647644043\n",
      "Loss for batch 87 = 1.0589771270751953\n",
      "Loss for batch 88 = 1.0249173641204834\n",
      "Loss for batch 89 = 1.0139248371124268\n",
      "Loss for batch 90 = 0.9990657567977905\n",
      "Loss for batch 91 = 1.0609443187713623\n",
      "Loss for batch 92 = 1.0442724227905273\n",
      "Loss for batch 93 = 1.0974432229995728\n",
      "Loss for batch 94 = 1.0587210655212402\n",
      "Loss for batch 95 = 1.112703561782837\n",
      "Loss for batch 96 = 1.1621869802474976\n",
      "Loss for batch 97 = 1.1514023542404175\n",
      "\n",
      "Training Loss for epoch 1 = 105.74614715576172\n",
      "\n",
      "Current Validation Loss = 27.56632423400879\n",
      "Best Validation Loss = 27.467853546142578\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 35.11%\n",
      "Validation Accuracy: 34.53%\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss for batch 0 = 1.0808134078979492\n",
      "Loss for batch 1 = 1.1130576133728027\n",
      "Loss for batch 2 = 1.1056395769119263\n",
      "Loss for batch 3 = 1.0838795900344849\n",
      "Loss for batch 4 = 1.1031181812286377\n",
      "Loss for batch 5 = 1.078977346420288\n",
      "Loss for batch 6 = 1.1053264141082764\n",
      "Loss for batch 7 = 1.0860052108764648\n",
      "Loss for batch 8 = 1.0896720886230469\n",
      "Loss for batch 9 = 1.1065781116485596\n",
      "Loss for batch 10 = 1.1069376468658447\n",
      "Loss for batch 11 = 1.1056320667266846\n",
      "Loss for batch 12 = 1.0946041345596313\n",
      "Loss for batch 13 = 1.0977898836135864\n",
      "Loss for batch 14 = 1.0781104564666748\n",
      "Loss for batch 15 = 1.1106728315353394\n",
      "Loss for batch 16 = 1.1037300825119019\n",
      "Loss for batch 17 = 1.095001459121704\n",
      "Loss for batch 18 = 1.0967950820922852\n",
      "Loss for batch 19 = 1.0892585515975952\n",
      "Loss for batch 20 = 1.102054238319397\n",
      "Loss for batch 21 = 1.071215033531189\n",
      "Loss for batch 22 = 1.0792419910430908\n",
      "Loss for batch 23 = 1.0811079740524292\n",
      "Loss for batch 24 = 1.0760823488235474\n",
      "Loss for batch 25 = 1.005183458328247\n",
      "Loss for batch 26 = 1.0124000310897827\n",
      "Loss for batch 27 = 0.9876372814178467\n",
      "Loss for batch 28 = 1.0500383377075195\n",
      "Loss for batch 29 = 1.15876305103302\n",
      "Loss for batch 30 = 0.9640978574752808\n",
      "Loss for batch 31 = 0.9369374513626099\n",
      "Loss for batch 32 = 1.1262253522872925\n",
      "Loss for batch 33 = 0.9874168634414673\n",
      "Loss for batch 34 = 1.172074794769287\n",
      "Loss for batch 35 = 1.0235198736190796\n",
      "Loss for batch 36 = 1.0854853391647339\n",
      "Loss for batch 37 = 1.046986699104309\n",
      "Loss for batch 38 = 0.9722793698310852\n",
      "Loss for batch 39 = 1.1365069150924683\n",
      "Loss for batch 40 = 1.1242010593414307\n",
      "Loss for batch 41 = 1.1798609495162964\n",
      "Loss for batch 42 = 1.0778303146362305\n",
      "Loss for batch 43 = 1.0676213502883911\n",
      "Loss for batch 44 = 1.1282302141189575\n",
      "Loss for batch 45 = 1.1496922969818115\n",
      "Loss for batch 46 = 1.0779083967208862\n",
      "Loss for batch 47 = 1.0590375661849976\n",
      "Loss for batch 48 = 1.1035312414169312\n",
      "Loss for batch 49 = 1.1115390062332153\n",
      "Loss for batch 50 = 1.1049853563308716\n",
      "Loss for batch 51 = 1.101771593093872\n",
      "Loss for batch 52 = 1.087907314300537\n",
      "Loss for batch 53 = 1.1132848262786865\n",
      "Loss for batch 54 = 1.0769052505493164\n",
      "Loss for batch 55 = 1.0650054216384888\n",
      "Loss for batch 56 = 1.1134647130966187\n",
      "Loss for batch 57 = 1.103577971458435\n",
      "Loss for batch 58 = 1.0982062816619873\n",
      "Loss for batch 59 = 1.088915467262268\n",
      "Loss for batch 60 = 1.0677075386047363\n",
      "Loss for batch 61 = 1.0778756141662598\n",
      "Loss for batch 62 = 1.0987799167633057\n",
      "Loss for batch 63 = 1.1003384590148926\n",
      "Loss for batch 64 = 1.1277501583099365\n",
      "Loss for batch 65 = 1.0610647201538086\n",
      "Loss for batch 66 = 1.0957064628601074\n",
      "Loss for batch 67 = 1.0801596641540527\n",
      "Loss for batch 68 = 1.0745291709899902\n",
      "Loss for batch 69 = 1.1028661727905273\n",
      "Loss for batch 70 = 1.0821951627731323\n",
      "Loss for batch 71 = 1.1279528141021729\n",
      "Loss for batch 72 = 1.0897246599197388\n",
      "Loss for batch 73 = 1.097678780555725\n",
      "Loss for batch 74 = 1.0770723819732666\n",
      "Loss for batch 75 = 1.1135776042938232\n",
      "Loss for batch 76 = 1.0992461442947388\n",
      "Loss for batch 77 = 1.0754115581512451\n",
      "Loss for batch 78 = 1.0899099111557007\n",
      "Loss for batch 79 = 1.0912164449691772\n",
      "Loss for batch 80 = 1.1065278053283691\n",
      "Loss for batch 81 = 1.0910472869873047\n",
      "Loss for batch 82 = 1.1320375204086304\n",
      "Loss for batch 83 = 1.0939412117004395\n",
      "Loss for batch 84 = 1.077713966369629\n",
      "Loss for batch 85 = 1.0852519273757935\n",
      "Loss for batch 86 = 1.114875316619873\n",
      "Loss for batch 87 = 1.0805071592330933\n",
      "Loss for batch 88 = 1.1141437292099\n",
      "Loss for batch 89 = 1.0876432657241821\n",
      "Loss for batch 90 = 1.075646162033081\n",
      "Loss for batch 91 = 1.0938957929611206\n",
      "Loss for batch 92 = 1.1068923473358154\n",
      "Loss for batch 93 = 1.1123192310333252\n",
      "Loss for batch 94 = 1.1016751527786255\n",
      "Loss for batch 95 = 1.093253254890442\n",
      "Loss for batch 96 = 1.0908057689666748\n",
      "Loss for batch 97 = 1.1083264350891113\n",
      "\n",
      "Training Loss for epoch 2 = 106.63758087158203\n",
      "\n",
      "Current Validation Loss = 27.431364059448242\n",
      "Best Validation Loss = 27.431364059448242\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 34.50%\n",
      "Validation Accuracy: 34.15%\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss for batch 0 = 1.097919225692749\n",
      "Loss for batch 1 = 1.1067380905151367\n",
      "Loss for batch 2 = 1.098960518836975\n",
      "Loss for batch 3 = 1.0886833667755127\n",
      "Loss for batch 4 = 1.1008121967315674\n",
      "Loss for batch 5 = 1.0871437788009644\n",
      "Loss for batch 6 = 1.104998230934143\n",
      "Loss for batch 7 = 1.1036875247955322\n",
      "Loss for batch 8 = 1.0950974225997925\n",
      "Loss for batch 9 = 1.102908730506897\n",
      "Loss for batch 10 = 1.091305136680603\n",
      "Loss for batch 11 = 1.1028904914855957\n",
      "Loss for batch 12 = 1.084411859512329\n",
      "Loss for batch 13 = 1.0991721153259277\n",
      "Loss for batch 14 = 1.074846863746643\n",
      "Loss for batch 15 = 1.1100780963897705\n",
      "Loss for batch 16 = 1.1107720136642456\n",
      "Loss for batch 17 = 1.1010764837265015\n",
      "Loss for batch 18 = 1.0941743850708008\n",
      "Loss for batch 19 = 1.0977866649627686\n",
      "Loss for batch 20 = 1.1002418994903564\n",
      "Loss for batch 21 = 1.0938102006912231\n",
      "Loss for batch 22 = 1.100287675857544\n",
      "Loss for batch 23 = 1.1015316247940063\n",
      "Loss for batch 24 = 1.0975391864776611\n",
      "Loss for batch 25 = 1.0931990146636963\n",
      "Loss for batch 26 = 1.0763804912567139\n",
      "Loss for batch 27 = 1.0782577991485596\n",
      "Loss for batch 28 = 1.0977938175201416\n",
      "Loss for batch 29 = 1.0869762897491455\n",
      "Loss for batch 30 = 1.0642850399017334\n",
      "Loss for batch 31 = 1.078059434890747\n",
      "Loss for batch 32 = 1.1211621761322021\n",
      "Loss for batch 33 = 1.0874842405319214\n",
      "Loss for batch 34 = 1.0818477869033813\n",
      "Loss for batch 35 = 1.1226599216461182\n",
      "Loss for batch 36 = 1.1056376695632935\n",
      "Loss for batch 37 = 1.0866124629974365\n",
      "Loss for batch 38 = 1.0742111206054688\n",
      "Loss for batch 39 = 1.0758717060089111\n",
      "Loss for batch 40 = 1.0916292667388916\n",
      "Loss for batch 41 = 1.124087929725647\n",
      "Loss for batch 42 = 1.080939769744873\n",
      "Loss for batch 43 = 1.0936335325241089\n",
      "Loss for batch 44 = 1.1191645860671997\n",
      "Loss for batch 45 = 1.1283565759658813\n",
      "Loss for batch 46 = 1.0780179500579834\n",
      "Loss for batch 47 = 1.0668156147003174\n",
      "Loss for batch 48 = 1.096658706665039\n",
      "Loss for batch 49 = 1.157934308052063\n",
      "Loss for batch 50 = 1.0736782550811768\n",
      "Loss for batch 51 = 1.0742278099060059\n",
      "Loss for batch 52 = 1.095268964767456\n",
      "Loss for batch 53 = 1.0785613059997559\n",
      "Loss for batch 54 = 0.9977336525917053\n",
      "Loss for batch 55 = 1.0629481077194214\n",
      "Loss for batch 56 = 1.1009197235107422\n",
      "Loss for batch 57 = 1.0729107856750488\n",
      "Loss for batch 58 = 1.01338791847229\n",
      "Loss for batch 59 = 1.0933935642242432\n",
      "Loss for batch 60 = 1.0438624620437622\n",
      "Loss for batch 61 = 1.0377496480941772\n",
      "Loss for batch 62 = 1.0846909284591675\n",
      "Loss for batch 63 = 1.0841537714004517\n",
      "Loss for batch 64 = 1.0834999084472656\n",
      "Loss for batch 65 = 1.0493829250335693\n",
      "Loss for batch 66 = 1.035069227218628\n",
      "Loss for batch 67 = 1.0107243061065674\n",
      "Loss for batch 68 = 1.0185295343399048\n",
      "Loss for batch 69 = 1.1975854635238647\n",
      "Loss for batch 70 = 1.0545169115066528\n",
      "Loss for batch 71 = 1.0462629795074463\n",
      "Loss for batch 72 = 1.0541565418243408\n",
      "Loss for batch 73 = 1.0917649269104004\n",
      "Loss for batch 74 = 1.0810006856918335\n",
      "Loss for batch 75 = 1.0978469848632812\n",
      "Loss for batch 76 = 1.181975245475769\n",
      "Loss for batch 77 = 1.059462308883667\n",
      "Loss for batch 78 = 1.1064238548278809\n",
      "Loss for batch 79 = 1.0789493322372437\n",
      "Loss for batch 80 = 1.0738840103149414\n",
      "Loss for batch 81 = 1.050113558769226\n",
      "Loss for batch 82 = 1.0908288955688477\n",
      "Loss for batch 83 = 1.0166972875595093\n",
      "Loss for batch 84 = 0.9857787489891052\n",
      "Loss for batch 85 = 1.1300983428955078\n",
      "Loss for batch 86 = 1.1330305337905884\n",
      "Loss for batch 87 = 1.0225484371185303\n",
      "Loss for batch 88 = 1.0545059442520142\n",
      "Loss for batch 89 = 1.0463746786117554\n",
      "Loss for batch 90 = 1.0182793140411377\n",
      "Loss for batch 91 = 1.1052225828170776\n",
      "Loss for batch 92 = 1.0628225803375244\n",
      "Loss for batch 93 = 1.0820285081863403\n",
      "Loss for batch 94 = 1.0459054708480835\n",
      "Loss for batch 95 = 1.0980224609375\n",
      "Loss for batch 96 = 1.1203787326812744\n",
      "Loss for batch 97 = 1.1811500787734985\n",
      "\n",
      "Training Loss for epoch 3 = 106.29285430908203\n",
      "\n",
      "Current Validation Loss = 27.412151336669922\n",
      "Best Validation Loss = 27.412151336669922\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 34.98%\n",
      "Validation Accuracy: 34.53%\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss for batch 0 = 1.0858501195907593\n",
      "Loss for batch 1 = 1.1016265153884888\n",
      "Loss for batch 2 = 1.093908429145813\n",
      "Loss for batch 3 = 1.0632755756378174\n",
      "Loss for batch 4 = 1.1077799797058105\n",
      "Loss for batch 5 = 1.070181131362915\n",
      "Loss for batch 6 = 1.0922033786773682\n",
      "Loss for batch 7 = 1.0817495584487915\n",
      "Loss for batch 8 = 1.1409947872161865\n",
      "Loss for batch 9 = 1.1014426946640015\n",
      "Loss for batch 10 = 1.0808781385421753\n",
      "Loss for batch 11 = 1.09267258644104\n",
      "Loss for batch 12 = 1.0791748762130737\n",
      "Loss for batch 13 = 1.106389045715332\n",
      "Loss for batch 14 = 1.0714161396026611\n",
      "Loss for batch 15 = 1.116194725036621\n",
      "Loss for batch 16 = 1.1100201606750488\n",
      "Loss for batch 17 = 1.0862584114074707\n",
      "Loss for batch 18 = 1.0959527492523193\n",
      "Loss for batch 19 = 1.0876550674438477\n",
      "Loss for batch 20 = 1.1210405826568604\n",
      "Loss for batch 21 = 1.0946754217147827\n",
      "Loss for batch 22 = 1.1000665426254272\n",
      "Loss for batch 23 = 1.1027348041534424\n",
      "Loss for batch 24 = 1.0976098775863647\n",
      "Loss for batch 25 = 1.0818973779678345\n",
      "Loss for batch 26 = 1.0776631832122803\n",
      "Loss for batch 27 = 1.0798460245132446\n",
      "Loss for batch 28 = 1.0956324338912964\n",
      "Loss for batch 29 = 1.0767648220062256\n",
      "Loss for batch 30 = 1.0650144815444946\n",
      "Loss for batch 31 = 1.075111746788025\n",
      "Loss for batch 32 = 1.116767406463623\n",
      "Loss for batch 33 = 1.0868395566940308\n",
      "Loss for batch 34 = 1.0818878412246704\n",
      "Loss for batch 35 = 1.1140228509902954\n",
      "Loss for batch 36 = 1.1107875108718872\n",
      "Loss for batch 37 = 1.0849714279174805\n",
      "Loss for batch 38 = 1.0676851272583008\n",
      "Loss for batch 39 = 1.0699831247329712\n",
      "Loss for batch 40 = 1.0865962505340576\n",
      "Loss for batch 41 = 1.127015233039856\n",
      "Loss for batch 42 = 1.0766545534133911\n",
      "Loss for batch 43 = 1.084455132484436\n",
      "Loss for batch 44 = 1.1023728847503662\n",
      "Loss for batch 45 = 1.1016204357147217\n",
      "Loss for batch 46 = 1.0757018327713013\n",
      "Loss for batch 47 = 1.085843801498413\n",
      "Loss for batch 48 = 1.075514793395996\n",
      "Loss for batch 49 = 1.1377161741256714\n",
      "Loss for batch 50 = 1.0905345678329468\n",
      "Loss for batch 51 = 1.098156452178955\n",
      "Loss for batch 52 = 1.0802855491638184\n",
      "Loss for batch 53 = 1.1069159507751465\n",
      "Loss for batch 54 = 1.0455390214920044\n",
      "Loss for batch 55 = 1.044677734375\n",
      "Loss for batch 56 = 1.1201738119125366\n",
      "Loss for batch 57 = 1.0944844484329224\n",
      "Loss for batch 58 = 1.0539264678955078\n",
      "Loss for batch 59 = 1.0768595933914185\n",
      "Loss for batch 60 = 1.0678166151046753\n",
      "Loss for batch 61 = 1.0517328977584839\n",
      "Loss for batch 62 = 1.1255770921707153\n",
      "Loss for batch 63 = 1.080428123474121\n",
      "Loss for batch 64 = 1.1250851154327393\n",
      "Loss for batch 65 = 1.0439074039459229\n",
      "Loss for batch 66 = 1.0775821208953857\n",
      "Loss for batch 67 = 1.0528533458709717\n",
      "Loss for batch 68 = 1.0250366926193237\n",
      "Loss for batch 69 = 1.1345587968826294\n",
      "Loss for batch 70 = 1.0660583972930908\n",
      "Loss for batch 71 = 1.0723308324813843\n",
      "Loss for batch 72 = 1.057796597480774\n",
      "Loss for batch 73 = 1.0565351247787476\n",
      "Loss for batch 74 = 1.1082111597061157\n",
      "Loss for batch 75 = 1.1094000339508057\n",
      "Loss for batch 76 = 1.144399642944336\n",
      "Loss for batch 77 = 1.0366002321243286\n",
      "Loss for batch 78 = 1.0674744844436646\n",
      "Loss for batch 79 = 1.0952125787734985\n",
      "Loss for batch 80 = 1.0878050327301025\n",
      "Loss for batch 81 = 1.0232943296432495\n",
      "Loss for batch 82 = 1.0654834508895874\n",
      "Loss for batch 83 = 1.0094692707061768\n",
      "Loss for batch 84 = 0.9772240519523621\n",
      "Loss for batch 85 = 1.0331918001174927\n",
      "Loss for batch 86 = 1.160561203956604\n",
      "Loss for batch 87 = 1.0154354572296143\n",
      "Loss for batch 88 = 1.0941201448440552\n",
      "Loss for batch 89 = 1.011205792427063\n",
      "Loss for batch 90 = 0.98188716173172\n",
      "Loss for batch 91 = 1.072070598602295\n",
      "Loss for batch 92 = 1.038589596748352\n",
      "Loss for batch 93 = 1.0740289688110352\n",
      "Loss for batch 94 = 1.0249300003051758\n",
      "Loss for batch 95 = 1.144874930381775\n",
      "Loss for batch 96 = 1.2085565328598022\n",
      "Loss for batch 97 = 1.1159700155258179\n",
      "\n",
      "Training Loss for epoch 4 = 106.16897583007812\n",
      "\n",
      "Current Validation Loss = 27.65666961669922\n",
      "Best Validation Loss = 27.412151336669922\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 35.37%\n",
      "Validation Accuracy: 34.27%\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss for batch 0 = 1.0805068016052246\n",
      "Loss for batch 1 = 1.105774998664856\n",
      "Loss for batch 2 = 1.0851421356201172\n",
      "Loss for batch 3 = 1.0963482856750488\n",
      "Loss for batch 4 = 1.091760516166687\n",
      "Loss for batch 5 = 1.0751729011535645\n",
      "Loss for batch 6 = 1.0923655033111572\n",
      "Loss for batch 7 = 1.0898100137710571\n",
      "Loss for batch 8 = 1.0716698169708252\n",
      "Loss for batch 9 = 1.086376667022705\n",
      "Loss for batch 10 = 1.0892587900161743\n",
      "Loss for batch 11 = 1.090041160583496\n",
      "Loss for batch 12 = 1.090907335281372\n",
      "Loss for batch 13 = 1.0693371295928955\n",
      "Loss for batch 14 = 1.0233129262924194\n",
      "Loss for batch 15 = 1.1119600534439087\n",
      "Loss for batch 16 = 1.09673273563385\n",
      "Loss for batch 17 = 1.100673794746399\n",
      "Loss for batch 18 = 1.080560564994812\n",
      "Loss for batch 19 = 1.065479040145874\n",
      "Loss for batch 20 = 1.1367723941802979\n",
      "Loss for batch 21 = 1.0744497776031494\n",
      "Loss for batch 22 = 1.0719081163406372\n",
      "Loss for batch 23 = 1.0944279432296753\n",
      "Loss for batch 24 = 1.0653855800628662\n",
      "Loss for batch 25 = 0.9900739789009094\n",
      "Loss for batch 26 = 0.9730044603347778\n",
      "Loss for batch 27 = 0.9283750653266907\n",
      "Loss for batch 28 = 1.0984174013137817\n",
      "Loss for batch 29 = 1.1493490934371948\n",
      "Loss for batch 30 = 0.9232075214385986\n",
      "Loss for batch 31 = 0.9066233038902283\n",
      "Loss for batch 32 = 1.1432065963745117\n",
      "Loss for batch 33 = 1.1098281145095825\n",
      "Loss for batch 34 = 1.1113890409469604\n",
      "Loss for batch 35 = 1.072320818901062\n",
      "Loss for batch 36 = 1.1194418668746948\n",
      "Loss for batch 37 = 1.1497832536697388\n",
      "Loss for batch 38 = 1.1203099489212036\n",
      "Loss for batch 39 = 1.1315795183181763\n",
      "Loss for batch 40 = 1.0893580913543701\n",
      "Loss for batch 41 = 1.0920815467834473\n",
      "Loss for batch 42 = 1.1004093885421753\n",
      "Loss for batch 43 = 1.087235689163208\n",
      "Loss for batch 44 = 1.0870007276535034\n",
      "Loss for batch 45 = 1.100071907043457\n",
      "Loss for batch 46 = 1.0630557537078857\n",
      "Loss for batch 47 = 1.0846809148788452\n",
      "Loss for batch 48 = 1.0977598428726196\n",
      "Loss for batch 49 = 1.1387584209442139\n",
      "Loss for batch 50 = 1.0700949430465698\n",
      "Loss for batch 51 = 1.0531972646713257\n",
      "Loss for batch 52 = 1.11681067943573\n",
      "Loss for batch 53 = 1.0830503702163696\n",
      "Loss for batch 54 = 0.9659031629562378\n",
      "Loss for batch 55 = 1.0513851642608643\n",
      "Loss for batch 56 = 1.1327588558197021\n",
      "Loss for batch 57 = 1.092799425125122\n",
      "Loss for batch 58 = 0.9966951012611389\n",
      "Loss for batch 59 = 1.1140320301055908\n",
      "Loss for batch 60 = 1.0295273065567017\n",
      "Loss for batch 61 = 1.0363729000091553\n",
      "Loss for batch 62 = 1.0701353549957275\n",
      "Loss for batch 63 = 1.106360912322998\n",
      "Loss for batch 64 = 1.1054257154464722\n",
      "Loss for batch 65 = 1.0445184707641602\n",
      "Loss for batch 66 = 1.0503722429275513\n",
      "Loss for batch 67 = 1.048341989517212\n",
      "Loss for batch 68 = 1.0359930992126465\n",
      "Loss for batch 69 = 1.1578071117401123\n",
      "Loss for batch 70 = 1.070191502571106\n",
      "Loss for batch 71 = 1.0699384212493896\n",
      "Loss for batch 72 = 1.0593827962875366\n",
      "Loss for batch 73 = 1.062258005142212\n",
      "Loss for batch 74 = 1.084497094154358\n",
      "Loss for batch 75 = 1.0915173292160034\n",
      "Loss for batch 76 = 1.1637542247772217\n",
      "Loss for batch 77 = 1.0407500267028809\n",
      "Loss for batch 78 = 1.0914547443389893\n",
      "Loss for batch 79 = 1.0884052515029907\n",
      "Loss for batch 80 = 1.0746232271194458\n",
      "Loss for batch 81 = 1.0538791418075562\n",
      "Loss for batch 82 = 1.0991326570510864\n",
      "Loss for batch 83 = 1.0070881843566895\n",
      "Loss for batch 84 = 0.9754074215888977\n",
      "Loss for batch 85 = 1.0577986240386963\n",
      "Loss for batch 86 = 1.1567257642745972\n",
      "Loss for batch 87 = 1.0153871774673462\n",
      "Loss for batch 88 = 1.0210509300231934\n",
      "Loss for batch 89 = 1.0251332521438599\n",
      "Loss for batch 90 = 0.9851188659667969\n",
      "Loss for batch 91 = 1.0503411293029785\n",
      "Loss for batch 92 = 1.0427833795547485\n",
      "Loss for batch 93 = 1.0649000406265259\n",
      "Loss for batch 94 = 1.048317551612854\n",
      "Loss for batch 95 = 1.089832067489624\n",
      "Loss for batch 96 = 1.1297945976257324\n",
      "Loss for batch 97 = 1.1742897033691406\n",
      "\n",
      "Training Loss for epoch 5 = 105.25877380371094\n",
      "\n",
      "Current Validation Loss = 26.928428649902344\n",
      "Best Validation Loss = 26.928428649902344\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.52%\n",
      "Validation Accuracy: 40.69%\n",
      "\n",
      "Epoch 6\n",
      "----------\n",
      "Loss for batch 0 = 1.1041849851608276\n",
      "Loss for batch 1 = 1.086197018623352\n",
      "Loss for batch 2 = 1.0608309507369995\n",
      "Loss for batch 3 = 1.049458622932434\n",
      "Loss for batch 4 = 1.074914813041687\n",
      "Loss for batch 5 = 1.0301178693771362\n",
      "Loss for batch 6 = 1.0766977071762085\n",
      "Loss for batch 7 = 1.088729739189148\n",
      "Loss for batch 8 = 1.0701676607131958\n",
      "Loss for batch 9 = 1.1006677150726318\n",
      "Loss for batch 10 = 1.0776698589324951\n",
      "Loss for batch 11 = 1.1115937232971191\n",
      "Loss for batch 12 = 1.0940834283828735\n",
      "Loss for batch 13 = 1.0381067991256714\n",
      "Loss for batch 14 = 1.005674958229065\n",
      "Loss for batch 15 = 1.1205480098724365\n",
      "Loss for batch 16 = 1.0782990455627441\n",
      "Loss for batch 17 = 1.130768060684204\n",
      "Loss for batch 18 = 1.0873634815216064\n",
      "Loss for batch 19 = 1.041242241859436\n",
      "Loss for batch 20 = 1.058061122894287\n",
      "Loss for batch 21 = 1.066735029220581\n",
      "Loss for batch 22 = 1.0643351078033447\n",
      "Loss for batch 23 = 1.080080509185791\n",
      "Loss for batch 24 = 1.04740309715271\n",
      "Loss for batch 25 = 0.9873088002204895\n",
      "Loss for batch 26 = 1.0292608737945557\n",
      "Loss for batch 27 = 0.948340892791748\n",
      "Loss for batch 28 = 1.0662846565246582\n",
      "Loss for batch 29 = 1.1287319660186768\n",
      "Loss for batch 30 = 0.9373987317085266\n",
      "Loss for batch 31 = 0.9079292416572571\n",
      "Loss for batch 32 = 1.1513062715530396\n",
      "Loss for batch 33 = 0.9978094100952148\n",
      "Loss for batch 34 = 1.1488938331604004\n",
      "Loss for batch 35 = 0.9924864768981934\n",
      "Loss for batch 36 = 1.0571308135986328\n",
      "Loss for batch 37 = 1.091005563735962\n",
      "Loss for batch 38 = 1.024370551109314\n",
      "Loss for batch 39 = 1.1740963459014893\n",
      "Loss for batch 40 = 1.1418911218643188\n",
      "Loss for batch 41 = 1.1121855974197388\n",
      "Loss for batch 42 = 1.0686893463134766\n",
      "Loss for batch 43 = 1.061904788017273\n",
      "Loss for batch 44 = 1.0977529287338257\n",
      "Loss for batch 45 = 1.13489830493927\n",
      "Loss for batch 46 = 1.0363500118255615\n",
      "Loss for batch 47 = 1.0903915166854858\n",
      "Loss for batch 48 = 1.0841203927993774\n",
      "Loss for batch 49 = 1.119020938873291\n",
      "Loss for batch 50 = 1.105601191520691\n",
      "Loss for batch 51 = 1.0823867321014404\n",
      "Loss for batch 52 = 1.0903853178024292\n",
      "Loss for batch 53 = 1.136244535446167\n",
      "Loss for batch 54 = 0.9763280749320984\n",
      "Loss for batch 55 = 1.0589693784713745\n",
      "Loss for batch 56 = 1.108770728111267\n",
      "Loss for batch 57 = 1.0763555765151978\n",
      "Loss for batch 58 = 0.977511465549469\n",
      "Loss for batch 59 = 1.1131120920181274\n",
      "Loss for batch 60 = 1.0447970628738403\n",
      "Loss for batch 61 = 1.0182232856750488\n",
      "Loss for batch 62 = 1.0935637950897217\n",
      "Loss for batch 63 = 1.073824167251587\n",
      "Loss for batch 64 = 1.123375654220581\n",
      "Loss for batch 65 = 1.0203582048416138\n",
      "Loss for batch 66 = 1.0393078327178955\n",
      "Loss for batch 67 = 1.0194778442382812\n",
      "Loss for batch 68 = 1.028870701789856\n",
      "Loss for batch 69 = 1.1493059396743774\n",
      "Loss for batch 70 = 1.0668303966522217\n",
      "Loss for batch 71 = 1.0508534908294678\n",
      "Loss for batch 72 = 1.0457779169082642\n",
      "Loss for batch 73 = 1.0433300733566284\n",
      "Loss for batch 74 = 1.0918238162994385\n",
      "Loss for batch 75 = 1.0791046619415283\n",
      "Loss for batch 76 = 1.1674617528915405\n",
      "Loss for batch 77 = 1.009944200515747\n",
      "Loss for batch 78 = 1.0790750980377197\n",
      "Loss for batch 79 = 1.0803855657577515\n",
      "Loss for batch 80 = 1.0671510696411133\n",
      "Loss for batch 81 = 1.0200356245040894\n",
      "Loss for batch 82 = 1.0715134143829346\n",
      "Loss for batch 83 = 0.9668182134628296\n",
      "Loss for batch 84 = 0.9346074461936951\n",
      "Loss for batch 85 = 1.056714653968811\n",
      "Loss for batch 86 = 1.1533665657043457\n",
      "Loss for batch 87 = 1.006734848022461\n",
      "Loss for batch 88 = 0.9941984415054321\n",
      "Loss for batch 89 = 1.0078026056289673\n",
      "Loss for batch 90 = 0.9805006980895996\n",
      "Loss for batch 91 = 1.0215373039245605\n",
      "Loss for batch 92 = 1.1232699155807495\n",
      "Loss for batch 93 = 1.0191401243209839\n",
      "Loss for batch 94 = 1.0457037687301636\n",
      "Loss for batch 95 = 1.0897233486175537\n",
      "Loss for batch 96 = 1.1359766721725464\n",
      "Loss for batch 97 = 1.1475937366485596\n",
      "\n",
      "Training Loss for epoch 6 = 104.3272476196289\n",
      "\n",
      "Current Validation Loss = 26.794795989990234\n",
      "Best Validation Loss = 26.794795989990234\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 43.26%\n",
      "Validation Accuracy: 40.82%\n",
      "\n",
      "Epoch 7\n",
      "----------\n",
      "Loss for batch 0 = 1.092110514640808\n",
      "Loss for batch 1 = 1.0499095916748047\n",
      "Loss for batch 2 = 1.0436726808547974\n",
      "Loss for batch 3 = 1.0264164209365845\n",
      "Loss for batch 4 = 1.0583858489990234\n",
      "Loss for batch 5 = 1.0209078788757324\n",
      "Loss for batch 6 = 1.0701274871826172\n",
      "Loss for batch 7 = 1.1035279035568237\n",
      "Loss for batch 8 = 1.0906888246536255\n",
      "Loss for batch 9 = 1.096795678138733\n",
      "Loss for batch 10 = 1.0548039674758911\n",
      "Loss for batch 11 = 1.1300479173660278\n",
      "Loss for batch 12 = 1.0875091552734375\n",
      "Loss for batch 13 = 1.0490764379501343\n",
      "Loss for batch 14 = 0.9758148789405823\n",
      "Loss for batch 15 = 1.1130414009094238\n",
      "Loss for batch 16 = 1.07503342628479\n",
      "Loss for batch 17 = 1.1234875917434692\n",
      "Loss for batch 18 = 1.0621508359909058\n",
      "Loss for batch 19 = 1.0047775506973267\n",
      "Loss for batch 20 = 1.0923316478729248\n",
      "Loss for batch 21 = 1.058640718460083\n",
      "Loss for batch 22 = 1.053620457649231\n",
      "Loss for batch 23 = 1.0737547874450684\n",
      "Loss for batch 24 = 1.0389742851257324\n",
      "Loss for batch 25 = 0.9849365949630737\n",
      "Loss for batch 26 = 1.0395236015319824\n",
      "Loss for batch 27 = 0.9478686451911926\n",
      "Loss for batch 28 = 1.057244062423706\n",
      "Loss for batch 29 = 1.1481918096542358\n",
      "Loss for batch 30 = 0.9435215592384338\n",
      "Loss for batch 31 = 0.9225802421569824\n",
      "Loss for batch 32 = 1.131615400314331\n",
      "Loss for batch 33 = 1.025510549545288\n",
      "Loss for batch 34 = 1.1494096517562866\n",
      "Loss for batch 35 = 1.0100452899932861\n",
      "Loss for batch 36 = 1.0599868297576904\n",
      "Loss for batch 37 = 1.025325894355774\n",
      "Loss for batch 38 = 1.0397703647613525\n",
      "Loss for batch 39 = 1.1219372749328613\n",
      "Loss for batch 40 = 1.1117898225784302\n",
      "Loss for batch 41 = 1.1031513214111328\n",
      "Loss for batch 42 = 1.065373182296753\n",
      "Loss for batch 43 = 1.0550423860549927\n",
      "Loss for batch 44 = 1.1049785614013672\n",
      "Loss for batch 45 = 1.1109989881515503\n",
      "Loss for batch 46 = 1.0328830480575562\n",
      "Loss for batch 47 = 1.0726312398910522\n",
      "Loss for batch 48 = 1.0746623277664185\n",
      "Loss for batch 49 = 1.1531193256378174\n",
      "Loss for batch 50 = 1.1130181550979614\n",
      "Loss for batch 51 = 1.0766448974609375\n",
      "Loss for batch 52 = 1.067384123802185\n",
      "Loss for batch 53 = 1.1198086738586426\n",
      "Loss for batch 54 = 1.0252870321273804\n",
      "Loss for batch 55 = 1.1094155311584473\n",
      "Loss for batch 56 = 1.1023818254470825\n",
      "Loss for batch 57 = 1.0943686962127686\n",
      "Loss for batch 58 = 0.9908112287521362\n",
      "Loss for batch 59 = 1.0991523265838623\n",
      "Loss for batch 60 = 1.053936243057251\n",
      "Loss for batch 61 = 1.0299320220947266\n",
      "Loss for batch 62 = 1.0701696872711182\n",
      "Loss for batch 63 = 1.0717880725860596\n",
      "Loss for batch 64 = 1.1291126012802124\n",
      "Loss for batch 65 = 1.0123146772384644\n",
      "Loss for batch 66 = 1.0391193628311157\n",
      "Loss for batch 67 = 0.9965561032295227\n",
      "Loss for batch 68 = 0.9923652410507202\n",
      "Loss for batch 69 = 1.1456210613250732\n",
      "Loss for batch 70 = 1.0755243301391602\n",
      "Loss for batch 71 = 1.0293169021606445\n",
      "Loss for batch 72 = 1.0195729732513428\n",
      "Loss for batch 73 = 1.0525941848754883\n",
      "Loss for batch 74 = 1.1021369695663452\n",
      "Loss for batch 75 = 1.0741820335388184\n",
      "Loss for batch 76 = 1.1627048254013062\n",
      "Loss for batch 77 = 0.9917289614677429\n",
      "Loss for batch 78 = 1.0559765100479126\n",
      "Loss for batch 79 = 1.0658458471298218\n",
      "Loss for batch 80 = 1.0560050010681152\n",
      "Loss for batch 81 = 1.0301756858825684\n",
      "Loss for batch 82 = 1.0670831203460693\n",
      "Loss for batch 83 = 0.965546727180481\n",
      "Loss for batch 84 = 0.9325570464134216\n",
      "Loss for batch 85 = 1.0602198839187622\n",
      "Loss for batch 86 = 1.1337838172912598\n",
      "Loss for batch 87 = 1.0029468536376953\n",
      "Loss for batch 88 = 0.9772807359695435\n",
      "Loss for batch 89 = 1.0070152282714844\n",
      "Loss for batch 90 = 0.9521589875221252\n",
      "Loss for batch 91 = 1.0302176475524902\n",
      "Loss for batch 92 = 1.0200746059417725\n",
      "Loss for batch 93 = 1.0296305418014526\n",
      "Loss for batch 94 = 1.0080289840698242\n",
      "Loss for batch 95 = 1.0933294296264648\n",
      "Loss for batch 96 = 1.0374488830566406\n",
      "Loss for batch 97 = 1.1112302541732788\n",
      "\n",
      "Training Loss for epoch 7 = 103.6211929321289\n",
      "\n",
      "Current Validation Loss = 26.755088806152344\n",
      "Best Validation Loss = 26.755088806152344\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 45.99%\n",
      "Validation Accuracy: 44.54%\n",
      "\n",
      "Epoch 8\n",
      "----------\n",
      "Loss for batch 0 = 1.0855287313461304\n",
      "Loss for batch 1 = 1.0278393030166626\n",
      "Loss for batch 2 = 1.0186318159103394\n",
      "Loss for batch 3 = 1.0076786279678345\n",
      "Loss for batch 4 = 1.037102222442627\n",
      "Loss for batch 5 = 1.027726411819458\n",
      "Loss for batch 6 = 1.0432133674621582\n",
      "Loss for batch 7 = 1.1235816478729248\n",
      "Loss for batch 8 = 1.05205237865448\n",
      "Loss for batch 9 = 1.0931482315063477\n",
      "Loss for batch 10 = 1.0579575300216675\n",
      "Loss for batch 11 = 1.1485595703125\n",
      "Loss for batch 12 = 1.10604989528656\n",
      "Loss for batch 13 = 1.0501688718795776\n",
      "Loss for batch 14 = 0.9290816783905029\n",
      "Loss for batch 15 = 1.089106798171997\n",
      "Loss for batch 16 = 1.0845786333084106\n",
      "Loss for batch 17 = 1.132535457611084\n",
      "Loss for batch 18 = 1.0544123649597168\n",
      "Loss for batch 19 = 1.0245068073272705\n",
      "Loss for batch 20 = 1.0491540431976318\n",
      "Loss for batch 21 = 1.0236016511917114\n",
      "Loss for batch 22 = 1.0514222383499146\n",
      "Loss for batch 23 = 1.062556266784668\n",
      "Loss for batch 24 = 1.0117807388305664\n",
      "Loss for batch 25 = 0.9828546643257141\n",
      "Loss for batch 26 = 1.0233268737792969\n",
      "Loss for batch 27 = 0.9274280667304993\n",
      "Loss for batch 28 = 1.028935194015503\n",
      "Loss for batch 29 = 1.1339699029922485\n",
      "Loss for batch 30 = 0.9405507445335388\n",
      "Loss for batch 31 = 0.9206874370574951\n",
      "Loss for batch 32 = 1.1020935773849487\n",
      "Loss for batch 33 = 0.9804263710975647\n",
      "Loss for batch 34 = 1.1444748640060425\n",
      "Loss for batch 35 = 1.0008751153945923\n",
      "Loss for batch 36 = 1.0448681116104126\n",
      "Loss for batch 37 = 1.100082516670227\n",
      "Loss for batch 38 = 1.0462231636047363\n",
      "Loss for batch 39 = 1.1863621473312378\n",
      "Loss for batch 40 = 1.1161417961120605\n",
      "Loss for batch 41 = 1.0849052667617798\n",
      "Loss for batch 42 = 1.0382585525512695\n",
      "Loss for batch 43 = 1.0338619947433472\n",
      "Loss for batch 44 = 1.0911457538604736\n",
      "Loss for batch 45 = 1.1982567310333252\n",
      "Loss for batch 46 = 1.0363006591796875\n",
      "Loss for batch 47 = 1.1118037700653076\n",
      "Loss for batch 48 = 1.1050829887390137\n",
      "Loss for batch 49 = 1.1093623638153076\n",
      "Loss for batch 50 = 1.1018873453140259\n",
      "Loss for batch 51 = 1.0999062061309814\n",
      "Loss for batch 52 = 1.0772368907928467\n",
      "Loss for batch 53 = 1.125313639640808\n",
      "Loss for batch 54 = 1.0267736911773682\n",
      "Loss for batch 55 = 1.0127029418945312\n",
      "Loss for batch 56 = 1.1648974418640137\n",
      "Loss for batch 57 = 1.1190743446350098\n",
      "Loss for batch 58 = 1.0999796390533447\n",
      "Loss for batch 59 = 1.0666437149047852\n",
      "Loss for batch 60 = 1.0601962804794312\n",
      "Loss for batch 61 = 1.0576562881469727\n",
      "Loss for batch 62 = 1.1113330125808716\n",
      "Loss for batch 63 = 1.107028603553772\n",
      "Loss for batch 64 = 1.105826735496521\n",
      "Loss for batch 65 = 1.0516400337219238\n",
      "Loss for batch 66 = 1.0829226970672607\n",
      "Loss for batch 67 = 1.0863008499145508\n",
      "Loss for batch 68 = 1.0545039176940918\n",
      "Loss for batch 69 = 1.1001756191253662\n",
      "Loss for batch 70 = 1.077054738998413\n",
      "Loss for batch 71 = 1.1079457998275757\n",
      "Loss for batch 72 = 1.0625745058059692\n",
      "Loss for batch 73 = 1.0937037467956543\n",
      "Loss for batch 74 = 1.0721163749694824\n",
      "Loss for batch 75 = 1.1003071069717407\n",
      "Loss for batch 76 = 1.1058673858642578\n",
      "Loss for batch 77 = 1.01596999168396\n",
      "Loss for batch 78 = 1.0404587984085083\n",
      "Loss for batch 79 = 1.072320580482483\n",
      "Loss for batch 80 = 1.0948402881622314\n",
      "Loss for batch 81 = 0.987628698348999\n",
      "Loss for batch 82 = 1.1094006299972534\n",
      "Loss for batch 83 = 1.0501922369003296\n",
      "Loss for batch 84 = 0.9666088819503784\n",
      "Loss for batch 85 = 0.9181706309318542\n",
      "Loss for batch 86 = 1.2812484502792358\n",
      "Loss for batch 87 = 1.0482312440872192\n",
      "Loss for batch 88 = 1.1744061708450317\n",
      "Loss for batch 89 = 1.114396572113037\n",
      "Loss for batch 90 = 1.0537114143371582\n",
      "Loss for batch 91 = 1.092017650604248\n",
      "Loss for batch 92 = 1.091111660003662\n",
      "Loss for batch 93 = 1.1137206554412842\n",
      "Loss for batch 94 = 1.085266351699829\n",
      "Loss for batch 95 = 1.091490387916565\n",
      "Loss for batch 96 = 1.0836868286132812\n",
      "Loss for batch 97 = 1.086565613746643\n",
      "\n",
      "Training Loss for epoch 8 = 104.78326416015625\n",
      "\n",
      "Current Validation Loss = 26.974334716796875\n",
      "Best Validation Loss = 26.755088806152344\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 42.91%\n",
      "Validation Accuracy: 39.54%\n",
      "\n",
      "Epoch 9\n",
      "----------\n",
      "Loss for batch 0 = 1.1063506603240967\n",
      "Loss for batch 1 = 1.0317004919052124\n",
      "Loss for batch 2 = 1.0563839673995972\n",
      "Loss for batch 3 = 1.029881238937378\n",
      "Loss for batch 4 = 1.044995903968811\n",
      "Loss for batch 5 = 1.0314078330993652\n",
      "Loss for batch 6 = 1.0708585977554321\n",
      "Loss for batch 7 = 1.170052409172058\n",
      "Loss for batch 8 = 1.0172101259231567\n",
      "Loss for batch 9 = 1.03548264503479\n",
      "Loss for batch 10 = 1.13271963596344\n",
      "Loss for batch 11 = 1.1187318563461304\n",
      "Loss for batch 12 = 1.094218134880066\n",
      "Loss for batch 13 = 1.0820432901382446\n",
      "Loss for batch 14 = 0.9261877536773682\n",
      "Loss for batch 15 = 1.0607428550720215\n",
      "Loss for batch 16 = 1.0528767108917236\n",
      "Loss for batch 17 = 1.1050814390182495\n",
      "Loss for batch 18 = 1.0545750856399536\n",
      "Loss for batch 19 = 1.0377684831619263\n",
      "Loss for batch 20 = 1.1082106828689575\n",
      "Loss for batch 21 = 1.049046516418457\n",
      "Loss for batch 22 = 1.0742931365966797\n",
      "Loss for batch 23 = 1.0529491901397705\n",
      "Loss for batch 24 = 1.0185779333114624\n",
      "Loss for batch 25 = 0.9496365189552307\n",
      "Loss for batch 26 = 0.9726237058639526\n",
      "Loss for batch 27 = 0.9214566349983215\n",
      "Loss for batch 28 = 1.0229651927947998\n",
      "Loss for batch 29 = 1.1704437732696533\n",
      "Loss for batch 30 = 0.9499856233596802\n",
      "Loss for batch 31 = 0.8399136066436768\n",
      "Loss for batch 32 = 1.078971266746521\n",
      "Loss for batch 33 = 0.9515856504440308\n",
      "Loss for batch 34 = 1.1532293558120728\n",
      "Loss for batch 35 = 0.9800248742103577\n",
      "Loss for batch 36 = 1.0087289810180664\n",
      "Loss for batch 37 = 1.2269154787063599\n",
      "Loss for batch 38 = 1.1283138990402222\n",
      "Loss for batch 39 = 1.166780948638916\n",
      "Loss for batch 40 = 1.0727806091308594\n",
      "Loss for batch 41 = 1.0725795030593872\n",
      "Loss for batch 42 = 1.0700229406356812\n",
      "Loss for batch 43 = 1.069170355796814\n",
      "Loss for batch 44 = 1.0606752634048462\n",
      "Loss for batch 45 = 1.0727733373641968\n",
      "Loss for batch 46 = 0.9984212517738342\n",
      "Loss for batch 47 = 1.0486682653427124\n",
      "Loss for batch 48 = 1.0846598148345947\n",
      "Loss for batch 49 = 1.1331948041915894\n",
      "Loss for batch 50 = 1.0964919328689575\n",
      "Loss for batch 51 = 1.036311388015747\n",
      "Loss for batch 52 = 1.054368495941162\n",
      "Loss for batch 53 = 1.0161718130111694\n",
      "Loss for batch 54 = 0.8246077299118042\n",
      "Loss for batch 55 = 1.0612423419952393\n",
      "Loss for batch 56 = 1.1244159936904907\n",
      "Loss for batch 57 = 1.0284159183502197\n",
      "Loss for batch 58 = 0.9322195053100586\n",
      "Loss for batch 59 = 1.1003056764602661\n",
      "Loss for batch 60 = 1.0189813375473022\n",
      "Loss for batch 61 = 1.0073908567428589\n",
      "Loss for batch 62 = 1.0148171186447144\n",
      "Loss for batch 63 = 0.9842371344566345\n",
      "Loss for batch 64 = 1.0799155235290527\n",
      "Loss for batch 65 = 0.942304790019989\n",
      "Loss for batch 66 = 1.012331247329712\n",
      "Loss for batch 67 = 0.8602826595306396\n",
      "Loss for batch 68 = 0.9477781057357788\n",
      "Loss for batch 69 = 1.214284896850586\n",
      "Loss for batch 70 = 1.106656551361084\n",
      "Loss for batch 71 = 1.0347009897232056\n",
      "Loss for batch 72 = 0.9840121269226074\n",
      "Loss for batch 73 = 1.0269286632537842\n",
      "Loss for batch 74 = 1.0187277793884277\n",
      "Loss for batch 75 = 1.0291635990142822\n",
      "Loss for batch 76 = 1.1662440299987793\n",
      "Loss for batch 77 = 0.9252265095710754\n",
      "Loss for batch 78 = 1.0913821458816528\n",
      "Loss for batch 79 = 1.0192962884902954\n",
      "Loss for batch 80 = 1.0361918210983276\n",
      "Loss for batch 81 = 1.0134700536727905\n",
      "Loss for batch 82 = 1.1229722499847412\n",
      "Loss for batch 83 = 1.0036098957061768\n",
      "Loss for batch 84 = 0.880933403968811\n",
      "Loss for batch 85 = 0.9361217021942139\n",
      "Loss for batch 86 = 1.1181120872497559\n",
      "Loss for batch 87 = 0.9505830407142639\n",
      "Loss for batch 88 = 1.0387545824050903\n",
      "Loss for batch 89 = 0.9244211912155151\n",
      "Loss for batch 90 = 0.8830561637878418\n",
      "Loss for batch 91 = 0.9966241717338562\n",
      "Loss for batch 92 = 0.9674349427223206\n",
      "Loss for batch 93 = 1.044628620147705\n",
      "Loss for batch 94 = 1.0069864988327026\n",
      "Loss for batch 95 = 0.9919171333312988\n",
      "Loss for batch 96 = 0.8682591915130615\n",
      "Loss for batch 97 = 0.9470064043998718\n",
      "\n",
      "Training Loss for epoch 9 = 101.25719451904297\n",
      "\n",
      "Current Validation Loss = 26.06134605407715\n",
      "Best Validation Loss = 26.06134605407715\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 51.73%\n",
      "Validation Accuracy: 48.65%\n",
      "\n",
      "Epoch 10\n",
      "----------\n",
      "Loss for batch 0 = 0.999325156211853\n",
      "Loss for batch 1 = 0.9149139523506165\n",
      "Loss for batch 2 = 0.9779335260391235\n",
      "Loss for batch 3 = 0.9025586247444153\n",
      "Loss for batch 4 = 1.0338748693466187\n",
      "Loss for batch 5 = 1.0419628620147705\n",
      "Loss for batch 6 = 1.0042786598205566\n",
      "Loss for batch 7 = 1.216334342956543\n",
      "Loss for batch 8 = 0.9770715236663818\n",
      "Loss for batch 9 = 1.034338116645813\n",
      "Loss for batch 10 = 1.0287153720855713\n",
      "Loss for batch 11 = 1.1472091674804688\n",
      "Loss for batch 12 = 1.1057226657867432\n",
      "Loss for batch 13 = 1.0568194389343262\n",
      "Loss for batch 14 = 0.9331395030021667\n",
      "Loss for batch 15 = 1.0580397844314575\n",
      "Loss for batch 16 = 0.974515974521637\n",
      "Loss for batch 17 = 1.147367238998413\n",
      "Loss for batch 18 = 1.0070536136627197\n",
      "Loss for batch 19 = 0.9806001782417297\n",
      "Loss for batch 20 = 0.8551956415176392\n",
      "Loss for batch 21 = 0.9287030100822449\n",
      "Loss for batch 22 = 0.9963861107826233\n",
      "Loss for batch 23 = 1.0439494848251343\n",
      "Loss for batch 24 = 0.9640257358551025\n",
      "Loss for batch 25 = 0.8232027292251587\n",
      "Loss for batch 26 = 0.9135944843292236\n",
      "Loss for batch 27 = 0.8471760749816895\n",
      "Loss for batch 28 = 0.9365755319595337\n",
      "Loss for batch 29 = 1.128201961517334\n",
      "Loss for batch 30 = 0.9199306964874268\n",
      "Loss for batch 31 = 0.816921591758728\n",
      "Loss for batch 32 = 1.0268713235855103\n",
      "Loss for batch 33 = 0.9613675475120544\n",
      "Loss for batch 34 = 1.0490254163742065\n",
      "Loss for batch 35 = 1.1206659078598022\n",
      "Loss for batch 36 = 0.9677309989929199\n",
      "Loss for batch 37 = 1.044074296951294\n",
      "Loss for batch 38 = 0.9491419792175293\n",
      "Loss for batch 39 = 1.0476089715957642\n",
      "Loss for batch 40 = 1.1049387454986572\n",
      "Loss for batch 41 = 1.0062224864959717\n",
      "Loss for batch 42 = 0.928253710269928\n",
      "Loss for batch 43 = 1.0358561277389526\n",
      "Loss for batch 44 = 0.9952898025512695\n",
      "Loss for batch 45 = 1.0409437417984009\n",
      "Loss for batch 46 = 0.7876045107841492\n",
      "Loss for batch 47 = 0.8969134092330933\n",
      "Loss for batch 48 = 1.2512792348861694\n",
      "Loss for batch 49 = 1.1464736461639404\n",
      "Loss for batch 50 = 1.1213968992233276\n",
      "Loss for batch 51 = 0.9138309955596924\n",
      "Loss for batch 52 = 1.003416895866394\n",
      "Loss for batch 53 = 0.9683637022972107\n",
      "Loss for batch 54 = 0.775192141532898\n",
      "Loss for batch 55 = 0.9738577604293823\n",
      "Loss for batch 56 = 1.030990481376648\n",
      "Loss for batch 57 = 0.9673630595207214\n",
      "Loss for batch 58 = 0.7518289685249329\n",
      "Loss for batch 59 = 0.9741230010986328\n",
      "Loss for batch 60 = 0.9860612154006958\n",
      "Loss for batch 61 = 0.9891275763511658\n",
      "Loss for batch 62 = 0.8593419194221497\n",
      "Loss for batch 63 = 0.921759843826294\n",
      "Loss for batch 64 = 0.9803469777107239\n",
      "Loss for batch 65 = 0.9007906317710876\n",
      "Loss for batch 66 = 0.937589168548584\n",
      "Loss for batch 67 = 0.7923927903175354\n",
      "Loss for batch 68 = 0.9498140215873718\n",
      "Loss for batch 69 = 1.1363941431045532\n",
      "Loss for batch 70 = 1.0931246280670166\n",
      "Loss for batch 71 = 0.9514899849891663\n",
      "Loss for batch 72 = 0.9366223812103271\n",
      "Loss for batch 73 = 0.9920110702514648\n",
      "Loss for batch 74 = 1.0231207609176636\n",
      "Loss for batch 75 = 1.0659009218215942\n",
      "Loss for batch 76 = 1.2223026752471924\n",
      "Loss for batch 77 = 0.8574548959732056\n",
      "Loss for batch 78 = 1.0270321369171143\n",
      "Loss for batch 79 = 0.990067720413208\n",
      "Loss for batch 80 = 0.8571789264678955\n",
      "Loss for batch 81 = 0.9424222707748413\n",
      "Loss for batch 82 = 1.1150213479995728\n",
      "Loss for batch 83 = 0.8331841826438904\n",
      "Loss for batch 84 = 0.7517852187156677\n",
      "Loss for batch 85 = 0.918843686580658\n",
      "Loss for batch 86 = 1.049447774887085\n",
      "Loss for batch 87 = 0.9400219321250916\n",
      "Loss for batch 88 = 0.9314643144607544\n",
      "Loss for batch 89 = 0.8444668054580688\n",
      "Loss for batch 90 = 0.7386057376861572\n",
      "Loss for batch 91 = 0.910552442073822\n",
      "Loss for batch 92 = 0.8224886655807495\n",
      "Loss for batch 93 = 1.0418349504470825\n",
      "Loss for batch 94 = 0.98193359375\n",
      "Loss for batch 95 = 0.9383880496025085\n",
      "Loss for batch 96 = 0.7854702472686768\n",
      "Loss for batch 97 = 0.8870300650596619\n",
      "\n",
      "Training Loss for epoch 10 = 95.45914459228516\n",
      "\n",
      "Current Validation Loss = 24.963714599609375\n",
      "Best Validation Loss = 24.963714599609375\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 57.25%\n",
      "Validation Accuracy: 54.43%\n",
      "\n",
      "Epoch 11\n",
      "----------\n",
      "Loss for batch 0 = 0.876615047454834\n",
      "Loss for batch 1 = 0.854706346988678\n",
      "Loss for batch 2 = 1.0081511735916138\n",
      "Loss for batch 3 = 0.8781433701515198\n",
      "Loss for batch 4 = 1.019207239151001\n",
      "Loss for batch 5 = 1.0264933109283447\n",
      "Loss for batch 6 = 0.9169653654098511\n",
      "Loss for batch 7 = 1.0479665994644165\n",
      "Loss for batch 8 = 0.8811277747154236\n",
      "Loss for batch 9 = 1.0168637037277222\n",
      "Loss for batch 10 = 1.0695455074310303\n",
      "Loss for batch 11 = 1.1028468608856201\n",
      "Loss for batch 12 = 1.0936678647994995\n",
      "Loss for batch 13 = 1.028306484222412\n",
      "Loss for batch 14 = 0.8443239331245422\n",
      "Loss for batch 15 = 0.9839488863945007\n",
      "Loss for batch 16 = 0.8868646025657654\n",
      "Loss for batch 17 = 1.0876497030258179\n",
      "Loss for batch 18 = 0.9383509755134583\n",
      "Loss for batch 19 = 0.9307661056518555\n",
      "Loss for batch 20 = 0.7599525451660156\n",
      "Loss for batch 21 = 0.794638991355896\n",
      "Loss for batch 22 = 0.9330464005470276\n",
      "Loss for batch 23 = 0.9205026030540466\n",
      "Loss for batch 24 = 0.968672513961792\n",
      "Loss for batch 25 = 0.754387617111206\n",
      "Loss for batch 26 = 0.830571711063385\n",
      "Loss for batch 27 = 0.8142910599708557\n",
      "Loss for batch 28 = 0.884649395942688\n",
      "Loss for batch 29 = 1.0022493600845337\n",
      "Loss for batch 30 = 0.968105137348175\n",
      "Loss for batch 31 = 0.7770019173622131\n",
      "Loss for batch 32 = 1.0168200731277466\n",
      "Loss for batch 33 = 0.8663442730903625\n",
      "Loss for batch 34 = 0.9629110097885132\n",
      "Loss for batch 35 = 0.94853276014328\n",
      "Loss for batch 36 = 0.8900435566902161\n",
      "Loss for batch 37 = 1.0570650100708008\n",
      "Loss for batch 38 = 0.8970527648925781\n",
      "Loss for batch 39 = 0.98848557472229\n",
      "Loss for batch 40 = 1.0430057048797607\n",
      "Loss for batch 41 = 0.9395496249198914\n",
      "Loss for batch 42 = 0.821331799030304\n",
      "Loss for batch 43 = 0.9600679278373718\n",
      "Loss for batch 44 = 0.9361894726753235\n",
      "Loss for batch 45 = 0.9896181225776672\n",
      "Loss for batch 46 = 0.7205313444137573\n",
      "Loss for batch 47 = 0.8859778642654419\n",
      "Loss for batch 48 = 1.2310951948165894\n",
      "Loss for batch 49 = 1.0381473302841187\n",
      "Loss for batch 50 = 1.0245511531829834\n",
      "Loss for batch 51 = 0.9209344983100891\n",
      "Loss for batch 52 = 0.9731038212776184\n",
      "Loss for batch 53 = 0.853304922580719\n",
      "Loss for batch 54 = 0.633426308631897\n",
      "Loss for batch 55 = 0.9742920994758606\n",
      "Loss for batch 56 = 0.9712555408477783\n",
      "Loss for batch 57 = 0.899105966091156\n",
      "Loss for batch 58 = 0.7608018517494202\n",
      "Loss for batch 59 = 0.9341113567352295\n",
      "Loss for batch 60 = 0.9880090951919556\n",
      "Loss for batch 61 = 0.9420779347419739\n",
      "Loss for batch 62 = 0.7408034205436707\n",
      "Loss for batch 63 = 0.8004913330078125\n",
      "Loss for batch 64 = 0.7918893098831177\n",
      "Loss for batch 65 = 0.9273118376731873\n",
      "Loss for batch 66 = 0.8499811887741089\n",
      "Loss for batch 67 = 0.7154390811920166\n",
      "Loss for batch 68 = 0.8847779631614685\n",
      "Loss for batch 69 = 1.02475106716156\n",
      "Loss for batch 70 = 1.1074299812316895\n",
      "Loss for batch 71 = 0.8614033460617065\n",
      "Loss for batch 72 = 0.8805512189865112\n",
      "Loss for batch 73 = 0.8904686570167542\n",
      "Loss for batch 74 = 0.9443705677986145\n",
      "Loss for batch 75 = 0.9962704181671143\n",
      "Loss for batch 76 = 1.154140830039978\n",
      "Loss for batch 77 = 0.774944007396698\n",
      "Loss for batch 78 = 1.0829882621765137\n",
      "Loss for batch 79 = 0.9351077079772949\n",
      "Loss for batch 80 = 0.7759475708007812\n",
      "Loss for batch 81 = 0.9009370803833008\n",
      "Loss for batch 82 = 0.9793024063110352\n",
      "Loss for batch 83 = 0.7717779874801636\n",
      "Loss for batch 84 = 0.728032112121582\n",
      "Loss for batch 85 = 0.9660843014717102\n",
      "Loss for batch 86 = 0.9971746206283569\n",
      "Loss for batch 87 = 0.9012011289596558\n",
      "Loss for batch 88 = 0.8988779187202454\n",
      "Loss for batch 89 = 0.8621477484703064\n",
      "Loss for batch 90 = 0.7139772176742554\n",
      "Loss for batch 91 = 0.8755707740783691\n",
      "Loss for batch 92 = 0.7774031162261963\n",
      "Loss for batch 93 = 1.0095727443695068\n",
      "Loss for batch 94 = 0.8283162713050842\n",
      "Loss for batch 95 = 0.8063338994979858\n",
      "Loss for batch 96 = 0.7077946066856384\n",
      "Loss for batch 97 = 0.8407745361328125\n",
      "\n",
      "Training Loss for epoch 11 = 89.67267608642578\n",
      "\n",
      "Current Validation Loss = 24.175321578979492\n",
      "Best Validation Loss = 24.175321578979492\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 61.17%\n",
      "Validation Accuracy: 55.33%\n",
      "\n",
      "Epoch 12\n",
      "----------\n",
      "Loss for batch 0 = 0.8184000253677368\n",
      "Loss for batch 1 = 0.8477155566215515\n",
      "Loss for batch 2 = 0.9739790558815002\n",
      "Loss for batch 3 = 0.7463567852973938\n",
      "Loss for batch 4 = 0.946080207824707\n",
      "Loss for batch 5 = 0.8589844107627869\n",
      "Loss for batch 6 = 0.9452575445175171\n",
      "Loss for batch 7 = 1.1513410806655884\n",
      "Loss for batch 8 = 0.8811275362968445\n",
      "Loss for batch 9 = 0.9215488433837891\n",
      "Loss for batch 10 = 1.0278408527374268\n",
      "Loss for batch 11 = 0.9881358742713928\n",
      "Loss for batch 12 = 1.064592719078064\n",
      "Loss for batch 13 = 1.008896827697754\n",
      "Loss for batch 14 = 0.8218516707420349\n",
      "Loss for batch 15 = 0.9821987152099609\n",
      "Loss for batch 16 = 0.9517438411712646\n",
      "Loss for batch 17 = 1.0364691019058228\n",
      "Loss for batch 18 = 0.9138809442520142\n",
      "Loss for batch 19 = 0.9447095990180969\n",
      "Loss for batch 20 = 0.702589750289917\n",
      "Loss for batch 21 = 0.7173420786857605\n",
      "Loss for batch 22 = 0.8265878558158875\n",
      "Loss for batch 23 = 0.8139893412590027\n",
      "Loss for batch 24 = 0.9093284010887146\n",
      "Loss for batch 25 = 0.701580286026001\n",
      "Loss for batch 26 = 0.8255015015602112\n",
      "Loss for batch 27 = 0.8341578841209412\n",
      "Loss for batch 28 = 0.8980892896652222\n",
      "Loss for batch 29 = 1.0509076118469238\n",
      "Loss for batch 30 = 0.9170417785644531\n",
      "Loss for batch 31 = 0.674262523651123\n",
      "Loss for batch 32 = 0.980347216129303\n",
      "Loss for batch 33 = 0.8974459767341614\n",
      "Loss for batch 34 = 0.9384710788726807\n",
      "Loss for batch 35 = 0.8231486082077026\n",
      "Loss for batch 36 = 0.8885115385055542\n",
      "Loss for batch 37 = 0.9932681918144226\n",
      "Loss for batch 38 = 0.8901853561401367\n",
      "Loss for batch 39 = 0.9261353611946106\n",
      "Loss for batch 40 = 0.9846987724304199\n",
      "Loss for batch 41 = 0.8436502814292908\n",
      "Loss for batch 42 = 1.092911958694458\n",
      "Loss for batch 43 = 0.9631547331809998\n",
      "Loss for batch 44 = 0.8619455099105835\n",
      "Loss for batch 45 = 0.9222985506057739\n",
      "Loss for batch 46 = 0.7224151492118835\n",
      "Loss for batch 47 = 0.8782536387443542\n",
      "Loss for batch 48 = 1.1235417127609253\n",
      "Loss for batch 49 = 0.9486609697341919\n",
      "Loss for batch 50 = 0.9275183081626892\n",
      "Loss for batch 51 = 0.8095499277114868\n",
      "Loss for batch 52 = 0.9828164577484131\n",
      "Loss for batch 53 = 0.8279643058776855\n",
      "Loss for batch 54 = 0.6017228364944458\n",
      "Loss for batch 55 = 0.9112102389335632\n",
      "Loss for batch 56 = 0.9500426650047302\n",
      "Loss for batch 57 = 0.8588629364967346\n",
      "Loss for batch 58 = 0.6921859979629517\n",
      "Loss for batch 59 = 0.8833950757980347\n",
      "Loss for batch 60 = 0.966571033000946\n",
      "Loss for batch 61 = 0.8739711046218872\n",
      "Loss for batch 62 = 0.6692127585411072\n",
      "Loss for batch 63 = 0.7862932682037354\n",
      "Loss for batch 64 = 0.7617189288139343\n",
      "Loss for batch 65 = 0.8576773405075073\n",
      "Loss for batch 66 = 0.8286093473434448\n",
      "Loss for batch 67 = 0.6805371046066284\n",
      "Loss for batch 68 = 0.851007342338562\n",
      "Loss for batch 69 = 0.8941871523857117\n",
      "Loss for batch 70 = 1.1035830974578857\n",
      "Loss for batch 71 = 0.7492477297782898\n",
      "Loss for batch 72 = 0.8828519582748413\n",
      "Loss for batch 73 = 0.8797575831413269\n",
      "Loss for batch 74 = 0.9362991452217102\n",
      "Loss for batch 75 = 0.9834302067756653\n",
      "Loss for batch 76 = 1.097102403640747\n",
      "Loss for batch 77 = 0.6988016963005066\n",
      "Loss for batch 78 = 1.0052989721298218\n",
      "Loss for batch 79 = 0.9061147570610046\n",
      "Loss for batch 80 = 0.7240374684333801\n",
      "Loss for batch 81 = 0.8566585183143616\n",
      "Loss for batch 82 = 0.9837527871131897\n",
      "Loss for batch 83 = 0.7250375747680664\n",
      "Loss for batch 84 = 0.6584265232086182\n",
      "Loss for batch 85 = 0.845489501953125\n",
      "Loss for batch 86 = 0.9844397306442261\n",
      "Loss for batch 87 = 0.8173499703407288\n",
      "Loss for batch 88 = 0.8402105569839478\n",
      "Loss for batch 89 = 0.8481886982917786\n",
      "Loss for batch 90 = 0.7093555331230164\n",
      "Loss for batch 91 = 0.8048989772796631\n",
      "Loss for batch 92 = 0.6573837995529175\n",
      "Loss for batch 93 = 0.8987232446670532\n",
      "Loss for batch 94 = 0.7216582894325256\n",
      "Loss for batch 95 = 0.7334765195846558\n",
      "Loss for batch 96 = 0.7036455273628235\n",
      "Loss for batch 97 = 0.8716669678688049\n",
      "\n",
      "Training Loss for epoch 12 = 85.62346649169922\n",
      "\n",
      "Current Validation Loss = 25.002376556396484\n",
      "Best Validation Loss = 24.175321578979492\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 57.99%\n",
      "Validation Accuracy: 52.63%\n",
      "\n",
      "Epoch 13\n",
      "----------\n",
      "Loss for batch 0 = 0.9384544491767883\n",
      "Loss for batch 1 = 0.9153306484222412\n",
      "Loss for batch 2 = 1.0032005310058594\n",
      "Loss for batch 3 = 0.7230457067489624\n",
      "Loss for batch 4 = 0.8639485239982605\n",
      "Loss for batch 5 = 0.8274174332618713\n",
      "Loss for batch 6 = 0.9221398234367371\n",
      "Loss for batch 7 = 1.0424697399139404\n",
      "Loss for batch 8 = 0.7570140361785889\n",
      "Loss for batch 9 = 1.0333707332611084\n",
      "Loss for batch 10 = 0.995549201965332\n",
      "Loss for batch 11 = 0.953195333480835\n",
      "Loss for batch 12 = 0.9645482301712036\n",
      "Loss for batch 13 = 1.0277745723724365\n",
      "Loss for batch 14 = 0.8250318765640259\n",
      "Loss for batch 15 = 0.9033843278884888\n",
      "Loss for batch 16 = 0.8504195213317871\n",
      "Loss for batch 17 = 0.9877917766571045\n",
      "Loss for batch 18 = 0.92508465051651\n",
      "Loss for batch 19 = 0.9503619074821472\n",
      "Loss for batch 20 = 0.8545342087745667\n",
      "Loss for batch 21 = 0.8404022455215454\n",
      "Loss for batch 22 = 0.7534948587417603\n",
      "Loss for batch 23 = 0.8461028337478638\n",
      "Loss for batch 24 = 0.8514506220817566\n",
      "Loss for batch 25 = 0.7386302351951599\n",
      "Loss for batch 26 = 0.9321823120117188\n",
      "Loss for batch 27 = 0.7967334389686584\n",
      "Loss for batch 28 = 0.940183699131012\n",
      "Loss for batch 29 = 1.041632056236267\n",
      "Loss for batch 30 = 0.9759430289268494\n",
      "Loss for batch 31 = 0.6592658162117004\n",
      "Loss for batch 32 = 0.883039653301239\n",
      "Loss for batch 33 = 0.8675519824028015\n",
      "Loss for batch 34 = 0.9433721303939819\n",
      "Loss for batch 35 = 0.8765165209770203\n",
      "Loss for batch 36 = 0.8701595664024353\n",
      "Loss for batch 37 = 1.0041553974151611\n",
      "Loss for batch 38 = 0.8956382870674133\n",
      "Loss for batch 39 = 1.0435172319412231\n",
      "Loss for batch 40 = 0.9632116556167603\n",
      "Loss for batch 41 = 0.9007720947265625\n",
      "Loss for batch 42 = 0.8271974921226501\n",
      "Loss for batch 43 = 0.8177700042724609\n",
      "Loss for batch 44 = 0.80992591381073\n",
      "Loss for batch 45 = 0.9583152532577515\n",
      "Loss for batch 46 = 0.6436576843261719\n",
      "Loss for batch 47 = 0.8507611155509949\n",
      "Loss for batch 48 = 1.136828064918518\n",
      "Loss for batch 49 = 0.9544405937194824\n",
      "Loss for batch 50 = 0.9282425045967102\n",
      "Loss for batch 51 = 0.773226797580719\n",
      "Loss for batch 52 = 0.9229718446731567\n",
      "Loss for batch 53 = 0.752051830291748\n",
      "Loss for batch 54 = 0.5693929195404053\n",
      "Loss for batch 55 = 0.9641555547714233\n",
      "Loss for batch 56 = 0.8204447627067566\n",
      "Loss for batch 57 = 0.8211190700531006\n",
      "Loss for batch 58 = 0.6747292876243591\n",
      "Loss for batch 59 = 1.0137284994125366\n",
      "Loss for batch 60 = 0.8796486854553223\n",
      "Loss for batch 61 = 0.858322024345398\n",
      "Loss for batch 62 = 0.654609739780426\n",
      "Loss for batch 63 = 0.6970251798629761\n",
      "Loss for batch 64 = 0.7337509393692017\n",
      "Loss for batch 65 = 0.7191262245178223\n",
      "Loss for batch 66 = 0.7913711071014404\n",
      "Loss for batch 67 = 0.6131176948547363\n",
      "Loss for batch 68 = 0.8377474546432495\n",
      "Loss for batch 69 = 0.8514302968978882\n",
      "Loss for batch 70 = 1.0392251014709473\n",
      "Loss for batch 71 = 0.7136496305465698\n",
      "Loss for batch 72 = 0.8423522710800171\n",
      "Loss for batch 73 = 0.734258770942688\n",
      "Loss for batch 74 = 0.8509524464607239\n",
      "Loss for batch 75 = 0.8161191344261169\n",
      "Loss for batch 76 = 1.0720994472503662\n",
      "Loss for batch 77 = 0.6452547907829285\n",
      "Loss for batch 78 = 1.0035873651504517\n",
      "Loss for batch 79 = 0.8949171900749207\n",
      "Loss for batch 80 = 0.6970863342285156\n",
      "Loss for batch 81 = 0.7300363779067993\n",
      "Loss for batch 82 = 0.8552117347717285\n",
      "Loss for batch 83 = 0.6914914846420288\n",
      "Loss for batch 84 = 0.6661605834960938\n",
      "Loss for batch 85 = 0.9096477031707764\n",
      "Loss for batch 86 = 0.8997871279716492\n",
      "Loss for batch 87 = 0.8269371390342712\n",
      "Loss for batch 88 = 0.6984931230545044\n",
      "Loss for batch 89 = 0.750173032283783\n",
      "Loss for batch 90 = 0.6143679618835449\n",
      "Loss for batch 91 = 0.7248544096946716\n",
      "Loss for batch 92 = 0.5399400591850281\n",
      "Loss for batch 93 = 0.8560450673103333\n",
      "Loss for batch 94 = 0.6427098512649536\n",
      "Loss for batch 95 = 0.5821206569671631\n",
      "Loss for batch 96 = 0.6752070784568787\n",
      "Loss for batch 97 = 0.6621412634849548\n",
      "\n",
      "Training Loss for epoch 13 = 82.39794921875\n",
      "\n",
      "Current Validation Loss = 25.133440017700195\n",
      "Best Validation Loss = 24.175321578979492\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 63.67%\n",
      "Validation Accuracy: 56.48%\n",
      "\n",
      "Epoch 14\n",
      "----------\n",
      "Loss for batch 0 = 0.7869477868080139\n",
      "Loss for batch 1 = 0.7269454598426819\n",
      "Loss for batch 2 = 1.0894381999969482\n",
      "Loss for batch 3 = 0.6331956386566162\n",
      "Loss for batch 4 = 0.8001968860626221\n",
      "Loss for batch 5 = 0.7363999485969543\n",
      "Loss for batch 6 = 0.9062374830245972\n",
      "Loss for batch 7 = 0.9300926923751831\n",
      "Loss for batch 8 = 0.8014022707939148\n",
      "Loss for batch 9 = 1.0139074325561523\n",
      "Loss for batch 10 = 1.0539077520370483\n",
      "Loss for batch 11 = 0.9181883931159973\n",
      "Loss for batch 12 = 1.0041511058807373\n",
      "Loss for batch 13 = 0.9619604349136353\n",
      "Loss for batch 14 = 0.7997578382492065\n",
      "Loss for batch 15 = 0.9081616401672363\n",
      "Loss for batch 16 = 0.9860019683837891\n",
      "Loss for batch 17 = 1.0274971723556519\n",
      "Loss for batch 18 = 0.8484525084495544\n",
      "Loss for batch 19 = 0.9383271932601929\n",
      "Loss for batch 20 = 0.6893537640571594\n",
      "Loss for batch 21 = 0.7866171002388\n",
      "Loss for batch 22 = 0.6760397553443909\n",
      "Loss for batch 23 = 0.7774313688278198\n",
      "Loss for batch 24 = 0.843076229095459\n",
      "Loss for batch 25 = 0.6930088400840759\n",
      "Loss for batch 26 = 0.7801989316940308\n",
      "Loss for batch 27 = 0.7759291529655457\n",
      "Loss for batch 28 = 0.9297073483467102\n",
      "Loss for batch 29 = 1.0133131742477417\n",
      "Loss for batch 30 = 0.9328736662864685\n",
      "Loss for batch 31 = 0.6391687393188477\n",
      "Loss for batch 32 = 0.973833441734314\n",
      "Loss for batch 33 = 0.8521273136138916\n",
      "Loss for batch 34 = 0.9231032729148865\n",
      "Loss for batch 35 = 0.7713828682899475\n",
      "Loss for batch 36 = 0.8986757397651672\n",
      "Loss for batch 37 = 0.9175716638565063\n",
      "Loss for batch 38 = 0.7833137512207031\n",
      "Loss for batch 39 = 0.8893779516220093\n",
      "Loss for batch 40 = 0.893206000328064\n",
      "Loss for batch 41 = 0.8431899547576904\n",
      "Loss for batch 42 = 0.7790881991386414\n",
      "Loss for batch 43 = 0.7040936350822449\n",
      "Loss for batch 44 = 0.7677603363990784\n",
      "Loss for batch 45 = 0.8743072152137756\n",
      "Loss for batch 46 = 0.6049017310142517\n",
      "Loss for batch 47 = 0.8731914758682251\n",
      "Loss for batch 48 = 0.9896306395530701\n",
      "Loss for batch 49 = 0.8357514142990112\n",
      "Loss for batch 50 = 0.8675641417503357\n",
      "Loss for batch 51 = 0.8171167373657227\n",
      "Loss for batch 52 = 0.8574787378311157\n",
      "Loss for batch 53 = 0.7408452033996582\n",
      "Loss for batch 54 = 0.5971486568450928\n",
      "Loss for batch 55 = 1.0043230056762695\n",
      "Loss for batch 56 = 0.7979934215545654\n",
      "Loss for batch 57 = 0.8348253965377808\n",
      "Loss for batch 58 = 0.7315120697021484\n",
      "Loss for batch 59 = 1.0418392419815063\n",
      "Loss for batch 60 = 0.7132260203361511\n",
      "Loss for batch 61 = 0.8511308431625366\n",
      "Loss for batch 62 = 0.5913906693458557\n",
      "Loss for batch 63 = 0.7515131831169128\n",
      "Loss for batch 64 = 0.6879602670669556\n",
      "Loss for batch 65 = 0.7867666482925415\n",
      "Loss for batch 66 = 0.729853630065918\n",
      "Loss for batch 67 = 0.6655483245849609\n",
      "Loss for batch 68 = 0.7507432103157043\n",
      "Loss for batch 69 = 0.8493685126304626\n",
      "Loss for batch 70 = 1.0822372436523438\n",
      "Loss for batch 71 = 0.7103641629219055\n",
      "Loss for batch 72 = 0.8235353827476501\n",
      "Loss for batch 73 = 0.5600810647010803\n",
      "Loss for batch 74 = 0.8649998903274536\n",
      "Loss for batch 75 = 0.8493694067001343\n",
      "Loss for batch 76 = 1.2099088430404663\n",
      "Loss for batch 77 = 0.6262864470481873\n",
      "Loss for batch 78 = 1.0716077089309692\n",
      "Loss for batch 79 = 0.903306245803833\n",
      "Loss for batch 80 = 0.7269378304481506\n",
      "Loss for batch 81 = 0.8114194869995117\n",
      "Loss for batch 82 = 0.7669903635978699\n",
      "Loss for batch 83 = 0.7263606190681458\n",
      "Loss for batch 84 = 0.6064801216125488\n",
      "Loss for batch 85 = 0.9353260397911072\n",
      "Loss for batch 86 = 0.861330509185791\n",
      "Loss for batch 87 = 0.8749184012413025\n",
      "Loss for batch 88 = 0.6512135863304138\n",
      "Loss for batch 89 = 0.6352368593215942\n",
      "Loss for batch 90 = 0.6517599821090698\n",
      "Loss for batch 91 = 0.7471411824226379\n",
      "Loss for batch 92 = 0.47006505727767944\n",
      "Loss for batch 93 = 0.8056615591049194\n",
      "Loss for batch 94 = 0.6410790681838989\n",
      "Loss for batch 95 = 0.6697988510131836\n",
      "Loss for batch 96 = 0.645510733127594\n",
      "Loss for batch 97 = 0.749335765838623\n",
      "\n",
      "Training Loss for epoch 14 = 79.9288101196289\n",
      "\n",
      "Current Validation Loss = 23.654874801635742\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 66.17%\n",
      "Validation Accuracy: 57.38%\n",
      "\n",
      "Epoch 15\n",
      "----------\n",
      "Loss for batch 0 = 0.7907912731170654\n",
      "Loss for batch 1 = 0.7137844562530518\n",
      "Loss for batch 2 = 0.8265435695648193\n",
      "Loss for batch 3 = 0.694655179977417\n",
      "Loss for batch 4 = 0.665765106678009\n",
      "Loss for batch 5 = 0.7483465671539307\n",
      "Loss for batch 6 = 0.8415738344192505\n",
      "Loss for batch 7 = 0.783774733543396\n",
      "Loss for batch 8 = 0.6951674818992615\n",
      "Loss for batch 9 = 0.8890988230705261\n",
      "Loss for batch 10 = 1.0276867151260376\n",
      "Loss for batch 11 = 0.8226067423820496\n",
      "Loss for batch 12 = 0.9754451513290405\n",
      "Loss for batch 13 = 0.9408290386199951\n",
      "Loss for batch 14 = 0.6915715336799622\n",
      "Loss for batch 15 = 0.7972303032875061\n",
      "Loss for batch 16 = 0.8677780628204346\n",
      "Loss for batch 17 = 0.941770076751709\n",
      "Loss for batch 18 = 0.7308276891708374\n",
      "Loss for batch 19 = 0.827907145023346\n",
      "Loss for batch 20 = 0.6345571279525757\n",
      "Loss for batch 21 = 0.7103671431541443\n",
      "Loss for batch 22 = 0.6012846827507019\n",
      "Loss for batch 23 = 0.7314019799232483\n",
      "Loss for batch 24 = 0.7676716446876526\n",
      "Loss for batch 25 = 0.6304196715354919\n",
      "Loss for batch 26 = 0.7627758383750916\n",
      "Loss for batch 27 = 0.7002261877059937\n",
      "Loss for batch 28 = 0.8348390460014343\n",
      "Loss for batch 29 = 1.0869373083114624\n",
      "Loss for batch 30 = 0.9076328873634338\n",
      "Loss for batch 31 = 0.6248654127120972\n",
      "Loss for batch 32 = 0.9494441747665405\n",
      "Loss for batch 33 = 0.7904190421104431\n",
      "Loss for batch 34 = 0.909305989742279\n",
      "Loss for batch 35 = 0.6838169097900391\n",
      "Loss for batch 36 = 0.8354387879371643\n",
      "Loss for batch 37 = 0.8664684891700745\n",
      "Loss for batch 38 = 0.7700976729393005\n",
      "Loss for batch 39 = 0.8196290135383606\n",
      "Loss for batch 40 = 0.8462159633636475\n",
      "Loss for batch 41 = 0.7318519949913025\n",
      "Loss for batch 42 = 0.7260257601737976\n",
      "Loss for batch 43 = 0.652140200138092\n",
      "Loss for batch 44 = 0.6998180747032166\n",
      "Loss for batch 45 = 0.7999550700187683\n",
      "Loss for batch 46 = 0.5619761347770691\n",
      "Loss for batch 47 = 0.8272784352302551\n",
      "Loss for batch 48 = 0.9363806247711182\n",
      "Loss for batch 49 = 0.7733253836631775\n",
      "Loss for batch 50 = 0.9327557682991028\n",
      "Loss for batch 51 = 0.7299233675003052\n",
      "Loss for batch 52 = 0.8191227912902832\n",
      "Loss for batch 53 = 0.7045482397079468\n",
      "Loss for batch 54 = 0.5312898755073547\n",
      "Loss for batch 55 = 0.9680142998695374\n",
      "Loss for batch 56 = 0.7835153937339783\n",
      "Loss for batch 57 = 0.7309451103210449\n",
      "Loss for batch 58 = 0.6416000723838806\n",
      "Loss for batch 59 = 0.9550381898880005\n",
      "Loss for batch 60 = 0.6529920697212219\n",
      "Loss for batch 61 = 0.7507386803627014\n",
      "Loss for batch 62 = 0.48598435521125793\n",
      "Loss for batch 63 = 0.6934544444084167\n",
      "Loss for batch 64 = 0.6842109560966492\n",
      "Loss for batch 65 = 0.6793074607849121\n",
      "Loss for batch 66 = 0.6122841835021973\n",
      "Loss for batch 67 = 0.46629956364631653\n",
      "Loss for batch 68 = 0.7569569945335388\n",
      "Loss for batch 69 = 0.8957780003547668\n",
      "Loss for batch 70 = 1.0105122327804565\n",
      "Loss for batch 71 = 0.5530514121055603\n",
      "Loss for batch 72 = 0.8260683417320251\n",
      "Loss for batch 73 = 0.7453897595405579\n",
      "Loss for batch 74 = 0.8916938304901123\n",
      "Loss for batch 75 = 0.7871312499046326\n",
      "Loss for batch 76 = 1.0025750398635864\n",
      "Loss for batch 77 = 0.6009397506713867\n",
      "Loss for batch 78 = 0.9103683829307556\n",
      "Loss for batch 79 = 0.8443389534950256\n",
      "Loss for batch 80 = 0.6717723608016968\n",
      "Loss for batch 81 = 0.7452446818351746\n",
      "Loss for batch 82 = 0.7712299227714539\n",
      "Loss for batch 83 = 0.6860306262969971\n",
      "Loss for batch 84 = 0.47733333706855774\n",
      "Loss for batch 85 = 0.8741602897644043\n",
      "Loss for batch 86 = 0.8482164740562439\n",
      "Loss for batch 87 = 0.8100919723510742\n",
      "Loss for batch 88 = 0.5753811597824097\n",
      "Loss for batch 89 = 0.555862545967102\n",
      "Loss for batch 90 = 0.564960777759552\n",
      "Loss for batch 91 = 0.6557416915893555\n",
      "Loss for batch 92 = 0.44266220927238464\n",
      "Loss for batch 93 = 0.7265543341636658\n",
      "Loss for batch 94 = 0.5286869406700134\n",
      "Loss for batch 95 = 0.6137382984161377\n",
      "Loss for batch 96 = 0.639159083366394\n",
      "Loss for batch 97 = 0.7994980812072754\n",
      "\n",
      "Training Loss for epoch 15 = 74.07887268066406\n",
      "\n",
      "Current Validation Loss = 23.720605850219727\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 68.29%\n",
      "Validation Accuracy: 60.33%\n",
      "\n",
      "Epoch 16\n",
      "----------\n",
      "Loss for batch 0 = 0.6872302293777466\n",
      "Loss for batch 1 = 0.7353699803352356\n",
      "Loss for batch 2 = 0.7331415414810181\n",
      "Loss for batch 3 = 0.7242171764373779\n",
      "Loss for batch 4 = 0.6657634973526001\n",
      "Loss for batch 5 = 0.7326830625534058\n",
      "Loss for batch 6 = 0.7752525806427002\n",
      "Loss for batch 7 = 0.7980266213417053\n",
      "Loss for batch 8 = 0.551102340221405\n",
      "Loss for batch 9 = 0.8556163311004639\n",
      "Loss for batch 10 = 1.0532976388931274\n",
      "Loss for batch 11 = 0.8176394104957581\n",
      "Loss for batch 12 = 0.939515233039856\n",
      "Loss for batch 13 = 0.9674716591835022\n",
      "Loss for batch 14 = 0.61250239610672\n",
      "Loss for batch 15 = 0.7578613758087158\n",
      "Loss for batch 16 = 0.8120502233505249\n",
      "Loss for batch 17 = 0.8062549233436584\n",
      "Loss for batch 18 = 0.7848383784294128\n",
      "Loss for batch 19 = 0.7908341288566589\n",
      "Loss for batch 20 = 0.5592659115791321\n",
      "Loss for batch 21 = 0.648581862449646\n",
      "Loss for batch 22 = 0.6063934564590454\n",
      "Loss for batch 23 = 0.7046445608139038\n",
      "Loss for batch 24 = 0.6588969826698303\n",
      "Loss for batch 25 = 0.6200233697891235\n",
      "Loss for batch 26 = 0.7799515724182129\n",
      "Loss for batch 27 = 0.7500583529472351\n",
      "Loss for batch 28 = 0.7620491981506348\n",
      "Loss for batch 29 = 1.0095962285995483\n",
      "Loss for batch 30 = 0.8280587792396545\n",
      "Loss for batch 31 = 0.6079998016357422\n",
      "Loss for batch 32 = 0.9724746346473694\n",
      "Loss for batch 33 = 0.6805663108825684\n",
      "Loss for batch 34 = 0.8366459012031555\n",
      "Loss for batch 35 = 0.5833002924919128\n",
      "Loss for batch 36 = 0.7523096799850464\n",
      "Loss for batch 37 = 0.8098013997077942\n",
      "Loss for batch 38 = 0.7989233136177063\n",
      "Loss for batch 39 = 0.7571821808815002\n",
      "Loss for batch 40 = 0.7557845115661621\n",
      "Loss for batch 41 = 0.7043647766113281\n",
      "Loss for batch 42 = 0.674880862236023\n",
      "Loss for batch 43 = 0.6066991686820984\n",
      "Loss for batch 44 = 0.7243200540542603\n",
      "Loss for batch 45 = 0.7238537073135376\n",
      "Loss for batch 46 = 0.5079378485679626\n",
      "Loss for batch 47 = 0.7510151863098145\n",
      "Loss for batch 48 = 0.8910081386566162\n",
      "Loss for batch 49 = 0.7609090805053711\n",
      "Loss for batch 50 = 0.8992175459861755\n",
      "Loss for batch 51 = 0.6689988970756531\n",
      "Loss for batch 52 = 0.741784930229187\n",
      "Loss for batch 53 = 0.6228060126304626\n",
      "Loss for batch 54 = 0.5670018792152405\n",
      "Loss for batch 55 = 0.919001579284668\n",
      "Loss for batch 56 = 0.7535045146942139\n",
      "Loss for batch 57 = 0.6964596509933472\n",
      "Loss for batch 58 = 0.6821420788764954\n",
      "Loss for batch 59 = 0.885744571685791\n",
      "Loss for batch 60 = 0.6898209452629089\n",
      "Loss for batch 61 = 0.7102715969085693\n",
      "Loss for batch 62 = 0.5164228677749634\n",
      "Loss for batch 63 = 0.6853969693183899\n",
      "Loss for batch 64 = 0.6671692132949829\n",
      "Loss for batch 65 = 0.6964359283447266\n",
      "Loss for batch 66 = 0.6414308547973633\n",
      "Loss for batch 67 = 0.5044774413108826\n",
      "Loss for batch 68 = 0.6548157334327698\n",
      "Loss for batch 69 = 0.9019138813018799\n",
      "Loss for batch 70 = 0.9624277949333191\n",
      "Loss for batch 71 = 0.47553014755249023\n",
      "Loss for batch 72 = 0.7788935899734497\n",
      "Loss for batch 73 = 0.5712030529975891\n",
      "Loss for batch 74 = 0.8105964064598083\n",
      "Loss for batch 75 = 0.7673027515411377\n",
      "Loss for batch 76 = 1.11101233959198\n",
      "Loss for batch 77 = 0.5344134569168091\n",
      "Loss for batch 78 = 0.867279052734375\n",
      "Loss for batch 79 = 0.7737685441970825\n",
      "Loss for batch 80 = 0.7376393675804138\n",
      "Loss for batch 81 = 0.7649023532867432\n",
      "Loss for batch 82 = 0.6826067566871643\n",
      "Loss for batch 83 = 0.613632321357727\n",
      "Loss for batch 84 = 0.4907051622867584\n",
      "Loss for batch 85 = 0.8825742602348328\n",
      "Loss for batch 86 = 0.7369235157966614\n",
      "Loss for batch 87 = 0.7539728283882141\n",
      "Loss for batch 88 = 0.5456478595733643\n",
      "Loss for batch 89 = 0.5660106539726257\n",
      "Loss for batch 90 = 0.5883904695510864\n",
      "Loss for batch 91 = 0.6566453576087952\n",
      "Loss for batch 92 = 0.4035522937774658\n",
      "Loss for batch 93 = 0.7689828276634216\n",
      "Loss for batch 94 = 0.5443880558013916\n",
      "Loss for batch 95 = 0.5822142362594604\n",
      "Loss for batch 96 = 0.5627391338348389\n",
      "Loss for batch 97 = 0.7186059951782227\n",
      "\n",
      "Training Loss for epoch 16 = 70.78553771972656\n",
      "\n",
      "Current Validation Loss = 23.83428382873535\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 71.31%\n",
      "Validation Accuracy: 60.85%\n",
      "\n",
      "Epoch 17\n",
      "----------\n",
      "Loss for batch 0 = 0.6767397522926331\n",
      "Loss for batch 1 = 0.6388434171676636\n",
      "Loss for batch 2 = 0.7634294033050537\n",
      "Loss for batch 3 = 0.6420750617980957\n",
      "Loss for batch 4 = 0.6312583088874817\n",
      "Loss for batch 5 = 0.7118646502494812\n",
      "Loss for batch 6 = 0.7724069356918335\n",
      "Loss for batch 7 = 0.7818741202354431\n",
      "Loss for batch 8 = 0.5815863609313965\n",
      "Loss for batch 9 = 0.7736772298812866\n",
      "Loss for batch 10 = 1.022644281387329\n",
      "Loss for batch 11 = 0.7401904463768005\n",
      "Loss for batch 12 = 0.8295338153839111\n",
      "Loss for batch 13 = 0.8878899216651917\n",
      "Loss for batch 14 = 0.5579551458358765\n",
      "Loss for batch 15 = 0.6595605611801147\n",
      "Loss for batch 16 = 0.7581892609596252\n",
      "Loss for batch 17 = 0.7486073970794678\n",
      "Loss for batch 18 = 0.695911169052124\n",
      "Loss for batch 19 = 0.7443689107894897\n",
      "Loss for batch 20 = 0.5121268033981323\n",
      "Loss for batch 21 = 0.6086352467536926\n",
      "Loss for batch 22 = 0.6110824346542358\n",
      "Loss for batch 23 = 0.6709379553794861\n",
      "Loss for batch 24 = 0.5969023108482361\n",
      "Loss for batch 25 = 0.5985470414161682\n",
      "Loss for batch 26 = 0.6837263107299805\n",
      "Loss for batch 27 = 0.7177063226699829\n",
      "Loss for batch 28 = 0.7519463896751404\n",
      "Loss for batch 29 = 0.9956689476966858\n",
      "Loss for batch 30 = 0.7674381732940674\n",
      "Loss for batch 31 = 0.5820820331573486\n",
      "Loss for batch 32 = 0.8885009288787842\n",
      "Loss for batch 33 = 0.6654821038246155\n",
      "Loss for batch 34 = 0.76470947265625\n",
      "Loss for batch 35 = 0.5578106641769409\n",
      "Loss for batch 36 = 0.6867671012878418\n",
      "Loss for batch 37 = 0.7342851161956787\n",
      "Loss for batch 38 = 0.7303720116615295\n",
      "Loss for batch 39 = 0.730364978313446\n",
      "Loss for batch 40 = 0.6755781173706055\n",
      "Loss for batch 41 = 0.6910409927368164\n",
      "Loss for batch 42 = 0.6561864018440247\n",
      "Loss for batch 43 = 0.5951401591300964\n",
      "Loss for batch 44 = 0.6991790533065796\n",
      "Loss for batch 45 = 0.6706399321556091\n",
      "Loss for batch 46 = 0.48513826727867126\n",
      "Loss for batch 47 = 0.702320396900177\n",
      "Loss for batch 48 = 0.9148655533790588\n",
      "Loss for batch 49 = 0.7299330234527588\n",
      "Loss for batch 50 = 0.8711687922477722\n",
      "Loss for batch 51 = 0.6655035018920898\n",
      "Loss for batch 52 = 0.7261043190956116\n",
      "Loss for batch 53 = 0.5424302816390991\n",
      "Loss for batch 54 = 0.56297367811203\n",
      "Loss for batch 55 = 0.9090746641159058\n",
      "Loss for batch 56 = 0.739964485168457\n",
      "Loss for batch 57 = 0.6746114492416382\n",
      "Loss for batch 58 = 0.6645169258117676\n",
      "Loss for batch 59 = 0.8338507413864136\n",
      "Loss for batch 60 = 0.6374114751815796\n",
      "Loss for batch 61 = 0.7015587091445923\n",
      "Loss for batch 62 = 0.467168927192688\n",
      "Loss for batch 63 = 0.6336222290992737\n",
      "Loss for batch 64 = 0.6526564955711365\n",
      "Loss for batch 65 = 0.6383689045906067\n",
      "Loss for batch 66 = 0.596264660358429\n",
      "Loss for batch 67 = 0.4825500547885895\n",
      "Loss for batch 68 = 0.679137110710144\n",
      "Loss for batch 69 = 0.8529248833656311\n",
      "Loss for batch 70 = 0.9463919997215271\n",
      "Loss for batch 71 = 0.4259248673915863\n",
      "Loss for batch 72 = 0.7572879791259766\n",
      "Loss for batch 73 = 0.5416642427444458\n",
      "Loss for batch 74 = 0.7901063561439514\n",
      "Loss for batch 75 = 0.6101373434066772\n",
      "Loss for batch 76 = 1.1020690202713013\n",
      "Loss for batch 77 = 0.4782097339630127\n",
      "Loss for batch 78 = 0.7168930768966675\n",
      "Loss for batch 79 = 0.7370324730873108\n",
      "Loss for batch 80 = 0.6430734395980835\n",
      "Loss for batch 81 = 0.7780163884162903\n",
      "Loss for batch 82 = 0.6951524019241333\n",
      "Loss for batch 83 = 0.5725700259208679\n",
      "Loss for batch 84 = 0.4835042357444763\n",
      "Loss for batch 85 = 0.8163812160491943\n",
      "Loss for batch 86 = 0.7194872498512268\n",
      "Loss for batch 87 = 0.7757152318954468\n",
      "Loss for batch 88 = 0.5065864324569702\n",
      "Loss for batch 89 = 0.4940461218357086\n",
      "Loss for batch 90 = 0.5104661583900452\n",
      "Loss for batch 91 = 0.629860520362854\n",
      "Loss for batch 92 = 0.34365248680114746\n",
      "Loss for batch 93 = 0.7739958167076111\n",
      "Loss for batch 94 = 0.49915704131126404\n",
      "Loss for batch 95 = 0.5422736406326294\n",
      "Loss for batch 96 = 0.4854191243648529\n",
      "Loss for batch 97 = 0.5816457867622375\n",
      "\n",
      "Training Loss for epoch 17 = 66.78231048583984\n",
      "\n",
      "Current Validation Loss = 25.135169982910156\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 72.08%\n",
      "Validation Accuracy: 61.49%\n",
      "\n",
      "Epoch 18\n",
      "----------\n",
      "Loss for batch 0 = 0.6310594081878662\n",
      "Loss for batch 1 = 0.5665780901908875\n",
      "Loss for batch 2 = 0.6603406071662903\n",
      "Loss for batch 3 = 0.6665952205657959\n",
      "Loss for batch 4 = 0.6670582294464111\n",
      "Loss for batch 5 = 0.683687686920166\n",
      "Loss for batch 6 = 0.725334644317627\n",
      "Loss for batch 7 = 0.7286709547042847\n",
      "Loss for batch 8 = 0.49756982922554016\n",
      "Loss for batch 9 = 0.7115815281867981\n",
      "Loss for batch 10 = 1.0566190481185913\n",
      "Loss for batch 11 = 0.7040059566497803\n",
      "Loss for batch 12 = 0.8728961944580078\n",
      "Loss for batch 13 = 0.884555995464325\n",
      "Loss for batch 14 = 0.5257127285003662\n",
      "Loss for batch 15 = 0.6087480187416077\n",
      "Loss for batch 16 = 0.7508761882781982\n",
      "Loss for batch 17 = 0.6614726781845093\n",
      "Loss for batch 18 = 0.7359005212783813\n",
      "Loss for batch 19 = 0.7194463014602661\n",
      "Loss for batch 20 = 0.46611201763153076\n",
      "Loss for batch 21 = 0.5972350835800171\n",
      "Loss for batch 22 = 0.6161402463912964\n",
      "Loss for batch 23 = 0.6518064141273499\n",
      "Loss for batch 24 = 0.5333634614944458\n",
      "Loss for batch 25 = 0.5424891710281372\n",
      "Loss for batch 26 = 0.6767970323562622\n",
      "Loss for batch 27 = 0.6836562156677246\n",
      "Loss for batch 28 = 0.697188675403595\n",
      "Loss for batch 29 = 0.8816088438034058\n",
      "Loss for batch 30 = 0.7944907546043396\n",
      "Loss for batch 31 = 0.589962363243103\n",
      "Loss for batch 32 = 0.8571054935455322\n",
      "Loss for batch 33 = 0.6819020509719849\n",
      "Loss for batch 34 = 0.7510507702827454\n",
      "Loss for batch 35 = 0.5228786468505859\n",
      "Loss for batch 36 = 0.6513417363166809\n",
      "Loss for batch 37 = 0.7611588835716248\n",
      "Loss for batch 38 = 0.701447069644928\n",
      "Loss for batch 39 = 0.7038147449493408\n",
      "Loss for batch 40 = 0.6413698792457581\n",
      "Loss for batch 41 = 0.6490207314491272\n",
      "Loss for batch 42 = 0.6427147388458252\n",
      "Loss for batch 43 = 0.5732113122940063\n",
      "Loss for batch 44 = 0.7037611603736877\n",
      "Loss for batch 45 = 0.6542863845825195\n",
      "Loss for batch 46 = 0.4675558805465698\n",
      "Loss for batch 47 = 0.6062787771224976\n",
      "Loss for batch 48 = 0.7609360814094543\n",
      "Loss for batch 49 = 0.7531708478927612\n",
      "Loss for batch 50 = 0.8095197081565857\n",
      "Loss for batch 51 = 0.6314860582351685\n",
      "Loss for batch 52 = 0.7154014110565186\n",
      "Loss for batch 53 = 0.4052216410636902\n",
      "Loss for batch 54 = 0.5324546098709106\n",
      "Loss for batch 55 = 0.8339090347290039\n",
      "Loss for batch 56 = 0.6804363131523132\n",
      "Loss for batch 57 = 0.5970062017440796\n",
      "Loss for batch 58 = 0.6606211066246033\n",
      "Loss for batch 59 = 0.7989266514778137\n",
      "Loss for batch 60 = 0.6191375851631165\n",
      "Loss for batch 61 = 0.6784313917160034\n",
      "Loss for batch 62 = 0.45796680450439453\n",
      "Loss for batch 63 = 0.5744674205780029\n",
      "Loss for batch 64 = 0.6598979830741882\n",
      "Loss for batch 65 = 0.6367160081863403\n",
      "Loss for batch 66 = 0.617969274520874\n",
      "Loss for batch 67 = 0.5094066262245178\n",
      "Loss for batch 68 = 0.6599454283714294\n",
      "Loss for batch 69 = 0.8416714668273926\n",
      "Loss for batch 70 = 0.9712569117546082\n",
      "Loss for batch 71 = 0.3861362338066101\n",
      "Loss for batch 72 = 0.7149350047111511\n",
      "Loss for batch 73 = 0.48889485001564026\n",
      "Loss for batch 74 = 0.7335254549980164\n",
      "Loss for batch 75 = 0.565877377986908\n",
      "Loss for batch 76 = 0.9713946580886841\n",
      "Loss for batch 77 = 0.49613726139068604\n",
      "Loss for batch 78 = 0.6159207820892334\n",
      "Loss for batch 79 = 0.6972286105155945\n",
      "Loss for batch 80 = 0.5771721005439758\n",
      "Loss for batch 81 = 0.6333409547805786\n",
      "Loss for batch 82 = 0.5915635228157043\n",
      "Loss for batch 83 = 0.46571704745292664\n",
      "Loss for batch 84 = 0.4474964141845703\n",
      "Loss for batch 85 = 0.8392638564109802\n",
      "Loss for batch 86 = 0.7548421025276184\n",
      "Loss for batch 87 = 0.7411847114562988\n",
      "Loss for batch 88 = 0.5199757814407349\n",
      "Loss for batch 89 = 0.4582822620868683\n",
      "Loss for batch 90 = 0.49448302388191223\n",
      "Loss for batch 91 = 0.5195910930633545\n",
      "Loss for batch 92 = 0.304351270198822\n",
      "Loss for batch 93 = 0.7734137177467346\n",
      "Loss for batch 94 = 0.5046363472938538\n",
      "Loss for batch 95 = 0.5262275338172913\n",
      "Loss for batch 96 = 0.46741294860839844\n",
      "Loss for batch 97 = 0.48463594913482666\n",
      "\n",
      "Training Loss for epoch 18 = 63.538047790527344\n",
      "\n",
      "Current Validation Loss = 25.528507232666016\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 4\n",
      "Train Accuracy: 71.53%\n",
      "Validation Accuracy: 61.36%\n",
      "\n",
      "Epoch 19\n",
      "----------\n",
      "Loss for batch 0 = 0.6064863204956055\n",
      "Loss for batch 1 = 0.561995267868042\n",
      "Loss for batch 2 = 0.6346259117126465\n",
      "Loss for batch 3 = 0.599388599395752\n",
      "Loss for batch 4 = 0.7259777188301086\n",
      "Loss for batch 5 = 0.7512143850326538\n",
      "Loss for batch 6 = 0.6166936159133911\n",
      "Loss for batch 7 = 0.7524702548980713\n",
      "Loss for batch 8 = 0.5171463489532471\n",
      "Loss for batch 9 = 0.7922414541244507\n",
      "Loss for batch 10 = 0.9909014105796814\n",
      "Loss for batch 11 = 0.7218778133392334\n",
      "Loss for batch 12 = 0.707323431968689\n",
      "Loss for batch 13 = 0.8809428811073303\n",
      "Loss for batch 14 = 0.4795781075954437\n",
      "Loss for batch 15 = 0.600117564201355\n",
      "Loss for batch 16 = 0.5763907432556152\n",
      "Loss for batch 17 = 0.6557859778404236\n",
      "Loss for batch 18 = 0.7184389233589172\n",
      "Loss for batch 19 = 0.72481369972229\n",
      "Loss for batch 20 = 0.5024831891059875\n",
      "Loss for batch 21 = 0.6153779029846191\n",
      "Loss for batch 22 = 0.6579282283782959\n",
      "Loss for batch 23 = 0.6517319083213806\n",
      "Loss for batch 24 = 0.49542298913002014\n",
      "Loss for batch 25 = 0.5520120859146118\n",
      "Loss for batch 26 = 0.5430909395217896\n",
      "Loss for batch 27 = 0.5024722218513489\n",
      "Loss for batch 28 = 0.6325595378875732\n",
      "Loss for batch 29 = 1.0036373138427734\n",
      "Loss for batch 30 = 0.780450701713562\n",
      "Loss for batch 31 = 0.5902755856513977\n",
      "Loss for batch 32 = 0.8661618828773499\n",
      "Loss for batch 33 = 0.6381499171257019\n",
      "Loss for batch 34 = 0.7283843159675598\n",
      "Loss for batch 35 = 0.5232086181640625\n",
      "Loss for batch 36 = 0.6217911839485168\n",
      "Loss for batch 37 = 0.6586179137229919\n",
      "Loss for batch 38 = 0.6610486507415771\n",
      "Loss for batch 39 = 0.6534191966056824\n",
      "Loss for batch 40 = 0.5686355233192444\n",
      "Loss for batch 41 = 0.6609501838684082\n",
      "Loss for batch 42 = 0.600017249584198\n",
      "Loss for batch 43 = 0.5662583112716675\n",
      "Loss for batch 44 = 0.6774507761001587\n",
      "Loss for batch 45 = 0.6045088171958923\n",
      "Loss for batch 46 = 0.4281090199947357\n",
      "Loss for batch 47 = 0.628486156463623\n",
      "Loss for batch 48 = 0.793863832950592\n",
      "Loss for batch 49 = 0.7396469712257385\n",
      "Loss for batch 50 = 0.7503460645675659\n",
      "Loss for batch 51 = 0.6668163537979126\n",
      "Loss for batch 52 = 0.5477199554443359\n",
      "Loss for batch 53 = 0.4661242365837097\n",
      "Loss for batch 54 = 0.4726203382015228\n",
      "Loss for batch 55 = 0.8106858730316162\n",
      "Loss for batch 56 = 0.6274200081825256\n",
      "Loss for batch 57 = 0.6720060110092163\n",
      "Loss for batch 58 = 0.5156145691871643\n",
      "Loss for batch 59 = 0.7413527965545654\n",
      "Loss for batch 60 = 0.6316434144973755\n",
      "Loss for batch 61 = 0.641148567199707\n",
      "Loss for batch 62 = 0.40157797932624817\n",
      "Loss for batch 63 = 0.5492982864379883\n",
      "Loss for batch 64 = 0.6550371050834656\n",
      "Loss for batch 65 = 0.558331310749054\n",
      "Loss for batch 66 = 0.6052367687225342\n",
      "Loss for batch 67 = 0.4188193380832672\n",
      "Loss for batch 68 = 0.5822626948356628\n",
      "Loss for batch 69 = 0.8052032589912415\n",
      "Loss for batch 70 = 0.9354919195175171\n",
      "Loss for batch 71 = 0.3816981315612793\n",
      "Loss for batch 72 = 0.6956161856651306\n",
      "Loss for batch 73 = 0.48403072357177734\n",
      "Loss for batch 74 = 0.6752183437347412\n",
      "Loss for batch 75 = 0.5536878108978271\n",
      "Loss for batch 76 = 0.930249810218811\n",
      "Loss for batch 77 = 0.4755195379257202\n",
      "Loss for batch 78 = 0.5543127655982971\n",
      "Loss for batch 79 = 0.6699405908584595\n",
      "Loss for batch 80 = 0.6054306030273438\n",
      "Loss for batch 81 = 0.6219838261604309\n",
      "Loss for batch 82 = 0.6234375238418579\n",
      "Loss for batch 83 = 0.4494505226612091\n",
      "Loss for batch 84 = 0.45152708888053894\n",
      "Loss for batch 85 = 0.7284544706344604\n",
      "Loss for batch 86 = 0.6885011792182922\n",
      "Loss for batch 87 = 0.6651374697685242\n",
      "Loss for batch 88 = 0.4747993052005768\n",
      "Loss for batch 89 = 0.36695143580436707\n",
      "Loss for batch 90 = 0.43569129705429077\n",
      "Loss for batch 91 = 0.5676438212394714\n",
      "Loss for batch 92 = 0.27657175064086914\n",
      "Loss for batch 93 = 0.733927309513092\n",
      "Loss for batch 94 = 0.46864748001098633\n",
      "Loss for batch 95 = 0.49210208654403687\n",
      "Loss for batch 96 = 0.42296209931373596\n",
      "Loss for batch 97 = 0.4758045971393585\n",
      "\n",
      "Training Loss for epoch 19 = 60.784610748291016\n",
      "\n",
      "Current Validation Loss = 26.2460994720459\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 5\n",
      "Train Accuracy: 74.36%\n",
      "Validation Accuracy: 61.23%\n",
      "\n",
      "Epoch 20\n",
      "----------\n",
      "Loss for batch 0 = 0.5850818157196045\n",
      "Loss for batch 1 = 0.5613352060317993\n",
      "Loss for batch 2 = 0.538826048374176\n",
      "Loss for batch 3 = 0.6210262775421143\n",
      "Loss for batch 4 = 0.5435643792152405\n",
      "Loss for batch 5 = 0.6512205004692078\n",
      "Loss for batch 6 = 0.6320214867591858\n",
      "Loss for batch 7 = 0.6820377707481384\n",
      "Loss for batch 8 = 0.4969899654388428\n",
      "Loss for batch 9 = 0.6384150385856628\n",
      "Loss for batch 10 = 0.9107503890991211\n",
      "Loss for batch 11 = 0.6426603198051453\n",
      "Loss for batch 12 = 0.6917232275009155\n",
      "Loss for batch 13 = 0.8573692440986633\n",
      "Loss for batch 14 = 0.420785516500473\n",
      "Loss for batch 15 = 0.5563052296638489\n",
      "Loss for batch 16 = 0.540396511554718\n",
      "Loss for batch 17 = 0.5376757383346558\n",
      "Loss for batch 18 = 0.648609459400177\n",
      "Loss for batch 19 = 0.6580044627189636\n",
      "Loss for batch 20 = 0.4799611270427704\n",
      "Loss for batch 21 = 0.6164554953575134\n",
      "Loss for batch 22 = 0.562674880027771\n",
      "Loss for batch 23 = 0.5948745608329773\n",
      "Loss for batch 24 = 0.4887397587299347\n",
      "Loss for batch 25 = 0.47572648525238037\n",
      "Loss for batch 26 = 0.4584158957004547\n",
      "Loss for batch 27 = 0.5144963264465332\n",
      "Loss for batch 28 = 0.5721167325973511\n",
      "Loss for batch 29 = 0.968553364276886\n",
      "Loss for batch 30 = 0.7412235736846924\n",
      "Loss for batch 31 = 0.6002576947212219\n",
      "Loss for batch 32 = 0.7749277949333191\n",
      "Loss for batch 33 = 0.5803297162055969\n",
      "Loss for batch 34 = 0.7020371556282043\n",
      "Loss for batch 35 = 0.4696676433086395\n",
      "Loss for batch 36 = 0.5456517338752747\n",
      "Loss for batch 37 = 0.6672962307929993\n",
      "Loss for batch 38 = 0.6367255449295044\n",
      "Loss for batch 39 = 0.5835973620414734\n",
      "Loss for batch 40 = 0.5650941729545593\n",
      "Loss for batch 41 = 0.6081562638282776\n",
      "Loss for batch 42 = 0.575437605381012\n",
      "Loss for batch 43 = 0.5356280207633972\n",
      "Loss for batch 44 = 0.6111936569213867\n",
      "Loss for batch 45 = 0.5325217247009277\n",
      "Loss for batch 46 = 0.38983407616615295\n",
      "Loss for batch 47 = 0.5992316603660583\n",
      "Loss for batch 48 = 0.8560397624969482\n",
      "Loss for batch 49 = 0.7652209401130676\n",
      "Loss for batch 50 = 0.7493528723716736\n",
      "Loss for batch 51 = 0.6603350043296814\n",
      "Loss for batch 52 = 0.5063176155090332\n",
      "Loss for batch 53 = 0.34603285789489746\n",
      "Loss for batch 54 = 0.4274439215660095\n",
      "Loss for batch 55 = 0.8374019265174866\n",
      "Loss for batch 56 = 0.6046060919761658\n",
      "Loss for batch 57 = 0.6278913021087646\n",
      "Loss for batch 58 = 0.4407117962837219\n",
      "Loss for batch 59 = 0.6154016852378845\n",
      "Loss for batch 60 = 0.5942411422729492\n",
      "Loss for batch 61 = 0.7140312194824219\n",
      "Loss for batch 62 = 0.4193969666957855\n",
      "Loss for batch 63 = 0.5526241064071655\n",
      "Loss for batch 64 = 0.7218769788742065\n",
      "Loss for batch 65 = 0.5383591651916504\n",
      "Loss for batch 66 = 0.5127224326133728\n",
      "Loss for batch 67 = 0.5037343502044678\n",
      "Loss for batch 68 = 0.6339593529701233\n",
      "Loss for batch 69 = 0.7747315764427185\n",
      "Loss for batch 70 = 0.9039363265037537\n",
      "Loss for batch 71 = 0.3501262366771698\n",
      "Loss for batch 72 = 0.71235191822052\n",
      "Loss for batch 73 = 0.405177503824234\n",
      "Loss for batch 74 = 0.6403480172157288\n",
      "Loss for batch 75 = 0.5526970624923706\n",
      "Loss for batch 76 = 0.9296584725379944\n",
      "Loss for batch 77 = 0.4378034770488739\n",
      "Loss for batch 78 = 0.5193716883659363\n",
      "Loss for batch 79 = 0.6686190962791443\n",
      "Loss for batch 80 = 0.5443446040153503\n",
      "Loss for batch 81 = 0.5179662108421326\n",
      "Loss for batch 82 = 0.65163254737854\n",
      "Loss for batch 83 = 0.4370402991771698\n",
      "Loss for batch 84 = 0.3770180642604828\n",
      "Loss for batch 85 = 0.6959059238433838\n",
      "Loss for batch 86 = 0.6770222187042236\n",
      "Loss for batch 87 = 0.6339155435562134\n",
      "Loss for batch 88 = 0.44460415840148926\n",
      "Loss for batch 89 = 0.4397188425064087\n",
      "Loss for batch 90 = 0.383522629737854\n",
      "Loss for batch 91 = 0.5584153532981873\n",
      "Loss for batch 92 = 0.20092111825942993\n",
      "Loss for batch 93 = 0.6747959852218628\n",
      "Loss for batch 94 = 0.4150436222553253\n",
      "Loss for batch 95 = 0.47004419565200806\n",
      "Loss for batch 96 = 0.3903597593307495\n",
      "Loss for batch 97 = 0.33068084716796875\n",
      "\n",
      "Training Loss for epoch 20 = 57.2310905456543\n",
      "\n",
      "Current Validation Loss = 26.327808380126953\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 6\n",
      "Train Accuracy: 75.35%\n",
      "Validation Accuracy: 62.39%\n",
      "\n",
      "Epoch 21\n",
      "----------\n",
      "Loss for batch 0 = 0.5866953730583191\n",
      "Loss for batch 1 = 0.49944978952407837\n",
      "Loss for batch 2 = 0.4783497750759125\n",
      "Loss for batch 3 = 0.5257894396781921\n",
      "Loss for batch 4 = 0.5199638605117798\n",
      "Loss for batch 5 = 0.6540072560310364\n",
      "Loss for batch 6 = 0.5750792622566223\n",
      "Loss for batch 7 = 0.6887287497520447\n",
      "Loss for batch 8 = 0.4727028012275696\n",
      "Loss for batch 9 = 0.6637017726898193\n",
      "Loss for batch 10 = 0.8962716460227966\n",
      "Loss for batch 11 = 0.5942628383636475\n",
      "Loss for batch 12 = 0.7596340775489807\n",
      "Loss for batch 13 = 0.8688100576400757\n",
      "Loss for batch 14 = 0.45432910323143005\n",
      "Loss for batch 15 = 0.4923638701438904\n",
      "Loss for batch 16 = 0.43413323163986206\n",
      "Loss for batch 17 = 0.48468467593193054\n",
      "Loss for batch 18 = 0.6767269968986511\n",
      "Loss for batch 19 = 0.674684464931488\n",
      "Loss for batch 20 = 0.4889448285102844\n",
      "Loss for batch 21 = 0.5933585166931152\n",
      "Loss for batch 22 = 0.633323609828949\n",
      "Loss for batch 23 = 0.5486793518066406\n",
      "Loss for batch 24 = 0.44693422317504883\n",
      "Loss for batch 25 = 0.44501709938049316\n",
      "Loss for batch 26 = 0.4990876019001007\n",
      "Loss for batch 27 = 0.5417579412460327\n",
      "Loss for batch 28 = 0.5472927093505859\n",
      "Loss for batch 29 = 0.913215160369873\n",
      "Loss for batch 30 = 0.6961837410926819\n",
      "Loss for batch 31 = 0.5849652290344238\n",
      "Loss for batch 32 = 0.7295065522193909\n",
      "Loss for batch 33 = 0.6372724175453186\n",
      "Loss for batch 34 = 0.6406451463699341\n",
      "Loss for batch 35 = 0.4718555510044098\n",
      "Loss for batch 36 = 0.568367063999176\n",
      "Loss for batch 37 = 0.6261935234069824\n",
      "Loss for batch 38 = 0.662446916103363\n",
      "Loss for batch 39 = 0.5750014185905457\n",
      "Loss for batch 40 = 0.5414578914642334\n",
      "Loss for batch 41 = 0.5544492602348328\n",
      "Loss for batch 42 = 0.5608344674110413\n",
      "Loss for batch 43 = 0.517033040523529\n",
      "Loss for batch 44 = 0.762902021408081\n",
      "Loss for batch 45 = 0.5540338158607483\n",
      "Loss for batch 46 = 0.38900548219680786\n",
      "Loss for batch 47 = 0.5677563548088074\n",
      "Loss for batch 48 = 0.727932870388031\n",
      "Loss for batch 49 = 0.7275876998901367\n",
      "Loss for batch 50 = 0.7226435542106628\n",
      "Loss for batch 51 = 0.5865184664726257\n",
      "Loss for batch 52 = 0.4819223880767822\n",
      "Loss for batch 53 = 0.2957320809364319\n",
      "Loss for batch 54 = 0.4089076817035675\n",
      "Loss for batch 55 = 0.7759019136428833\n",
      "Loss for batch 56 = 0.5804761648178101\n",
      "Loss for batch 57 = 0.555910587310791\n",
      "Loss for batch 58 = 0.35431480407714844\n",
      "Loss for batch 59 = 0.5618219971656799\n",
      "Loss for batch 60 = 0.48019933700561523\n",
      "Loss for batch 61 = 0.5964308977127075\n",
      "Loss for batch 62 = 0.35584357380867004\n",
      "Loss for batch 63 = 0.4763520359992981\n",
      "Loss for batch 64 = 0.5801876187324524\n",
      "Loss for batch 65 = 0.5220907926559448\n",
      "Loss for batch 66 = 0.4165555238723755\n",
      "Loss for batch 67 = 0.43467631936073303\n",
      "Loss for batch 68 = 0.5878698229789734\n",
      "Loss for batch 69 = 0.7412045001983643\n",
      "Loss for batch 70 = 0.9739132523536682\n",
      "Loss for batch 71 = 0.3185662627220154\n",
      "Loss for batch 72 = 0.6459643244743347\n",
      "Loss for batch 73 = 0.46650585532188416\n",
      "Loss for batch 74 = 0.6168249249458313\n",
      "Loss for batch 75 = 0.5468351244926453\n",
      "Loss for batch 76 = 0.9455722570419312\n",
      "Loss for batch 77 = 0.3929644823074341\n",
      "Loss for batch 78 = 0.4678807854652405\n",
      "Loss for batch 79 = 0.6508308053016663\n",
      "Loss for batch 80 = 0.49914732575416565\n",
      "Loss for batch 81 = 0.48530441522598267\n",
      "Loss for batch 82 = 0.6116657257080078\n",
      "Loss for batch 83 = 0.34412333369255066\n",
      "Loss for batch 84 = 0.35643479228019714\n",
      "Loss for batch 85 = 0.6487852334976196\n",
      "Loss for batch 86 = 0.6642720103263855\n",
      "Loss for batch 87 = 0.5972632169723511\n",
      "Loss for batch 88 = 0.46751394867897034\n",
      "Loss for batch 89 = 0.3724953532218933\n",
      "Loss for batch 90 = 0.41720056533813477\n",
      "Loss for batch 91 = 0.45993444323539734\n",
      "Loss for batch 92 = 0.18577519059181213\n",
      "Loss for batch 93 = 0.6811954975128174\n",
      "Loss for batch 94 = 0.42175376415252686\n",
      "Loss for batch 95 = 0.44227054715156555\n",
      "Loss for batch 96 = 0.38975638151168823\n",
      "Loss for batch 97 = 0.3803383409976959\n",
      "\n",
      "Training Loss for epoch 21 = 54.720062255859375\n",
      "\n",
      "Current Validation Loss = 27.07785987854004\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 7\n",
      "Train Accuracy: 75.35%\n",
      "Validation Accuracy: 60.98%\n",
      "\n",
      "Epoch 22\n",
      "----------\n",
      "Loss for batch 0 = 0.5636559724807739\n",
      "Loss for batch 1 = 0.4317256808280945\n",
      "Loss for batch 2 = 0.47398802638053894\n",
      "Loss for batch 3 = 0.4785583019256592\n",
      "Loss for batch 4 = 0.5489319562911987\n",
      "Loss for batch 5 = 0.7012443542480469\n",
      "Loss for batch 6 = 0.5147804617881775\n",
      "Loss for batch 7 = 0.684226393699646\n",
      "Loss for batch 8 = 0.46054327487945557\n",
      "Loss for batch 9 = 0.5595334768295288\n",
      "Loss for batch 10 = 0.8776184320449829\n",
      "Loss for batch 11 = 0.6019671559333801\n",
      "Loss for batch 12 = 0.6260700225830078\n",
      "Loss for batch 13 = 0.7898640632629395\n",
      "Loss for batch 14 = 0.4149722158908844\n",
      "Loss for batch 15 = 0.508405864238739\n",
      "Loss for batch 16 = 0.4339292049407959\n",
      "Loss for batch 17 = 0.4086698591709137\n",
      "Loss for batch 18 = 0.5627316236495972\n",
      "Loss for batch 19 = 0.671029806137085\n",
      "Loss for batch 20 = 0.4619828462600708\n",
      "Loss for batch 21 = 0.5779266953468323\n",
      "Loss for batch 22 = 0.5874667167663574\n",
      "Loss for batch 23 = 0.48300832509994507\n",
      "Loss for batch 24 = 0.41272231936454773\n",
      "Loss for batch 25 = 0.4012260437011719\n",
      "Loss for batch 26 = 0.4095003008842468\n",
      "Loss for batch 27 = 0.5212422609329224\n",
      "Loss for batch 28 = 0.5393092036247253\n",
      "Loss for batch 29 = 0.7892150282859802\n",
      "Loss for batch 30 = 0.7148132920265198\n",
      "Loss for batch 31 = 0.5159916281700134\n",
      "Loss for batch 32 = 0.7161855697631836\n",
      "Loss for batch 33 = 0.5541926622390747\n",
      "Loss for batch 34 = 0.6121850609779358\n",
      "Loss for batch 35 = 0.5126007795333862\n",
      "Loss for batch 36 = 0.5707029700279236\n",
      "Loss for batch 37 = 0.5705716609954834\n",
      "Loss for batch 38 = 0.6386342644691467\n",
      "Loss for batch 39 = 0.553695559501648\n",
      "Loss for batch 40 = 0.5445339679718018\n",
      "Loss for batch 41 = 0.5717354416847229\n",
      "Loss for batch 42 = 0.4915984272956848\n",
      "Loss for batch 43 = 0.5770078301429749\n",
      "Loss for batch 44 = 0.5584884881973267\n",
      "Loss for batch 45 = 0.5252446532249451\n",
      "Loss for batch 46 = 0.40055930614471436\n",
      "Loss for batch 47 = 0.5257205963134766\n",
      "Loss for batch 48 = 0.7157312035560608\n",
      "Loss for batch 49 = 0.6447106599807739\n",
      "Loss for batch 50 = 0.7211920619010925\n",
      "Loss for batch 51 = 0.5137540698051453\n",
      "Loss for batch 52 = 0.4542457163333893\n",
      "Loss for batch 53 = 0.3258492052555084\n",
      "Loss for batch 54 = 0.367973268032074\n",
      "Loss for batch 55 = 0.6688182353973389\n",
      "Loss for batch 56 = 0.624859631061554\n",
      "Loss for batch 57 = 0.5005608797073364\n",
      "Loss for batch 58 = 0.386452317237854\n",
      "Loss for batch 59 = 0.5942423343658447\n",
      "Loss for batch 60 = 0.5075257420539856\n",
      "Loss for batch 61 = 0.6020768880844116\n",
      "Loss for batch 62 = 0.3207571506500244\n",
      "Loss for batch 63 = 0.39303621649742126\n",
      "Loss for batch 64 = 0.6100940704345703\n",
      "Loss for batch 65 = 0.56607586145401\n",
      "Loss for batch 66 = 0.45963603258132935\n",
      "Loss for batch 67 = 0.4120922088623047\n",
      "Loss for batch 68 = 0.5272731781005859\n",
      "Loss for batch 69 = 0.7078725695610046\n",
      "Loss for batch 70 = 0.8801682591438293\n",
      "Loss for batch 71 = 0.3400067389011383\n",
      "Loss for batch 72 = 0.6560479998588562\n",
      "Loss for batch 73 = 0.3967956006526947\n",
      "Loss for batch 74 = 0.6325777173042297\n",
      "Loss for batch 75 = 0.4652518332004547\n",
      "Loss for batch 76 = 0.9378135800361633\n",
      "Loss for batch 77 = 0.40788954496383667\n",
      "Loss for batch 78 = 0.45006263256073\n",
      "Loss for batch 79 = 0.6595989465713501\n",
      "Loss for batch 80 = 0.5044349431991577\n",
      "Loss for batch 81 = 0.4503781199455261\n",
      "Loss for batch 82 = 0.5311112999916077\n",
      "Loss for batch 83 = 0.38130566477775574\n",
      "Loss for batch 84 = 0.35189706087112427\n",
      "Loss for batch 85 = 0.6454495191574097\n",
      "Loss for batch 86 = 0.6678988933563232\n",
      "Loss for batch 87 = 0.5710126161575317\n",
      "Loss for batch 88 = 0.4055240750312805\n",
      "Loss for batch 89 = 0.36938849091529846\n",
      "Loss for batch 90 = 0.3813577890396118\n",
      "Loss for batch 91 = 0.5276703834533691\n",
      "Loss for batch 92 = 0.17611925303936005\n",
      "Loss for batch 93 = 0.630901575088501\n",
      "Loss for batch 94 = 0.4338831901550293\n",
      "Loss for batch 95 = 0.41916343569755554\n",
      "Loss for batch 96 = 0.34255996346473694\n",
      "Loss for batch 97 = 0.2802148759365082\n",
      "\n",
      "Training Loss for epoch 22 = 52.17184066772461\n",
      "\n",
      "Current Validation Loss = 27.185821533203125\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 8\n",
      "Train Accuracy: 76.48%\n",
      "Validation Accuracy: 62.39%\n",
      "\n",
      "Epoch 23\n",
      "----------\n",
      "Loss for batch 0 = 0.6171814799308777\n",
      "Loss for batch 1 = 0.48840078711509705\n",
      "Loss for batch 2 = 0.42262861132621765\n",
      "Loss for batch 3 = 0.4805276393890381\n",
      "Loss for batch 4 = 0.46271467208862305\n",
      "Loss for batch 5 = 0.7150413393974304\n",
      "Loss for batch 6 = 0.4850611388683319\n",
      "Loss for batch 7 = 0.6623736619949341\n",
      "Loss for batch 8 = 0.4535315930843353\n",
      "Loss for batch 9 = 0.5749005675315857\n",
      "Loss for batch 10 = 0.7330994606018066\n",
      "Loss for batch 11 = 0.5448000431060791\n",
      "Loss for batch 12 = 0.593856930732727\n",
      "Loss for batch 13 = 0.7824183106422424\n",
      "Loss for batch 14 = 0.4222411811351776\n",
      "Loss for batch 15 = 0.5009303689002991\n",
      "Loss for batch 16 = 0.3834196925163269\n",
      "Loss for batch 17 = 0.3717847466468811\n",
      "Loss for batch 18 = 0.5207040905952454\n",
      "Loss for batch 19 = 0.6375890374183655\n",
      "Loss for batch 20 = 0.42723631858825684\n",
      "Loss for batch 21 = 0.5263574719429016\n",
      "Loss for batch 22 = 0.5197402238845825\n",
      "Loss for batch 23 = 0.4745905101299286\n",
      "Loss for batch 24 = 0.42380374670028687\n",
      "Loss for batch 25 = 0.38175228238105774\n",
      "Loss for batch 26 = 0.4424212574958801\n",
      "Loss for batch 27 = 0.6032204031944275\n",
      "Loss for batch 28 = 0.5399017333984375\n",
      "Loss for batch 29 = 0.7120503783226013\n",
      "Loss for batch 30 = 0.6568757891654968\n",
      "Loss for batch 31 = 0.49680429697036743\n",
      "Loss for batch 32 = 0.7298756837844849\n",
      "Loss for batch 33 = 0.548819899559021\n",
      "Loss for batch 34 = 0.6266865134239197\n",
      "Loss for batch 35 = 0.45843636989593506\n",
      "Loss for batch 36 = 0.5143107175827026\n",
      "Loss for batch 37 = 0.6024854779243469\n",
      "Loss for batch 38 = 0.5902729630470276\n",
      "Loss for batch 39 = 0.585481584072113\n",
      "Loss for batch 40 = 0.5542082190513611\n",
      "Loss for batch 41 = 0.5203104615211487\n",
      "Loss for batch 42 = 0.45791059732437134\n",
      "Loss for batch 43 = 0.4980383813381195\n",
      "Loss for batch 44 = 0.5658838152885437\n",
      "Loss for batch 45 = 0.48032692074775696\n",
      "Loss for batch 46 = 0.3307434618473053\n",
      "Loss for batch 47 = 0.43699249625205994\n",
      "Loss for batch 48 = 0.7723375558853149\n",
      "Loss for batch 49 = 0.7888920903205872\n",
      "Loss for batch 50 = 0.7861331701278687\n",
      "Loss for batch 51 = 0.5020306706428528\n",
      "Loss for batch 52 = 0.42057180404663086\n",
      "Loss for batch 53 = 0.272813618183136\n",
      "Loss for batch 54 = 0.3361346125602722\n",
      "Loss for batch 55 = 0.652376651763916\n",
      "Loss for batch 56 = 0.5086329579353333\n",
      "Loss for batch 57 = 0.6180095076560974\n",
      "Loss for batch 58 = 0.3447137176990509\n",
      "Loss for batch 59 = 0.6169767379760742\n",
      "Loss for batch 60 = 0.47957590222358704\n",
      "Loss for batch 61 = 0.5914815664291382\n",
      "Loss for batch 62 = 0.31999555230140686\n",
      "Loss for batch 63 = 0.4179982542991638\n",
      "Loss for batch 64 = 0.5939369797706604\n",
      "Loss for batch 65 = 0.5495694875717163\n",
      "Loss for batch 66 = 0.4386473298072815\n",
      "Loss for batch 67 = 0.42191728949546814\n",
      "Loss for batch 68 = 0.6700509786605835\n",
      "Loss for batch 69 = 0.8375225067138672\n",
      "Loss for batch 70 = 0.9251776337623596\n",
      "Loss for batch 71 = 0.32409772276878357\n",
      "Loss for batch 72 = 0.6532989740371704\n",
      "Loss for batch 73 = 0.32695499062538147\n",
      "Loss for batch 74 = 0.5671012997627258\n",
      "Loss for batch 75 = 0.5642188191413879\n",
      "Loss for batch 76 = 0.8793691992759705\n",
      "Loss for batch 77 = 0.37765371799468994\n",
      "Loss for batch 78 = 0.43777135014533997\n",
      "Loss for batch 79 = 0.582826554775238\n",
      "Loss for batch 80 = 0.45275387167930603\n",
      "Loss for batch 81 = 0.426663875579834\n",
      "Loss for batch 82 = 0.5432350635528564\n",
      "Loss for batch 83 = 0.343930184841156\n",
      "Loss for batch 84 = 0.3171164393424988\n",
      "Loss for batch 85 = 0.6043694019317627\n",
      "Loss for batch 86 = 0.6322341561317444\n",
      "Loss for batch 87 = 0.5706143975257874\n",
      "Loss for batch 88 = 0.4016444981098175\n",
      "Loss for batch 89 = 0.3582368493080139\n",
      "Loss for batch 90 = 0.376753032207489\n",
      "Loss for batch 91 = 0.5473946332931519\n",
      "Loss for batch 92 = 0.20803947746753693\n",
      "Loss for batch 93 = 0.5930778980255127\n",
      "Loss for batch 94 = 0.4400117099285126\n",
      "Loss for batch 95 = 0.463923841714859\n",
      "Loss for batch 96 = 0.30382511019706726\n",
      "Loss for batch 97 = 0.2462497353553772\n",
      "\n",
      "Training Loss for epoch 23 = 50.96760940551758\n",
      "\n",
      "Current Validation Loss = 27.83087730407715\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 9\n",
      "Train Accuracy: 76.64%\n",
      "Validation Accuracy: 60.21%\n",
      "\n",
      "Epoch 24\n",
      "----------\n",
      "Loss for batch 0 = 0.5557777881622314\n",
      "Loss for batch 1 = 0.419389545917511\n",
      "Loss for batch 2 = 0.45006251335144043\n",
      "Loss for batch 3 = 0.5232456922531128\n",
      "Loss for batch 4 = 0.44674405455589294\n",
      "Loss for batch 5 = 0.61473548412323\n",
      "Loss for batch 6 = 0.4473005533218384\n",
      "Loss for batch 7 = 0.6185137033462524\n",
      "Loss for batch 8 = 0.46055909991264343\n",
      "Loss for batch 9 = 0.6231364011764526\n",
      "Loss for batch 10 = 0.6871428489685059\n",
      "Loss for batch 11 = 0.6195959448814392\n",
      "Loss for batch 12 = 0.6992703080177307\n",
      "Loss for batch 13 = 0.7264952063560486\n",
      "Loss for batch 14 = 0.3627397418022156\n",
      "Loss for batch 15 = 0.4492815434932709\n",
      "Loss for batch 16 = 0.3584260642528534\n",
      "Loss for batch 17 = 0.413442462682724\n",
      "Loss for batch 18 = 0.4668886959552765\n",
      "Loss for batch 19 = 0.7282179594039917\n",
      "Loss for batch 20 = 0.41172829270362854\n",
      "Loss for batch 21 = 0.4495019316673279\n",
      "Loss for batch 22 = 0.4700751304626465\n",
      "Loss for batch 23 = 0.5032480359077454\n",
      "Loss for batch 24 = 0.46106916666030884\n",
      "Loss for batch 25 = 0.582108199596405\n",
      "Loss for batch 26 = 0.39249253273010254\n",
      "Loss for batch 27 = 0.5123255252838135\n",
      "Loss for batch 28 = 0.5249394774436951\n",
      "Loss for batch 29 = 0.6998365521430969\n",
      "Loss for batch 30 = 0.6697070598602295\n",
      "Loss for batch 31 = 0.452770859003067\n",
      "Loss for batch 32 = 0.7121814489364624\n",
      "Loss for batch 33 = 0.5445319414138794\n",
      "Loss for batch 34 = 0.5459098815917969\n",
      "Loss for batch 35 = 0.4646936357021332\n",
      "Loss for batch 36 = 0.5393006205558777\n",
      "Loss for batch 37 = 0.507254421710968\n",
      "Loss for batch 38 = 0.5508817434310913\n",
      "Loss for batch 39 = 0.5123145580291748\n",
      "Loss for batch 40 = 0.5146607756614685\n",
      "Loss for batch 41 = 0.4895763099193573\n",
      "Loss for batch 42 = 0.4283141791820526\n",
      "Loss for batch 43 = 0.48935461044311523\n",
      "Loss for batch 44 = 0.5244093537330627\n",
      "Loss for batch 45 = 0.48190411925315857\n",
      "Loss for batch 46 = 0.341943621635437\n",
      "Loss for batch 47 = 0.44483059644699097\n",
      "Loss for batch 48 = 0.5676578879356384\n",
      "Loss for batch 49 = 0.6571264863014221\n",
      "Loss for batch 50 = 0.6879297494888306\n",
      "Loss for batch 51 = 0.5173099040985107\n",
      "Loss for batch 52 = 0.3964305520057678\n",
      "Loss for batch 53 = 0.2540872395038605\n",
      "Loss for batch 54 = 0.34918978810310364\n",
      "Loss for batch 55 = 0.5975269079208374\n",
      "Loss for batch 56 = 0.5159084796905518\n",
      "Loss for batch 57 = 0.48729032278060913\n",
      "Loss for batch 58 = 0.29883840680122375\n",
      "Loss for batch 59 = 0.46824145317077637\n",
      "Loss for batch 60 = 0.41354912519454956\n",
      "Loss for batch 61 = 0.48890164494514465\n",
      "Loss for batch 62 = 0.25064942240715027\n",
      "Loss for batch 63 = 0.46346578001976013\n",
      "Loss for batch 64 = 0.5917333364486694\n",
      "Loss for batch 65 = 0.4532648026943207\n",
      "Loss for batch 66 = 0.34081631898880005\n",
      "Loss for batch 67 = 0.3918842375278473\n",
      "Loss for batch 68 = 0.5105625987052917\n",
      "Loss for batch 69 = 0.7234962582588196\n",
      "Loss for batch 70 = 0.9115310907363892\n",
      "Loss for batch 71 = 0.26431962847709656\n",
      "Loss for batch 72 = 0.6343306303024292\n",
      "Loss for batch 73 = 0.33362263441085815\n",
      "Loss for batch 74 = 0.6478183269500732\n",
      "Loss for batch 75 = 0.3844096064567566\n",
      "Loss for batch 76 = 0.9011487364768982\n",
      "Loss for batch 77 = 0.36095744371414185\n",
      "Loss for batch 78 = 0.4575432538986206\n",
      "Loss for batch 79 = 0.4722704291343689\n",
      "Loss for batch 80 = 0.4105502665042877\n",
      "Loss for batch 81 = 0.4010196328163147\n",
      "Loss for batch 82 = 0.4830837547779083\n",
      "Loss for batch 83 = 0.2934993505477905\n",
      "Loss for batch 84 = 0.2595677077770233\n",
      "Loss for batch 85 = 0.5712189674377441\n",
      "Loss for batch 86 = 0.6053187847137451\n",
      "Loss for batch 87 = 0.4809010922908783\n",
      "Loss for batch 88 = 0.3320130705833435\n",
      "Loss for batch 89 = 0.3011838495731354\n",
      "Loss for batch 90 = 0.3514517545700073\n",
      "Loss for batch 91 = 0.47586581110954285\n",
      "Loss for batch 92 = 0.1277654618024826\n",
      "Loss for batch 93 = 0.581906259059906\n",
      "Loss for batch 94 = 0.42879343032836914\n",
      "Loss for batch 95 = 0.3349441587924957\n",
      "Loss for batch 96 = 0.2599538266658783\n",
      "Loss for batch 97 = 0.2518785297870636\n",
      "\n",
      "Training Loss for epoch 24 = 47.63755416870117\n",
      "\n",
      "Current Validation Loss = 28.36989402770996\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 10\n",
      "Train Accuracy: 78.43%\n",
      "Validation Accuracy: 61.75%\n",
      "\n",
      "Epoch 25\n",
      "----------\n",
      "Loss for batch 0 = 0.5594002604484558\n",
      "Loss for batch 1 = 0.4778808653354645\n",
      "Loss for batch 2 = 0.39826250076293945\n",
      "Loss for batch 3 = 0.4669548273086548\n",
      "Loss for batch 4 = 0.41485920548439026\n",
      "Loss for batch 5 = 0.5930718779563904\n",
      "Loss for batch 6 = 0.4225209057331085\n",
      "Loss for batch 7 = 0.5862142443656921\n",
      "Loss for batch 8 = 0.4466381072998047\n",
      "Loss for batch 9 = 0.5933769941329956\n",
      "Loss for batch 10 = 0.6802769899368286\n",
      "Loss for batch 11 = 0.5418045520782471\n",
      "Loss for batch 12 = 0.6544346809387207\n",
      "Loss for batch 13 = 0.7518328428268433\n",
      "Loss for batch 14 = 0.37153661251068115\n",
      "Loss for batch 15 = 0.4243452548980713\n",
      "Loss for batch 16 = 0.3439667522907257\n",
      "Loss for batch 17 = 0.3330472707748413\n",
      "Loss for batch 18 = 0.4654378890991211\n",
      "Loss for batch 19 = 0.5971754193305969\n",
      "Loss for batch 20 = 0.40298324823379517\n",
      "Loss for batch 21 = 0.45367351174354553\n",
      "Loss for batch 22 = 0.4623377025127411\n",
      "Loss for batch 23 = 0.43878334760665894\n",
      "Loss for batch 24 = 0.4444180727005005\n",
      "Loss for batch 25 = 0.483654260635376\n",
      "Loss for batch 26 = 0.3802095651626587\n",
      "Loss for batch 27 = 0.47531741857528687\n",
      "Loss for batch 28 = 0.5330305099487305\n",
      "Loss for batch 29 = 0.5844883918762207\n",
      "Loss for batch 30 = 0.6593196988105774\n",
      "Loss for batch 31 = 0.4676275849342346\n",
      "Loss for batch 32 = 0.6739523410797119\n",
      "Loss for batch 33 = 0.5122509598731995\n",
      "Loss for batch 34 = 0.5517588257789612\n",
      "Loss for batch 35 = 0.4365582764148712\n",
      "Loss for batch 36 = 0.4962924122810364\n",
      "Loss for batch 37 = 0.4911749064922333\n",
      "Loss for batch 38 = 0.5565012693405151\n",
      "Loss for batch 39 = 0.4812650680541992\n",
      "Loss for batch 40 = 0.5138360261917114\n",
      "Loss for batch 41 = 0.46528738737106323\n",
      "Loss for batch 42 = 0.3731893301010132\n",
      "Loss for batch 43 = 0.4987333416938782\n",
      "Loss for batch 44 = 0.5040841698646545\n",
      "Loss for batch 45 = 0.44436919689178467\n",
      "Loss for batch 46 = 0.317984938621521\n",
      "Loss for batch 47 = 0.4156024158000946\n",
      "Loss for batch 48 = 0.5465794801712036\n",
      "Loss for batch 49 = 0.5969473719596863\n",
      "Loss for batch 50 = 0.6920700669288635\n",
      "Loss for batch 51 = 0.49343734979629517\n",
      "Loss for batch 52 = 0.3777574300765991\n",
      "Loss for batch 53 = 0.21344561874866486\n",
      "Loss for batch 54 = 0.30060046911239624\n",
      "Loss for batch 55 = 0.5599837899208069\n",
      "Loss for batch 56 = 0.4911678433418274\n",
      "Loss for batch 57 = 0.4890945553779602\n",
      "Loss for batch 58 = 0.2977515161037445\n",
      "Loss for batch 59 = 0.4421541690826416\n",
      "Loss for batch 60 = 0.3827563524246216\n",
      "Loss for batch 61 = 0.4665229618549347\n",
      "Loss for batch 62 = 0.22693999111652374\n",
      "Loss for batch 63 = 0.3738502562046051\n",
      "Loss for batch 64 = 0.49318626523017883\n",
      "Loss for batch 65 = 0.4282934069633484\n",
      "Loss for batch 66 = 0.33671456575393677\n",
      "Loss for batch 67 = 0.3999291658401489\n",
      "Loss for batch 68 = 0.5134334564208984\n",
      "Loss for batch 69 = 0.7151854634284973\n",
      "Loss for batch 70 = 0.8551691174507141\n",
      "Loss for batch 71 = 0.25116705894470215\n",
      "Loss for batch 72 = 0.6269748210906982\n",
      "Loss for batch 73 = 0.28657037019729614\n",
      "Loss for batch 74 = 0.5640900731086731\n",
      "Loss for batch 75 = 0.3700738549232483\n",
      "Loss for batch 76 = 0.8932152390480042\n",
      "Loss for batch 77 = 0.32341843843460083\n",
      "Loss for batch 78 = 0.4027099013328552\n",
      "Loss for batch 79 = 0.43610242009162903\n",
      "Loss for batch 80 = 0.3873281478881836\n",
      "Loss for batch 81 = 0.3944084346294403\n",
      "Loss for batch 82 = 0.4540643095970154\n",
      "Loss for batch 83 = 0.2903403341770172\n",
      "Loss for batch 84 = 0.25261425971984863\n",
      "Loss for batch 85 = 0.5598013401031494\n",
      "Loss for batch 86 = 0.5977860689163208\n",
      "Loss for batch 87 = 0.4775961637496948\n",
      "Loss for batch 88 = 0.33725619316101074\n",
      "Loss for batch 89 = 0.2751700282096863\n",
      "Loss for batch 90 = 0.3372263014316559\n",
      "Loss for batch 91 = 0.3871702551841736\n",
      "Loss for batch 92 = 0.10948394238948822\n",
      "Loss for batch 93 = 0.5414175391197205\n",
      "Loss for batch 94 = 0.386442095041275\n",
      "Loss for batch 95 = 0.3240203559398651\n",
      "Loss for batch 96 = 0.27263134717941284\n",
      "Loss for batch 97 = 0.22925634682178497\n",
      "\n",
      "Training Loss for epoch 25 = 45.103031158447266\n",
      "\n",
      "Current Validation Loss = 29.482072830200195\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 11\n",
      "Train Accuracy: 79.59%\n",
      "Validation Accuracy: 60.98%\n",
      "\n",
      "Epoch 26\n",
      "----------\n",
      "Loss for batch 0 = 0.5531654357910156\n",
      "Loss for batch 1 = 0.46536383032798767\n",
      "Loss for batch 2 = 0.36041998863220215\n",
      "Loss for batch 3 = 0.48061439394950867\n",
      "Loss for batch 4 = 0.40998372435569763\n",
      "Loss for batch 5 = 0.49349743127822876\n",
      "Loss for batch 6 = 0.4046366810798645\n",
      "Loss for batch 7 = 0.556044340133667\n",
      "Loss for batch 8 = 0.4573242664337158\n",
      "Loss for batch 9 = 0.6153861284255981\n",
      "Loss for batch 10 = 0.6810483932495117\n",
      "Loss for batch 11 = 0.5233797430992126\n",
      "Loss for batch 12 = 0.5727545619010925\n",
      "Loss for batch 13 = 0.785426676273346\n",
      "Loss for batch 14 = 0.35211285948753357\n",
      "Loss for batch 15 = 0.392894983291626\n",
      "Loss for batch 16 = 0.33388057351112366\n",
      "Loss for batch 17 = 0.26874786615371704\n",
      "Loss for batch 18 = 0.45744338631629944\n",
      "Loss for batch 19 = 0.5606077313423157\n",
      "Loss for batch 20 = 0.40599051117897034\n",
      "Loss for batch 21 = 0.4558628797531128\n",
      "Loss for batch 22 = 0.45448124408721924\n",
      "Loss for batch 23 = 0.3891299366950989\n",
      "Loss for batch 24 = 0.46120205521583557\n",
      "Loss for batch 25 = 0.4169081747531891\n",
      "Loss for batch 26 = 0.3438255786895752\n",
      "Loss for batch 27 = 0.43833231925964355\n",
      "Loss for batch 28 = 0.5468394756317139\n",
      "Loss for batch 29 = 0.5118000507354736\n",
      "Loss for batch 30 = 0.6226053833961487\n",
      "Loss for batch 31 = 0.4680385887622833\n",
      "Loss for batch 32 = 0.6431570053100586\n",
      "Loss for batch 33 = 0.4963759183883667\n",
      "Loss for batch 34 = 0.5173003077507019\n",
      "Loss for batch 35 = 0.4171236753463745\n",
      "Loss for batch 36 = 0.4657418429851532\n",
      "Loss for batch 37 = 0.4844227731227875\n",
      "Loss for batch 38 = 0.5385417342185974\n",
      "Loss for batch 39 = 0.4712795615196228\n",
      "Loss for batch 40 = 0.4965056777000427\n",
      "Loss for batch 41 = 0.4472976326942444\n",
      "Loss for batch 42 = 0.34399908781051636\n",
      "Loss for batch 43 = 0.463302880525589\n",
      "Loss for batch 44 = 0.502148449420929\n",
      "Loss for batch 45 = 0.42787033319473267\n",
      "Loss for batch 46 = 0.30029061436653137\n",
      "Loss for batch 47 = 0.387533575296402\n",
      "Loss for batch 48 = 0.5344828367233276\n",
      "Loss for batch 49 = 0.5622596740722656\n",
      "Loss for batch 50 = 0.6675511598587036\n",
      "Loss for batch 51 = 0.42939579486846924\n",
      "Loss for batch 52 = 0.35501953959465027\n",
      "Loss for batch 53 = 0.1957559734582901\n",
      "Loss for batch 54 = 0.30153486132621765\n",
      "Loss for batch 55 = 0.5261375904083252\n",
      "Loss for batch 56 = 0.46613237261772156\n",
      "Loss for batch 57 = 0.47427546977996826\n",
      "Loss for batch 58 = 0.28255438804626465\n",
      "Loss for batch 59 = 0.42031410336494446\n",
      "Loss for batch 60 = 0.3449324369430542\n",
      "Loss for batch 61 = 0.446743369102478\n",
      "Loss for batch 62 = 0.21403615176677704\n",
      "Loss for batch 63 = 0.36057475209236145\n",
      "Loss for batch 64 = 0.4652532637119293\n",
      "Loss for batch 65 = 0.4249856472015381\n",
      "Loss for batch 66 = 0.3105297088623047\n",
      "Loss for batch 67 = 0.400680273771286\n",
      "Loss for batch 68 = 0.5044379830360413\n",
      "Loss for batch 69 = 0.703167736530304\n",
      "Loss for batch 70 = 0.8006503582000732\n",
      "Loss for batch 71 = 0.24531561136245728\n",
      "Loss for batch 72 = 0.6067233085632324\n",
      "Loss for batch 73 = 0.2767806351184845\n",
      "Loss for batch 74 = 0.5392541289329529\n",
      "Loss for batch 75 = 0.35445883870124817\n",
      "Loss for batch 76 = 0.8674289584159851\n",
      "Loss for batch 77 = 0.3153579831123352\n",
      "Loss for batch 78 = 0.3734842836856842\n",
      "Loss for batch 79 = 0.43052351474761963\n",
      "Loss for batch 80 = 0.37619471549987793\n",
      "Loss for batch 81 = 0.37771645188331604\n",
      "Loss for batch 82 = 0.4360775947570801\n",
      "Loss for batch 83 = 0.2884317636489868\n",
      "Loss for batch 84 = 0.2550642788410187\n",
      "Loss for batch 85 = 0.5240592956542969\n",
      "Loss for batch 86 = 0.5572433471679688\n",
      "Loss for batch 87 = 0.4582262337207794\n",
      "Loss for batch 88 = 0.28752270340919495\n",
      "Loss for batch 89 = 0.26141357421875\n",
      "Loss for batch 90 = 0.33056193590164185\n",
      "Loss for batch 91 = 0.4015507996082306\n",
      "Loss for batch 92 = 0.09669896960258484\n",
      "Loss for batch 93 = 0.5435178875923157\n",
      "Loss for batch 94 = 0.37277334928512573\n",
      "Loss for batch 95 = 0.2888903021812439\n",
      "Loss for batch 96 = 0.24365577101707458\n",
      "Loss for batch 97 = 0.20328547060489655\n",
      "\n",
      "Training Loss for epoch 26 = 43.14625549316406\n",
      "\n",
      "Current Validation Loss = 30.60686492919922\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 12\n",
      "Train Accuracy: 80.68%\n",
      "Validation Accuracy: 60.98%\n",
      "\n",
      "Epoch 27\n",
      "----------\n",
      "Loss for batch 0 = 0.5558305978775024\n",
      "Loss for batch 1 = 0.436695396900177\n",
      "Loss for batch 2 = 0.32584547996520996\n",
      "Loss for batch 3 = 0.4502142667770386\n",
      "Loss for batch 4 = 0.3775705099105835\n",
      "Loss for batch 5 = 0.4967306852340698\n",
      "Loss for batch 6 = 0.4036894738674164\n",
      "Loss for batch 7 = 0.5294317603111267\n",
      "Loss for batch 8 = 0.459696888923645\n",
      "Loss for batch 9 = 0.6155303120613098\n",
      "Loss for batch 10 = 0.6717821359634399\n",
      "Loss for batch 11 = 0.5221288204193115\n",
      "Loss for batch 12 = 0.5597919225692749\n",
      "Loss for batch 13 = 0.7661463022232056\n",
      "Loss for batch 14 = 0.33428266644477844\n",
      "Loss for batch 15 = 0.3731100261211395\n",
      "Loss for batch 16 = 0.3248967230319977\n",
      "Loss for batch 17 = 0.27131468057632446\n",
      "Loss for batch 18 = 0.42691609263420105\n",
      "Loss for batch 19 = 0.5377988219261169\n",
      "Loss for batch 20 = 0.41455867886543274\n",
      "Loss for batch 21 = 0.43987351655960083\n",
      "Loss for batch 22 = 0.42681246995925903\n",
      "Loss for batch 23 = 0.3461185097694397\n",
      "Loss for batch 24 = 0.46267175674438477\n",
      "Loss for batch 25 = 0.3936357796192169\n",
      "Loss for batch 26 = 0.32575273513793945\n",
      "Loss for batch 27 = 0.3829295039176941\n",
      "Loss for batch 28 = 0.5568519830703735\n",
      "Loss for batch 29 = 0.4608297646045685\n",
      "Loss for batch 30 = 0.6305050253868103\n",
      "Loss for batch 31 = 0.47182267904281616\n",
      "Loss for batch 32 = 0.6484010815620422\n",
      "Loss for batch 33 = 0.4897697865962982\n",
      "Loss for batch 34 = 0.5039368867874146\n",
      "Loss for batch 35 = 0.39698049426078796\n",
      "Loss for batch 36 = 0.45917922258377075\n",
      "Loss for batch 37 = 0.5116592049598694\n",
      "Loss for batch 38 = 0.49645036458969116\n",
      "Loss for batch 39 = 0.45662862062454224\n",
      "Loss for batch 40 = 0.49918630719184875\n",
      "Loss for batch 41 = 0.4479158818721771\n",
      "Loss for batch 42 = 0.35034069418907166\n",
      "Loss for batch 43 = 0.4549688696861267\n",
      "Loss for batch 44 = 0.49001288414001465\n",
      "Loss for batch 45 = 0.43037179112434387\n",
      "Loss for batch 46 = 0.32326406240463257\n",
      "Loss for batch 47 = 0.3586459457874298\n",
      "Loss for batch 48 = 0.5064765214920044\n",
      "Loss for batch 49 = 0.5334811210632324\n",
      "Loss for batch 50 = 0.6419561505317688\n",
      "Loss for batch 51 = 0.4036654829978943\n",
      "Loss for batch 52 = 0.3316603899002075\n",
      "Loss for batch 53 = 0.19238607585430145\n",
      "Loss for batch 54 = 0.28039371967315674\n",
      "Loss for batch 55 = 0.4914497435092926\n",
      "Loss for batch 56 = 0.45556509494781494\n",
      "Loss for batch 57 = 0.46197739243507385\n",
      "Loss for batch 58 = 0.2748505175113678\n",
      "Loss for batch 59 = 0.40395689010620117\n",
      "Loss for batch 60 = 0.32661691308021545\n",
      "Loss for batch 61 = 0.4239215552806854\n",
      "Loss for batch 62 = 0.20154647529125214\n",
      "Loss for batch 63 = 0.3317474126815796\n",
      "Loss for batch 64 = 0.477402925491333\n",
      "Loss for batch 65 = 0.42307406663894653\n",
      "Loss for batch 66 = 0.3107079267501831\n",
      "Loss for batch 67 = 0.3988867402076721\n",
      "Loss for batch 68 = 0.4592572748661041\n",
      "Loss for batch 69 = 0.6926485896110535\n",
      "Loss for batch 70 = 0.7548503279685974\n",
      "Loss for batch 71 = 0.25053995847702026\n",
      "Loss for batch 72 = 0.5641893148422241\n",
      "Loss for batch 73 = 0.2296939194202423\n",
      "Loss for batch 74 = 0.49772995710372925\n",
      "Loss for batch 75 = 0.3537669777870178\n",
      "Loss for batch 76 = 0.8012006282806396\n",
      "Loss for batch 77 = 0.3233393728733063\n",
      "Loss for batch 78 = 0.36426791548728943\n",
      "Loss for batch 79 = 0.44426560401916504\n",
      "Loss for batch 80 = 0.3486732542514801\n",
      "Loss for batch 81 = 0.37139567732810974\n",
      "Loss for batch 82 = 0.4283730983734131\n",
      "Loss for batch 83 = 0.28086069226264954\n",
      "Loss for batch 84 = 0.24623140692710876\n",
      "Loss for batch 85 = 0.5127546191215515\n",
      "Loss for batch 86 = 0.5425291061401367\n",
      "Loss for batch 87 = 0.4276352524757385\n",
      "Loss for batch 88 = 0.24720236659049988\n",
      "Loss for batch 89 = 0.2399483174085617\n",
      "Loss for batch 90 = 0.3268658220767975\n",
      "Loss for batch 91 = 0.3740878403186798\n",
      "Loss for batch 92 = 0.09543842822313309\n",
      "Loss for batch 93 = 0.5688915252685547\n",
      "Loss for batch 94 = 0.3569099009037018\n",
      "Loss for batch 95 = 0.2751871943473816\n",
      "Loss for batch 96 = 0.22493165731430054\n",
      "Loss for batch 97 = 0.19015969336032867\n",
      "\n",
      "Training Loss for epoch 27 = 41.73503875732422\n",
      "\n",
      "Current Validation Loss = 31.866661071777344\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 13\n",
      "Train Accuracy: 80.42%\n",
      "Validation Accuracy: 61.10%\n",
      "\n",
      "Epoch 28\n",
      "----------\n",
      "Loss for batch 0 = 0.5597558617591858\n",
      "Loss for batch 1 = 0.4341910183429718\n",
      "Loss for batch 2 = 0.33445030450820923\n",
      "Loss for batch 3 = 0.4061339199542999\n",
      "Loss for batch 4 = 0.3504708409309387\n",
      "Loss for batch 5 = 0.5695146322250366\n",
      "Loss for batch 6 = 0.3762960135936737\n",
      "Loss for batch 7 = 0.5637201070785522\n",
      "Loss for batch 8 = 0.44860517978668213\n",
      "Loss for batch 9 = 0.5940307974815369\n",
      "Loss for batch 10 = 0.690851628780365\n",
      "Loss for batch 11 = 0.5181149244308472\n",
      "Loss for batch 12 = 0.5475887060165405\n",
      "Loss for batch 13 = 0.734511137008667\n",
      "Loss for batch 14 = 0.3412785828113556\n",
      "Loss for batch 15 = 0.3463221490383148\n",
      "Loss for batch 16 = 0.3174600303173065\n",
      "Loss for batch 17 = 0.2852995693683624\n",
      "Loss for batch 18 = 0.43153780698776245\n",
      "Loss for batch 19 = 0.5183384418487549\n",
      "Loss for batch 20 = 0.3916001617908478\n",
      "Loss for batch 21 = 0.42810726165771484\n",
      "Loss for batch 22 = 0.4155484437942505\n",
      "Loss for batch 23 = 0.3426024615764618\n",
      "Loss for batch 24 = 0.45341792702674866\n",
      "Loss for batch 25 = 0.4152534306049347\n",
      "Loss for batch 26 = 0.3561665415763855\n",
      "Loss for batch 27 = 0.3753184378147125\n",
      "Loss for batch 28 = 0.5461100935935974\n",
      "Loss for batch 29 = 0.482684850692749\n",
      "Loss for batch 30 = 0.6194280385971069\n",
      "Loss for batch 31 = 0.43567129969596863\n",
      "Loss for batch 32 = 0.6050000190734863\n",
      "Loss for batch 33 = 0.4870527982711792\n",
      "Loss for batch 34 = 0.5010741353034973\n",
      "Loss for batch 35 = 0.40291333198547363\n",
      "Loss for batch 36 = 0.4212605059146881\n",
      "Loss for batch 37 = 0.479134738445282\n",
      "Loss for batch 38 = 0.4244098365306854\n",
      "Loss for batch 39 = 0.45886310935020447\n",
      "Loss for batch 40 = 0.4768822491168976\n",
      "Loss for batch 41 = 0.4448116421699524\n",
      "Loss for batch 42 = 0.3267512023448944\n",
      "Loss for batch 43 = 0.46091169118881226\n",
      "Loss for batch 44 = 0.47928860783576965\n",
      "Loss for batch 45 = 0.4383932054042816\n",
      "Loss for batch 46 = 0.3204905688762665\n",
      "Loss for batch 47 = 0.34328997135162354\n",
      "Loss for batch 48 = 0.49341896176338196\n",
      "Loss for batch 49 = 0.4860125482082367\n",
      "Loss for batch 50 = 0.6306963562965393\n",
      "Loss for batch 51 = 0.37750187516212463\n",
      "Loss for batch 52 = 0.34338241815567017\n",
      "Loss for batch 53 = 0.1999312788248062\n",
      "Loss for batch 54 = 0.27216848731040955\n",
      "Loss for batch 55 = 0.423056423664093\n",
      "Loss for batch 56 = 0.4319547414779663\n",
      "Loss for batch 57 = 0.43759939074516296\n",
      "Loss for batch 58 = 0.27077212929725647\n",
      "Loss for batch 59 = 0.37686997652053833\n",
      "Loss for batch 60 = 0.32677507400512695\n",
      "Loss for batch 61 = 0.4128917157649994\n",
      "Loss for batch 62 = 0.20331129431724548\n",
      "Loss for batch 63 = 0.320684015750885\n",
      "Loss for batch 64 = 0.4543607234954834\n",
      "Loss for batch 65 = 0.4128492772579193\n",
      "Loss for batch 66 = 0.3042528033256531\n",
      "Loss for batch 67 = 0.3641895353794098\n",
      "Loss for batch 68 = 0.4176839292049408\n",
      "Loss for batch 69 = 0.6988306641578674\n",
      "Loss for batch 70 = 0.7741777896881104\n",
      "Loss for batch 71 = 0.25595369935035706\n",
      "Loss for batch 72 = 0.583966076374054\n",
      "Loss for batch 73 = 0.2105812430381775\n",
      "Loss for batch 74 = 0.46823686361312866\n",
      "Loss for batch 75 = 0.36249732971191406\n",
      "Loss for batch 76 = 0.6873677968978882\n",
      "Loss for batch 77 = 0.3069538176059723\n",
      "Loss for batch 78 = 0.3523294925689697\n",
      "Loss for batch 79 = 0.47188541293144226\n",
      "Loss for batch 80 = 0.3211762607097626\n",
      "Loss for batch 81 = 0.3600941598415375\n",
      "Loss for batch 82 = 0.41859716176986694\n",
      "Loss for batch 83 = 0.2749631702899933\n",
      "Loss for batch 84 = 0.263188898563385\n",
      "Loss for batch 85 = 0.471730500459671\n",
      "Loss for batch 86 = 0.5307153463363647\n",
      "Loss for batch 87 = 0.3971974551677704\n",
      "Loss for batch 88 = 0.23495671153068542\n",
      "Loss for batch 89 = 0.2311270385980606\n",
      "Loss for batch 90 = 0.3208501636981964\n",
      "Loss for batch 91 = 0.3561038672924042\n",
      "Loss for batch 92 = 0.07892461121082306\n",
      "Loss for batch 93 = 0.5528433322906494\n",
      "Loss for batch 94 = 0.348519891500473\n",
      "Loss for batch 95 = 0.2666073143482208\n",
      "Loss for batch 96 = 0.20894822478294373\n",
      "Loss for batch 97 = 0.19966162741184235\n",
      "\n",
      "Training Loss for epoch 28 = 40.67026138305664\n",
      "\n",
      "Current Validation Loss = 32.653053283691406\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 14\n",
      "Train Accuracy: 80.52%\n",
      "Validation Accuracy: 60.98%\n",
      "\n",
      "Epoch 29\n",
      "----------\n",
      "Loss for batch 0 = 0.5528994202613831\n",
      "Loss for batch 1 = 0.45708686113357544\n",
      "Loss for batch 2 = 0.31830474734306335\n",
      "Loss for batch 3 = 0.4044378697872162\n",
      "Loss for batch 4 = 0.33893483877182007\n",
      "Loss for batch 5 = 0.45226389169692993\n",
      "Loss for batch 6 = 0.37201350927352905\n",
      "Loss for batch 7 = 0.5419664978981018\n",
      "Loss for batch 8 = 0.4422169327735901\n",
      "Loss for batch 9 = 0.5414632558822632\n",
      "Loss for batch 10 = 0.6730991005897522\n",
      "Loss for batch 11 = 0.48091575503349304\n",
      "Loss for batch 12 = 0.5389614105224609\n",
      "Loss for batch 13 = 0.741041898727417\n",
      "Loss for batch 14 = 0.313322514295578\n",
      "Loss for batch 15 = 0.3342048227787018\n",
      "Loss for batch 16 = 0.3133118450641632\n",
      "Loss for batch 17 = 0.23938003182411194\n",
      "Loss for batch 18 = 0.38392409682273865\n",
      "Loss for batch 19 = 0.49734365940093994\n",
      "Loss for batch 20 = 0.37547966837882996\n",
      "Loss for batch 21 = 0.4019777178764343\n",
      "Loss for batch 22 = 0.4108775556087494\n",
      "Loss for batch 23 = 0.30720508098602295\n",
      "Loss for batch 24 = 0.46577948331832886\n",
      "Loss for batch 25 = 0.3880724012851715\n",
      "Loss for batch 26 = 0.2939940392971039\n",
      "Loss for batch 27 = 0.32838311791419983\n",
      "Loss for batch 28 = 0.5362150073051453\n",
      "Loss for batch 29 = 0.5468782186508179\n",
      "Loss for batch 30 = 0.6025155186653137\n",
      "Loss for batch 31 = 0.4984048902988434\n",
      "Loss for batch 32 = 0.6200114488601685\n",
      "Loss for batch 33 = 0.41754385828971863\n",
      "Loss for batch 34 = 0.5154185891151428\n",
      "Loss for batch 35 = 0.4061308801174164\n",
      "Loss for batch 36 = 0.4342675507068634\n",
      "Loss for batch 37 = 0.5171169638633728\n",
      "Loss for batch 38 = 0.44103989005088806\n",
      "Loss for batch 39 = 0.4586445987224579\n",
      "Loss for batch 40 = 0.4639773964881897\n",
      "Loss for batch 41 = 0.4243921637535095\n",
      "Loss for batch 42 = 0.3361625075340271\n",
      "Loss for batch 43 = 0.4430690109729767\n",
      "Loss for batch 44 = 0.45512109994888306\n",
      "Loss for batch 45 = 0.4824892282485962\n",
      "Loss for batch 46 = 0.30832013487815857\n",
      "Loss for batch 47 = 0.3413325548171997\n",
      "Loss for batch 48 = 0.48340725898742676\n",
      "Loss for batch 49 = 0.4640780985355377\n",
      "Loss for batch 50 = 0.5729904174804688\n",
      "Loss for batch 51 = 0.4069880545139313\n",
      "Loss for batch 52 = 0.3542993366718292\n",
      "Loss for batch 53 = 0.18450912833213806\n",
      "Loss for batch 54 = 0.26924169063568115\n",
      "Loss for batch 55 = 0.5041753649711609\n",
      "Loss for batch 56 = 0.3900921940803528\n",
      "Loss for batch 57 = 0.41729000210762024\n",
      "Loss for batch 58 = 0.25903645157814026\n",
      "Loss for batch 59 = 0.33888572454452515\n",
      "Loss for batch 60 = 0.3221198320388794\n",
      "Loss for batch 61 = 0.403962105512619\n",
      "Loss for batch 62 = 0.18239225447177887\n",
      "Loss for batch 63 = 0.31078413128852844\n",
      "Loss for batch 64 = 0.4531455338001251\n",
      "Loss for batch 65 = 0.3894047737121582\n",
      "Loss for batch 66 = 0.30788224935531616\n",
      "Loss for batch 67 = 0.42153751850128174\n",
      "Loss for batch 68 = 0.3843759000301361\n",
      "Loss for batch 69 = 0.6978620886802673\n",
      "Loss for batch 70 = 0.77602618932724\n",
      "Loss for batch 71 = 0.2577919065952301\n",
      "Loss for batch 72 = 0.5529278516769409\n",
      "Loss for batch 73 = 0.20907515287399292\n",
      "Loss for batch 74 = 0.45551007986068726\n",
      "Loss for batch 75 = 0.3756900131702423\n",
      "Loss for batch 76 = 0.6647152304649353\n",
      "Loss for batch 77 = 0.3077693283557892\n",
      "Loss for batch 78 = 0.35221508145332336\n",
      "Loss for batch 79 = 0.4027950167655945\n",
      "Loss for batch 80 = 0.31534963846206665\n",
      "Loss for batch 81 = 0.353481262922287\n",
      "Loss for batch 82 = 0.41753849387168884\n",
      "Loss for batch 83 = 0.2713225185871124\n",
      "Loss for batch 84 = 0.253690630197525\n",
      "Loss for batch 85 = 0.43948879837989807\n",
      "Loss for batch 86 = 0.53171706199646\n",
      "Loss for batch 87 = 0.38075393438339233\n",
      "Loss for batch 88 = 0.2304026186466217\n",
      "Loss for batch 89 = 0.2322109490633011\n",
      "Loss for batch 90 = 0.302903950214386\n",
      "Loss for batch 91 = 0.35767096281051636\n",
      "Loss for batch 92 = 0.0797395184636116\n",
      "Loss for batch 93 = 0.550701916217804\n",
      "Loss for batch 94 = 0.3512805700302124\n",
      "Loss for batch 95 = 0.26706433296203613\n",
      "Loss for batch 96 = 0.22020170092582703\n",
      "Loss for batch 97 = 0.18681170046329498\n",
      "\n",
      "Training Loss for epoch 29 = 39.773216247558594\n",
      "\n",
      "Current Validation Loss = 32.91987991333008\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 15\n",
      "Train Accuracy: 81.80%\n",
      "Validation Accuracy: 61.36%\n",
      "\n",
      "Epoch 30\n",
      "----------\n",
      "Loss for batch 0 = 0.5572636127471924\n",
      "Loss for batch 1 = 0.396390825510025\n",
      "Loss for batch 2 = 0.30871886014938354\n",
      "Loss for batch 3 = 0.3773287534713745\n",
      "Loss for batch 4 = 0.3419903516769409\n",
      "Loss for batch 5 = 0.468490868806839\n",
      "Loss for batch 6 = 0.36405324935913086\n",
      "Loss for batch 7 = 0.5191100239753723\n",
      "Loss for batch 8 = 0.43933218717575073\n",
      "Loss for batch 9 = 0.5484386682510376\n",
      "Loss for batch 10 = 0.6596896648406982\n",
      "Loss for batch 11 = 0.46348583698272705\n",
      "Loss for batch 12 = 0.5199939608573914\n",
      "Loss for batch 13 = 0.72446608543396\n",
      "Loss for batch 14 = 0.2836953103542328\n",
      "Loss for batch 15 = 0.3052023649215698\n",
      "Loss for batch 16 = 0.3004680573940277\n",
      "Loss for batch 17 = 0.21685458719730377\n",
      "Loss for batch 18 = 0.3775162100791931\n",
      "Loss for batch 19 = 0.5070743560791016\n",
      "Loss for batch 20 = 0.384076327085495\n",
      "Loss for batch 21 = 0.38681745529174805\n",
      "Loss for batch 22 = 0.3971441984176636\n",
      "Loss for batch 23 = 0.2942270040512085\n",
      "Loss for batch 24 = 0.46203354001045227\n",
      "Loss for batch 25 = 0.3761885166168213\n",
      "Loss for batch 26 = 0.2571713924407959\n",
      "Loss for batch 27 = 0.3163168430328369\n",
      "Loss for batch 28 = 0.5067662000656128\n",
      "Loss for batch 29 = 0.4523523449897766\n",
      "Loss for batch 30 = 0.5776694416999817\n",
      "Loss for batch 31 = 0.4508596360683441\n",
      "Loss for batch 32 = 0.5894954800605774\n",
      "Loss for batch 33 = 0.3996112048625946\n",
      "Loss for batch 34 = 0.4625304043292999\n",
      "Loss for batch 35 = 0.3700379431247711\n",
      "Loss for batch 36 = 0.43010446429252625\n",
      "Loss for batch 37 = 0.49735432863235474\n",
      "Loss for batch 38 = 0.43994924426078796\n",
      "Loss for batch 39 = 0.46327120065689087\n",
      "Loss for batch 40 = 0.45583099126815796\n",
      "Loss for batch 41 = 0.40788114070892334\n",
      "Loss for batch 42 = 0.3341829478740692\n",
      "Loss for batch 43 = 0.41687697172164917\n",
      "Loss for batch 44 = 0.4605104327201843\n",
      "Loss for batch 45 = 0.44463208317756653\n",
      "Loss for batch 46 = 0.2578531503677368\n",
      "Loss for batch 47 = 0.32888561487197876\n",
      "Loss for batch 48 = 0.4360087513923645\n",
      "Loss for batch 49 = 0.4810752272605896\n",
      "Loss for batch 50 = 0.555998682975769\n",
      "Loss for batch 51 = 0.3623986542224884\n",
      "Loss for batch 52 = 0.3333011269569397\n",
      "Loss for batch 53 = 0.1813514679670334\n",
      "Loss for batch 54 = 0.2530776858329773\n",
      "Loss for batch 55 = 0.390520304441452\n",
      "Loss for batch 56 = 0.3989503085613251\n",
      "Loss for batch 57 = 0.40741610527038574\n",
      "Loss for batch 58 = 0.2574050724506378\n",
      "Loss for batch 59 = 0.3100394606590271\n",
      "Loss for batch 60 = 0.35535672307014465\n",
      "Loss for batch 61 = 0.38855069875717163\n",
      "Loss for batch 62 = 0.20016789436340332\n",
      "Loss for batch 63 = 0.2962968349456787\n",
      "Loss for batch 64 = 0.437000036239624\n",
      "Loss for batch 65 = 0.39510059356689453\n",
      "Loss for batch 66 = 0.3187519907951355\n",
      "Loss for batch 67 = 0.3484514653682709\n",
      "Loss for batch 68 = 0.38007214665412903\n",
      "Loss for batch 69 = 0.6763597726821899\n",
      "Loss for batch 70 = 0.7165710926055908\n",
      "Loss for batch 71 = 0.25349801778793335\n",
      "Loss for batch 72 = 0.5636128187179565\n",
      "Loss for batch 73 = 0.20787832140922546\n",
      "Loss for batch 74 = 0.47388923168182373\n",
      "Loss for batch 75 = 0.37115970253944397\n",
      "Loss for batch 76 = 0.6637389659881592\n",
      "Loss for batch 77 = 0.30673035979270935\n",
      "Loss for batch 78 = 0.33538684248924255\n",
      "Loss for batch 79 = 0.4072273075580597\n",
      "Loss for batch 80 = 0.2898347079753876\n",
      "Loss for batch 81 = 0.3408886790275574\n",
      "Loss for batch 82 = 0.41108739376068115\n",
      "Loss for batch 83 = 0.262508362531662\n",
      "Loss for batch 84 = 0.24854516983032227\n",
      "Loss for batch 85 = 0.4417327642440796\n",
      "Loss for batch 86 = 0.5258694887161255\n",
      "Loss for batch 87 = 0.3584688603878021\n",
      "Loss for batch 88 = 0.20765477418899536\n",
      "Loss for batch 89 = 0.22638344764709473\n",
      "Loss for batch 90 = 0.3072434961795807\n",
      "Loss for batch 91 = 0.3611573874950409\n",
      "Loss for batch 92 = 0.07157416641712189\n",
      "Loss for batch 93 = 0.5844260454177856\n",
      "Loss for batch 94 = 0.34418362379074097\n",
      "Loss for batch 95 = 0.26037734746932983\n",
      "Loss for batch 96 = 0.1970670223236084\n",
      "Loss for batch 97 = 0.1921105980873108\n",
      "\n",
      "Training Loss for epoch 30 = 38.394649505615234\n",
      "\n",
      "Current Validation Loss = 33.78429412841797\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 16\n",
      "Train Accuracy: 81.10%\n",
      "Validation Accuracy: 61.36%\n",
      "\n",
      "Epoch 31\n",
      "----------\n",
      "Loss for batch 0 = 0.5360015034675598\n",
      "Loss for batch 1 = 0.4928787052631378\n",
      "Loss for batch 2 = 0.2816260755062103\n",
      "Loss for batch 3 = 0.3811119794845581\n",
      "Loss for batch 4 = 0.33566775918006897\n",
      "Loss for batch 5 = 0.48094528913497925\n",
      "Loss for batch 6 = 0.36086133122444153\n",
      "Loss for batch 7 = 0.48636889457702637\n",
      "Loss for batch 8 = 0.4295550286769867\n",
      "Loss for batch 9 = 0.5154883861541748\n",
      "Loss for batch 10 = 0.6518610119819641\n",
      "Loss for batch 11 = 0.4613475799560547\n",
      "Loss for batch 12 = 0.5074360370635986\n",
      "Loss for batch 13 = 0.7267163395881653\n",
      "Loss for batch 14 = 0.26228728890419006\n",
      "Loss for batch 15 = 0.2957604229450226\n",
      "Loss for batch 16 = 0.3102509677410126\n",
      "Loss for batch 17 = 0.2802075743675232\n",
      "Loss for batch 18 = 0.3512420058250427\n",
      "Loss for batch 19 = 0.49661552906036377\n",
      "Loss for batch 20 = 0.3853411078453064\n",
      "Loss for batch 21 = 0.3579879403114319\n",
      "Loss for batch 22 = 0.391919881105423\n",
      "Loss for batch 23 = 0.266632616519928\n",
      "Loss for batch 24 = 0.4542553126811981\n",
      "Loss for batch 25 = 0.3590683937072754\n",
      "Loss for batch 26 = 0.23705324530601501\n",
      "Loss for batch 27 = 0.2932663559913635\n",
      "Loss for batch 28 = 0.4562426209449768\n",
      "Loss for batch 29 = 0.351505309343338\n",
      "Loss for batch 30 = 0.569205105304718\n",
      "Loss for batch 31 = 0.4627961218357086\n",
      "Loss for batch 32 = 0.615779459476471\n",
      "Loss for batch 33 = 0.36293622851371765\n",
      "Loss for batch 34 = 0.46798139810562134\n",
      "Loss for batch 35 = 0.3434903025627136\n",
      "Loss for batch 36 = 0.4158417582511902\n",
      "Loss for batch 37 = 0.483300119638443\n",
      "Loss for batch 38 = 0.4087078869342804\n",
      "Loss for batch 39 = 0.41070127487182617\n",
      "Loss for batch 40 = 0.4652077555656433\n",
      "Loss for batch 41 = 0.40341073274612427\n",
      "Loss for batch 42 = 0.33285608887672424\n",
      "Loss for batch 43 = 0.41043350100517273\n",
      "Loss for batch 44 = 0.4868730306625366\n",
      "Loss for batch 45 = 0.3996478021144867\n",
      "Loss for batch 46 = 0.2481072098016739\n",
      "Loss for batch 47 = 0.31174179911613464\n",
      "Loss for batch 48 = 0.4079928398132324\n",
      "Loss for batch 49 = 0.44530531764030457\n",
      "Loss for batch 50 = 0.48927539587020874\n",
      "Loss for batch 51 = 0.3438640832901001\n",
      "Loss for batch 52 = 0.3019636571407318\n",
      "Loss for batch 53 = 0.19333302974700928\n",
      "Loss for batch 54 = 0.2556426525115967\n",
      "Loss for batch 55 = 0.36574018001556396\n",
      "Loss for batch 56 = 0.3760416805744171\n",
      "Loss for batch 57 = 0.39846497774124146\n",
      "Loss for batch 58 = 0.23638592660427094\n",
      "Loss for batch 59 = 0.2716505527496338\n",
      "Loss for batch 60 = 0.31329119205474854\n",
      "Loss for batch 61 = 0.38009974360466003\n",
      "Loss for batch 62 = 0.16116993129253387\n",
      "Loss for batch 63 = 0.26806724071502686\n",
      "Loss for batch 64 = 0.43452662229537964\n",
      "Loss for batch 65 = 0.38306090235710144\n",
      "Loss for batch 66 = 0.3236309885978699\n",
      "Loss for batch 67 = 0.289245069026947\n",
      "Loss for batch 68 = 0.37712082266807556\n",
      "Loss for batch 69 = 0.6758322715759277\n",
      "Loss for batch 70 = 0.7457016110420227\n",
      "Loss for batch 71 = 0.2568986415863037\n",
      "Loss for batch 72 = 0.6207800507545471\n",
      "Loss for batch 73 = 0.3050563335418701\n",
      "Loss for batch 74 = 0.45765647292137146\n",
      "Loss for batch 75 = 0.44112715125083923\n",
      "Loss for batch 76 = 0.7449653148651123\n",
      "Loss for batch 77 = 0.32587292790412903\n",
      "Loss for batch 78 = 0.3557804524898529\n",
      "Loss for batch 79 = 0.3972592353820801\n",
      "Loss for batch 80 = 0.2902894914150238\n",
      "Loss for batch 81 = 0.337626576423645\n",
      "Loss for batch 82 = 0.42280006408691406\n",
      "Loss for batch 83 = 0.2722610533237457\n",
      "Loss for batch 84 = 0.26504096388816833\n",
      "Loss for batch 85 = 0.5242336988449097\n",
      "Loss for batch 86 = 0.5262535810470581\n",
      "Loss for batch 87 = 0.5517171025276184\n",
      "Loss for batch 88 = 0.2665727436542511\n",
      "Loss for batch 89 = 0.2350318282842636\n",
      "Loss for batch 90 = 0.30756786465644836\n",
      "Loss for batch 91 = 0.311302125453949\n",
      "Loss for batch 92 = 0.0874851644039154\n",
      "Loss for batch 93 = 0.6078910827636719\n",
      "Loss for batch 94 = 0.340038925409317\n",
      "Loss for batch 95 = 0.26227056980133057\n",
      "Loss for batch 96 = 0.27542904019355774\n",
      "Loss for batch 97 = 0.20056462287902832\n",
      "\n",
      "Training Loss for epoch 31 = 38.22370147705078\n",
      "\n",
      "Current Validation Loss = 34.615577697753906\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 17\n",
      "Train Accuracy: 78.82%\n",
      "Validation Accuracy: 60.98%\n",
      "\n",
      "Epoch 32\n",
      "----------\n",
      "Loss for batch 0 = 0.5731418132781982\n",
      "Loss for batch 1 = 0.4058477580547333\n",
      "Loss for batch 2 = 0.3346565067768097\n",
      "Loss for batch 3 = 0.3372570872306824\n",
      "Loss for batch 4 = 0.47919121384620667\n",
      "Loss for batch 5 = 0.5622588396072388\n",
      "Loss for batch 6 = 0.39545515179634094\n",
      "Loss for batch 7 = 0.5249090194702148\n",
      "Loss for batch 8 = 0.424386590719223\n",
      "Loss for batch 9 = 0.5285466909408569\n",
      "Loss for batch 10 = 0.6339658498764038\n",
      "Loss for batch 11 = 0.48703572154045105\n",
      "Loss for batch 12 = 0.6160091161727905\n",
      "Loss for batch 13 = 0.6393129825592041\n",
      "Loss for batch 14 = 0.27747124433517456\n",
      "Loss for batch 15 = 0.3144633173942566\n",
      "Loss for batch 16 = 0.3137144148349762\n",
      "Loss for batch 17 = 0.24655649065971375\n",
      "Loss for batch 18 = 0.3481651246547699\n",
      "Loss for batch 19 = 0.47313567996025085\n",
      "Loss for batch 20 = 0.3747609853744507\n",
      "Loss for batch 21 = 0.3434392511844635\n",
      "Loss for batch 22 = 0.38806208968162537\n",
      "Loss for batch 23 = 0.26138511300086975\n",
      "Loss for batch 24 = 0.47140470147132874\n",
      "Loss for batch 25 = 0.3804783821105957\n",
      "Loss for batch 26 = 0.23862892389297485\n",
      "Loss for batch 27 = 0.30848169326782227\n",
      "Loss for batch 28 = 0.42758676409721375\n",
      "Loss for batch 29 = 0.28161975741386414\n",
      "Loss for batch 30 = 0.5637485384941101\n",
      "Loss for batch 31 = 0.46145951747894287\n",
      "Loss for batch 32 = 0.5601404309272766\n",
      "Loss for batch 33 = 0.3976356089115143\n",
      "Loss for batch 34 = 0.46124550700187683\n",
      "Loss for batch 35 = 0.3436638414859772\n",
      "Loss for batch 36 = 0.4102652668952942\n",
      "Loss for batch 37 = 0.4826578199863434\n",
      "Loss for batch 38 = 0.4090796709060669\n",
      "Loss for batch 39 = 0.37564340233802795\n",
      "Loss for batch 40 = 0.4637790322303772\n",
      "Loss for batch 41 = 0.4361362159252167\n",
      "Loss for batch 42 = 0.37113648653030396\n",
      "Loss for batch 43 = 0.3905659317970276\n",
      "Loss for batch 44 = 0.5734758377075195\n",
      "Loss for batch 45 = 0.4005742073059082\n",
      "Loss for batch 46 = 0.2740374207496643\n",
      "Loss for batch 47 = 0.2868148982524872\n",
      "Loss for batch 48 = 0.45822471380233765\n",
      "Loss for batch 49 = 0.3927088975906372\n",
      "Loss for batch 50 = 0.4751390218734741\n",
      "Loss for batch 51 = 0.2958352565765381\n",
      "Loss for batch 52 = 0.29546505212783813\n",
      "Loss for batch 53 = 0.18141908943653107\n",
      "Loss for batch 54 = 0.25775784254074097\n",
      "Loss for batch 55 = 0.47526735067367554\n",
      "Loss for batch 56 = 0.3481023609638214\n",
      "Loss for batch 57 = 0.4046827554702759\n",
      "Loss for batch 58 = 0.23455598950386047\n",
      "Loss for batch 59 = 0.26683273911476135\n",
      "Loss for batch 60 = 0.31318122148513794\n",
      "Loss for batch 61 = 0.36702683568000793\n",
      "Loss for batch 62 = 0.12066221982240677\n",
      "Loss for batch 63 = 0.26118263602256775\n",
      "Loss for batch 64 = 0.46536263823509216\n",
      "Loss for batch 65 = 0.35920819640159607\n",
      "Loss for batch 66 = 0.3003433346748352\n",
      "Loss for batch 67 = 0.2693714499473572\n",
      "Loss for batch 68 = 0.3737645447254181\n",
      "Loss for batch 69 = 0.6518909931182861\n",
      "Loss for batch 70 = 0.7107415795326233\n",
      "Loss for batch 71 = 0.29350847005844116\n",
      "Loss for batch 72 = 0.5568099617958069\n",
      "Loss for batch 73 = 0.29467469453811646\n",
      "Loss for batch 74 = 0.4947400391101837\n",
      "Loss for batch 75 = 0.39825475215911865\n",
      "Loss for batch 76 = 0.6403580904006958\n",
      "Loss for batch 77 = 0.34265992045402527\n",
      "Loss for batch 78 = 0.41724693775177\n",
      "Loss for batch 79 = 0.4099019765853882\n",
      "Loss for batch 80 = 0.2891070544719696\n",
      "Loss for batch 81 = 0.3343299627304077\n",
      "Loss for batch 82 = 0.42335236072540283\n",
      "Loss for batch 83 = 0.2666802406311035\n",
      "Loss for batch 84 = 0.2638798952102661\n",
      "Loss for batch 85 = 0.47324028611183167\n",
      "Loss for batch 86 = 0.5052306652069092\n",
      "Loss for batch 87 = 0.3802506923675537\n",
      "Loss for batch 88 = 0.24702498316764832\n",
      "Loss for batch 89 = 0.23659659922122955\n",
      "Loss for batch 90 = 0.29760029911994934\n",
      "Loss for batch 91 = 0.3579225540161133\n",
      "Loss for batch 92 = 0.08900764584541321\n",
      "Loss for batch 93 = 0.6098089814186096\n",
      "Loss for batch 94 = 0.32682064175605774\n",
      "Loss for batch 95 = 0.26151159405708313\n",
      "Loss for batch 96 = 0.22993001341819763\n",
      "Loss for batch 97 = 0.18239732086658478\n",
      "\n",
      "Training Loss for epoch 32 = 37.95496368408203\n",
      "\n",
      "Current Validation Loss = 32.792701721191406\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 18\n",
      "Train Accuracy: 83.02%\n",
      "Validation Accuracy: 61.75%\n",
      "\n",
      "Epoch 33\n",
      "----------\n",
      "Loss for batch 0 = 0.5227646827697754\n",
      "Loss for batch 1 = 0.36657726764678955\n",
      "Loss for batch 2 = 0.32305434346199036\n",
      "Loss for batch 3 = 0.3243110179901123\n",
      "Loss for batch 4 = 0.33270910382270813\n",
      "Loss for batch 5 = 0.4947362244129181\n",
      "Loss for batch 6 = 0.3874814808368683\n",
      "Loss for batch 7 = 0.6617569327354431\n",
      "Loss for batch 8 = 0.414406955242157\n",
      "Loss for batch 9 = 0.4509420692920685\n",
      "Loss for batch 10 = 0.6368297338485718\n",
      "Loss for batch 11 = 0.5266232490539551\n",
      "Loss for batch 12 = 0.6426305174827576\n",
      "Loss for batch 13 = 0.587990403175354\n",
      "Loss for batch 14 = 0.2571021616458893\n",
      "Loss for batch 15 = 0.2956954538822174\n",
      "Loss for batch 16 = 0.2918635606765747\n",
      "Loss for batch 17 = 0.21306411921977997\n",
      "Loss for batch 18 = 0.31709372997283936\n",
      "Loss for batch 19 = 0.43324774503707886\n",
      "Loss for batch 20 = 0.35783901810646057\n",
      "Loss for batch 21 = 0.31740352511405945\n",
      "Loss for batch 22 = 0.36750200390815735\n",
      "Loss for batch 23 = 0.2426283359527588\n",
      "Loss for batch 24 = 0.4300503432750702\n",
      "Loss for batch 25 = 0.34092235565185547\n",
      "Loss for batch 26 = 0.21170341968536377\n",
      "Loss for batch 27 = 0.3074815571308136\n",
      "Loss for batch 28 = 0.4197189211845398\n",
      "Loss for batch 29 = 0.36124247312545776\n",
      "Loss for batch 30 = 0.5461791157722473\n",
      "Loss for batch 31 = 0.3977598249912262\n",
      "Loss for batch 32 = 0.5367213487625122\n",
      "Loss for batch 33 = 0.4198186695575714\n",
      "Loss for batch 34 = 0.460110068321228\n",
      "Loss for batch 35 = 0.33311277627944946\n",
      "Loss for batch 36 = 0.391056627035141\n",
      "Loss for batch 37 = 0.4678456485271454\n",
      "Loss for batch 38 = 0.40624338388442993\n",
      "Loss for batch 39 = 0.32053861021995544\n",
      "Loss for batch 40 = 0.4607079327106476\n",
      "Loss for batch 41 = 0.4160690903663635\n",
      "Loss for batch 42 = 0.3025999665260315\n",
      "Loss for batch 43 = 0.41217198967933655\n",
      "Loss for batch 44 = 0.4759632647037506\n",
      "Loss for batch 45 = 0.384724497795105\n",
      "Loss for batch 46 = 0.2980636954307556\n",
      "Loss for batch 47 = 0.298587441444397\n",
      "Loss for batch 48 = 0.41709020733833313\n",
      "Loss for batch 49 = 0.3928402066230774\n",
      "Loss for batch 50 = 0.4688569903373718\n",
      "Loss for batch 51 = 0.26713332533836365\n",
      "Loss for batch 52 = 0.3019421696662903\n",
      "Loss for batch 53 = 0.18676325678825378\n",
      "Loss for batch 54 = 0.2620007395744324\n",
      "Loss for batch 55 = 0.3450120687484741\n",
      "Loss for batch 56 = 0.33139097690582275\n",
      "Loss for batch 57 = 0.3800153136253357\n",
      "Loss for batch 58 = 0.2412947565317154\n",
      "Loss for batch 59 = 0.28010672330856323\n",
      "Loss for batch 60 = 0.3061441481113434\n",
      "Loss for batch 61 = 0.3791898190975189\n",
      "Loss for batch 62 = 0.1337565779685974\n",
      "Loss for batch 63 = 0.2817946970462799\n",
      "Loss for batch 64 = 0.4066283106803894\n",
      "Loss for batch 65 = 0.31807741522789\n",
      "Loss for batch 66 = 0.2878745198249817\n",
      "Loss for batch 67 = 0.30160409212112427\n",
      "Loss for batch 68 = 0.362448513507843\n",
      "Loss for batch 69 = 0.5835408568382263\n",
      "Loss for batch 70 = 0.6896676421165466\n",
      "Loss for batch 71 = 0.22247463464736938\n",
      "Loss for batch 72 = 0.5389509797096252\n",
      "Loss for batch 73 = 0.18246568739414215\n",
      "Loss for batch 74 = 0.4208701252937317\n",
      "Loss for batch 75 = 0.3977915644645691\n",
      "Loss for batch 76 = 0.625935435295105\n",
      "Loss for batch 77 = 0.3152315020561218\n",
      "Loss for batch 78 = 0.31232750415802\n",
      "Loss for batch 79 = 0.45268237590789795\n",
      "Loss for batch 80 = 0.30979326367378235\n",
      "Loss for batch 81 = 0.3222968578338623\n",
      "Loss for batch 82 = 0.40987440943717957\n",
      "Loss for batch 83 = 0.2767941355705261\n",
      "Loss for batch 84 = 0.2403773069381714\n",
      "Loss for batch 85 = 0.40593212842941284\n",
      "Loss for batch 86 = 0.5170201063156128\n",
      "Loss for batch 87 = 0.3943977355957031\n",
      "Loss for batch 88 = 0.23087289929389954\n",
      "Loss for batch 89 = 0.2332955002784729\n",
      "Loss for batch 90 = 0.3215673863887787\n",
      "Loss for batch 91 = 0.2998886704444885\n",
      "Loss for batch 92 = 0.06574710458517075\n",
      "Loss for batch 93 = 0.5452607274055481\n",
      "Loss for batch 94 = 0.3343088626861572\n",
      "Loss for batch 95 = 0.24139966070652008\n",
      "Loss for batch 96 = 0.18306392431259155\n",
      "Loss for batch 97 = 0.17615139484405518\n",
      "\n",
      "Training Loss for epoch 33 = 36.067588806152344\n",
      "\n",
      "Current Validation Loss = 32.95256423950195\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 19\n",
      "Train Accuracy: 83.25%\n",
      "Validation Accuracy: 61.49%\n",
      "\n",
      "Epoch 34\n",
      "----------\n",
      "Loss for batch 0 = 0.5122906565666199\n",
      "Loss for batch 1 = 0.3666585087776184\n",
      "Loss for batch 2 = 0.3016377091407776\n",
      "Loss for batch 3 = 0.2936493754386902\n",
      "Loss for batch 4 = 0.3321022093296051\n",
      "Loss for batch 5 = 0.41719117760658264\n",
      "Loss for batch 6 = 0.36271411180496216\n",
      "Loss for batch 7 = 0.6166746020317078\n",
      "Loss for batch 8 = 0.41032087802886963\n",
      "Loss for batch 9 = 0.46380317211151123\n",
      "Loss for batch 10 = 0.6364120244979858\n",
      "Loss for batch 11 = 0.5125027894973755\n",
      "Loss for batch 12 = 0.6035334467887878\n",
      "Loss for batch 13 = 0.5706834197044373\n",
      "Loss for batch 14 = 0.2500668168067932\n",
      "Loss for batch 15 = 0.2853415310382843\n",
      "Loss for batch 16 = 0.28950515389442444\n",
      "Loss for batch 17 = 0.2114265412092209\n",
      "Loss for batch 18 = 0.28358379006385803\n",
      "Loss for batch 19 = 0.4245239496231079\n",
      "Loss for batch 20 = 0.3202122747898102\n",
      "Loss for batch 21 = 0.2636791169643402\n",
      "Loss for batch 22 = 0.3496619462966919\n",
      "Loss for batch 23 = 0.24557848274707794\n",
      "Loss for batch 24 = 0.4321458041667938\n",
      "Loss for batch 25 = 0.32269489765167236\n",
      "Loss for batch 26 = 0.1810365468263626\n",
      "Loss for batch 27 = 0.3061482012271881\n",
      "Loss for batch 28 = 0.39011186361312866\n",
      "Loss for batch 29 = 0.3024638593196869\n",
      "Loss for batch 30 = 0.53912353515625\n",
      "Loss for batch 31 = 0.36747094988822937\n",
      "Loss for batch 32 = 0.5199061632156372\n",
      "Loss for batch 33 = 0.37101632356643677\n",
      "Loss for batch 34 = 0.43359506130218506\n",
      "Loss for batch 35 = 0.3263339102268219\n",
      "Loss for batch 36 = 0.3893119692802429\n",
      "Loss for batch 37 = 0.4703647196292877\n",
      "Loss for batch 38 = 0.38845428824424744\n",
      "Loss for batch 39 = 0.31309086084365845\n",
      "Loss for batch 40 = 0.4648074805736542\n",
      "Loss for batch 41 = 0.4117918014526367\n",
      "Loss for batch 42 = 0.28255218267440796\n",
      "Loss for batch 43 = 0.3747260570526123\n",
      "Loss for batch 44 = 0.4966750144958496\n",
      "Loss for batch 45 = 0.38546255230903625\n",
      "Loss for batch 46 = 0.2587105631828308\n",
      "Loss for batch 47 = 0.2811830937862396\n",
      "Loss for batch 48 = 0.4178209602832794\n",
      "Loss for batch 49 = 0.38819465041160583\n",
      "Loss for batch 50 = 0.46629393100738525\n",
      "Loss for batch 51 = 0.2558634877204895\n",
      "Loss for batch 52 = 0.29633477330207825\n",
      "Loss for batch 53 = 0.18284039199352264\n",
      "Loss for batch 54 = 0.2422475516796112\n",
      "Loss for batch 55 = 0.3361961841583252\n",
      "Loss for batch 56 = 0.32749125361442566\n",
      "Loss for batch 57 = 0.36797603964805603\n",
      "Loss for batch 58 = 0.22380776703357697\n",
      "Loss for batch 59 = 0.24366134405136108\n",
      "Loss for batch 60 = 0.30407387018203735\n",
      "Loss for batch 61 = 0.37922656536102295\n",
      "Loss for batch 62 = 0.12739510834217072\n",
      "Loss for batch 63 = 0.2901093661785126\n",
      "Loss for batch 64 = 0.4068233072757721\n",
      "Loss for batch 65 = 0.3145987093448639\n",
      "Loss for batch 66 = 0.28807997703552246\n",
      "Loss for batch 67 = 0.30672094225883484\n",
      "Loss for batch 68 = 0.3626904785633087\n",
      "Loss for batch 69 = 0.5968788266181946\n",
      "Loss for batch 70 = 0.6924949884414673\n",
      "Loss for batch 71 = 0.22037439048290253\n",
      "Loss for batch 72 = 0.526606559753418\n",
      "Loss for batch 73 = 0.18037967383861542\n",
      "Loss for batch 74 = 0.42018547654151917\n",
      "Loss for batch 75 = 0.38550305366516113\n",
      "Loss for batch 76 = 0.6088107824325562\n",
      "Loss for batch 77 = 0.3201946020126343\n",
      "Loss for batch 78 = 0.30189672112464905\n",
      "Loss for batch 79 = 0.3683702051639557\n",
      "Loss for batch 80 = 0.2997119724750519\n",
      "Loss for batch 81 = 0.3099408447742462\n",
      "Loss for batch 82 = 0.4109164774417877\n",
      "Loss for batch 83 = 0.25362077355384827\n",
      "Loss for batch 84 = 0.2563371956348419\n",
      "Loss for batch 85 = 0.40306219458580017\n",
      "Loss for batch 86 = 0.47185513377189636\n",
      "Loss for batch 87 = 0.3976564109325409\n",
      "Loss for batch 88 = 0.21158556640148163\n",
      "Loss for batch 89 = 0.23330701887607574\n",
      "Loss for batch 90 = 0.30951356887817383\n",
      "Loss for batch 91 = 0.2922823131084442\n",
      "Loss for batch 92 = 0.060392871499061584\n",
      "Loss for batch 93 = 0.5579511523246765\n",
      "Loss for batch 94 = 0.330542653799057\n",
      "Loss for batch 95 = 0.23914708197116852\n",
      "Loss for batch 96 = 0.17638640105724335\n",
      "Loss for batch 97 = 0.17716336250305176\n",
      "\n",
      "Training Loss for epoch 34 = 34.874454498291016\n",
      "\n",
      "Current Validation Loss = 33.84771728515625\n",
      "Best Validation Loss = 23.654874801635742\n",
      "Epochs without Improvement = 20\n",
      "Train Accuracy: 83.73%\n",
      "Validation Accuracy: 61.75%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TrainLoopText(text_modelv5, optimizer, loss_fn, train_loader, val_loader, scheduler, 100, 20, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.75%\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv5(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe5df07982046ecb185e106f7e47101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n",
      "----------\n",
      "Loss for batch 0 = 1.0995458364486694\n",
      "Loss for batch 1 = 1.1070764064788818\n",
      "Loss for batch 2 = 1.1017833948135376\n",
      "Loss for batch 3 = 1.1030775308609009\n",
      "Loss for batch 4 = 1.1020548343658447\n",
      "Loss for batch 5 = 1.0915840864181519\n",
      "Loss for batch 6 = 1.1061722040176392\n",
      "Loss for batch 7 = 1.101550817489624\n",
      "Loss for batch 8 = 1.1057859659194946\n",
      "Loss for batch 9 = 1.0973962545394897\n",
      "Loss for batch 10 = 1.0887336730957031\n",
      "Loss for batch 11 = 1.1021159887313843\n",
      "Loss for batch 12 = 1.0891231298446655\n",
      "Loss for batch 13 = 1.104174256324768\n",
      "Loss for batch 14 = 1.0841104984283447\n",
      "Loss for batch 15 = 1.1168212890625\n",
      "Loss for batch 16 = 1.1103835105895996\n",
      "Loss for batch 17 = 1.0997503995895386\n",
      "Loss for batch 18 = 1.0886342525482178\n",
      "Loss for batch 19 = 1.0996333360671997\n",
      "Loss for batch 20 = 1.1186861991882324\n",
      "Loss for batch 21 = 1.0967698097229004\n",
      "Loss for batch 22 = 1.0959604978561401\n",
      "Loss for batch 23 = 1.1032906770706177\n",
      "Loss for batch 24 = 1.0978248119354248\n",
      "Loss for batch 25 = 1.0941659212112427\n",
      "Loss for batch 26 = 1.0902893543243408\n",
      "Loss for batch 27 = 1.0901435613632202\n",
      "Loss for batch 28 = 1.0993289947509766\n",
      "Loss for batch 29 = 1.0855598449707031\n",
      "Loss for batch 30 = 1.0674690008163452\n",
      "Loss for batch 31 = 1.0874024629592896\n",
      "Loss for batch 32 = 1.1169615983963013\n",
      "Loss for batch 33 = 1.0863656997680664\n",
      "Loss for batch 34 = 1.0845789909362793\n",
      "Loss for batch 35 = 1.114417314529419\n",
      "Loss for batch 36 = 1.1093629598617554\n",
      "Loss for batch 37 = 1.0884747505187988\n",
      "Loss for batch 38 = 1.0659633874893188\n",
      "Loss for batch 39 = 1.1185615062713623\n",
      "Loss for batch 40 = 1.0893501043319702\n",
      "Loss for batch 41 = 1.126960277557373\n",
      "Loss for batch 42 = 1.0931211709976196\n",
      "Loss for batch 43 = 1.0956931114196777\n",
      "Loss for batch 44 = 1.1074533462524414\n",
      "Loss for batch 45 = 1.091457486152649\n",
      "Loss for batch 46 = 1.0983226299285889\n",
      "Loss for batch 47 = 1.0857268571853638\n",
      "Loss for batch 48 = 1.099768877029419\n",
      "Loss for batch 49 = 1.1095997095108032\n",
      "Loss for batch 50 = 1.089413046836853\n",
      "Loss for batch 51 = 1.0998402833938599\n",
      "Loss for batch 52 = 1.1006367206573486\n",
      "Loss for batch 53 = 1.082483172416687\n",
      "Loss for batch 54 = 1.0589311122894287\n",
      "Loss for batch 55 = 1.0707708597183228\n",
      "Loss for batch 56 = 1.1132558584213257\n",
      "Loss for batch 57 = 1.1034890413284302\n",
      "Loss for batch 58 = 1.0751370191574097\n",
      "Loss for batch 59 = 1.0889064073562622\n",
      "Loss for batch 60 = 1.0614579916000366\n",
      "Loss for batch 61 = 1.0519657135009766\n",
      "Loss for batch 62 = 1.1171224117279053\n",
      "Loss for batch 63 = 1.084578514099121\n",
      "Loss for batch 64 = 1.1169699430465698\n",
      "Loss for batch 65 = 1.0644934177398682\n",
      "Loss for batch 66 = 1.0813695192337036\n",
      "Loss for batch 67 = 1.0488011837005615\n",
      "Loss for batch 68 = 1.009566307067871\n",
      "Loss for batch 69 = 1.3468656539916992\n",
      "Loss for batch 70 = 1.0740233659744263\n",
      "Loss for batch 71 = 1.0586413145065308\n",
      "Loss for batch 72 = 1.1301003694534302\n",
      "Loss for batch 73 = 1.090639352798462\n",
      "Loss for batch 74 = 1.0832902193069458\n",
      "Loss for batch 75 = 1.1038602590560913\n",
      "Loss for batch 76 = 1.1129833459854126\n",
      "Loss for batch 77 = 1.0730953216552734\n",
      "Loss for batch 78 = 1.0866833925247192\n",
      "Loss for batch 79 = 1.0865379571914673\n",
      "Loss for batch 80 = 1.0850099325180054\n",
      "Loss for batch 81 = 1.046688199043274\n",
      "Loss for batch 82 = 1.0895253419876099\n",
      "Loss for batch 83 = 1.0019108057022095\n",
      "Loss for batch 84 = 0.9597926139831543\n",
      "Loss for batch 85 = 1.0906116962432861\n",
      "Loss for batch 86 = 1.167162537574768\n",
      "Loss for batch 87 = 1.047958254814148\n",
      "Loss for batch 88 = 1.1188267469406128\n",
      "Loss for batch 89 = 1.0842561721801758\n",
      "Loss for batch 90 = 1.0948758125305176\n",
      "Loss for batch 91 = 1.1032592058181763\n",
      "Loss for batch 92 = 1.1205791234970093\n",
      "Loss for batch 93 = 1.1140040159225464\n",
      "Loss for batch 94 = 1.097159743309021\n",
      "Loss for batch 95 = 1.0789979696273804\n",
      "Loss for batch 96 = 1.0713603496551514\n",
      "Loss for batch 97 = 1.1085838079452515\n",
      "\n",
      "Training Loss for epoch 0 = 107.15498352050781\n",
      "\n",
      "Current Validation Loss = 27.089214324951172\n",
      "Best Validation Loss = 27.089214324951172\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 42.20%\n",
      "Validation Accuracy: 40.44%\n",
      "\n",
      "Epoch 1\n",
      "----------\n",
      "Loss for batch 0 = 1.1069073677062988\n",
      "Loss for batch 1 = 1.0812418460845947\n",
      "Loss for batch 2 = 1.071004033088684\n",
      "Loss for batch 3 = 1.0567402839660645\n",
      "Loss for batch 4 = 1.059912919998169\n",
      "Loss for batch 5 = 1.0346755981445312\n",
      "Loss for batch 6 = 1.0900111198425293\n",
      "Loss for batch 7 = 1.1468535661697388\n",
      "Loss for batch 8 = 1.0811865329742432\n",
      "Loss for batch 9 = 1.0891176462173462\n",
      "Loss for batch 10 = 1.0696752071380615\n",
      "Loss for batch 11 = 1.1244196891784668\n",
      "Loss for batch 12 = 1.107253074645996\n",
      "Loss for batch 13 = 1.072850227355957\n",
      "Loss for batch 14 = 1.0334739685058594\n",
      "Loss for batch 15 = 1.103960394859314\n",
      "Loss for batch 16 = 1.120418667793274\n",
      "Loss for batch 17 = 1.1410351991653442\n",
      "Loss for batch 18 = 1.0692262649536133\n",
      "Loss for batch 19 = 1.0578163862228394\n",
      "Loss for batch 20 = 1.0832196474075317\n",
      "Loss for batch 21 = 1.068279504776001\n",
      "Loss for batch 22 = 1.0714988708496094\n",
      "Loss for batch 23 = 1.0767852067947388\n",
      "Loss for batch 24 = 1.0516753196716309\n",
      "Loss for batch 25 = 1.0175566673278809\n",
      "Loss for batch 26 = 1.0209331512451172\n",
      "Loss for batch 27 = 0.8994555473327637\n",
      "Loss for batch 28 = 1.1423423290252686\n",
      "Loss for batch 29 = 1.2085649967193604\n",
      "Loss for batch 30 = 0.9914190769195557\n",
      "Loss for batch 31 = 0.9688661098480225\n",
      "Loss for batch 32 = 1.125844955444336\n",
      "Loss for batch 33 = 1.0461746454238892\n",
      "Loss for batch 34 = 1.1315982341766357\n",
      "Loss for batch 35 = 1.0319578647613525\n",
      "Loss for batch 36 = 1.05673086643219\n",
      "Loss for batch 37 = 1.109464168548584\n",
      "Loss for batch 38 = 0.9946455955505371\n",
      "Loss for batch 39 = 1.1573340892791748\n",
      "Loss for batch 40 = 1.0901447534561157\n",
      "Loss for batch 41 = 1.1685521602630615\n",
      "Loss for batch 42 = 1.0725723505020142\n",
      "Loss for batch 43 = 1.0700350999832153\n",
      "Loss for batch 44 = 1.1151856184005737\n",
      "Loss for batch 45 = 1.1310863494873047\n",
      "Loss for batch 46 = 1.0750778913497925\n",
      "Loss for batch 47 = 1.0598540306091309\n",
      "Loss for batch 48 = 1.0899391174316406\n",
      "Loss for batch 49 = 1.1245958805084229\n",
      "Loss for batch 50 = 1.0909030437469482\n",
      "Loss for batch 51 = 1.0719448328018188\n",
      "Loss for batch 52 = 1.0782530307769775\n",
      "Loss for batch 53 = 1.0798530578613281\n",
      "Loss for batch 54 = 0.996045708656311\n",
      "Loss for batch 55 = 1.085483193397522\n",
      "Loss for batch 56 = 1.107014536857605\n",
      "Loss for batch 57 = 1.0808367729187012\n",
      "Loss for batch 58 = 1.00686514377594\n",
      "Loss for batch 59 = 1.113682746887207\n",
      "Loss for batch 60 = 1.0503602027893066\n",
      "Loss for batch 61 = 1.0307623147964478\n",
      "Loss for batch 62 = 1.0795434713363647\n",
      "Loss for batch 63 = 1.034499168395996\n",
      "Loss for batch 64 = 1.1231915950775146\n",
      "Loss for batch 65 = 1.022129774093628\n",
      "Loss for batch 66 = 1.0410469770431519\n",
      "Loss for batch 67 = 1.0147459506988525\n",
      "Loss for batch 68 = 1.010270118713379\n",
      "Loss for batch 69 = 1.1549811363220215\n",
      "Loss for batch 70 = 1.0956878662109375\n",
      "Loss for batch 71 = 1.053063154220581\n",
      "Loss for batch 72 = 1.0415942668914795\n",
      "Loss for batch 73 = 1.0512808561325073\n",
      "Loss for batch 74 = 1.1093584299087524\n",
      "Loss for batch 75 = 1.140307903289795\n",
      "Loss for batch 76 = 1.15170419216156\n",
      "Loss for batch 77 = 1.0359197854995728\n",
      "Loss for batch 78 = 1.0945876836776733\n",
      "Loss for batch 79 = 1.091362476348877\n",
      "Loss for batch 80 = 1.0751361846923828\n",
      "Loss for batch 81 = 1.019389033317566\n",
      "Loss for batch 82 = 1.0641233921051025\n",
      "Loss for batch 83 = 0.9943546652793884\n",
      "Loss for batch 84 = 0.973191499710083\n",
      "Loss for batch 85 = 1.1005007028579712\n",
      "Loss for batch 86 = 1.1182869672775269\n",
      "Loss for batch 87 = 1.0538479089736938\n",
      "Loss for batch 88 = 1.0459164381027222\n",
      "Loss for batch 89 = 1.0047341585159302\n",
      "Loss for batch 90 = 0.9872416853904724\n",
      "Loss for batch 91 = 1.01807701587677\n",
      "Loss for batch 92 = 1.0271284580230713\n",
      "Loss for batch 93 = 1.1161881685256958\n",
      "Loss for batch 94 = 1.0805308818817139\n",
      "Loss for batch 95 = 1.0946799516677856\n",
      "Loss for batch 96 = 1.1303879022598267\n",
      "Loss for batch 97 = 1.162993311882019\n",
      "\n",
      "Training Loss for epoch 1 = 105.17314910888672\n",
      "\n",
      "Current Validation Loss = 26.892330169677734\n",
      "Best Validation Loss = 26.892330169677734\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 37.48%\n",
      "Validation Accuracy: 38.51%\n",
      "\n",
      "Epoch 2\n",
      "----------\n",
      "Loss for batch 0 = 1.1013315916061401\n",
      "Loss for batch 1 = 1.095108151435852\n",
      "Loss for batch 2 = 1.0813345909118652\n",
      "Loss for batch 3 = 1.0721691846847534\n",
      "Loss for batch 4 = 1.1016638278961182\n",
      "Loss for batch 5 = 1.0632034540176392\n",
      "Loss for batch 6 = 1.0961393117904663\n",
      "Loss for batch 7 = 1.08367121219635\n",
      "Loss for batch 8 = 1.096367359161377\n",
      "Loss for batch 9 = 1.10386323928833\n",
      "Loss for batch 10 = 1.0857222080230713\n",
      "Loss for batch 11 = 1.1173274517059326\n",
      "Loss for batch 12 = 1.088834524154663\n",
      "Loss for batch 13 = 1.0828689336776733\n",
      "Loss for batch 14 = 1.0466630458831787\n",
      "Loss for batch 15 = 1.1007657051086426\n",
      "Loss for batch 16 = 1.0898756980895996\n",
      "Loss for batch 17 = 1.1214396953582764\n",
      "Loss for batch 18 = 1.080385446548462\n",
      "Loss for batch 19 = 1.0372601747512817\n",
      "Loss for batch 20 = 1.0484055280685425\n",
      "Loss for batch 21 = 1.0454376935958862\n",
      "Loss for batch 22 = 1.0657309293746948\n",
      "Loss for batch 23 = 1.068372368812561\n",
      "Loss for batch 24 = 1.0443798303604126\n",
      "Loss for batch 25 = 0.9793254137039185\n",
      "Loss for batch 26 = 0.9944353103637695\n",
      "Loss for batch 27 = 0.8844584822654724\n",
      "Loss for batch 28 = 1.0946775674819946\n",
      "Loss for batch 29 = 1.1725841760635376\n",
      "Loss for batch 30 = 0.9384863972663879\n",
      "Loss for batch 31 = 0.9361544847488403\n",
      "Loss for batch 32 = 1.138750672340393\n",
      "Loss for batch 33 = 1.0063214302062988\n",
      "Loss for batch 34 = 1.1470202207565308\n",
      "Loss for batch 35 = 1.0377346277236938\n",
      "Loss for batch 36 = 1.0505107641220093\n",
      "Loss for batch 37 = 1.102068543434143\n",
      "Loss for batch 38 = 0.9791846871376038\n",
      "Loss for batch 39 = 1.1348650455474854\n",
      "Loss for batch 40 = 1.0924798250198364\n",
      "Loss for batch 41 = 1.1895205974578857\n",
      "Loss for batch 42 = 1.0628559589385986\n",
      "Loss for batch 43 = 1.0651198625564575\n",
      "Loss for batch 44 = 1.1090606451034546\n",
      "Loss for batch 45 = 1.1355477571487427\n",
      "Loss for batch 46 = 1.0668599605560303\n",
      "Loss for batch 47 = 1.0284734964370728\n",
      "Loss for batch 48 = 1.1174274682998657\n",
      "Loss for batch 49 = 1.129134178161621\n",
      "Loss for batch 50 = 1.0908972024917603\n",
      "Loss for batch 51 = 1.0502047538757324\n",
      "Loss for batch 52 = 1.0791269540786743\n",
      "Loss for batch 53 = 1.0669628381729126\n",
      "Loss for batch 54 = 0.9719027280807495\n",
      "Loss for batch 55 = 1.0686641931533813\n",
      "Loss for batch 56 = 1.1393685340881348\n",
      "Loss for batch 57 = 1.0614112615585327\n",
      "Loss for batch 58 = 0.9633884429931641\n",
      "Loss for batch 59 = 1.1228625774383545\n",
      "Loss for batch 60 = 1.030503273010254\n",
      "Loss for batch 61 = 1.0310356616973877\n",
      "Loss for batch 62 = 1.0205092430114746\n",
      "Loss for batch 63 = 0.9710310697555542\n",
      "Loss for batch 64 = 1.113783597946167\n",
      "Loss for batch 65 = 1.0011972188949585\n",
      "Loss for batch 66 = 1.0959023237228394\n",
      "Loss for batch 67 = 1.033616304397583\n",
      "Loss for batch 68 = 0.9938979148864746\n",
      "Loss for batch 69 = 1.1015182733535767\n",
      "Loss for batch 70 = 1.075230360031128\n",
      "Loss for batch 71 = 1.0764782428741455\n",
      "Loss for batch 72 = 1.0057249069213867\n",
      "Loss for batch 73 = 1.0322084426879883\n",
      "Loss for batch 74 = 1.0740844011306763\n",
      "Loss for batch 75 = 1.128502607345581\n",
      "Loss for batch 76 = 1.1216613054275513\n",
      "Loss for batch 77 = 0.9765809178352356\n",
      "Loss for batch 78 = 1.1154309511184692\n",
      "Loss for batch 79 = 1.027909517288208\n",
      "Loss for batch 80 = 1.0636420249938965\n",
      "Loss for batch 81 = 0.9428194761276245\n",
      "Loss for batch 82 = 1.1346009969711304\n",
      "Loss for batch 83 = 0.9531950950622559\n",
      "Loss for batch 84 = 0.8831105828285217\n",
      "Loss for batch 85 = 0.9628371000289917\n",
      "Loss for batch 86 = 1.1357662677764893\n",
      "Loss for batch 87 = 1.02552330493927\n",
      "Loss for batch 88 = 1.0466084480285645\n",
      "Loss for batch 89 = 0.9612982869148254\n",
      "Loss for batch 90 = 0.9379197955131531\n",
      "Loss for batch 91 = 0.9214233756065369\n",
      "Loss for batch 92 = 1.0666931867599487\n",
      "Loss for batch 93 = 1.1101034879684448\n",
      "Loss for batch 94 = 1.034588098526001\n",
      "Loss for batch 95 = 1.0683914422988892\n",
      "Loss for batch 96 = 1.0214121341705322\n",
      "Loss for batch 97 = 1.0830482244491577\n",
      "\n",
      "Training Loss for epoch 2 = 103.60594177246094\n",
      "\n",
      "Current Validation Loss = 25.363086700439453\n",
      "Best Validation Loss = 25.363086700439453\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 51.06%\n",
      "Validation Accuracy: 47.37%\n",
      "\n",
      "Epoch 3\n",
      "----------\n",
      "Loss for batch 0 = 1.0642096996307373\n",
      "Loss for batch 1 = 0.9875818490982056\n",
      "Loss for batch 2 = 1.0030430555343628\n",
      "Loss for batch 3 = 0.9727631211280823\n",
      "Loss for batch 4 = 1.1015293598175049\n",
      "Loss for batch 5 = 1.0265717506408691\n",
      "Loss for batch 6 = 1.0512593984603882\n",
      "Loss for batch 7 = 1.115373969078064\n",
      "Loss for batch 8 = 1.0706616640090942\n",
      "Loss for batch 9 = 1.0494714975357056\n",
      "Loss for batch 10 = 1.0480070114135742\n",
      "Loss for batch 11 = 1.1361463069915771\n",
      "Loss for batch 12 = 1.0826690196990967\n",
      "Loss for batch 13 = 1.0958011150360107\n",
      "Loss for batch 14 = 1.0217094421386719\n",
      "Loss for batch 15 = 1.0528991222381592\n",
      "Loss for batch 16 = 1.0245006084442139\n",
      "Loss for batch 17 = 1.0671318769454956\n",
      "Loss for batch 18 = 1.0692355632781982\n",
      "Loss for batch 19 = 1.0283693075180054\n",
      "Loss for batch 20 = 0.8606289625167847\n",
      "Loss for batch 21 = 0.9898824691772461\n",
      "Loss for batch 22 = 0.9852581024169922\n",
      "Loss for batch 23 = 0.9245504140853882\n",
      "Loss for batch 24 = 0.9487591981887817\n",
      "Loss for batch 25 = 0.8110896944999695\n",
      "Loss for batch 26 = 1.030320167541504\n",
      "Loss for batch 27 = 0.7883689403533936\n",
      "Loss for batch 28 = 0.9835397005081177\n",
      "Loss for batch 29 = 1.2845027446746826\n",
      "Loss for batch 30 = 0.9415199756622314\n",
      "Loss for batch 31 = 0.9264209270477295\n",
      "Loss for batch 32 = 1.0524137020111084\n",
      "Loss for batch 33 = 1.01956307888031\n",
      "Loss for batch 34 = 0.9903774261474609\n",
      "Loss for batch 35 = 0.9643572568893433\n",
      "Loss for batch 36 = 1.0108217000961304\n",
      "Loss for batch 37 = 0.989190399646759\n",
      "Loss for batch 38 = 0.9316399097442627\n",
      "Loss for batch 39 = 1.0514471530914307\n",
      "Loss for batch 40 = 1.093392252922058\n",
      "Loss for batch 41 = 1.1315981149673462\n",
      "Loss for batch 42 = 1.0054441690444946\n",
      "Loss for batch 43 = 0.9527906179428101\n",
      "Loss for batch 44 = 1.0160256624221802\n",
      "Loss for batch 45 = 1.2141673564910889\n",
      "Loss for batch 46 = 0.9478203654289246\n",
      "Loss for batch 47 = 0.9883624315261841\n",
      "Loss for batch 48 = 1.2137844562530518\n",
      "Loss for batch 49 = 1.0816468000411987\n",
      "Loss for batch 50 = 1.0669081211090088\n",
      "Loss for batch 51 = 0.9740294218063354\n",
      "Loss for batch 52 = 0.9976351857185364\n",
      "Loss for batch 53 = 0.9745960235595703\n",
      "Loss for batch 54 = 0.8740769624710083\n",
      "Loss for batch 55 = 1.0386662483215332\n",
      "Loss for batch 56 = 1.101623773574829\n",
      "Loss for batch 57 = 0.9652055501937866\n",
      "Loss for batch 58 = 0.836458146572113\n",
      "Loss for batch 59 = 1.0635440349578857\n",
      "Loss for batch 60 = 0.9418414831161499\n",
      "Loss for batch 61 = 1.0612878799438477\n",
      "Loss for batch 62 = 0.8828287720680237\n",
      "Loss for batch 63 = 0.8512647747993469\n",
      "Loss for batch 64 = 1.0467406511306763\n",
      "Loss for batch 65 = 1.171275019645691\n",
      "Loss for batch 66 = 1.0533523559570312\n",
      "Loss for batch 67 = 0.9204974174499512\n",
      "Loss for batch 68 = 0.963681697845459\n",
      "Loss for batch 69 = 1.1029571294784546\n",
      "Loss for batch 70 = 1.0219019651412964\n",
      "Loss for batch 71 = 0.9559694528579712\n",
      "Loss for batch 72 = 1.023473858833313\n",
      "Loss for batch 73 = 0.9205829501152039\n",
      "Loss for batch 74 = 0.9792030453681946\n",
      "Loss for batch 75 = 1.033996820449829\n",
      "Loss for batch 76 = 1.267470121383667\n",
      "Loss for batch 77 = 0.9001041054725647\n",
      "Loss for batch 78 = 1.0769329071044922\n",
      "Loss for batch 79 = 0.9660618305206299\n",
      "Loss for batch 80 = 0.960588812828064\n",
      "Loss for batch 81 = 0.8466863036155701\n",
      "Loss for batch 82 = 1.0309138298034668\n",
      "Loss for batch 83 = 0.899833619594574\n",
      "Loss for batch 84 = 0.8646293878555298\n",
      "Loss for batch 85 = 0.9500513672828674\n",
      "Loss for batch 86 = 1.113149881362915\n",
      "Loss for batch 87 = 0.9493564367294312\n",
      "Loss for batch 88 = 0.8852776885032654\n",
      "Loss for batch 89 = 0.9963431358337402\n",
      "Loss for batch 90 = 0.837584912776947\n",
      "Loss for batch 91 = 0.7863509654998779\n",
      "Loss for batch 92 = 1.005178451538086\n",
      "Loss for batch 93 = 1.0567727088928223\n",
      "Loss for batch 94 = 0.9699239134788513\n",
      "Loss for batch 95 = 0.9560032486915588\n",
      "Loss for batch 96 = 0.8914169669151306\n",
      "Loss for batch 97 = 1.0123825073242188\n",
      "\n",
      "Training Loss for epoch 3 = 98.24522399902344\n",
      "\n",
      "Current Validation Loss = 24.58601188659668\n",
      "Best Validation Loss = 24.58601188659668\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 54.24%\n",
      "Validation Accuracy: 52.50%\n",
      "\n",
      "Epoch 4\n",
      "----------\n",
      "Loss for batch 0 = 0.9929400682449341\n",
      "Loss for batch 1 = 0.9280875325202942\n",
      "Loss for batch 2 = 1.0445334911346436\n",
      "Loss for batch 3 = 0.9159117937088013\n",
      "Loss for batch 4 = 1.0065183639526367\n",
      "Loss for batch 5 = 0.9261005520820618\n",
      "Loss for batch 6 = 0.9798518419265747\n",
      "Loss for batch 7 = 1.0593732595443726\n",
      "Loss for batch 8 = 0.9576619863510132\n",
      "Loss for batch 9 = 1.0525517463684082\n",
      "Loss for batch 10 = 1.0728415250778198\n",
      "Loss for batch 11 = 1.0466134548187256\n",
      "Loss for batch 12 = 1.1393204927444458\n",
      "Loss for batch 13 = 1.0697047710418701\n",
      "Loss for batch 14 = 0.8897550702095032\n",
      "Loss for batch 15 = 0.9543390870094299\n",
      "Loss for batch 16 = 0.9092720150947571\n",
      "Loss for batch 17 = 1.0172008275985718\n",
      "Loss for batch 18 = 1.1765260696411133\n",
      "Loss for batch 19 = 0.9824125170707703\n",
      "Loss for batch 20 = 0.7592781782150269\n",
      "Loss for batch 21 = 0.8680190443992615\n",
      "Loss for batch 22 = 0.9551523327827454\n",
      "Loss for batch 23 = 0.9021471738815308\n",
      "Loss for batch 24 = 0.9858034253120422\n",
      "Loss for batch 25 = 0.8102278113365173\n",
      "Loss for batch 26 = 1.0006953477859497\n",
      "Loss for batch 27 = 0.8667995929718018\n",
      "Loss for batch 28 = 0.9123328328132629\n",
      "Loss for batch 29 = 1.1075496673583984\n",
      "Loss for batch 30 = 0.9795454144477844\n",
      "Loss for batch 31 = 0.8585458397865295\n",
      "Loss for batch 32 = 1.00202214717865\n",
      "Loss for batch 33 = 1.020220160484314\n",
      "Loss for batch 34 = 0.9122927784919739\n",
      "Loss for batch 35 = 0.8816666603088379\n",
      "Loss for batch 36 = 0.9790457487106323\n",
      "Loss for batch 37 = 0.9410759806632996\n",
      "Loss for batch 38 = 0.9063351154327393\n",
      "Loss for batch 39 = 1.0208970308303833\n",
      "Loss for batch 40 = 0.9330177307128906\n",
      "Loss for batch 41 = 1.0669292211532593\n",
      "Loss for batch 42 = 0.9078330397605896\n",
      "Loss for batch 43 = 0.8729742765426636\n",
      "Loss for batch 44 = 0.9662867784500122\n",
      "Loss for batch 45 = 1.0644317865371704\n",
      "Loss for batch 46 = 0.8596450686454773\n",
      "Loss for batch 47 = 0.9163922071456909\n",
      "Loss for batch 48 = 1.0972387790679932\n",
      "Loss for batch 49 = 0.9665813446044922\n",
      "Loss for batch 50 = 0.9901496767997742\n",
      "Loss for batch 51 = 0.8879770040512085\n",
      "Loss for batch 52 = 0.8912619948387146\n",
      "Loss for batch 53 = 0.9104705452919006\n",
      "Loss for batch 54 = 0.8216609358787537\n",
      "Loss for batch 55 = 1.03799569606781\n",
      "Loss for batch 56 = 1.027400016784668\n",
      "Loss for batch 57 = 0.947780430316925\n",
      "Loss for batch 58 = 0.7875335216522217\n",
      "Loss for batch 59 = 1.0088627338409424\n",
      "Loss for batch 60 = 0.9488502740859985\n",
      "Loss for batch 61 = 0.9848562479019165\n",
      "Loss for batch 62 = 0.7915025353431702\n",
      "Loss for batch 63 = 0.8340672254562378\n",
      "Loss for batch 64 = 0.9815441966056824\n",
      "Loss for batch 65 = 0.9329874515533447\n",
      "Loss for batch 66 = 1.004990816116333\n",
      "Loss for batch 67 = 0.8528962731361389\n",
      "Loss for batch 68 = 0.964158296585083\n",
      "Loss for batch 69 = 0.9473439455032349\n",
      "Loss for batch 70 = 1.0312910079956055\n",
      "Loss for batch 71 = 0.8071070313453674\n",
      "Loss for batch 72 = 0.9612745046615601\n",
      "Loss for batch 73 = 0.8146541118621826\n",
      "Loss for batch 74 = 0.9440363049507141\n",
      "Loss for batch 75 = 1.178170919418335\n",
      "Loss for batch 76 = 1.0733842849731445\n",
      "Loss for batch 77 = 0.8841704726219177\n",
      "Loss for batch 78 = 1.071344256401062\n",
      "Loss for batch 79 = 1.0059809684753418\n",
      "Loss for batch 80 = 0.9120328426361084\n",
      "Loss for batch 81 = 0.961501955986023\n",
      "Loss for batch 82 = 1.0329275131225586\n",
      "Loss for batch 83 = 0.8888065814971924\n",
      "Loss for batch 84 = 0.7284001111984253\n",
      "Loss for batch 85 = 0.9905238747596741\n",
      "Loss for batch 86 = 1.0468976497650146\n",
      "Loss for batch 87 = 0.9555826783180237\n",
      "Loss for batch 88 = 0.8337825536727905\n",
      "Loss for batch 89 = 0.8590863347053528\n",
      "Loss for batch 90 = 0.8117151856422424\n",
      "Loss for batch 91 = 0.7744089365005493\n",
      "Loss for batch 92 = 0.9264317154884338\n",
      "Loss for batch 93 = 0.930732011795044\n",
      "Loss for batch 94 = 1.1071535348892212\n",
      "Loss for batch 95 = 0.9080753922462463\n",
      "Loss for batch 96 = 0.8278219103813171\n",
      "Loss for batch 97 = 0.9204406142234802\n",
      "\n",
      "Training Loss for epoch 4 = 93.18450927734375\n",
      "\n",
      "Current Validation Loss = 23.591228485107422\n",
      "Best Validation Loss = 23.591228485107422\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 57.83%\n",
      "Validation Accuracy: 55.46%\n",
      "\n",
      "Epoch 5\n",
      "----------\n",
      "Loss for batch 0 = 0.8998565077781677\n",
      "Loss for batch 1 = 0.8866069912910461\n",
      "Loss for batch 2 = 0.9564897418022156\n",
      "Loss for batch 3 = 0.8464695811271667\n",
      "Loss for batch 4 = 0.8407889604568481\n",
      "Loss for batch 5 = 1.0062929391860962\n",
      "Loss for batch 6 = 0.9772287607192993\n",
      "Loss for batch 7 = 1.081045389175415\n",
      "Loss for batch 8 = 0.9085180163383484\n",
      "Loss for batch 9 = 1.013617992401123\n",
      "Loss for batch 10 = 1.0949149131774902\n",
      "Loss for batch 11 = 0.9922165870666504\n",
      "Loss for batch 12 = 1.0442007780075073\n",
      "Loss for batch 13 = 1.1478935480117798\n",
      "Loss for batch 14 = 0.9301766753196716\n",
      "Loss for batch 15 = 0.982352077960968\n",
      "Loss for batch 16 = 0.9216699600219727\n",
      "Loss for batch 17 = 0.9758224487304688\n",
      "Loss for batch 18 = 0.9952465295791626\n",
      "Loss for batch 19 = 0.9343911409378052\n",
      "Loss for batch 20 = 0.6573402285575867\n",
      "Loss for batch 21 = 0.8616364598274231\n",
      "Loss for batch 22 = 0.8707171082496643\n",
      "Loss for batch 23 = 0.8141066431999207\n",
      "Loss for batch 24 = 0.8869997262954712\n",
      "Loss for batch 25 = 0.7226725816726685\n",
      "Loss for batch 26 = 0.8768101334571838\n",
      "Loss for batch 27 = 0.804024338722229\n",
      "Loss for batch 28 = 0.8917249441146851\n",
      "Loss for batch 29 = 1.0605536699295044\n",
      "Loss for batch 30 = 0.9246213436126709\n",
      "Loss for batch 31 = 0.6913652420043945\n",
      "Loss for batch 32 = 0.9620427489280701\n",
      "Loss for batch 33 = 0.9196073412895203\n",
      "Loss for batch 34 = 0.918316662311554\n",
      "Loss for batch 35 = 0.8084027767181396\n",
      "Loss for batch 36 = 0.9389180541038513\n",
      "Loss for batch 37 = 0.9408207535743713\n",
      "Loss for batch 38 = 0.8430122137069702\n",
      "Loss for batch 39 = 0.9766658544540405\n",
      "Loss for batch 40 = 0.9205029606819153\n",
      "Loss for batch 41 = 1.0324671268463135\n",
      "Loss for batch 42 = 0.8779392242431641\n",
      "Loss for batch 43 = 0.8745175004005432\n",
      "Loss for batch 44 = 1.0053871870040894\n",
      "Loss for batch 45 = 1.045932412147522\n",
      "Loss for batch 46 = 0.8134889006614685\n",
      "Loss for batch 47 = 0.8496081829071045\n",
      "Loss for batch 48 = 1.1586090326309204\n",
      "Loss for batch 49 = 1.0410853624343872\n",
      "Loss for batch 50 = 0.9712519645690918\n",
      "Loss for batch 51 = 0.7967356443405151\n",
      "Loss for batch 52 = 0.8645769357681274\n",
      "Loss for batch 53 = 0.9226048588752747\n",
      "Loss for batch 54 = 0.7595272660255432\n",
      "Loss for batch 55 = 0.9942044615745544\n",
      "Loss for batch 56 = 1.0066919326782227\n",
      "Loss for batch 57 = 0.880482017993927\n",
      "Loss for batch 58 = 0.75295090675354\n",
      "Loss for batch 59 = 1.0075538158416748\n",
      "Loss for batch 60 = 0.9347866773605347\n",
      "Loss for batch 61 = 0.9355619549751282\n",
      "Loss for batch 62 = 0.7554154992103577\n",
      "Loss for batch 63 = 0.8020449876785278\n",
      "Loss for batch 64 = 0.9902904033660889\n",
      "Loss for batch 65 = 0.9102304577827454\n",
      "Loss for batch 66 = 0.910210907459259\n",
      "Loss for batch 67 = 0.7040566205978394\n",
      "Loss for batch 68 = 0.8394197225570679\n",
      "Loss for batch 69 = 1.1346615552902222\n",
      "Loss for batch 70 = 1.0108394622802734\n",
      "Loss for batch 71 = 0.8903392553329468\n",
      "Loss for batch 72 = 0.9452664256095886\n",
      "Loss for batch 73 = 0.968653678894043\n",
      "Loss for batch 74 = 0.878577470779419\n",
      "Loss for batch 75 = 1.0923256874084473\n",
      "Loss for batch 76 = 1.2047287225723267\n",
      "Loss for batch 77 = 1.0084689855575562\n",
      "Loss for batch 78 = 1.0716562271118164\n",
      "Loss for batch 79 = 1.0182281732559204\n",
      "Loss for batch 80 = 0.9589366912841797\n",
      "Loss for batch 81 = 0.8649663329124451\n",
      "Loss for batch 82 = 0.9701902866363525\n",
      "Loss for batch 83 = 0.9415698051452637\n",
      "Loss for batch 84 = 0.8578592538833618\n",
      "Loss for batch 85 = 0.9571669697761536\n",
      "Loss for batch 86 = 0.9602065086364746\n",
      "Loss for batch 87 = 0.9342431426048279\n",
      "Loss for batch 88 = 0.9037166833877563\n",
      "Loss for batch 89 = 0.8548309206962585\n",
      "Loss for batch 90 = 0.949665904045105\n",
      "Loss for batch 91 = 0.7595545649528503\n",
      "Loss for batch 92 = 0.9635990262031555\n",
      "Loss for batch 93 = 1.09906005859375\n",
      "Loss for batch 94 = 0.9524496793746948\n",
      "Loss for batch 95 = 0.826305091381073\n",
      "Loss for batch 96 = 0.8064329028129578\n",
      "Loss for batch 97 = 0.9936795234680176\n",
      "\n",
      "Training Loss for epoch 5 = 90.94246673583984\n",
      "\n",
      "Current Validation Loss = 24.160032272338867\n",
      "Best Validation Loss = 23.591228485107422\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 54.81%\n",
      "Validation Accuracy: 51.35%\n",
      "\n",
      "Epoch 6\n",
      "----------\n",
      "Loss for batch 0 = 0.9183939695358276\n",
      "Loss for batch 1 = 0.9616108536720276\n",
      "Loss for batch 2 = 0.9396383166313171\n",
      "Loss for batch 3 = 0.845110297203064\n",
      "Loss for batch 4 = 0.9360225796699524\n",
      "Loss for batch 5 = 0.919897735118866\n",
      "Loss for batch 6 = 0.9639939069747925\n",
      "Loss for batch 7 = 1.1003131866455078\n",
      "Loss for batch 8 = 0.8567575216293335\n",
      "Loss for batch 9 = 1.0296640396118164\n",
      "Loss for batch 10 = 1.0702767372131348\n",
      "Loss for batch 11 = 0.9669699668884277\n",
      "Loss for batch 12 = 1.0064232349395752\n",
      "Loss for batch 13 = 1.0000898838043213\n",
      "Loss for batch 14 = 0.9051576256752014\n",
      "Loss for batch 15 = 0.898206353187561\n",
      "Loss for batch 16 = 0.8948715925216675\n",
      "Loss for batch 17 = 0.8684654235839844\n",
      "Loss for batch 18 = 0.9448901414871216\n",
      "Loss for batch 19 = 0.9974252581596375\n",
      "Loss for batch 20 = 0.6128333806991577\n",
      "Loss for batch 21 = 0.8578233122825623\n",
      "Loss for batch 22 = 0.8754744529724121\n",
      "Loss for batch 23 = 0.8100425004959106\n",
      "Loss for batch 24 = 0.9102550148963928\n",
      "Loss for batch 25 = 0.7458972930908203\n",
      "Loss for batch 26 = 1.0052342414855957\n",
      "Loss for batch 27 = 0.8403925895690918\n",
      "Loss for batch 28 = 0.9333686232566833\n",
      "Loss for batch 29 = 0.9422736167907715\n",
      "Loss for batch 30 = 0.9803417325019836\n",
      "Loss for batch 31 = 0.7045155167579651\n",
      "Loss for batch 32 = 0.9366990327835083\n",
      "Loss for batch 33 = 1.035319209098816\n",
      "Loss for batch 34 = 0.8805914521217346\n",
      "Loss for batch 35 = 0.8383430242538452\n",
      "Loss for batch 36 = 0.9333839416503906\n",
      "Loss for batch 37 = 0.8635387420654297\n",
      "Loss for batch 38 = 0.9236838817596436\n",
      "Loss for batch 39 = 0.9451230764389038\n",
      "Loss for batch 40 = 0.9608039259910583\n",
      "Loss for batch 41 = 1.1073187589645386\n",
      "Loss for batch 42 = 0.9026442170143127\n",
      "Loss for batch 43 = 0.850062370300293\n",
      "Loss for batch 44 = 0.9464322328567505\n",
      "Loss for batch 45 = 0.8921051621437073\n",
      "Loss for batch 46 = 0.8562888503074646\n",
      "Loss for batch 47 = 0.8958439230918884\n",
      "Loss for batch 48 = 1.0047963857650757\n",
      "Loss for batch 49 = 0.8798395395278931\n",
      "Loss for batch 50 = 0.9516814947128296\n",
      "Loss for batch 51 = 0.8203336000442505\n",
      "Loss for batch 52 = 0.7895886898040771\n",
      "Loss for batch 53 = 0.8813637495040894\n",
      "Loss for batch 54 = 0.7652170658111572\n",
      "Loss for batch 55 = 0.9345144629478455\n",
      "Loss for batch 56 = 1.0002115964889526\n",
      "Loss for batch 57 = 0.8972432613372803\n",
      "Loss for batch 58 = 0.7478627562522888\n",
      "Loss for batch 59 = 1.0855493545532227\n",
      "Loss for batch 60 = 0.8666989207267761\n",
      "Loss for batch 61 = 0.909806489944458\n",
      "Loss for batch 62 = 0.7267546653747559\n",
      "Loss for batch 63 = 0.7573976516723633\n",
      "Loss for batch 64 = 0.9258379936218262\n",
      "Loss for batch 65 = 0.9101330041885376\n",
      "Loss for batch 66 = 1.0194278955459595\n",
      "Loss for batch 67 = 0.7499082088470459\n",
      "Loss for batch 68 = 0.7588376402854919\n",
      "Loss for batch 69 = 0.9215210676193237\n",
      "Loss for batch 70 = 0.9530638456344604\n",
      "Loss for batch 71 = 0.8012738823890686\n",
      "Loss for batch 72 = 0.853119432926178\n",
      "Loss for batch 73 = 0.8629822134971619\n",
      "Loss for batch 74 = 0.8604889512062073\n",
      "Loss for batch 75 = 1.0181657075881958\n",
      "Loss for batch 76 = 1.0915708541870117\n",
      "Loss for batch 77 = 0.7749954462051392\n",
      "Loss for batch 78 = 1.0381441116333008\n",
      "Loss for batch 79 = 0.9000784158706665\n",
      "Loss for batch 80 = 0.8828195333480835\n",
      "Loss for batch 81 = 0.8426879644393921\n",
      "Loss for batch 82 = 0.8174211978912354\n",
      "Loss for batch 83 = 0.7670224905014038\n",
      "Loss for batch 84 = 0.620194137096405\n",
      "Loss for batch 85 = 0.9108179211616516\n",
      "Loss for batch 86 = 1.013514518737793\n",
      "Loss for batch 87 = 0.8609926700592041\n",
      "Loss for batch 88 = 0.7450289726257324\n",
      "Loss for batch 89 = 0.8254679441452026\n",
      "Loss for batch 90 = 0.7098587155342102\n",
      "Loss for batch 91 = 0.6986318230628967\n",
      "Loss for batch 92 = 0.8338268995285034\n",
      "Loss for batch 93 = 0.8552474975585938\n",
      "Loss for batch 94 = 0.7705880403518677\n",
      "Loss for batch 95 = 0.8078994750976562\n",
      "Loss for batch 96 = 0.7033284306526184\n",
      "Loss for batch 97 = 0.9580095410346985\n",
      "\n",
      "Training Loss for epoch 6 = 87.09258270263672\n",
      "\n",
      "Current Validation Loss = 23.344860076904297\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 0\n",
      "Train Accuracy: 60.14%\n",
      "Validation Accuracy: 57.64%\n",
      "\n",
      "Epoch 7\n",
      "----------\n",
      "Loss for batch 0 = 0.8406984210014343\n",
      "Loss for batch 1 = 0.8423002362251282\n",
      "Loss for batch 2 = 0.9103326201438904\n",
      "Loss for batch 3 = 0.8167470693588257\n",
      "Loss for batch 4 = 0.9090088605880737\n",
      "Loss for batch 5 = 0.8183703422546387\n",
      "Loss for batch 6 = 0.9358880519866943\n",
      "Loss for batch 7 = 1.0597336292266846\n",
      "Loss for batch 8 = 0.8731604814529419\n",
      "Loss for batch 9 = 0.9938479661941528\n",
      "Loss for batch 10 = 1.122453212738037\n",
      "Loss for batch 11 = 0.862013578414917\n",
      "Loss for batch 12 = 1.0554039478302002\n",
      "Loss for batch 13 = 1.0898312330245972\n",
      "Loss for batch 14 = 0.9430175423622131\n",
      "Loss for batch 15 = 0.8624939322471619\n",
      "Loss for batch 16 = 0.8584749698638916\n",
      "Loss for batch 17 = 0.8634498715400696\n",
      "Loss for batch 18 = 0.9072006940841675\n",
      "Loss for batch 19 = 0.8713331818580627\n",
      "Loss for batch 20 = 0.5828197002410889\n",
      "Loss for batch 21 = 0.8833757638931274\n",
      "Loss for batch 22 = 0.838205099105835\n",
      "Loss for batch 23 = 0.8354379534721375\n",
      "Loss for batch 24 = 0.7911601662635803\n",
      "Loss for batch 25 = 0.6672531962394714\n",
      "Loss for batch 26 = 0.8775956630706787\n",
      "Loss for batch 27 = 0.8010433316230774\n",
      "Loss for batch 28 = 0.8942976593971252\n",
      "Loss for batch 29 = 0.9715197682380676\n",
      "Loss for batch 30 = 0.9362366795539856\n",
      "Loss for batch 31 = 0.661534309387207\n",
      "Loss for batch 32 = 0.9128474593162537\n",
      "Loss for batch 33 = 0.9688332676887512\n",
      "Loss for batch 34 = 0.9057989716529846\n",
      "Loss for batch 35 = 0.718634307384491\n",
      "Loss for batch 36 = 0.8722007274627686\n",
      "Loss for batch 37 = 0.9096238613128662\n",
      "Loss for batch 38 = 0.7932184934616089\n",
      "Loss for batch 39 = 0.959791362285614\n",
      "Loss for batch 40 = 0.9176511168479919\n",
      "Loss for batch 41 = 1.0273069143295288\n",
      "Loss for batch 42 = 0.8024861812591553\n",
      "Loss for batch 43 = 0.7571532726287842\n",
      "Loss for batch 44 = 0.9701848030090332\n",
      "Loss for batch 45 = 0.8913038372993469\n",
      "Loss for batch 46 = 0.7997166514396667\n",
      "Loss for batch 47 = 0.8180477619171143\n",
      "Loss for batch 48 = 1.002001166343689\n",
      "Loss for batch 49 = 0.9067013263702393\n",
      "Loss for batch 50 = 0.9077556729316711\n",
      "Loss for batch 51 = 0.7604144811630249\n",
      "Loss for batch 52 = 0.7741619348526001\n",
      "Loss for batch 53 = 0.8620391488075256\n",
      "Loss for batch 54 = 0.6657922267913818\n",
      "Loss for batch 55 = 0.9656553268432617\n",
      "Loss for batch 56 = 0.8988485336303711\n",
      "Loss for batch 57 = 0.8465233445167542\n",
      "Loss for batch 58 = 0.6849828958511353\n",
      "Loss for batch 59 = 1.0855274200439453\n",
      "Loss for batch 60 = 0.839912474155426\n",
      "Loss for batch 61 = 0.8751686811447144\n",
      "Loss for batch 62 = 0.7138072848320007\n",
      "Loss for batch 63 = 0.7301751971244812\n",
      "Loss for batch 64 = 0.8159352540969849\n",
      "Loss for batch 65 = 0.8792334794998169\n",
      "Loss for batch 66 = 0.8738046884536743\n",
      "Loss for batch 67 = 0.6805569529533386\n",
      "Loss for batch 68 = 0.7489915490150452\n",
      "Loss for batch 69 = 0.9396454691886902\n",
      "Loss for batch 70 = 1.0039433240890503\n",
      "Loss for batch 71 = 0.64971923828125\n",
      "Loss for batch 72 = 0.8669595718383789\n",
      "Loss for batch 73 = 0.9635575413703918\n",
      "Loss for batch 74 = 0.8660032153129578\n",
      "Loss for batch 75 = 0.9978174567222595\n",
      "Loss for batch 76 = 0.9578111171722412\n",
      "Loss for batch 77 = 0.760129988193512\n",
      "Loss for batch 78 = 1.1138509511947632\n",
      "Loss for batch 79 = 0.9397880434989929\n",
      "Loss for batch 80 = 0.7796891927719116\n",
      "Loss for batch 81 = 0.7939426898956299\n",
      "Loss for batch 82 = 0.7685854434967041\n",
      "Loss for batch 83 = 0.7771641612052917\n",
      "Loss for batch 84 = 0.7334645390510559\n",
      "Loss for batch 85 = 0.8059108257293701\n",
      "Loss for batch 86 = 1.0253392457962036\n",
      "Loss for batch 87 = 0.8877658247947693\n",
      "Loss for batch 88 = 0.7734097242355347\n",
      "Loss for batch 89 = 0.7513465881347656\n",
      "Loss for batch 90 = 0.7087602019309998\n",
      "Loss for batch 91 = 0.7415212392807007\n",
      "Loss for batch 92 = 0.9120104312896729\n",
      "Loss for batch 93 = 0.9005091786384583\n",
      "Loss for batch 94 = 0.8160984516143799\n",
      "Loss for batch 95 = 0.7021788358688354\n",
      "Loss for batch 96 = 0.7779427766799927\n",
      "Loss for batch 97 = 0.9617263674736023\n",
      "\n",
      "Training Loss for epoch 7 = 84.39562225341797\n",
      "\n",
      "Current Validation Loss = 24.998512268066406\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 1\n",
      "Train Accuracy: 60.08%\n",
      "Validation Accuracy: 55.33%\n",
      "\n",
      "Epoch 8\n",
      "----------\n",
      "Loss for batch 0 = 0.7957682013511658\n",
      "Loss for batch 1 = 0.7685514688491821\n",
      "Loss for batch 2 = 0.8822991847991943\n",
      "Loss for batch 3 = 0.7720993757247925\n",
      "Loss for batch 4 = 0.8318081498146057\n",
      "Loss for batch 5 = 0.7889378070831299\n",
      "Loss for batch 6 = 0.871601939201355\n",
      "Loss for batch 7 = 0.9860687851905823\n",
      "Loss for batch 8 = 0.8626300692558289\n",
      "Loss for batch 9 = 0.9737492203712463\n",
      "Loss for batch 10 = 1.0839132070541382\n",
      "Loss for batch 11 = 0.9067800045013428\n",
      "Loss for batch 12 = 0.9648387432098389\n",
      "Loss for batch 13 = 1.0587375164031982\n",
      "Loss for batch 14 = 0.9088457822799683\n",
      "Loss for batch 15 = 0.8631406426429749\n",
      "Loss for batch 16 = 0.8213720321655273\n",
      "Loss for batch 17 = 0.8124420642852783\n",
      "Loss for batch 18 = 0.8562768697738647\n",
      "Loss for batch 19 = 0.7649682760238647\n",
      "Loss for batch 20 = 0.5429984927177429\n",
      "Loss for batch 21 = 0.7243184447288513\n",
      "Loss for batch 22 = 0.7471597790718079\n",
      "Loss for batch 23 = 0.7833379507064819\n",
      "Loss for batch 24 = 0.8601883053779602\n",
      "Loss for batch 25 = 0.6170986294746399\n",
      "Loss for batch 26 = 0.7724655270576477\n",
      "Loss for batch 27 = 0.6790032386779785\n",
      "Loss for batch 28 = 0.8520205020904541\n",
      "Loss for batch 29 = 1.055281400680542\n",
      "Loss for batch 30 = 0.8933928608894348\n",
      "Loss for batch 31 = 0.6336844563484192\n",
      "Loss for batch 32 = 0.8347314596176147\n",
      "Loss for batch 33 = 0.8283053040504456\n",
      "Loss for batch 34 = 0.8896462321281433\n",
      "Loss for batch 35 = 0.6808879971504211\n",
      "Loss for batch 36 = 0.8664044737815857\n",
      "Loss for batch 37 = 0.8312100768089294\n",
      "Loss for batch 38 = 0.7770342826843262\n",
      "Loss for batch 39 = 0.9881883859634399\n",
      "Loss for batch 40 = 0.8385562896728516\n",
      "Loss for batch 41 = 1.047309160232544\n",
      "Loss for batch 42 = 0.7822118997573853\n",
      "Loss for batch 43 = 0.7300769090652466\n",
      "Loss for batch 44 = 0.9156334400177002\n",
      "Loss for batch 45 = 0.866052508354187\n",
      "Loss for batch 46 = 0.7252333164215088\n",
      "Loss for batch 47 = 0.7262046933174133\n",
      "Loss for batch 48 = 1.0255281925201416\n",
      "Loss for batch 49 = 0.8598017692565918\n",
      "Loss for batch 50 = 0.9465686678886414\n",
      "Loss for batch 51 = 0.7282732725143433\n",
      "Loss for batch 52 = 0.7397714257240295\n",
      "Loss for batch 53 = 0.8739906549453735\n",
      "Loss for batch 54 = 0.6316297054290771\n",
      "Loss for batch 55 = 0.9869874119758606\n",
      "Loss for batch 56 = 0.9117879271507263\n",
      "Loss for batch 57 = 0.7862511873245239\n",
      "Loss for batch 58 = 0.6850494742393494\n",
      "Loss for batch 59 = 1.0893062353134155\n",
      "Loss for batch 60 = 0.8040661811828613\n",
      "Loss for batch 61 = 0.8597534894943237\n",
      "Loss for batch 62 = 0.6464404463768005\n",
      "Loss for batch 63 = 0.7150426506996155\n",
      "Loss for batch 64 = 0.7954043745994568\n",
      "Loss for batch 65 = 0.847849428653717\n",
      "Loss for batch 66 = 0.8114696741104126\n",
      "Loss for batch 67 = 0.6727429032325745\n",
      "Loss for batch 68 = 0.6826735138893127\n",
      "Loss for batch 69 = 0.962018609046936\n",
      "Loss for batch 70 = 0.9855831861495972\n",
      "Loss for batch 71 = 0.8233697414398193\n",
      "Loss for batch 72 = 0.8389904499053955\n",
      "Loss for batch 73 = 0.7264348864555359\n",
      "Loss for batch 74 = 0.8386849164962769\n",
      "Loss for batch 75 = 0.9216918349266052\n",
      "Loss for batch 76 = 0.98360276222229\n",
      "Loss for batch 77 = 0.7309287190437317\n",
      "Loss for batch 78 = 1.03086519241333\n",
      "Loss for batch 79 = 0.8211056590080261\n",
      "Loss for batch 80 = 0.7960126399993896\n",
      "Loss for batch 81 = 0.687537670135498\n",
      "Loss for batch 82 = 0.7305877208709717\n",
      "Loss for batch 83 = 0.7169190645217896\n",
      "Loss for batch 84 = 0.562015175819397\n",
      "Loss for batch 85 = 0.8666529059410095\n",
      "Loss for batch 86 = 0.9586821794509888\n",
      "Loss for batch 87 = 0.8205844163894653\n",
      "Loss for batch 88 = 0.6614858508110046\n",
      "Loss for batch 89 = 0.7085439562797546\n",
      "Loss for batch 90 = 0.6199305653572083\n",
      "Loss for batch 91 = 0.6483650207519531\n",
      "Loss for batch 92 = 0.7718313336372375\n",
      "Loss for batch 93 = 0.8240681290626526\n",
      "Loss for batch 94 = 0.7421572804450989\n",
      "Loss for batch 95 = 0.7235156893730164\n",
      "Loss for batch 96 = 0.6477529406547546\n",
      "Loss for batch 97 = 0.8235761523246765\n",
      "\n",
      "Training Loss for epoch 8 = 80.13734436035156\n",
      "\n",
      "Current Validation Loss = 24.268665313720703\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 2\n",
      "Train Accuracy: 62.36%\n",
      "Validation Accuracy: 57.77%\n",
      "\n",
      "Epoch 9\n",
      "----------\n",
      "Loss for batch 0 = 0.7435821890830994\n",
      "Loss for batch 1 = 0.7865754961967468\n",
      "Loss for batch 2 = 0.8719596266746521\n",
      "Loss for batch 3 = 0.7475883960723877\n",
      "Loss for batch 4 = 0.8225318193435669\n",
      "Loss for batch 5 = 0.7945350408554077\n",
      "Loss for batch 6 = 0.8872748613357544\n",
      "Loss for batch 7 = 0.9504079222679138\n",
      "Loss for batch 8 = 0.8002819418907166\n",
      "Loss for batch 9 = 0.9575382471084595\n",
      "Loss for batch 10 = 1.1360596418380737\n",
      "Loss for batch 11 = 0.8656531572341919\n",
      "Loss for batch 12 = 1.0173096656799316\n",
      "Loss for batch 13 = 1.027497410774231\n",
      "Loss for batch 14 = 0.8334004878997803\n",
      "Loss for batch 15 = 0.8814433813095093\n",
      "Loss for batch 16 = 0.8241081237792969\n",
      "Loss for batch 17 = 0.841008186340332\n",
      "Loss for batch 18 = 0.8698851466178894\n",
      "Loss for batch 19 = 0.7595568299293518\n",
      "Loss for batch 20 = 0.5155748128890991\n",
      "Loss for batch 21 = 0.7007879018783569\n",
      "Loss for batch 22 = 0.7237719297409058\n",
      "Loss for batch 23 = 0.7899825572967529\n",
      "Loss for batch 24 = 0.8060600757598877\n",
      "Loss for batch 25 = 0.6216971278190613\n",
      "Loss for batch 26 = 0.7546483874320984\n",
      "Loss for batch 27 = 0.6675055623054504\n",
      "Loss for batch 28 = 0.8120790123939514\n",
      "Loss for batch 29 = 1.0508649349212646\n",
      "Loss for batch 30 = 0.8271922469139099\n",
      "Loss for batch 31 = 0.5627500414848328\n",
      "Loss for batch 32 = 0.841774046421051\n",
      "Loss for batch 33 = 0.7961678504943848\n",
      "Loss for batch 34 = 0.8825485706329346\n",
      "Loss for batch 35 = 0.6834690570831299\n",
      "Loss for batch 36 = 0.9297206401824951\n",
      "Loss for batch 37 = 0.8400548100471497\n",
      "Loss for batch 38 = 0.7728157639503479\n",
      "Loss for batch 39 = 0.9389172196388245\n",
      "Loss for batch 40 = 0.7754843831062317\n",
      "Loss for batch 41 = 0.9299106597900391\n",
      "Loss for batch 42 = 0.7218875288963318\n",
      "Loss for batch 43 = 0.6838159561157227\n",
      "Loss for batch 44 = 0.9179778695106506\n",
      "Loss for batch 45 = 0.7884371876716614\n",
      "Loss for batch 46 = 0.6913001537322998\n",
      "Loss for batch 47 = 0.6789978742599487\n",
      "Loss for batch 48 = 0.9451740980148315\n",
      "Loss for batch 49 = 0.7729328870773315\n",
      "Loss for batch 50 = 0.9839555621147156\n",
      "Loss for batch 51 = 0.8581136465072632\n",
      "Loss for batch 52 = 0.9447111487388611\n",
      "Loss for batch 53 = 0.9497572183609009\n",
      "Loss for batch 54 = 0.6340850591659546\n",
      "Loss for batch 55 = 0.9197495579719543\n",
      "Loss for batch 56 = 0.8806633949279785\n",
      "Loss for batch 57 = 0.8264097571372986\n",
      "Loss for batch 58 = 0.7099890112876892\n",
      "Loss for batch 59 = 0.9973207116127014\n",
      "Loss for batch 60 = 0.7870131134986877\n",
      "Loss for batch 61 = 0.8592356443405151\n",
      "Loss for batch 62 = 0.6333919763565063\n",
      "Loss for batch 63 = 0.6559455394744873\n",
      "Loss for batch 64 = 0.7910058498382568\n",
      "Loss for batch 65 = 0.9687955379486084\n",
      "Loss for batch 66 = 0.8708625435829163\n",
      "Loss for batch 67 = 0.6826940178871155\n",
      "Loss for batch 68 = 0.6427834630012512\n",
      "Loss for batch 69 = 1.0043566226959229\n",
      "Loss for batch 70 = 0.9460169076919556\n",
      "Loss for batch 71 = 0.7652071714401245\n",
      "Loss for batch 72 = 0.9059396386146545\n",
      "Loss for batch 73 = 0.9047190546989441\n",
      "Loss for batch 74 = 0.9154718518257141\n",
      "Loss for batch 75 = 0.8948748707771301\n",
      "Loss for batch 76 = 1.0372040271759033\n",
      "Loss for batch 77 = 0.7047341465950012\n",
      "Loss for batch 78 = 1.0322859287261963\n",
      "Loss for batch 79 = 0.9562913179397583\n",
      "Loss for batch 80 = 0.8465867638587952\n",
      "Loss for batch 81 = 0.8059409856796265\n",
      "Loss for batch 82 = 0.841293454170227\n",
      "Loss for batch 83 = 0.7006168961524963\n",
      "Loss for batch 84 = 0.5702045559883118\n",
      "Loss for batch 85 = 0.8829723000526428\n",
      "Loss for batch 86 = 0.9523556232452393\n",
      "Loss for batch 87 = 0.8318066000938416\n",
      "Loss for batch 88 = 0.688267171382904\n",
      "Loss for batch 89 = 0.6179748773574829\n",
      "Loss for batch 90 = 0.6286876797676086\n",
      "Loss for batch 91 = 0.6590992212295532\n",
      "Loss for batch 92 = 0.7521932125091553\n",
      "Loss for batch 93 = 0.8704102039337158\n",
      "Loss for batch 94 = 0.7849717140197754\n",
      "Loss for batch 95 = 0.6191321611404419\n",
      "Loss for batch 96 = 0.6784958839416504\n",
      "Loss for batch 97 = 0.7610766291618347\n",
      "\n",
      "Training Loss for epoch 9 = 79.99815368652344\n",
      "\n",
      "Current Validation Loss = 25.397228240966797\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 3\n",
      "Train Accuracy: 61.65%\n",
      "Validation Accuracy: 55.58%\n",
      "\n",
      "Epoch 10\n",
      "----------\n",
      "Loss for batch 0 = 0.7263124585151672\n",
      "Loss for batch 1 = 0.8689330816268921\n",
      "Loss for batch 2 = 0.7563924193382263\n",
      "Loss for batch 3 = 0.8445215225219727\n",
      "Loss for batch 4 = 0.8603641390800476\n",
      "Loss for batch 5 = 0.7453828454017639\n",
      "Loss for batch 6 = 0.8029190301895142\n",
      "Loss for batch 7 = 1.0771404504776\n",
      "Loss for batch 8 = 0.8328918218612671\n",
      "Loss for batch 9 = 0.9252907633781433\n",
      "Loss for batch 10 = 1.157995343208313\n",
      "Loss for batch 11 = 0.9333754181861877\n",
      "Loss for batch 12 = 0.89573073387146\n",
      "Loss for batch 13 = 0.927420437335968\n",
      "Loss for batch 14 = 0.913313090801239\n",
      "Loss for batch 15 = 0.933097779750824\n",
      "Loss for batch 16 = 0.8690444231033325\n",
      "Loss for batch 17 = 0.9500027298927307\n",
      "Loss for batch 18 = 0.9074134826660156\n",
      "Loss for batch 19 = 0.7834596037864685\n",
      "Loss for batch 20 = 0.5335079431533813\n",
      "Loss for batch 21 = 0.659321129322052\n",
      "Loss for batch 22 = 0.7128622531890869\n",
      "Loss for batch 23 = 0.8279746174812317\n",
      "Loss for batch 24 = 0.773715078830719\n",
      "Loss for batch 25 = 0.5810770392417908\n",
      "Loss for batch 26 = 0.7592330574989319\n",
      "Loss for batch 27 = 0.7522309422492981\n",
      "Loss for batch 28 = 0.9202102422714233\n",
      "Loss for batch 29 = 1.0673874616622925\n",
      "Loss for batch 30 = 0.9526592493057251\n",
      "Loss for batch 31 = 0.5851605534553528\n",
      "Loss for batch 32 = 0.8830998539924622\n",
      "Loss for batch 33 = 0.7906904220581055\n",
      "Loss for batch 34 = 0.8707758784294128\n",
      "Loss for batch 35 = 0.6486200094223022\n",
      "Loss for batch 36 = 0.7938647270202637\n",
      "Loss for batch 37 = 0.9020981788635254\n",
      "Loss for batch 38 = 0.7601048946380615\n",
      "Loss for batch 39 = 0.913939356803894\n",
      "Loss for batch 40 = 0.8189085721969604\n",
      "Loss for batch 41 = 0.8837127685546875\n",
      "Loss for batch 42 = 0.7405151128768921\n",
      "Loss for batch 43 = 0.6610510349273682\n",
      "Loss for batch 44 = 0.8661773204803467\n",
      "Loss for batch 45 = 0.7996460199356079\n",
      "Loss for batch 46 = 0.695023775100708\n",
      "Loss for batch 47 = 0.7212919592857361\n",
      "Loss for batch 48 = 0.9571974277496338\n",
      "Loss for batch 49 = 0.777131974697113\n",
      "Loss for batch 50 = 0.9083091616630554\n",
      "Loss for batch 51 = 0.7490886449813843\n",
      "Loss for batch 52 = 0.7771359086036682\n",
      "Loss for batch 53 = 0.8697813749313354\n",
      "Loss for batch 54 = 0.5943756103515625\n",
      "Loss for batch 55 = 0.937564492225647\n",
      "Loss for batch 56 = 0.8281688094139099\n",
      "Loss for batch 57 = 0.8421366810798645\n",
      "Loss for batch 58 = 0.6299587488174438\n",
      "Loss for batch 59 = 1.0198198556900024\n",
      "Loss for batch 60 = 0.7517426013946533\n",
      "Loss for batch 61 = 0.8139445781707764\n",
      "Loss for batch 62 = 0.6087620258331299\n",
      "Loss for batch 63 = 0.6494132280349731\n",
      "Loss for batch 64 = 0.6973881721496582\n",
      "Loss for batch 65 = 0.8741282224655151\n",
      "Loss for batch 66 = 0.789604902267456\n",
      "Loss for batch 67 = 0.6593072414398193\n",
      "Loss for batch 68 = 0.6110829710960388\n",
      "Loss for batch 69 = 0.9729613065719604\n",
      "Loss for batch 70 = 0.9375260472297668\n",
      "Loss for batch 71 = 0.7269375324249268\n",
      "Loss for batch 72 = 0.8496861457824707\n",
      "Loss for batch 73 = 0.7195680141448975\n",
      "Loss for batch 74 = 0.8870168924331665\n",
      "Loss for batch 75 = 0.8252898454666138\n",
      "Loss for batch 76 = 0.9302431344985962\n",
      "Loss for batch 77 = 0.7461535334587097\n",
      "Loss for batch 78 = 1.0109342336654663\n",
      "Loss for batch 79 = 0.9455073475837708\n",
      "Loss for batch 80 = 0.7158705592155457\n",
      "Loss for batch 81 = 0.7851159572601318\n",
      "Loss for batch 82 = 0.6626037955284119\n",
      "Loss for batch 83 = 0.5748541951179504\n",
      "Loss for batch 84 = 0.5100253224372864\n",
      "Loss for batch 85 = 0.8109047412872314\n",
      "Loss for batch 86 = 0.8825235962867737\n",
      "Loss for batch 87 = 0.7588863372802734\n",
      "Loss for batch 88 = 0.682144284248352\n",
      "Loss for batch 89 = 0.5595210194587708\n",
      "Loss for batch 90 = 0.5664021372795105\n",
      "Loss for batch 91 = 0.6151079535484314\n",
      "Loss for batch 92 = 0.711651623249054\n",
      "Loss for batch 93 = 0.9822338819503784\n",
      "Loss for batch 94 = 0.6432681679725647\n",
      "Loss for batch 95 = 0.6788622736930847\n",
      "Loss for batch 96 = 0.634025514125824\n",
      "Loss for batch 97 = 0.9699496626853943\n",
      "\n",
      "Training Loss for epoch 10 = 78.2276840209961\n",
      "\n",
      "Current Validation Loss = 23.372835159301758\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 4\n",
      "Train Accuracy: 63.61%\n",
      "Validation Accuracy: 58.54%\n",
      "\n",
      "Epoch 11\n",
      "----------\n",
      "Loss for batch 0 = 0.8128038644790649\n",
      "Loss for batch 1 = 0.8552579879760742\n",
      "Loss for batch 2 = 0.8365446329116821\n",
      "Loss for batch 3 = 0.8028419613838196\n",
      "Loss for batch 4 = 0.7473462224006653\n",
      "Loss for batch 5 = 0.7863032817840576\n",
      "Loss for batch 6 = 0.8130759596824646\n",
      "Loss for batch 7 = 0.9438474774360657\n",
      "Loss for batch 8 = 0.7302619814872742\n",
      "Loss for batch 9 = 0.9291604161262512\n",
      "Loss for batch 10 = 1.2128115892410278\n",
      "Loss for batch 11 = 0.8599326014518738\n",
      "Loss for batch 12 = 0.9144046902656555\n",
      "Loss for batch 13 = 0.9295554757118225\n",
      "Loss for batch 14 = 0.7643460631370544\n",
      "Loss for batch 15 = 0.7654823064804077\n",
      "Loss for batch 16 = 0.7518170475959778\n",
      "Loss for batch 17 = 0.7753065228462219\n",
      "Loss for batch 18 = 0.8822972774505615\n",
      "Loss for batch 19 = 0.742435097694397\n",
      "Loss for batch 20 = 0.5226773619651794\n",
      "Loss for batch 21 = 0.6716957688331604\n",
      "Loss for batch 22 = 0.711002767086029\n",
      "Loss for batch 23 = 0.7562763094902039\n",
      "Loss for batch 24 = 0.7786873579025269\n",
      "Loss for batch 25 = 0.5603913068771362\n",
      "Loss for batch 26 = 0.7017955780029297\n",
      "Loss for batch 27 = 0.6880315542221069\n",
      "Loss for batch 28 = 0.8374793529510498\n",
      "Loss for batch 29 = 1.0997055768966675\n",
      "Loss for batch 30 = 0.8495310544967651\n",
      "Loss for batch 31 = 0.5440216660499573\n",
      "Loss for batch 32 = 0.8117405772209167\n",
      "Loss for batch 33 = 0.7241974472999573\n",
      "Loss for batch 34 = 0.9285551309585571\n",
      "Loss for batch 35 = 0.5415170788764954\n",
      "Loss for batch 36 = 0.8378015756607056\n",
      "Loss for batch 37 = 0.8472921252250671\n",
      "Loss for batch 38 = 0.758462131023407\n",
      "Loss for batch 39 = 0.9087057113647461\n",
      "Loss for batch 40 = 0.7564884424209595\n",
      "Loss for batch 41 = 0.8902249336242676\n",
      "Loss for batch 42 = 0.7071258425712585\n",
      "Loss for batch 43 = 0.6226711869239807\n",
      "Loss for batch 44 = 0.8339044451713562\n",
      "Loss for batch 45 = 0.778183102607727\n",
      "Loss for batch 46 = 0.6351116299629211\n",
      "Loss for batch 47 = 0.6751067042350769\n",
      "Loss for batch 48 = 0.9052868485450745\n",
      "Loss for batch 49 = 0.7697169184684753\n",
      "Loss for batch 50 = 0.8447468280792236\n",
      "Loss for batch 51 = 0.7207954525947571\n",
      "Loss for batch 52 = 0.7289859652519226\n",
      "Loss for batch 53 = 0.8456807732582092\n",
      "Loss for batch 54 = 0.5421757698059082\n",
      "Loss for batch 55 = 0.9618067741394043\n",
      "Loss for batch 56 = 0.8430930972099304\n",
      "Loss for batch 57 = 0.7972879409790039\n",
      "Loss for batch 58 = 0.6185286641120911\n",
      "Loss for batch 59 = 1.0514706373214722\n",
      "Loss for batch 60 = 0.7110737562179565\n",
      "Loss for batch 61 = 0.7882638573646545\n",
      "Loss for batch 62 = 0.6340442299842834\n",
      "Loss for batch 63 = 0.6324856877326965\n",
      "Loss for batch 64 = 0.6501699090003967\n",
      "Loss for batch 65 = 0.8406578898429871\n",
      "Loss for batch 66 = 0.7998093962669373\n",
      "Loss for batch 67 = 0.6439763307571411\n",
      "Loss for batch 68 = 0.5968144536018372\n",
      "Loss for batch 69 = 0.9544755220413208\n",
      "Loss for batch 70 = 0.9333682060241699\n",
      "Loss for batch 71 = 0.6556858420372009\n",
      "Loss for batch 72 = 0.7451062202453613\n",
      "Loss for batch 73 = 0.6643763184547424\n",
      "Loss for batch 74 = 0.8658578395843506\n",
      "Loss for batch 75 = 0.8073247671127319\n",
      "Loss for batch 76 = 0.9278667569160461\n",
      "Loss for batch 77 = 0.6997340321540833\n",
      "Loss for batch 78 = 0.9373543858528137\n",
      "Loss for batch 79 = 0.7986800670623779\n",
      "Loss for batch 80 = 0.7175899744033813\n",
      "Loss for batch 81 = 0.6645691394805908\n",
      "Loss for batch 82 = 0.7440277934074402\n",
      "Loss for batch 83 = 0.6092143058776855\n",
      "Loss for batch 84 = 0.5291479229927063\n",
      "Loss for batch 85 = 0.8603931069374084\n",
      "Loss for batch 86 = 0.852289080619812\n",
      "Loss for batch 87 = 0.7164709568023682\n",
      "Loss for batch 88 = 0.5834494233131409\n",
      "Loss for batch 89 = 0.5918735265731812\n",
      "Loss for batch 90 = 0.5219000577926636\n",
      "Loss for batch 91 = 0.630496084690094\n",
      "Loss for batch 92 = 0.7476115226745605\n",
      "Loss for batch 93 = 0.8107846975326538\n",
      "Loss for batch 94 = 0.6696075201034546\n",
      "Loss for batch 95 = 0.7523583173751831\n",
      "Loss for batch 96 = 0.5235085487365723\n",
      "Loss for batch 97 = 0.8095079064369202\n",
      "\n",
      "Training Loss for epoch 11 = 75.085693359375\n",
      "\n",
      "Current Validation Loss = 23.703641891479492\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 5\n",
      "Train Accuracy: 68.10%\n",
      "Validation Accuracy: 60.21%\n",
      "\n",
      "Epoch 12\n",
      "----------\n",
      "Loss for batch 0 = 0.6874995827674866\n",
      "Loss for batch 1 = 0.8443560600280762\n",
      "Loss for batch 2 = 0.864298939704895\n",
      "Loss for batch 3 = 0.682131290435791\n",
      "Loss for batch 4 = 0.6864765286445618\n",
      "Loss for batch 5 = 0.7541843056678772\n",
      "Loss for batch 6 = 0.8274665474891663\n",
      "Loss for batch 7 = 0.9568769931793213\n",
      "Loss for batch 8 = 0.7703280448913574\n",
      "Loss for batch 9 = 0.8759485483169556\n",
      "Loss for batch 10 = 1.206331491470337\n",
      "Loss for batch 11 = 0.7997017502784729\n",
      "Loss for batch 12 = 0.9738324284553528\n",
      "Loss for batch 13 = 1.0396403074264526\n",
      "Loss for batch 14 = 0.7947990298271179\n",
      "Loss for batch 15 = 0.773041844367981\n",
      "Loss for batch 16 = 0.7919822335243225\n",
      "Loss for batch 17 = 0.7220445871353149\n",
      "Loss for batch 18 = 0.9032037258148193\n",
      "Loss for batch 19 = 0.75510174036026\n",
      "Loss for batch 20 = 0.5592631697654724\n",
      "Loss for batch 21 = 0.697940468788147\n",
      "Loss for batch 22 = 0.664008378982544\n",
      "Loss for batch 23 = 0.7302474975585938\n",
      "Loss for batch 24 = 0.6349694132804871\n",
      "Loss for batch 25 = 0.5507380366325378\n",
      "Loss for batch 26 = 0.7003973722457886\n",
      "Loss for batch 27 = 0.6436139941215515\n",
      "Loss for batch 28 = 0.7931159138679504\n",
      "Loss for batch 29 = 1.003974437713623\n",
      "Loss for batch 30 = 0.7920202016830444\n",
      "Loss for batch 31 = 0.4994472563266754\n",
      "Loss for batch 32 = 0.7850351333618164\n",
      "Loss for batch 33 = 0.7025110125541687\n",
      "Loss for batch 34 = 0.8474408984184265\n",
      "Loss for batch 35 = 0.5200980305671692\n",
      "Loss for batch 36 = 0.7530651092529297\n",
      "Loss for batch 37 = 0.7687714099884033\n",
      "Loss for batch 38 = 0.685478925704956\n",
      "Loss for batch 39 = 0.8025496602058411\n",
      "Loss for batch 40 = 0.719002902507782\n",
      "Loss for batch 41 = 0.845936119556427\n",
      "Loss for batch 42 = 0.5966476202011108\n",
      "Loss for batch 43 = 0.5762842893600464\n",
      "Loss for batch 44 = 0.8036163449287415\n",
      "Loss for batch 45 = 0.7122644186019897\n",
      "Loss for batch 46 = 0.6161051392555237\n",
      "Loss for batch 47 = 0.6254876255989075\n",
      "Loss for batch 48 = 0.8244559168815613\n",
      "Loss for batch 49 = 0.7315545082092285\n",
      "Loss for batch 50 = 0.8651070594787598\n",
      "Loss for batch 51 = 0.7551889419555664\n",
      "Loss for batch 52 = 0.7374188303947449\n",
      "Loss for batch 53 = 0.8216104507446289\n",
      "Loss for batch 54 = 0.5667478442192078\n",
      "Loss for batch 55 = 0.9740886092185974\n",
      "Loss for batch 56 = 0.8414233326911926\n",
      "Loss for batch 57 = 0.8225248456001282\n",
      "Loss for batch 58 = 0.5923995971679688\n",
      "Loss for batch 59 = 0.9842631220817566\n",
      "Loss for batch 60 = 0.6866602897644043\n",
      "Loss for batch 61 = 0.7748227119445801\n",
      "Loss for batch 62 = 0.5997576117515564\n",
      "Loss for batch 63 = 0.6484614610671997\n",
      "Loss for batch 64 = 0.6162219643592834\n",
      "Loss for batch 65 = 0.8900811672210693\n",
      "Loss for batch 66 = 0.6818710565567017\n",
      "Loss for batch 67 = 0.6196280121803284\n",
      "Loss for batch 68 = 0.5539671778678894\n",
      "Loss for batch 69 = 0.9508950710296631\n",
      "Loss for batch 70 = 0.9176998138427734\n",
      "Loss for batch 71 = 0.6094967722892761\n",
      "Loss for batch 72 = 0.7388232946395874\n",
      "Loss for batch 73 = 0.7088406682014465\n",
      "Loss for batch 74 = 0.8814664483070374\n",
      "Loss for batch 75 = 0.878679096698761\n",
      "Loss for batch 76 = 0.8484158515930176\n",
      "Loss for batch 77 = 0.6831838488578796\n",
      "Loss for batch 78 = 0.9446454644203186\n",
      "Loss for batch 79 = 0.8768066167831421\n",
      "Loss for batch 80 = 0.682293713092804\n",
      "Loss for batch 81 = 0.6977390050888062\n",
      "Loss for batch 82 = 0.6564629077911377\n",
      "Loss for batch 83 = 0.5218042135238647\n",
      "Loss for batch 84 = 0.4580179750919342\n",
      "Loss for batch 85 = 0.7863789200782776\n",
      "Loss for batch 86 = 0.8812270164489746\n",
      "Loss for batch 87 = 0.6738914847373962\n",
      "Loss for batch 88 = 0.5666664242744446\n",
      "Loss for batch 89 = 0.48199036717414856\n",
      "Loss for batch 90 = 0.5678909420967102\n",
      "Loss for batch 91 = 0.5802491903305054\n",
      "Loss for batch 92 = 0.5954551100730896\n",
      "Loss for batch 93 = 0.8810152411460876\n",
      "Loss for batch 94 = 0.6166254281997681\n",
      "Loss for batch 95 = 0.5928153991699219\n",
      "Loss for batch 96 = 0.5406544804573059\n",
      "Loss for batch 97 = 0.5310523509979248\n",
      "\n",
      "Training Loss for epoch 12 = 72.27869415283203\n",
      "\n",
      "Current Validation Loss = 28.105026245117188\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 6\n",
      "Train Accuracy: 66.43%\n",
      "Validation Accuracy: 57.38%\n",
      "\n",
      "Epoch 13\n",
      "----------\n",
      "Loss for batch 0 = 0.9256943464279175\n",
      "Loss for batch 1 = 0.8084160089492798\n",
      "Loss for batch 2 = 0.8140349388122559\n",
      "Loss for batch 3 = 0.743660569190979\n",
      "Loss for batch 4 = 0.687180757522583\n",
      "Loss for batch 5 = 0.7410555481910706\n",
      "Loss for batch 6 = 0.7854189276695251\n",
      "Loss for batch 7 = 1.0512815713882446\n",
      "Loss for batch 8 = 0.6882545948028564\n",
      "Loss for batch 9 = 0.8600035905838013\n",
      "Loss for batch 10 = 1.1606709957122803\n",
      "Loss for batch 11 = 0.7856830358505249\n",
      "Loss for batch 12 = 0.9212918877601624\n",
      "Loss for batch 13 = 1.0206679105758667\n",
      "Loss for batch 14 = 0.7076021432876587\n",
      "Loss for batch 15 = 0.7234911322593689\n",
      "Loss for batch 16 = 0.7558234333992004\n",
      "Loss for batch 17 = 0.7678163051605225\n",
      "Loss for batch 18 = 0.870002031326294\n",
      "Loss for batch 19 = 0.6616612076759338\n",
      "Loss for batch 20 = 0.53620845079422\n",
      "Loss for batch 21 = 0.6492202877998352\n",
      "Loss for batch 22 = 0.6828368306159973\n",
      "Loss for batch 23 = 0.7448241710662842\n",
      "Loss for batch 24 = 0.6142820119857788\n",
      "Loss for batch 25 = 0.5185930132865906\n",
      "Loss for batch 26 = 0.8005664944648743\n",
      "Loss for batch 27 = 0.6290200352668762\n",
      "Loss for batch 28 = 0.739519476890564\n",
      "Loss for batch 29 = 1.0114566087722778\n",
      "Loss for batch 30 = 0.7948734760284424\n",
      "Loss for batch 31 = 0.5156456828117371\n",
      "Loss for batch 32 = 0.760804295539856\n",
      "Loss for batch 33 = 0.6629509329795837\n",
      "Loss for batch 34 = 0.8405828475952148\n",
      "Loss for batch 35 = 0.5287147164344788\n",
      "Loss for batch 36 = 0.7030415534973145\n",
      "Loss for batch 37 = 0.7126707434654236\n",
      "Loss for batch 38 = 0.6381276845932007\n",
      "Loss for batch 39 = 0.8217173218727112\n",
      "Loss for batch 40 = 0.6947613954544067\n",
      "Loss for batch 41 = 0.797278881072998\n",
      "Loss for batch 42 = 0.5481090545654297\n",
      "Loss for batch 43 = 0.5650842785835266\n",
      "Loss for batch 44 = 0.7323770523071289\n",
      "Loss for batch 45 = 0.7231022119522095\n",
      "Loss for batch 46 = 0.7142777442932129\n",
      "Loss for batch 47 = 0.6050286889076233\n",
      "Loss for batch 48 = 0.7956594228744507\n",
      "Loss for batch 49 = 0.7128680944442749\n",
      "Loss for batch 50 = 0.8033519983291626\n",
      "Loss for batch 51 = 0.7735940217971802\n",
      "Loss for batch 52 = 0.7453816533088684\n",
      "Loss for batch 53 = 0.7226234674453735\n",
      "Loss for batch 54 = 0.5180560946464539\n",
      "Loss for batch 55 = 0.9796850681304932\n",
      "Loss for batch 56 = 0.7987131476402283\n",
      "Loss for batch 57 = 0.7592827677726746\n",
      "Loss for batch 58 = 0.532676637172699\n",
      "Loss for batch 59 = 0.940603494644165\n",
      "Loss for batch 60 = 0.7445352673530579\n",
      "Loss for batch 61 = 0.812835156917572\n",
      "Loss for batch 62 = 0.5976987481117249\n",
      "Loss for batch 63 = 0.6275267004966736\n",
      "Loss for batch 64 = 0.6210700869560242\n",
      "Loss for batch 65 = 0.8040470480918884\n",
      "Loss for batch 66 = 0.6254250407218933\n",
      "Loss for batch 67 = 0.6096307039260864\n",
      "Loss for batch 68 = 0.5200982093811035\n",
      "Loss for batch 69 = 0.9277938604354858\n",
      "Loss for batch 70 = 0.8573184609413147\n",
      "Loss for batch 71 = 0.619547426700592\n",
      "Loss for batch 72 = 0.7957494258880615\n",
      "Loss for batch 73 = 0.6568099856376648\n",
      "Loss for batch 74 = 0.7974219918251038\n",
      "Loss for batch 75 = 0.7324923276901245\n",
      "Loss for batch 76 = 0.8620826601982117\n",
      "Loss for batch 77 = 0.6304884552955627\n",
      "Loss for batch 78 = 0.9549432396888733\n",
      "Loss for batch 79 = 0.849716305732727\n",
      "Loss for batch 80 = 0.6784080266952515\n",
      "Loss for batch 81 = 0.6715170741081238\n",
      "Loss for batch 82 = 0.6226150989532471\n",
      "Loss for batch 83 = 0.47153130173683167\n",
      "Loss for batch 84 = 0.4570964574813843\n",
      "Loss for batch 85 = 0.7678560614585876\n",
      "Loss for batch 86 = 0.8805302381515503\n",
      "Loss for batch 87 = 0.6833335161209106\n",
      "Loss for batch 88 = 0.5109822750091553\n",
      "Loss for batch 89 = 0.48664310574531555\n",
      "Loss for batch 90 = 0.4806007146835327\n",
      "Loss for batch 91 = 0.6714159250259399\n",
      "Loss for batch 92 = 0.6428796648979187\n",
      "Loss for batch 93 = 0.8636006116867065\n",
      "Loss for batch 94 = 0.6238281726837158\n",
      "Loss for batch 95 = 0.5205195546150208\n",
      "Loss for batch 96 = 0.5470399856567383\n",
      "Loss for batch 97 = 0.7115428447723389\n",
      "\n",
      "Training Loss for epoch 13 = 70.78705596923828\n",
      "\n",
      "Current Validation Loss = 24.26947784423828\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 7\n",
      "Train Accuracy: 70.54%\n",
      "Validation Accuracy: 60.46%\n",
      "\n",
      "Epoch 14\n",
      "----------\n",
      "Loss for batch 0 = 0.6965914368629456\n",
      "Loss for batch 1 = 0.7627069354057312\n",
      "Loss for batch 2 = 0.7260619401931763\n",
      "Loss for batch 3 = 0.7302847504615784\n",
      "Loss for batch 4 = 0.6802957653999329\n",
      "Loss for batch 5 = 0.7907401323318481\n",
      "Loss for batch 6 = 0.829369306564331\n",
      "Loss for batch 7 = 0.903245210647583\n",
      "Loss for batch 8 = 0.772281289100647\n",
      "Loss for batch 9 = 0.849186360836029\n",
      "Loss for batch 10 = 1.106239914894104\n",
      "Loss for batch 11 = 0.7325144410133362\n",
      "Loss for batch 12 = 0.930254340171814\n",
      "Loss for batch 13 = 0.9221334457397461\n",
      "Loss for batch 14 = 0.7061202526092529\n",
      "Loss for batch 15 = 0.6882050037384033\n",
      "Loss for batch 16 = 0.7259326577186584\n",
      "Loss for batch 17 = 0.7123740315437317\n",
      "Loss for batch 18 = 0.8690530061721802\n",
      "Loss for batch 19 = 0.6568970084190369\n",
      "Loss for batch 20 = 0.5328395366668701\n",
      "Loss for batch 21 = 0.6778961420059204\n",
      "Loss for batch 22 = 0.6679997444152832\n",
      "Loss for batch 23 = 0.6969790458679199\n",
      "Loss for batch 24 = 0.5872721076011658\n",
      "Loss for batch 25 = 0.5338792204856873\n",
      "Loss for batch 26 = 0.7386683821678162\n",
      "Loss for batch 27 = 0.6350730657577515\n",
      "Loss for batch 28 = 0.6978025436401367\n",
      "Loss for batch 29 = 0.9569069147109985\n",
      "Loss for batch 30 = 0.709617555141449\n",
      "Loss for batch 31 = 0.4523695707321167\n",
      "Loss for batch 32 = 0.7273482084274292\n",
      "Loss for batch 33 = 0.6549862623214722\n",
      "Loss for batch 34 = 0.8347575664520264\n",
      "Loss for batch 35 = 0.5540974140167236\n",
      "Loss for batch 36 = 0.7194591164588928\n",
      "Loss for batch 37 = 0.6776487231254578\n",
      "Loss for batch 38 = 0.6128035187721252\n",
      "Loss for batch 39 = 0.787638783454895\n",
      "Loss for batch 40 = 0.6631873250007629\n",
      "Loss for batch 41 = 0.8049437999725342\n",
      "Loss for batch 42 = 0.5472359657287598\n",
      "Loss for batch 43 = 0.5456088781356812\n",
      "Loss for batch 44 = 0.6577692031860352\n",
      "Loss for batch 45 = 0.6853886246681213\n",
      "Loss for batch 46 = 0.6469172239303589\n",
      "Loss for batch 47 = 0.6159307360649109\n",
      "Loss for batch 48 = 0.760718047618866\n",
      "Loss for batch 49 = 0.6548177003860474\n",
      "Loss for batch 50 = 0.7162660360336304\n",
      "Loss for batch 51 = 0.7617219686508179\n",
      "Loss for batch 52 = 0.6774080991744995\n",
      "Loss for batch 53 = 0.7110306024551392\n",
      "Loss for batch 54 = 0.49182000756263733\n",
      "Loss for batch 55 = 0.9195954203605652\n",
      "Loss for batch 56 = 0.7663403153419495\n",
      "Loss for batch 57 = 0.7296791076660156\n",
      "Loss for batch 58 = 0.5068831443786621\n",
      "Loss for batch 59 = 0.953892707824707\n",
      "Loss for batch 60 = 0.6935240030288696\n",
      "Loss for batch 61 = 0.8327800631523132\n",
      "Loss for batch 62 = 0.5408567190170288\n",
      "Loss for batch 63 = 0.6483215093612671\n",
      "Loss for batch 64 = 0.569527268409729\n",
      "Loss for batch 65 = 0.7523465156555176\n",
      "Loss for batch 66 = 0.6207099556922913\n",
      "Loss for batch 67 = 0.5438699126243591\n",
      "Loss for batch 68 = 0.5698050856590271\n",
      "Loss for batch 69 = 0.9557599425315857\n",
      "Loss for batch 70 = 0.8671181201934814\n",
      "Loss for batch 71 = 0.5279169678688049\n",
      "Loss for batch 72 = 0.7439125776290894\n",
      "Loss for batch 73 = 0.7034040093421936\n",
      "Loss for batch 74 = 0.8681074380874634\n",
      "Loss for batch 75 = 0.6385904550552368\n",
      "Loss for batch 76 = 0.9714298248291016\n",
      "Loss for batch 77 = 0.5172557234764099\n",
      "Loss for batch 78 = 0.9327930212020874\n",
      "Loss for batch 79 = 0.8557847142219543\n",
      "Loss for batch 80 = 0.6725546717643738\n",
      "Loss for batch 81 = 0.8343104124069214\n",
      "Loss for batch 82 = 0.6594468951225281\n",
      "Loss for batch 83 = 0.5772706270217896\n",
      "Loss for batch 84 = 0.543407678604126\n",
      "Loss for batch 85 = 0.7235068678855896\n",
      "Loss for batch 86 = 0.8933295011520386\n",
      "Loss for batch 87 = 0.7380489110946655\n",
      "Loss for batch 88 = 0.5700212121009827\n",
      "Loss for batch 89 = 0.476999968290329\n",
      "Loss for batch 90 = 0.4610745906829834\n",
      "Loss for batch 91 = 0.6758527755737305\n",
      "Loss for batch 92 = 0.6461357474327087\n",
      "Loss for batch 93 = 0.7672752141952515\n",
      "Loss for batch 94 = 0.6489036679267883\n",
      "Loss for batch 95 = 0.5246594548225403\n",
      "Loss for batch 96 = 0.535913348197937\n",
      "Loss for batch 97 = 0.46700653433799744\n",
      "\n",
      "Training Loss for epoch 14 = 68.83319854736328\n",
      "\n",
      "Current Validation Loss = 24.82624053955078\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 8\n",
      "Train Accuracy: 69.61%\n",
      "Validation Accuracy: 59.44%\n",
      "\n",
      "Epoch 15\n",
      "----------\n",
      "Loss for batch 0 = 0.6910746693611145\n",
      "Loss for batch 1 = 0.7573655247688293\n",
      "Loss for batch 2 = 0.6887630820274353\n",
      "Loss for batch 3 = 0.6826556324958801\n",
      "Loss for batch 4 = 0.6235693693161011\n",
      "Loss for batch 5 = 0.7440091371536255\n",
      "Loss for batch 6 = 0.8392893671989441\n",
      "Loss for batch 7 = 0.9717988967895508\n",
      "Loss for batch 8 = 0.678504228591919\n",
      "Loss for batch 9 = 0.831973671913147\n",
      "Loss for batch 10 = 1.0611426830291748\n",
      "Loss for batch 11 = 0.7059017419815063\n",
      "Loss for batch 12 = 0.9523966312408447\n",
      "Loss for batch 13 = 0.8425760269165039\n",
      "Loss for batch 14 = 0.7508147358894348\n",
      "Loss for batch 15 = 0.6707711815834045\n",
      "Loss for batch 16 = 0.7066879272460938\n",
      "Loss for batch 17 = 0.6617470383644104\n",
      "Loss for batch 18 = 0.8902916312217712\n",
      "Loss for batch 19 = 0.705655038356781\n",
      "Loss for batch 20 = 0.5513675808906555\n",
      "Loss for batch 21 = 0.6075887084007263\n",
      "Loss for batch 22 = 0.6524889469146729\n",
      "Loss for batch 23 = 0.6434861421585083\n",
      "Loss for batch 24 = 0.5779666304588318\n",
      "Loss for batch 25 = 0.485658198595047\n",
      "Loss for batch 26 = 0.7129645943641663\n",
      "Loss for batch 27 = 0.6447993516921997\n",
      "Loss for batch 28 = 0.641207754611969\n",
      "Loss for batch 29 = 0.922770082950592\n",
      "Loss for batch 30 = 0.6487643718719482\n",
      "Loss for batch 31 = 0.3990973234176636\n",
      "Loss for batch 32 = 0.7512204051017761\n",
      "Loss for batch 33 = 0.6008598208427429\n",
      "Loss for batch 34 = 0.8109200596809387\n",
      "Loss for batch 35 = 0.48137426376342773\n",
      "Loss for batch 36 = 0.7006457448005676\n",
      "Loss for batch 37 = 0.6621295213699341\n",
      "Loss for batch 38 = 0.5883763432502747\n",
      "Loss for batch 39 = 0.7858388423919678\n",
      "Loss for batch 40 = 0.6234546303749084\n",
      "Loss for batch 41 = 0.8166720867156982\n",
      "Loss for batch 42 = 0.5271148681640625\n",
      "Loss for batch 43 = 0.5812399983406067\n",
      "Loss for batch 44 = 0.6878966093063354\n",
      "Loss for batch 45 = 0.7029740214347839\n",
      "Loss for batch 46 = 0.6049445271492004\n",
      "Loss for batch 47 = 0.5992283821105957\n",
      "Loss for batch 48 = 0.7297278046607971\n",
      "Loss for batch 49 = 0.6040105223655701\n",
      "Loss for batch 50 = 0.6949473023414612\n",
      "Loss for batch 51 = 0.7880175709724426\n",
      "Loss for batch 52 = 0.5877175331115723\n",
      "Loss for batch 53 = 0.701831579208374\n",
      "Loss for batch 54 = 0.4546053111553192\n",
      "Loss for batch 55 = 0.8753404021263123\n",
      "Loss for batch 56 = 0.7520162463188171\n",
      "Loss for batch 57 = 0.7382935881614685\n",
      "Loss for batch 58 = 0.47167104482650757\n",
      "Loss for batch 59 = 0.9538888931274414\n",
      "Loss for batch 60 = 0.7540287375450134\n",
      "Loss for batch 61 = 0.784228503704071\n",
      "Loss for batch 62 = 0.4984782338142395\n",
      "Loss for batch 63 = 0.5619032382965088\n",
      "Loss for batch 64 = 0.5181331634521484\n",
      "Loss for batch 65 = 0.7448463439941406\n",
      "Loss for batch 66 = 0.6639291048049927\n",
      "Loss for batch 67 = 0.5542364120483398\n",
      "Loss for batch 68 = 0.4907248318195343\n",
      "Loss for batch 69 = 0.961384117603302\n",
      "Loss for batch 70 = 0.8572601079940796\n",
      "Loss for batch 71 = 0.4540212154388428\n",
      "Loss for batch 72 = 0.6745268106460571\n",
      "Loss for batch 73 = 0.6193755865097046\n",
      "Loss for batch 74 = 0.7322066426277161\n",
      "Loss for batch 75 = 0.6226590275764465\n",
      "Loss for batch 76 = 0.8085573315620422\n",
      "Loss for batch 77 = 0.5671018958091736\n",
      "Loss for batch 78 = 0.9404200911521912\n",
      "Loss for batch 79 = 0.8788653016090393\n",
      "Loss for batch 80 = 0.7049590349197388\n",
      "Loss for batch 81 = 0.776244044303894\n",
      "Loss for batch 82 = 0.5216786861419678\n",
      "Loss for batch 83 = 0.44157546758651733\n",
      "Loss for batch 84 = 0.486095130443573\n",
      "Loss for batch 85 = 0.7336778044700623\n",
      "Loss for batch 86 = 0.7947508096694946\n",
      "Loss for batch 87 = 0.6880443096160889\n",
      "Loss for batch 88 = 0.46899497509002686\n",
      "Loss for batch 89 = 0.5765305161476135\n",
      "Loss for batch 90 = 0.43365344405174255\n",
      "Loss for batch 91 = 0.6503129005432129\n",
      "Loss for batch 92 = 0.6112619042396545\n",
      "Loss for batch 93 = 0.7679042816162109\n",
      "Loss for batch 94 = 0.6027159690856934\n",
      "Loss for batch 95 = 0.5192930698394775\n",
      "Loss for batch 96 = 0.4517240822315216\n",
      "Loss for batch 97 = 0.3837321996688843\n",
      "\n",
      "Training Loss for epoch 15 = 66.12214660644531\n",
      "\n",
      "Current Validation Loss = 25.496919631958008\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 9\n",
      "Train Accuracy: 72.63%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 16\n",
      "----------\n",
      "Loss for batch 0 = 0.6249774098396301\n",
      "Loss for batch 1 = 0.6992002129554749\n",
      "Loss for batch 2 = 0.670913577079773\n",
      "Loss for batch 3 = 0.638279914855957\n",
      "Loss for batch 4 = 0.5450500845909119\n",
      "Loss for batch 5 = 0.7626503109931946\n",
      "Loss for batch 6 = 0.8660179376602173\n",
      "Loss for batch 7 = 0.8591923713684082\n",
      "Loss for batch 8 = 0.6948446035385132\n",
      "Loss for batch 9 = 0.8153730630874634\n",
      "Loss for batch 10 = 1.2350537776947021\n",
      "Loss for batch 11 = 0.6820432543754578\n",
      "Loss for batch 12 = 0.9569821953773499\n",
      "Loss for batch 13 = 1.0118142366409302\n",
      "Loss for batch 14 = 0.5579138994216919\n",
      "Loss for batch 15 = 0.6089328527450562\n",
      "Loss for batch 16 = 0.6510699987411499\n",
      "Loss for batch 17 = 0.6818528771400452\n",
      "Loss for batch 18 = 0.8158317804336548\n",
      "Loss for batch 19 = 0.6776233315467834\n",
      "Loss for batch 20 = 0.5055490732192993\n",
      "Loss for batch 21 = 0.6634283065795898\n",
      "Loss for batch 22 = 0.6281965970993042\n",
      "Loss for batch 23 = 0.6162407398223877\n",
      "Loss for batch 24 = 0.5103859305381775\n",
      "Loss for batch 25 = 0.550864040851593\n",
      "Loss for batch 26 = 0.6913579702377319\n",
      "Loss for batch 27 = 0.5944380760192871\n",
      "Loss for batch 28 = 0.6104593873023987\n",
      "Loss for batch 29 = 0.7874235510826111\n",
      "Loss for batch 30 = 0.6750192046165466\n",
      "Loss for batch 31 = 0.4125789999961853\n",
      "Loss for batch 32 = 0.7120175957679749\n",
      "Loss for batch 33 = 0.583796501159668\n",
      "Loss for batch 34 = 0.7322796583175659\n",
      "Loss for batch 35 = 0.5037693381309509\n",
      "Loss for batch 36 = 0.6465244889259338\n",
      "Loss for batch 37 = 0.6941248178482056\n",
      "Loss for batch 38 = 0.6599669456481934\n",
      "Loss for batch 39 = 0.7183594107627869\n",
      "Loss for batch 40 = 0.563288152217865\n",
      "Loss for batch 41 = 0.752000629901886\n",
      "Loss for batch 42 = 0.5039001703262329\n",
      "Loss for batch 43 = 0.5110347867012024\n",
      "Loss for batch 44 = 0.5608953237533569\n",
      "Loss for batch 45 = 0.6054666042327881\n",
      "Loss for batch 46 = 0.5679240822792053\n",
      "Loss for batch 47 = 0.5447269678115845\n",
      "Loss for batch 48 = 0.7142786383628845\n",
      "Loss for batch 49 = 0.5560670495033264\n",
      "Loss for batch 50 = 0.6641800403594971\n",
      "Loss for batch 51 = 0.7073720097541809\n",
      "Loss for batch 52 = 0.5428156852722168\n",
      "Loss for batch 53 = 0.6312729716300964\n",
      "Loss for batch 54 = 0.46748968958854675\n",
      "Loss for batch 55 = 0.8305099010467529\n",
      "Loss for batch 56 = 0.7862177491188049\n",
      "Loss for batch 57 = 0.7503078579902649\n",
      "Loss for batch 58 = 0.40645650029182434\n",
      "Loss for batch 59 = 0.8475862145423889\n",
      "Loss for batch 60 = 0.5904785394668579\n",
      "Loss for batch 61 = 0.7559189796447754\n",
      "Loss for batch 62 = 0.42455512285232544\n",
      "Loss for batch 63 = 0.519443929195404\n",
      "Loss for batch 64 = 0.48413777351379395\n",
      "Loss for batch 65 = 0.7132770419120789\n",
      "Loss for batch 66 = 0.5789899230003357\n",
      "Loss for batch 67 = 0.5113440155982971\n",
      "Loss for batch 68 = 0.4775345027446747\n",
      "Loss for batch 69 = 0.9417707920074463\n",
      "Loss for batch 70 = 0.7670794725418091\n",
      "Loss for batch 71 = 0.38415777683258057\n",
      "Loss for batch 72 = 0.6484656929969788\n",
      "Loss for batch 73 = 0.5056589841842651\n",
      "Loss for batch 74 = 0.6451655626296997\n",
      "Loss for batch 75 = 0.5586189031600952\n",
      "Loss for batch 76 = 0.7677586674690247\n",
      "Loss for batch 77 = 0.46247047185897827\n",
      "Loss for batch 78 = 0.810723602771759\n",
      "Loss for batch 79 = 0.8393077254295349\n",
      "Loss for batch 80 = 0.6070165038108826\n",
      "Loss for batch 81 = 0.6346011161804199\n",
      "Loss for batch 82 = 0.47267499566078186\n",
      "Loss for batch 83 = 0.34836453199386597\n",
      "Loss for batch 84 = 0.46652984619140625\n",
      "Loss for batch 85 = 0.642262876033783\n",
      "Loss for batch 86 = 0.7800289392471313\n",
      "Loss for batch 87 = 0.5783788561820984\n",
      "Loss for batch 88 = 0.4094938039779663\n",
      "Loss for batch 89 = 0.3993642032146454\n",
      "Loss for batch 90 = 0.39781394600868225\n",
      "Loss for batch 91 = 0.5452542901039124\n",
      "Loss for batch 92 = 0.5794479250907898\n",
      "Loss for batch 93 = 0.8434988856315613\n",
      "Loss for batch 94 = 0.5303692817687988\n",
      "Loss for batch 95 = 0.4936967194080353\n",
      "Loss for batch 96 = 0.44654178619384766\n",
      "Loss for batch 97 = 0.37077832221984863\n",
      "\n",
      "Training Loss for epoch 16 = 61.99916458129883\n",
      "\n",
      "Current Validation Loss = 25.302335739135742\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 10\n",
      "Train Accuracy: 73.84%\n",
      "Validation Accuracy: 58.92%\n",
      "\n",
      "Epoch 17\n",
      "----------\n",
      "Loss for batch 0 = 0.5672132968902588\n",
      "Loss for batch 1 = 0.6779437065124512\n",
      "Loss for batch 2 = 0.6680524349212646\n",
      "Loss for batch 3 = 0.6240395307540894\n",
      "Loss for batch 4 = 0.5129092931747437\n",
      "Loss for batch 5 = 0.7790929079055786\n",
      "Loss for batch 6 = 0.7589719295501709\n",
      "Loss for batch 7 = 0.9187740087509155\n",
      "Loss for batch 8 = 0.6672039031982422\n",
      "Loss for batch 9 = 0.7511190176010132\n",
      "Loss for batch 10 = 1.2347784042358398\n",
      "Loss for batch 11 = 0.6115760207176208\n",
      "Loss for batch 12 = 0.9095869064331055\n",
      "Loss for batch 13 = 0.924196720123291\n",
      "Loss for batch 14 = 0.5326511263847351\n",
      "Loss for batch 15 = 0.5736469626426697\n",
      "Loss for batch 16 = 0.6177600622177124\n",
      "Loss for batch 17 = 0.6782373189926147\n",
      "Loss for batch 18 = 0.8559108376502991\n",
      "Loss for batch 19 = 0.6751242876052856\n",
      "Loss for batch 20 = 0.4595157504081726\n",
      "Loss for batch 21 = 0.6312885284423828\n",
      "Loss for batch 22 = 0.6412125825881958\n",
      "Loss for batch 23 = 0.6078284382820129\n",
      "Loss for batch 24 = 0.5045557618141174\n",
      "Loss for batch 25 = 0.5509744882583618\n",
      "Loss for batch 26 = 0.6919029951095581\n",
      "Loss for batch 27 = 0.5580074787139893\n",
      "Loss for batch 28 = 0.6155579090118408\n",
      "Loss for batch 29 = 0.7490848898887634\n",
      "Loss for batch 30 = 0.6373433470726013\n",
      "Loss for batch 31 = 0.37517860531806946\n",
      "Loss for batch 32 = 0.691386878490448\n",
      "Loss for batch 33 = 0.5631383061408997\n",
      "Loss for batch 34 = 0.7369502782821655\n",
      "Loss for batch 35 = 0.52027827501297\n",
      "Loss for batch 36 = 0.6419059038162231\n",
      "Loss for batch 37 = 0.695218563079834\n",
      "Loss for batch 38 = 0.6453354954719543\n",
      "Loss for batch 39 = 0.7038269639015198\n",
      "Loss for batch 40 = 0.5508005619049072\n",
      "Loss for batch 41 = 0.7168429493904114\n",
      "Loss for batch 42 = 0.4868773818016052\n",
      "Loss for batch 43 = 0.49822404980659485\n",
      "Loss for batch 44 = 0.5452430248260498\n",
      "Loss for batch 45 = 0.5757842659950256\n",
      "Loss for batch 46 = 0.5472477078437805\n",
      "Loss for batch 47 = 0.48886245489120483\n",
      "Loss for batch 48 = 0.6840105056762695\n",
      "Loss for batch 49 = 0.5413161516189575\n",
      "Loss for batch 50 = 0.6322513222694397\n",
      "Loss for batch 51 = 0.6834120750427246\n",
      "Loss for batch 52 = 0.5503791570663452\n",
      "Loss for batch 53 = 0.6326923370361328\n",
      "Loss for batch 54 = 0.4084230959415436\n",
      "Loss for batch 55 = 0.8251011967658997\n",
      "Loss for batch 56 = 0.7740733027458191\n",
      "Loss for batch 57 = 0.7581300139427185\n",
      "Loss for batch 58 = 0.3697437345981598\n",
      "Loss for batch 59 = 0.8073946237564087\n",
      "Loss for batch 60 = 0.5740069150924683\n",
      "Loss for batch 61 = 0.7166491150856018\n",
      "Loss for batch 62 = 0.3896026015281677\n",
      "Loss for batch 63 = 0.5005797743797302\n",
      "Loss for batch 64 = 0.4928745627403259\n",
      "Loss for batch 65 = 0.7058536410331726\n",
      "Loss for batch 66 = 0.5666304230690002\n",
      "Loss for batch 67 = 0.5061953067779541\n",
      "Loss for batch 68 = 0.47289344668388367\n",
      "Loss for batch 69 = 0.9015337824821472\n",
      "Loss for batch 70 = 0.7489811182022095\n",
      "Loss for batch 71 = 0.36587706208229065\n",
      "Loss for batch 72 = 0.6251413226127625\n",
      "Loss for batch 73 = 0.5105683207511902\n",
      "Loss for batch 74 = 0.6409960985183716\n",
      "Loss for batch 75 = 0.4992958903312683\n",
      "Loss for batch 76 = 0.7635719180107117\n",
      "Loss for batch 77 = 0.44781598448753357\n",
      "Loss for batch 78 = 0.7867153286933899\n",
      "Loss for batch 79 = 0.8103741407394409\n",
      "Loss for batch 80 = 0.5845381617546082\n",
      "Loss for batch 81 = 0.6058181524276733\n",
      "Loss for batch 82 = 0.4742486774921417\n",
      "Loss for batch 83 = 0.33207184076309204\n",
      "Loss for batch 84 = 0.4599691927433014\n",
      "Loss for batch 85 = 0.6310675144195557\n",
      "Loss for batch 86 = 0.7548093199729919\n",
      "Loss for batch 87 = 0.554043173789978\n",
      "Loss for batch 88 = 0.40924060344696045\n",
      "Loss for batch 89 = 0.39393350481987\n",
      "Loss for batch 90 = 0.3931081295013428\n",
      "Loss for batch 91 = 0.5180448293685913\n",
      "Loss for batch 92 = 0.5079159140586853\n",
      "Loss for batch 93 = 0.8027859926223755\n",
      "Loss for batch 94 = 0.4984387755393982\n",
      "Loss for batch 95 = 0.46166670322418213\n",
      "Loss for batch 96 = 0.3694525957107544\n",
      "Loss for batch 97 = 0.31877872347831726\n",
      "\n",
      "Training Loss for epoch 17 = 59.93217849731445\n",
      "\n",
      "Current Validation Loss = 26.05420684814453\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 11\n",
      "Train Accuracy: 72.50%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 18\n",
      "----------\n",
      "Loss for batch 0 = 0.6154283881187439\n",
      "Loss for batch 1 = 0.7069792747497559\n",
      "Loss for batch 2 = 0.6735946536064148\n",
      "Loss for batch 3 = 0.592796266078949\n",
      "Loss for batch 4 = 0.5258829593658447\n",
      "Loss for batch 5 = 0.7714051008224487\n",
      "Loss for batch 6 = 0.7603830695152283\n",
      "Loss for batch 7 = 0.8918147683143616\n",
      "Loss for batch 8 = 0.588808000087738\n",
      "Loss for batch 9 = 0.7322835326194763\n",
      "Loss for batch 10 = 1.1748907566070557\n",
      "Loss for batch 11 = 0.5950621962547302\n",
      "Loss for batch 12 = 0.8270146250724792\n",
      "Loss for batch 13 = 0.893493115901947\n",
      "Loss for batch 14 = 0.49540379643440247\n",
      "Loss for batch 15 = 0.5817825794219971\n",
      "Loss for batch 16 = 0.5959318280220032\n",
      "Loss for batch 17 = 0.6414147019386292\n",
      "Loss for batch 18 = 0.8346677422523499\n",
      "Loss for batch 19 = 0.6584474444389343\n",
      "Loss for batch 20 = 0.4378798305988312\n",
      "Loss for batch 21 = 0.6308286190032959\n",
      "Loss for batch 22 = 0.6144102215766907\n",
      "Loss for batch 23 = 0.5702998042106628\n",
      "Loss for batch 24 = 0.482102632522583\n",
      "Loss for batch 25 = 0.533141553401947\n",
      "Loss for batch 26 = 0.6685768961906433\n",
      "Loss for batch 27 = 0.5409037470817566\n",
      "Loss for batch 28 = 0.5889820456504822\n",
      "Loss for batch 29 = 0.7531814575195312\n",
      "Loss for batch 30 = 0.6078771948814392\n",
      "Loss for batch 31 = 0.3579782247543335\n",
      "Loss for batch 32 = 0.6538008451461792\n",
      "Loss for batch 33 = 0.5343663692474365\n",
      "Loss for batch 34 = 0.7118854522705078\n",
      "Loss for batch 35 = 0.5210059881210327\n",
      "Loss for batch 36 = 0.6323999166488647\n",
      "Loss for batch 37 = 0.7098000645637512\n",
      "Loss for batch 38 = 0.616598904132843\n",
      "Loss for batch 39 = 0.7033257484436035\n",
      "Loss for batch 40 = 0.5431236624717712\n",
      "Loss for batch 41 = 0.6624754667282104\n",
      "Loss for batch 42 = 0.469373881816864\n",
      "Loss for batch 43 = 0.49602118134498596\n",
      "Loss for batch 44 = 0.5496657490730286\n",
      "Loss for batch 45 = 0.5689324140548706\n",
      "Loss for batch 46 = 0.5454994440078735\n",
      "Loss for batch 47 = 0.45525237917900085\n",
      "Loss for batch 48 = 0.670612096786499\n",
      "Loss for batch 49 = 0.5288441777229309\n",
      "Loss for batch 50 = 0.5829651951789856\n",
      "Loss for batch 51 = 0.6704283356666565\n",
      "Loss for batch 52 = 0.5406265258789062\n",
      "Loss for batch 53 = 0.6445428133010864\n",
      "Loss for batch 54 = 0.42154866456985474\n",
      "Loss for batch 55 = 0.684859573841095\n",
      "Loss for batch 56 = 0.7958826422691345\n",
      "Loss for batch 57 = 0.7550618052482605\n",
      "Loss for batch 58 = 0.3552827835083008\n",
      "Loss for batch 59 = 0.7534229755401611\n",
      "Loss for batch 60 = 0.5236835479736328\n",
      "Loss for batch 61 = 0.716450035572052\n",
      "Loss for batch 62 = 0.3728335201740265\n",
      "Loss for batch 63 = 0.49600592255592346\n",
      "Loss for batch 64 = 0.460775226354599\n",
      "Loss for batch 65 = 0.6491725444793701\n",
      "Loss for batch 66 = 0.5431698560714722\n",
      "Loss for batch 67 = 0.4913383722305298\n",
      "Loss for batch 68 = 0.46012061834335327\n",
      "Loss for batch 69 = 0.8618021011352539\n",
      "Loss for batch 70 = 0.7252697348594666\n",
      "Loss for batch 71 = 0.34648287296295166\n",
      "Loss for batch 72 = 0.6211978793144226\n",
      "Loss for batch 73 = 0.497506707906723\n",
      "Loss for batch 74 = 0.632804811000824\n",
      "Loss for batch 75 = 0.4843178987503052\n",
      "Loss for batch 76 = 0.7768129706382751\n",
      "Loss for batch 77 = 0.4349105954170227\n",
      "Loss for batch 78 = 0.7675459384918213\n",
      "Loss for batch 79 = 0.7918428778648376\n",
      "Loss for batch 80 = 0.5630762577056885\n",
      "Loss for batch 81 = 0.5775928497314453\n",
      "Loss for batch 82 = 0.4649476408958435\n",
      "Loss for batch 83 = 0.300929456949234\n",
      "Loss for batch 84 = 0.4761802852153778\n",
      "Loss for batch 85 = 0.6241077184677124\n",
      "Loss for batch 86 = 0.7425485849380493\n",
      "Loss for batch 87 = 0.5466503500938416\n",
      "Loss for batch 88 = 0.40223321318626404\n",
      "Loss for batch 89 = 0.367817223072052\n",
      "Loss for batch 90 = 0.38528719544410706\n",
      "Loss for batch 91 = 0.5026748180389404\n",
      "Loss for batch 92 = 0.4856085777282715\n",
      "Loss for batch 93 = 0.8044610023498535\n",
      "Loss for batch 94 = 0.5067122578620911\n",
      "Loss for batch 95 = 0.4546682834625244\n",
      "Loss for batch 96 = 0.3540192246437073\n",
      "Loss for batch 97 = 0.27453336119651794\n",
      "\n",
      "Training Loss for epoch 18 = 58.20934295654297\n",
      "\n",
      "Current Validation Loss = 26.57417869567871\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 12\n",
      "Train Accuracy: 73.23%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 19\n",
      "----------\n",
      "Loss for batch 0 = 0.5698782801628113\n",
      "Loss for batch 1 = 0.6717900633811951\n",
      "Loss for batch 2 = 0.6362530589103699\n",
      "Loss for batch 3 = 0.5926897525787354\n",
      "Loss for batch 4 = 0.4802209436893463\n",
      "Loss for batch 5 = 0.8009166717529297\n",
      "Loss for batch 6 = 0.7157226800918579\n",
      "Loss for batch 7 = 0.8396404385566711\n",
      "Loss for batch 8 = 0.5463117361068726\n",
      "Loss for batch 9 = 0.7227920293807983\n",
      "Loss for batch 10 = 1.1674913167953491\n",
      "Loss for batch 11 = 0.5793392062187195\n",
      "Loss for batch 12 = 0.8174237012863159\n",
      "Loss for batch 13 = 0.9892598390579224\n",
      "Loss for batch 14 = 0.45369476079940796\n",
      "Loss for batch 15 = 0.5915825366973877\n",
      "Loss for batch 16 = 0.5893886089324951\n",
      "Loss for batch 17 = 0.6328430771827698\n",
      "Loss for batch 18 = 0.8217788338661194\n",
      "Loss for batch 19 = 0.6840922832489014\n",
      "Loss for batch 20 = 0.4418830871582031\n",
      "Loss for batch 21 = 0.6413856148719788\n",
      "Loss for batch 22 = 0.6004732251167297\n",
      "Loss for batch 23 = 0.5616413354873657\n",
      "Loss for batch 24 = 0.506458580493927\n",
      "Loss for batch 25 = 0.5316608548164368\n",
      "Loss for batch 26 = 0.6379426121711731\n",
      "Loss for batch 27 = 0.5557655096054077\n",
      "Loss for batch 28 = 0.570106029510498\n",
      "Loss for batch 29 = 0.7574136853218079\n",
      "Loss for batch 30 = 0.6201035380363464\n",
      "Loss for batch 31 = 0.3422096371650696\n",
      "Loss for batch 32 = 0.6418159604072571\n",
      "Loss for batch 33 = 0.5230556130409241\n",
      "Loss for batch 34 = 0.6938337087631226\n",
      "Loss for batch 35 = 0.5297601819038391\n",
      "Loss for batch 36 = 0.6019474864006042\n",
      "Loss for batch 37 = 0.6704846620559692\n",
      "Loss for batch 38 = 0.6086907386779785\n",
      "Loss for batch 39 = 0.6723803281784058\n",
      "Loss for batch 40 = 0.5872018933296204\n",
      "Loss for batch 41 = 0.6328005194664001\n",
      "Loss for batch 42 = 0.47386452555656433\n",
      "Loss for batch 43 = 0.5056630969047546\n",
      "Loss for batch 44 = 0.5571552515029907\n",
      "Loss for batch 45 = 0.5531291961669922\n",
      "Loss for batch 46 = 0.5136198997497559\n",
      "Loss for batch 47 = 0.4472368359565735\n",
      "Loss for batch 48 = 0.6959604620933533\n",
      "Loss for batch 49 = 0.5190153121948242\n",
      "Loss for batch 50 = 0.5692617297172546\n",
      "Loss for batch 51 = 0.5982494354248047\n",
      "Loss for batch 52 = 0.5081683397293091\n",
      "Loss for batch 53 = 0.6377599239349365\n",
      "Loss for batch 54 = 0.38402146100997925\n",
      "Loss for batch 55 = 0.6588524580001831\n",
      "Loss for batch 56 = 0.7559379935264587\n",
      "Loss for batch 57 = 0.738018810749054\n",
      "Loss for batch 58 = 0.35226014256477356\n",
      "Loss for batch 59 = 0.7737430334091187\n",
      "Loss for batch 60 = 0.529167652130127\n",
      "Loss for batch 61 = 0.6965001225471497\n",
      "Loss for batch 62 = 0.3753032684326172\n",
      "Loss for batch 63 = 0.4885617792606354\n",
      "Loss for batch 64 = 0.5043291449546814\n",
      "Loss for batch 65 = 0.6292593479156494\n",
      "Loss for batch 66 = 0.546175479888916\n",
      "Loss for batch 67 = 0.4703077971935272\n",
      "Loss for batch 68 = 0.4579108655452728\n",
      "Loss for batch 69 = 0.8182087540626526\n",
      "Loss for batch 70 = 0.7305272221565247\n",
      "Loss for batch 71 = 0.31666526198387146\n",
      "Loss for batch 72 = 0.6225672364234924\n",
      "Loss for batch 73 = 0.5019728541374207\n",
      "Loss for batch 74 = 0.6259742379188538\n",
      "Loss for batch 75 = 0.46534013748168945\n",
      "Loss for batch 76 = 0.7692509293556213\n",
      "Loss for batch 77 = 0.4444896876811981\n",
      "Loss for batch 78 = 0.7462791800498962\n",
      "Loss for batch 79 = 0.75667804479599\n",
      "Loss for batch 80 = 0.5307666659355164\n",
      "Loss for batch 81 = 0.5728816986083984\n",
      "Loss for batch 82 = 0.4611283838748932\n",
      "Loss for batch 83 = 0.34272706508636475\n",
      "Loss for batch 84 = 0.4611378312110901\n",
      "Loss for batch 85 = 0.6168102025985718\n",
      "Loss for batch 86 = 0.7261072397232056\n",
      "Loss for batch 87 = 0.5299186706542969\n",
      "Loss for batch 88 = 0.39531221985816956\n",
      "Loss for batch 89 = 0.364971399307251\n",
      "Loss for batch 90 = 0.39642077684402466\n",
      "Loss for batch 91 = 0.5143523812294006\n",
      "Loss for batch 92 = 0.46717002987861633\n",
      "Loss for batch 93 = 0.7850829362869263\n",
      "Loss for batch 94 = 0.4819689989089966\n",
      "Loss for batch 95 = 0.4386339485645294\n",
      "Loss for batch 96 = 0.34229934215545654\n",
      "Loss for batch 97 = 0.24667644500732422\n",
      "\n",
      "Training Loss for epoch 19 = 57.2438850402832\n",
      "\n",
      "Current Validation Loss = 26.716480255126953\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 13\n",
      "Train Accuracy: 73.65%\n",
      "Validation Accuracy: 59.95%\n",
      "\n",
      "Epoch 20\n",
      "----------\n",
      "Loss for batch 0 = 0.552179217338562\n",
      "Loss for batch 1 = 0.674763560295105\n",
      "Loss for batch 2 = 0.662214994430542\n",
      "Loss for batch 3 = 0.5554342865943909\n",
      "Loss for batch 4 = 0.44543150067329407\n",
      "Loss for batch 5 = 0.7897196412086487\n",
      "Loss for batch 6 = 0.7804774641990662\n",
      "Loss for batch 7 = 0.8355076313018799\n",
      "Loss for batch 8 = 0.5283228754997253\n",
      "Loss for batch 9 = 0.6842877864837646\n",
      "Loss for batch 10 = 1.1300122737884521\n",
      "Loss for batch 11 = 0.5476734638214111\n",
      "Loss for batch 12 = 0.7782638669013977\n",
      "Loss for batch 13 = 1.0153268575668335\n",
      "Loss for batch 14 = 0.4243120849132538\n",
      "Loss for batch 15 = 0.6305456757545471\n",
      "Loss for batch 16 = 0.5684629082679749\n",
      "Loss for batch 17 = 0.636279821395874\n",
      "Loss for batch 18 = 0.8461503982543945\n",
      "Loss for batch 19 = 0.6510134339332581\n",
      "Loss for batch 20 = 0.5204134583473206\n",
      "Loss for batch 21 = 0.6450690627098083\n",
      "Loss for batch 22 = 0.6047329306602478\n",
      "Loss for batch 23 = 0.5843056440353394\n",
      "Loss for batch 24 = 0.4661298394203186\n",
      "Loss for batch 25 = 0.5414725542068481\n",
      "Loss for batch 26 = 0.5892906785011292\n",
      "Loss for batch 27 = 0.538016140460968\n",
      "Loss for batch 28 = 0.5646487474441528\n",
      "Loss for batch 29 = 0.7906631827354431\n",
      "Loss for batch 30 = 0.6130035519599915\n",
      "Loss for batch 31 = 0.3384415805339813\n",
      "Loss for batch 32 = 0.6296454071998596\n",
      "Loss for batch 33 = 0.5059101581573486\n",
      "Loss for batch 34 = 0.7041037678718567\n",
      "Loss for batch 35 = 0.5286830067634583\n",
      "Loss for batch 36 = 0.603095531463623\n",
      "Loss for batch 37 = 0.6773509979248047\n",
      "Loss for batch 38 = 0.6031882166862488\n",
      "Loss for batch 39 = 0.679582953453064\n",
      "Loss for batch 40 = 0.5250956416130066\n",
      "Loss for batch 41 = 0.6432778835296631\n",
      "Loss for batch 42 = 0.46168676018714905\n",
      "Loss for batch 43 = 0.5001941919326782\n",
      "Loss for batch 44 = 0.5406795144081116\n",
      "Loss for batch 45 = 0.5166636109352112\n",
      "Loss for batch 46 = 0.5311471819877625\n",
      "Loss for batch 47 = 0.4190753698348999\n",
      "Loss for batch 48 = 0.650458812713623\n",
      "Loss for batch 49 = 0.5014480948448181\n",
      "Loss for batch 50 = 0.580978274345398\n",
      "Loss for batch 51 = 0.5283008217811584\n",
      "Loss for batch 52 = 0.5020756721496582\n",
      "Loss for batch 53 = 0.6115222573280334\n",
      "Loss for batch 54 = 0.38471102714538574\n",
      "Loss for batch 55 = 0.6423258781433105\n",
      "Loss for batch 56 = 0.7240689992904663\n",
      "Loss for batch 57 = 0.7373775839805603\n",
      "Loss for batch 58 = 0.34624046087265015\n",
      "Loss for batch 59 = 0.7351282238960266\n",
      "Loss for batch 60 = 0.4781530499458313\n",
      "Loss for batch 61 = 0.6517599821090698\n",
      "Loss for batch 62 = 0.3596247434616089\n",
      "Loss for batch 63 = 0.5075055360794067\n",
      "Loss for batch 64 = 0.47848665714263916\n",
      "Loss for batch 65 = 0.6165570616722107\n",
      "Loss for batch 66 = 0.5618834495544434\n",
      "Loss for batch 67 = 0.4860047399997711\n",
      "Loss for batch 68 = 0.4526959955692291\n",
      "Loss for batch 69 = 0.8068684339523315\n",
      "Loss for batch 70 = 0.7077909708023071\n",
      "Loss for batch 71 = 0.31216129660606384\n",
      "Loss for batch 72 = 0.5803049802780151\n",
      "Loss for batch 73 = 0.4698353111743927\n",
      "Loss for batch 74 = 0.6286828517913818\n",
      "Loss for batch 75 = 0.47452762722969055\n",
      "Loss for batch 76 = 0.7261711955070496\n",
      "Loss for batch 77 = 0.4181607663631439\n",
      "Loss for batch 78 = 0.7271825671195984\n",
      "Loss for batch 79 = 0.7402693629264832\n",
      "Loss for batch 80 = 0.5346713662147522\n",
      "Loss for batch 81 = 0.5584437251091003\n",
      "Loss for batch 82 = 0.4476815462112427\n",
      "Loss for batch 83 = 0.29155316948890686\n",
      "Loss for batch 84 = 0.4577299952507019\n",
      "Loss for batch 85 = 0.613742470741272\n",
      "Loss for batch 86 = 0.7281343936920166\n",
      "Loss for batch 87 = 0.5392159819602966\n",
      "Loss for batch 88 = 0.36204636096954346\n",
      "Loss for batch 89 = 0.3782477378845215\n",
      "Loss for batch 90 = 0.34728187322616577\n",
      "Loss for batch 91 = 0.5410863161087036\n",
      "Loss for batch 92 = 0.4436536431312561\n",
      "Loss for batch 93 = 0.7902603149414062\n",
      "Loss for batch 94 = 0.46895426511764526\n",
      "Loss for batch 95 = 0.4399862289428711\n",
      "Loss for batch 96 = 0.36884087324142456\n",
      "Loss for batch 97 = 0.31230881810188293\n",
      "\n",
      "Training Loss for epoch 20 = 56.355045318603516\n",
      "\n",
      "Current Validation Loss = 26.87746810913086\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 14\n",
      "Train Accuracy: 76.03%\n",
      "Validation Accuracy: 58.66%\n",
      "\n",
      "Epoch 21\n",
      "----------\n",
      "Loss for batch 0 = 0.5105302929878235\n",
      "Loss for batch 1 = 0.594683825969696\n",
      "Loss for batch 2 = 0.671920657157898\n",
      "Loss for batch 3 = 0.4653709828853607\n",
      "Loss for batch 4 = 0.4594581425189972\n",
      "Loss for batch 5 = 0.8096076250076294\n",
      "Loss for batch 6 = 0.7226189970970154\n",
      "Loss for batch 7 = 0.8139087557792664\n",
      "Loss for batch 8 = 0.47971829771995544\n",
      "Loss for batch 9 = 0.674950122833252\n",
      "Loss for batch 10 = 1.241686224937439\n",
      "Loss for batch 11 = 0.5806698799133301\n",
      "Loss for batch 12 = 0.7383700609207153\n",
      "Loss for batch 13 = 0.8852826356887817\n",
      "Loss for batch 14 = 0.42142921686172485\n",
      "Loss for batch 15 = 0.6113273501396179\n",
      "Loss for batch 16 = 0.5767180919647217\n",
      "Loss for batch 17 = 0.629158079624176\n",
      "Loss for batch 18 = 0.8249440789222717\n",
      "Loss for batch 19 = 0.6794360280036926\n",
      "Loss for batch 20 = 0.426387757062912\n",
      "Loss for batch 21 = 0.6227872371673584\n",
      "Loss for batch 22 = 0.6343740224838257\n",
      "Loss for batch 23 = 0.5784638524055481\n",
      "Loss for batch 24 = 0.47236400842666626\n",
      "Loss for batch 25 = 0.588122546672821\n",
      "Loss for batch 26 = 0.6081288456916809\n",
      "Loss for batch 27 = 0.5077423453330994\n",
      "Loss for batch 28 = 0.609666645526886\n",
      "Loss for batch 29 = 0.7203323841094971\n",
      "Loss for batch 30 = 0.6225503087043762\n",
      "Loss for batch 31 = 0.32401034235954285\n",
      "Loss for batch 32 = 0.6367060542106628\n",
      "Loss for batch 33 = 0.5009418725967407\n",
      "Loss for batch 34 = 0.6542216539382935\n",
      "Loss for batch 35 = 0.5050981640815735\n",
      "Loss for batch 36 = 0.5894977450370789\n",
      "Loss for batch 37 = 0.680077075958252\n",
      "Loss for batch 38 = 0.6029815673828125\n",
      "Loss for batch 39 = 0.643491268157959\n",
      "Loss for batch 40 = 0.5437997579574585\n",
      "Loss for batch 41 = 0.6176012754440308\n",
      "Loss for batch 42 = 0.43718400597572327\n",
      "Loss for batch 43 = 0.492184579372406\n",
      "Loss for batch 44 = 0.5114954710006714\n",
      "Loss for batch 45 = 0.48032239079475403\n",
      "Loss for batch 46 = 0.4692600965499878\n",
      "Loss for batch 47 = 0.4243101179599762\n",
      "Loss for batch 48 = 0.6928117871284485\n",
      "Loss for batch 49 = 0.4872743785381317\n",
      "Loss for batch 50 = 0.5747964978218079\n",
      "Loss for batch 51 = 0.5251911282539368\n",
      "Loss for batch 52 = 0.4982215166091919\n",
      "Loss for batch 53 = 0.6198028326034546\n",
      "Loss for batch 54 = 0.39003780484199524\n",
      "Loss for batch 55 = 0.6681473255157471\n",
      "Loss for batch 56 = 0.7370192408561707\n",
      "Loss for batch 57 = 0.7263283729553223\n",
      "Loss for batch 58 = 0.36057135462760925\n",
      "Loss for batch 59 = 0.7441908717155457\n",
      "Loss for batch 60 = 0.48739734292030334\n",
      "Loss for batch 61 = 0.6394595503807068\n",
      "Loss for batch 62 = 0.35526400804519653\n",
      "Loss for batch 63 = 0.49749699234962463\n",
      "Loss for batch 64 = 0.4795129597187042\n",
      "Loss for batch 65 = 0.6219151020050049\n",
      "Loss for batch 66 = 0.5171325206756592\n",
      "Loss for batch 67 = 0.47343844175338745\n",
      "Loss for batch 68 = 0.46885430812835693\n",
      "Loss for batch 69 = 0.7981761693954468\n",
      "Loss for batch 70 = 0.7254091501235962\n",
      "Loss for batch 71 = 0.31300097703933716\n",
      "Loss for batch 72 = 0.6194524765014648\n",
      "Loss for batch 73 = 0.46082180738449097\n",
      "Loss for batch 74 = 0.6152333617210388\n",
      "Loss for batch 75 = 0.42435935139656067\n",
      "Loss for batch 76 = 0.761523425579071\n",
      "Loss for batch 77 = 0.4352889955043793\n",
      "Loss for batch 78 = 0.7203417420387268\n",
      "Loss for batch 79 = 0.6831008195877075\n",
      "Loss for batch 80 = 0.5747377872467041\n",
      "Loss for batch 81 = 0.5131544470787048\n",
      "Loss for batch 82 = 0.47903504967689514\n",
      "Loss for batch 83 = 0.2848404049873352\n",
      "Loss for batch 84 = 0.4445866346359253\n",
      "Loss for batch 85 = 0.5501764416694641\n",
      "Loss for batch 86 = 0.7011098265647888\n",
      "Loss for batch 87 = 0.5571134090423584\n",
      "Loss for batch 88 = 0.38732820749282837\n",
      "Loss for batch 89 = 0.34691405296325684\n",
      "Loss for batch 90 = 0.36688780784606934\n",
      "Loss for batch 91 = 0.46540960669517517\n",
      "Loss for batch 92 = 0.45354175567626953\n",
      "Loss for batch 93 = 0.7781814932823181\n",
      "Loss for batch 94 = 0.4832777976989746\n",
      "Loss for batch 95 = 0.44092291593551636\n",
      "Loss for batch 96 = 0.368545800447464\n",
      "Loss for batch 97 = 0.2680239975452423\n",
      "\n",
      "Training Loss for epoch 21 = 55.48124313354492\n",
      "\n",
      "Current Validation Loss = 27.133703231811523\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 15\n",
      "Train Accuracy: 73.91%\n",
      "Validation Accuracy: 59.69%\n",
      "\n",
      "Epoch 22\n",
      "----------\n",
      "Loss for batch 0 = 0.5635591149330139\n",
      "Loss for batch 1 = 0.6738666296005249\n",
      "Loss for batch 2 = 0.6963898539543152\n",
      "Loss for batch 3 = 0.4398728907108307\n",
      "Loss for batch 4 = 0.4630154073238373\n",
      "Loss for batch 5 = 0.7669103145599365\n",
      "Loss for batch 6 = 0.7218374609947205\n",
      "Loss for batch 7 = 0.8015904426574707\n",
      "Loss for batch 8 = 0.46094438433647156\n",
      "Loss for batch 9 = 0.7064487338066101\n",
      "Loss for batch 10 = 1.1500582695007324\n",
      "Loss for batch 11 = 0.5241329073905945\n",
      "Loss for batch 12 = 0.7380445003509521\n",
      "Loss for batch 13 = 0.8411312699317932\n",
      "Loss for batch 14 = 0.43948477506637573\n",
      "Loss for batch 15 = 0.54355788230896\n",
      "Loss for batch 16 = 0.5777108669281006\n",
      "Loss for batch 17 = 0.6242733597755432\n",
      "Loss for batch 18 = 0.719931960105896\n",
      "Loss for batch 19 = 0.6409472227096558\n",
      "Loss for batch 20 = 0.4368533492088318\n",
      "Loss for batch 21 = 0.5816177129745483\n",
      "Loss for batch 22 = 0.6643491983413696\n",
      "Loss for batch 23 = 0.5012038350105286\n",
      "Loss for batch 24 = 0.4731408357620239\n",
      "Loss for batch 25 = 0.4631098508834839\n",
      "Loss for batch 26 = 0.5681352019309998\n",
      "Loss for batch 27 = 0.5001706480979919\n",
      "Loss for batch 28 = 0.547751247882843\n",
      "Loss for batch 29 = 0.6926257610321045\n",
      "Loss for batch 30 = 0.6119716167449951\n",
      "Loss for batch 31 = 0.29046809673309326\n",
      "Loss for batch 32 = 0.6307075023651123\n",
      "Loss for batch 33 = 0.5058013200759888\n",
      "Loss for batch 34 = 0.5964376330375671\n",
      "Loss for batch 35 = 0.4894208014011383\n",
      "Loss for batch 36 = 0.5983483791351318\n",
      "Loss for batch 37 = 0.6140458583831787\n",
      "Loss for batch 38 = 0.5991379022598267\n",
      "Loss for batch 39 = 0.6564960479736328\n",
      "Loss for batch 40 = 0.5849224328994751\n",
      "Loss for batch 41 = 0.590214729309082\n",
      "Loss for batch 42 = 0.4464929699897766\n",
      "Loss for batch 43 = 0.48598209023475647\n",
      "Loss for batch 44 = 0.4578130841255188\n",
      "Loss for batch 45 = 0.4806296229362488\n",
      "Loss for batch 46 = 0.5034989714622498\n",
      "Loss for batch 47 = 0.39571091532707214\n",
      "Loss for batch 48 = 0.6572588682174683\n",
      "Loss for batch 49 = 0.47167932987213135\n",
      "Loss for batch 50 = 0.5327107906341553\n",
      "Loss for batch 51 = 0.5066203474998474\n",
      "Loss for batch 52 = 0.46899154782295227\n",
      "Loss for batch 53 = 0.6686608195304871\n",
      "Loss for batch 54 = 0.38629433512687683\n",
      "Loss for batch 55 = 0.6356498599052429\n",
      "Loss for batch 56 = 0.7862240076065063\n",
      "Loss for batch 57 = 0.6935930848121643\n",
      "Loss for batch 58 = 0.3499528169631958\n",
      "Loss for batch 59 = 0.6967083215713501\n",
      "Loss for batch 60 = 0.49799907207489014\n",
      "Loss for batch 61 = 0.6263154149055481\n",
      "Loss for batch 62 = 0.32302868366241455\n",
      "Loss for batch 63 = 0.4882555305957794\n",
      "Loss for batch 64 = 0.4663689136505127\n",
      "Loss for batch 65 = 0.6243212223052979\n",
      "Loss for batch 66 = 0.5024265050888062\n",
      "Loss for batch 67 = 0.4516977369785309\n",
      "Loss for batch 68 = 0.4485791325569153\n",
      "Loss for batch 69 = 0.7732816338539124\n",
      "Loss for batch 70 = 0.707049548625946\n",
      "Loss for batch 71 = 0.3023839592933655\n",
      "Loss for batch 72 = 0.5767697691917419\n",
      "Loss for batch 73 = 0.45311692357063293\n",
      "Loss for batch 74 = 0.5820808410644531\n",
      "Loss for batch 75 = 0.4352433979511261\n",
      "Loss for batch 76 = 0.8218415975570679\n",
      "Loss for batch 77 = 0.44345998764038086\n",
      "Loss for batch 78 = 0.739479660987854\n",
      "Loss for batch 79 = 0.6158013343811035\n",
      "Loss for batch 80 = 0.5282934904098511\n",
      "Loss for batch 81 = 0.5852505564689636\n",
      "Loss for batch 82 = 0.4561481177806854\n",
      "Loss for batch 83 = 0.2749377191066742\n",
      "Loss for batch 84 = 0.458780974149704\n",
      "Loss for batch 85 = 0.543401300907135\n",
      "Loss for batch 86 = 0.7522344589233398\n",
      "Loss for batch 87 = 0.567834734916687\n",
      "Loss for batch 88 = 0.3931734561920166\n",
      "Loss for batch 89 = 0.36122021079063416\n",
      "Loss for batch 90 = 0.36031192541122437\n",
      "Loss for batch 91 = 0.45442870259284973\n",
      "Loss for batch 92 = 0.45098021626472473\n",
      "Loss for batch 93 = 0.7984919548034668\n",
      "Loss for batch 94 = 0.5068631768226624\n",
      "Loss for batch 95 = 0.4408285319805145\n",
      "Loss for batch 96 = 0.29667264223098755\n",
      "Loss for batch 97 = 0.2287716418504715\n",
      "\n",
      "Training Loss for epoch 22 = 54.25322723388672\n",
      "\n",
      "Current Validation Loss = 26.81016731262207\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 16\n",
      "Train Accuracy: 76.57%\n",
      "Validation Accuracy: 60.72%\n",
      "\n",
      "Epoch 23\n",
      "----------\n",
      "Loss for batch 0 = 0.5452703833580017\n",
      "Loss for batch 1 = 0.5871052742004395\n",
      "Loss for batch 2 = 0.6529163718223572\n",
      "Loss for batch 3 = 0.4806215167045593\n",
      "Loss for batch 4 = 0.4596431851387024\n",
      "Loss for batch 5 = 0.7376288175582886\n",
      "Loss for batch 6 = 0.7317122220993042\n",
      "Loss for batch 7 = 0.7861815690994263\n",
      "Loss for batch 8 = 0.49608075618743896\n",
      "Loss for batch 9 = 0.6557043194770813\n",
      "Loss for batch 10 = 1.1601585149765015\n",
      "Loss for batch 11 = 0.5105080604553223\n",
      "Loss for batch 12 = 0.7269396185874939\n",
      "Loss for batch 13 = 0.7696382999420166\n",
      "Loss for batch 14 = 0.43930068612098694\n",
      "Loss for batch 15 = 0.5106585025787354\n",
      "Loss for batch 16 = 0.6133859157562256\n",
      "Loss for batch 17 = 0.6149736642837524\n",
      "Loss for batch 18 = 0.7766185402870178\n",
      "Loss for batch 19 = 0.6731677055358887\n",
      "Loss for batch 20 = 0.4313279092311859\n",
      "Loss for batch 21 = 0.5164575576782227\n",
      "Loss for batch 22 = 0.6574272513389587\n",
      "Loss for batch 23 = 0.5036645531654358\n",
      "Loss for batch 24 = 0.4704495072364807\n",
      "Loss for batch 25 = 0.5118898153305054\n",
      "Loss for batch 26 = 0.6380462050437927\n",
      "Loss for batch 27 = 0.4134620726108551\n",
      "Loss for batch 28 = 0.5076979398727417\n",
      "Loss for batch 29 = 0.6360915899276733\n",
      "Loss for batch 30 = 0.61054527759552\n",
      "Loss for batch 31 = 0.3199879825115204\n",
      "Loss for batch 32 = 0.6265950798988342\n",
      "Loss for batch 33 = 0.5078925490379333\n",
      "Loss for batch 34 = 0.5736737847328186\n",
      "Loss for batch 35 = 0.46121710538864136\n",
      "Loss for batch 36 = 0.5984076261520386\n",
      "Loss for batch 37 = 0.6365809440612793\n",
      "Loss for batch 38 = 0.5748065114021301\n",
      "Loss for batch 39 = 0.6177844405174255\n",
      "Loss for batch 40 = 0.5719618201255798\n",
      "Loss for batch 41 = 0.5853548645973206\n",
      "Loss for batch 42 = 0.4324396252632141\n",
      "Loss for batch 43 = 0.5133857727050781\n",
      "Loss for batch 44 = 0.3860476016998291\n",
      "Loss for batch 45 = 0.4625694155693054\n",
      "Loss for batch 46 = 0.45585593581199646\n",
      "Loss for batch 47 = 0.3534776270389557\n",
      "Loss for batch 48 = 0.637891411781311\n",
      "Loss for batch 49 = 0.46675243973731995\n",
      "Loss for batch 50 = 0.510806143283844\n",
      "Loss for batch 51 = 0.46977436542510986\n",
      "Loss for batch 52 = 0.45508405566215515\n",
      "Loss for batch 53 = 0.6331064701080322\n",
      "Loss for batch 54 = 0.36197054386138916\n",
      "Loss for batch 55 = 0.6380472183227539\n",
      "Loss for batch 56 = 0.7237147688865662\n",
      "Loss for batch 57 = 0.7044980525970459\n",
      "Loss for batch 58 = 0.3439313769340515\n",
      "Loss for batch 59 = 0.6745845079421997\n",
      "Loss for batch 60 = 0.46780040860176086\n",
      "Loss for batch 61 = 0.6173901557922363\n",
      "Loss for batch 62 = 0.3104010224342346\n",
      "Loss for batch 63 = 0.47876405715942383\n",
      "Loss for batch 64 = 0.44292566180229187\n",
      "Loss for batch 65 = 0.570561408996582\n",
      "Loss for batch 66 = 0.5230531692504883\n",
      "Loss for batch 67 = 0.46320101618766785\n",
      "Loss for batch 68 = 0.4323960840702057\n",
      "Loss for batch 69 = 0.764334499835968\n",
      "Loss for batch 70 = 0.7059508562088013\n",
      "Loss for batch 71 = 0.3134990930557251\n",
      "Loss for batch 72 = 0.5592137575149536\n",
      "Loss for batch 73 = 0.45889782905578613\n",
      "Loss for batch 74 = 0.5499247312545776\n",
      "Loss for batch 75 = 0.41321220993995667\n",
      "Loss for batch 76 = 0.6877329349517822\n",
      "Loss for batch 77 = 0.43515968322753906\n",
      "Loss for batch 78 = 0.7213230729103088\n",
      "Loss for batch 79 = 0.602103054523468\n",
      "Loss for batch 80 = 0.46516457200050354\n",
      "Loss for batch 81 = 0.531958281993866\n",
      "Loss for batch 82 = 0.45459693670272827\n",
      "Loss for batch 83 = 0.28844335675239563\n",
      "Loss for batch 84 = 0.4596717953681946\n",
      "Loss for batch 85 = 0.5278351306915283\n",
      "Loss for batch 86 = 0.7244592905044556\n",
      "Loss for batch 87 = 0.5003194808959961\n",
      "Loss for batch 88 = 0.3562939167022705\n",
      "Loss for batch 89 = 0.3349306583404541\n",
      "Loss for batch 90 = 0.3561817407608032\n",
      "Loss for batch 91 = 0.4942767918109894\n",
      "Loss for batch 92 = 0.44208717346191406\n",
      "Loss for batch 93 = 0.7642599940299988\n",
      "Loss for batch 94 = 0.4605906009674072\n",
      "Loss for batch 95 = 0.29573777318000793\n",
      "Loss for batch 96 = 0.3104180693626404\n",
      "Loss for batch 97 = 0.2247050404548645\n",
      "\n",
      "Training Loss for epoch 23 = 52.63325500488281\n",
      "\n",
      "Current Validation Loss = 27.4514102935791\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 17\n",
      "Train Accuracy: 77.60%\n",
      "Validation Accuracy: 60.08%\n",
      "\n",
      "Epoch 24\n",
      "----------\n",
      "Loss for batch 0 = 0.5019740462303162\n",
      "Loss for batch 1 = 0.5530436635017395\n",
      "Loss for batch 2 = 0.6474555730819702\n",
      "Loss for batch 3 = 0.42194414138793945\n",
      "Loss for batch 4 = 0.43541109561920166\n",
      "Loss for batch 5 = 0.727970540523529\n",
      "Loss for batch 6 = 0.7001630067825317\n",
      "Loss for batch 7 = 0.7409036159515381\n",
      "Loss for batch 8 = 0.4428291320800781\n",
      "Loss for batch 9 = 0.5923603773117065\n",
      "Loss for batch 10 = 1.214897871017456\n",
      "Loss for batch 11 = 0.5668269395828247\n",
      "Loss for batch 12 = 0.6780563592910767\n",
      "Loss for batch 13 = 0.7725351452827454\n",
      "Loss for batch 14 = 0.4073236584663391\n",
      "Loss for batch 15 = 0.5109487771987915\n",
      "Loss for batch 16 = 0.5665577054023743\n",
      "Loss for batch 17 = 0.5206477046012878\n",
      "Loss for batch 18 = 0.7091704607009888\n",
      "Loss for batch 19 = 0.6576401591300964\n",
      "Loss for batch 20 = 0.4240691661834717\n",
      "Loss for batch 21 = 0.5033487677574158\n",
      "Loss for batch 22 = 0.6021750569343567\n",
      "Loss for batch 23 = 0.5178801417350769\n",
      "Loss for batch 24 = 0.4522329568862915\n",
      "Loss for batch 25 = 0.47489824891090393\n",
      "Loss for batch 26 = 0.5732614398002625\n",
      "Loss for batch 27 = 0.42095470428466797\n",
      "Loss for batch 28 = 0.5117216110229492\n",
      "Loss for batch 29 = 0.6371542811393738\n",
      "Loss for batch 30 = 0.6295260190963745\n",
      "Loss for batch 31 = 0.30570295453071594\n",
      "Loss for batch 32 = 0.6336286664009094\n",
      "Loss for batch 33 = 0.4894722104072571\n",
      "Loss for batch 34 = 0.628503680229187\n",
      "Loss for batch 35 = 0.5078250765800476\n",
      "Loss for batch 36 = 0.5981646776199341\n",
      "Loss for batch 37 = 0.6059592962265015\n",
      "Loss for batch 38 = 0.5903075933456421\n",
      "Loss for batch 39 = 0.6133052110671997\n",
      "Loss for batch 40 = 0.5680224299430847\n",
      "Loss for batch 41 = 0.5718591213226318\n",
      "Loss for batch 42 = 0.4231322407722473\n",
      "Loss for batch 43 = 0.5187896490097046\n",
      "Loss for batch 44 = 0.38616085052490234\n",
      "Loss for batch 45 = 0.4471462368965149\n",
      "Loss for batch 46 = 0.4115224778652191\n",
      "Loss for batch 47 = 0.3809260427951813\n",
      "Loss for batch 48 = 0.6443735957145691\n",
      "Loss for batch 49 = 0.44771164655685425\n",
      "Loss for batch 50 = 0.48361387848854065\n",
      "Loss for batch 51 = 0.37187111377716064\n",
      "Loss for batch 52 = 0.44703909754753113\n",
      "Loss for batch 53 = 0.62359219789505\n",
      "Loss for batch 54 = 0.3605521321296692\n",
      "Loss for batch 55 = 0.5843561887741089\n",
      "Loss for batch 56 = 0.7042977213859558\n",
      "Loss for batch 57 = 0.72878497838974\n",
      "Loss for batch 58 = 0.3599156439304352\n",
      "Loss for batch 59 = 0.6051252484321594\n",
      "Loss for batch 60 = 0.42811667919158936\n",
      "Loss for batch 61 = 0.5978624820709229\n",
      "Loss for batch 62 = 0.307625949382782\n",
      "Loss for batch 63 = 0.4700866639614105\n",
      "Loss for batch 64 = 0.4451654255390167\n",
      "Loss for batch 65 = 0.5453474521636963\n",
      "Loss for batch 66 = 0.528924286365509\n",
      "Loss for batch 67 = 0.44918206334114075\n",
      "Loss for batch 68 = 0.41012275218963623\n",
      "Loss for batch 69 = 0.7463739514350891\n",
      "Loss for batch 70 = 0.6781911253929138\n",
      "Loss for batch 71 = 0.3280278444290161\n",
      "Loss for batch 72 = 0.5777211785316467\n",
      "Loss for batch 73 = 0.4188704788684845\n",
      "Loss for batch 74 = 0.5158844590187073\n",
      "Loss for batch 75 = 0.4059757888317108\n",
      "Loss for batch 76 = 0.7021437287330627\n",
      "Loss for batch 77 = 0.41155806183815\n",
      "Loss for batch 78 = 0.684912383556366\n",
      "Loss for batch 79 = 0.636838972568512\n",
      "Loss for batch 80 = 0.4063979685306549\n",
      "Loss for batch 81 = 0.4906657040119171\n",
      "Loss for batch 82 = 0.4583145081996918\n",
      "Loss for batch 83 = 0.2697887122631073\n",
      "Loss for batch 84 = 0.4740341305732727\n",
      "Loss for batch 85 = 0.5145876407623291\n",
      "Loss for batch 86 = 0.7093855738639832\n",
      "Loss for batch 87 = 0.5097474455833435\n",
      "Loss for batch 88 = 0.3738686740398407\n",
      "Loss for batch 89 = 0.3339938223361969\n",
      "Loss for batch 90 = 0.34652388095855713\n",
      "Loss for batch 91 = 0.4743717312812805\n",
      "Loss for batch 92 = 0.41293585300445557\n",
      "Loss for batch 93 = 0.7716835141181946\n",
      "Loss for batch 94 = 0.4215661585330963\n",
      "Loss for batch 95 = 0.27056846022605896\n",
      "Loss for batch 96 = 0.2751663625240326\n",
      "Loss for batch 97 = 0.19950588047504425\n",
      "\n",
      "Training Loss for epoch 24 = 51.159568786621094\n",
      "\n",
      "Current Validation Loss = 28.38364601135254\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 18\n",
      "Train Accuracy: 76.41%\n",
      "Validation Accuracy: 59.82%\n",
      "\n",
      "Epoch 25\n",
      "----------\n",
      "Loss for batch 0 = 0.5355238914489746\n",
      "Loss for batch 1 = 0.5801926851272583\n",
      "Loss for batch 2 = 0.6605148911476135\n",
      "Loss for batch 3 = 0.5271123647689819\n",
      "Loss for batch 4 = 0.5092442035675049\n",
      "Loss for batch 5 = 0.7908152937889099\n",
      "Loss for batch 6 = 0.8304541110992432\n",
      "Loss for batch 7 = 0.7080803513526917\n",
      "Loss for batch 8 = 0.45072945952415466\n",
      "Loss for batch 9 = 0.5807753205299377\n",
      "Loss for batch 10 = 1.1129037141799927\n",
      "Loss for batch 11 = 0.4645322859287262\n",
      "Loss for batch 12 = 0.7655845284461975\n",
      "Loss for batch 13 = 0.7491814494132996\n",
      "Loss for batch 14 = 0.40795472264289856\n",
      "Loss for batch 15 = 0.43904203176498413\n",
      "Loss for batch 16 = 0.6020708084106445\n",
      "Loss for batch 17 = 0.5446231365203857\n",
      "Loss for batch 18 = 0.6458513736724854\n",
      "Loss for batch 19 = 0.6338151693344116\n",
      "Loss for batch 20 = 0.35048118233680725\n",
      "Loss for batch 21 = 0.4744303822517395\n",
      "Loss for batch 22 = 0.6314431428909302\n",
      "Loss for batch 23 = 0.4123147130012512\n",
      "Loss for batch 24 = 0.4432540535926819\n",
      "Loss for batch 25 = 0.4548409879207611\n",
      "Loss for batch 26 = 0.5516194105148315\n",
      "Loss for batch 27 = 0.4386816620826721\n",
      "Loss for batch 28 = 0.5376245379447937\n",
      "Loss for batch 29 = 0.5365127921104431\n",
      "Loss for batch 30 = 0.6030097603797913\n",
      "Loss for batch 31 = 0.27498647570610046\n",
      "Loss for batch 32 = 0.5990527868270874\n",
      "Loss for batch 33 = 0.5164755582809448\n",
      "Loss for batch 34 = 0.5083619952201843\n",
      "Loss for batch 35 = 0.44395288825035095\n",
      "Loss for batch 36 = 0.5728738903999329\n",
      "Loss for batch 37 = 0.5833715796470642\n",
      "Loss for batch 38 = 0.539833664894104\n",
      "Loss for batch 39 = 0.5718729496002197\n",
      "Loss for batch 40 = 0.5217663645744324\n",
      "Loss for batch 41 = 0.5520099997520447\n",
      "Loss for batch 42 = 0.45376795530319214\n",
      "Loss for batch 43 = 0.48019105195999146\n",
      "Loss for batch 44 = 0.35747531056404114\n",
      "Loss for batch 45 = 0.4458567798137665\n",
      "Loss for batch 46 = 0.4199064075946808\n",
      "Loss for batch 47 = 0.3586984872817993\n",
      "Loss for batch 48 = 0.6419468522071838\n",
      "Loss for batch 49 = 0.43947985768318176\n",
      "Loss for batch 50 = 0.5110625624656677\n",
      "Loss for batch 51 = 0.41264423727989197\n",
      "Loss for batch 52 = 0.454461008310318\n",
      "Loss for batch 53 = 0.621519148349762\n",
      "Loss for batch 54 = 0.3597475290298462\n",
      "Loss for batch 55 = 0.596833348274231\n",
      "Loss for batch 56 = 0.6524048447608948\n",
      "Loss for batch 57 = 0.5951555967330933\n",
      "Loss for batch 58 = 0.3826618194580078\n",
      "Loss for batch 59 = 0.6170540452003479\n",
      "Loss for batch 60 = 0.45922407507896423\n",
      "Loss for batch 61 = 0.5243664979934692\n",
      "Loss for batch 62 = 0.28650158643722534\n",
      "Loss for batch 63 = 0.485933393239975\n",
      "Loss for batch 64 = 0.4204115569591522\n",
      "Loss for batch 65 = 0.541161060333252\n",
      "Loss for batch 66 = 0.5077589750289917\n",
      "Loss for batch 67 = 0.44966140389442444\n",
      "Loss for batch 68 = 0.39678940176963806\n",
      "Loss for batch 69 = 0.7186112999916077\n",
      "Loss for batch 70 = 0.6703146696090698\n",
      "Loss for batch 71 = 0.32564684748649597\n",
      "Loss for batch 72 = 0.5283442139625549\n",
      "Loss for batch 73 = 0.43060678243637085\n",
      "Loss for batch 74 = 0.4863480031490326\n",
      "Loss for batch 75 = 0.37214916944503784\n",
      "Loss for batch 76 = 0.660493791103363\n",
      "Loss for batch 77 = 0.3928002119064331\n",
      "Loss for batch 78 = 0.6646246910095215\n",
      "Loss for batch 79 = 0.5641658306121826\n",
      "Loss for batch 80 = 0.3847125172615051\n",
      "Loss for batch 81 = 0.48002946376800537\n",
      "Loss for batch 82 = 0.4629332423210144\n",
      "Loss for batch 83 = 0.2433008998632431\n",
      "Loss for batch 84 = 0.4417290985584259\n",
      "Loss for batch 85 = 0.507955014705658\n",
      "Loss for batch 86 = 0.7297898530960083\n",
      "Loss for batch 87 = 0.48840025067329407\n",
      "Loss for batch 88 = 0.3060484826564789\n",
      "Loss for batch 89 = 0.29966700077056885\n",
      "Loss for batch 90 = 0.3483680188655853\n",
      "Loss for batch 91 = 0.488922119140625\n",
      "Loss for batch 92 = 0.39627495408058167\n",
      "Loss for batch 93 = 0.7451963424682617\n",
      "Loss for batch 94 = 0.44406741857528687\n",
      "Loss for batch 95 = 0.2631538212299347\n",
      "Loss for batch 96 = 0.2645648419857025\n",
      "Loss for batch 97 = 0.20037733018398285\n",
      "\n",
      "Training Loss for epoch 25 = 49.84004592895508\n",
      "\n",
      "Current Validation Loss = 28.168930053710938\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 19\n",
      "Train Accuracy: 78.05%\n",
      "Validation Accuracy: 59.95%\n",
      "\n",
      "Epoch 26\n",
      "----------\n",
      "Loss for batch 0 = 0.5498532056808472\n",
      "Loss for batch 1 = 0.5212364792823792\n",
      "Loss for batch 2 = 0.6498093008995056\n",
      "Loss for batch 3 = 0.4399760663509369\n",
      "Loss for batch 4 = 0.47870221734046936\n",
      "Loss for batch 5 = 0.7650731205940247\n",
      "Loss for batch 6 = 0.8005679249763489\n",
      "Loss for batch 7 = 0.6706963777542114\n",
      "Loss for batch 8 = 0.39667633175849915\n",
      "Loss for batch 9 = 0.571117639541626\n",
      "Loss for batch 10 = 1.1146481037139893\n",
      "Loss for batch 11 = 0.46702447533607483\n",
      "Loss for batch 12 = 0.6901282072067261\n",
      "Loss for batch 13 = 0.7398838400840759\n",
      "Loss for batch 14 = 0.3983217775821686\n",
      "Loss for batch 15 = 0.4302076995372772\n",
      "Loss for batch 16 = 0.6007483005523682\n",
      "Loss for batch 17 = 0.5003076791763306\n",
      "Loss for batch 18 = 0.6917133331298828\n",
      "Loss for batch 19 = 0.6310263872146606\n",
      "Loss for batch 20 = 0.3388022780418396\n",
      "Loss for batch 21 = 0.5282620191574097\n",
      "Loss for batch 22 = 0.645783007144928\n",
      "Loss for batch 23 = 0.3947259783744812\n",
      "Loss for batch 24 = 0.42181140184402466\n",
      "Loss for batch 25 = 0.43540215492248535\n",
      "Loss for batch 26 = 0.4789862632751465\n",
      "Loss for batch 27 = 0.3900023102760315\n",
      "Loss for batch 28 = 0.5499792098999023\n",
      "Loss for batch 29 = 0.5456359386444092\n",
      "Loss for batch 30 = 0.6005635261535645\n",
      "Loss for batch 31 = 0.26510995626449585\n",
      "Loss for batch 32 = 0.6042251586914062\n",
      "Loss for batch 33 = 0.49867957830429077\n",
      "Loss for batch 34 = 0.5176247358322144\n",
      "Loss for batch 35 = 0.43490877747535706\n",
      "Loss for batch 36 = 0.5563609004020691\n",
      "Loss for batch 37 = 0.5857784748077393\n",
      "Loss for batch 38 = 0.5594950914382935\n",
      "Loss for batch 39 = 0.5690203309059143\n",
      "Loss for batch 40 = 0.5134974122047424\n",
      "Loss for batch 41 = 0.5463380813598633\n",
      "Loss for batch 42 = 0.46500587463378906\n",
      "Loss for batch 43 = 0.497083455324173\n",
      "Loss for batch 44 = 0.35501083731651306\n",
      "Loss for batch 45 = 0.43060243129730225\n",
      "Loss for batch 46 = 0.41650262475013733\n",
      "Loss for batch 47 = 0.3552643954753876\n",
      "Loss for batch 48 = 0.6326940059661865\n",
      "Loss for batch 49 = 0.4327501058578491\n",
      "Loss for batch 50 = 0.5081726312637329\n",
      "Loss for batch 51 = 0.3839527368545532\n",
      "Loss for batch 52 = 0.443094938993454\n",
      "Loss for batch 53 = 0.6253366470336914\n",
      "Loss for batch 54 = 0.34640368819236755\n",
      "Loss for batch 55 = 0.5731615424156189\n",
      "Loss for batch 56 = 0.6232209205627441\n",
      "Loss for batch 57 = 0.5500444769859314\n",
      "Loss for batch 58 = 0.34475815296173096\n",
      "Loss for batch 59 = 0.6084681749343872\n",
      "Loss for batch 60 = 0.44915154576301575\n",
      "Loss for batch 61 = 0.5057103633880615\n",
      "Loss for batch 62 = 0.279162734746933\n",
      "Loss for batch 63 = 0.46549931168556213\n",
      "Loss for batch 64 = 0.3946923613548279\n",
      "Loss for batch 65 = 0.5315157175064087\n",
      "Loss for batch 66 = 0.5062174797058105\n",
      "Loss for batch 67 = 0.44355282187461853\n",
      "Loss for batch 68 = 0.326040118932724\n",
      "Loss for batch 69 = 0.7006140947341919\n",
      "Loss for batch 70 = 0.646953284740448\n",
      "Loss for batch 71 = 0.2921876013278961\n",
      "Loss for batch 72 = 0.5267478227615356\n",
      "Loss for batch 73 = 0.4135555624961853\n",
      "Loss for batch 74 = 0.4885791838169098\n",
      "Loss for batch 75 = 0.35907602310180664\n",
      "Loss for batch 76 = 0.6747312545776367\n",
      "Loss for batch 77 = 0.37462323904037476\n",
      "Loss for batch 78 = 0.6706340909004211\n",
      "Loss for batch 79 = 0.5233026742935181\n",
      "Loss for batch 80 = 0.42121997475624084\n",
      "Loss for batch 81 = 0.514651358127594\n",
      "Loss for batch 82 = 0.4555422365665436\n",
      "Loss for batch 83 = 0.22704878449440002\n",
      "Loss for batch 84 = 0.39765307307243347\n",
      "Loss for batch 85 = 0.5016778111457825\n",
      "Loss for batch 86 = 0.7203658223152161\n",
      "Loss for batch 87 = 0.48523858189582825\n",
      "Loss for batch 88 = 0.29264000058174133\n",
      "Loss for batch 89 = 0.311209112405777\n",
      "Loss for batch 90 = 0.34703099727630615\n",
      "Loss for batch 91 = 0.47866058349609375\n",
      "Loss for batch 92 = 0.40743234753608704\n",
      "Loss for batch 93 = 0.7137005925178528\n",
      "Loss for batch 94 = 0.5063729882240295\n",
      "Loss for batch 95 = 0.2548116445541382\n",
      "Loss for batch 96 = 0.286516934633255\n",
      "Loss for batch 97 = 0.20095586776733398\n",
      "\n",
      "Training Loss for epoch 26 = 48.77552032470703\n",
      "\n",
      "Current Validation Loss = 28.590028762817383\n",
      "Best Validation Loss = 23.344860076904297\n",
      "Epochs without Improvement = 20\n",
      "Train Accuracy: 77.89%\n",
      "Validation Accuracy: 58.66%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_modelv6 = LSTMmodel(4, 25, 256, bidirectionality=True, freeze=False)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.NAdam(text_modelv6.parameters(), 0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 0.4, 8)\n",
    "TrainLoopText(text_modelv6, optimizer, loss_fn, train_loader, val_loader, scheduler, 100, 20, device='cuda', return_best_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.91%\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "with torch.inference_mode():\n",
    "    for batch in test_loader:\n",
    "        texts = batch['text_indices'].to('cuda')\n",
    "        labels = batch['label']\n",
    "        outputs = text_modelv6(texts)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "model_accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print(f'Accuracy: {model_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2441a09ed10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
